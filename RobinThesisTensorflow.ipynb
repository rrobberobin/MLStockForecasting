{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# print(\"Num GPUs Available: \", len(physical_devices))\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras #I think this package produces a discrepency between val_loss and val_metric (where both are MAE)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.metrics\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#data_file_path = os.path.join(os.path.dirname(__file__), \"YX.csv\")\n",
    "data_file_path = os.path.join(os.getcwd(), \"Data\\YX.csv\")\n",
    "#data_file_path = os.path.join(os.getcwd(), \"Compustat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>fdateYQ</th>\n",
       "      <th>returns</th>\n",
       "      <th>volatility</th>\n",
       "      <th>MktCap</th>\n",
       "      <th>Split</th>\n",
       "      <th>TimeDifferenceInDays</th>\n",
       "      <th>loc</th>\n",
       "      <th>city</th>\n",
       "      <th>acctstdq</th>\n",
       "      <th>...</th>\n",
       "      <th>2Classes</th>\n",
       "      <th>4Classes</th>\n",
       "      <th>6Classes</th>\n",
       "      <th>8Classes</th>\n",
       "      <th>10Classes</th>\n",
       "      <th>Simple2Classes</th>\n",
       "      <th>Simple4Classes</th>\n",
       "      <th>Simple6Classes</th>\n",
       "      <th>Simple8Classes</th>\n",
       "      <th>Simple10Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1166</td>\n",
       "      <td>2010.25</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.06e+09</td>\n",
       "      <td>Train</td>\n",
       "      <td>33</td>\n",
       "      <td>NLD</td>\n",
       "      <td>Almere</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1166</td>\n",
       "      <td>2010.50</td>\n",
       "      <td>-9.88</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.08e+09</td>\n",
       "      <td>Train</td>\n",
       "      <td>69</td>\n",
       "      <td>NLD</td>\n",
       "      <td>Almere</td>\n",
       "      <td>DI</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1166</td>\n",
       "      <td>2010.75</td>\n",
       "      <td>52.04</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.77e+08</td>\n",
       "      <td>Train</td>\n",
       "      <td>36</td>\n",
       "      <td>NLD</td>\n",
       "      <td>Almere</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1166</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>7.98</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.49e+09</td>\n",
       "      <td>Train</td>\n",
       "      <td>89</td>\n",
       "      <td>NLD</td>\n",
       "      <td>Almere</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1166</td>\n",
       "      <td>2011.50</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.09e+09</td>\n",
       "      <td>Train</td>\n",
       "      <td>42</td>\n",
       "      <td>NLD</td>\n",
       "      <td>Almere</td>\n",
       "      <td>DI</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57838</th>\n",
       "      <td>339371</td>\n",
       "      <td>2022.25</td>\n",
       "      <td>-18.66</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.15e+09</td>\n",
       "      <td>Test</td>\n",
       "      <td>67</td>\n",
       "      <td>TWN</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>DI</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57839</th>\n",
       "      <td>339371</td>\n",
       "      <td>2022.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.75e+09</td>\n",
       "      <td>Test</td>\n",
       "      <td>67</td>\n",
       "      <td>TWN</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>DI</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57840</th>\n",
       "      <td>339372</td>\n",
       "      <td>2022.50</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.94e+09</td>\n",
       "      <td>Test</td>\n",
       "      <td>55</td>\n",
       "      <td>TWN</td>\n",
       "      <td>New Taipei City</td>\n",
       "      <td>DI</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57841</th>\n",
       "      <td>341329</td>\n",
       "      <td>2022.50</td>\n",
       "      <td>29.78</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.33e+08</td>\n",
       "      <td>Test</td>\n",
       "      <td>82</td>\n",
       "      <td>TWN</td>\n",
       "      <td>Taichung</td>\n",
       "      <td>DI</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57842</th>\n",
       "      <td>341563</td>\n",
       "      <td>2022.50</td>\n",
       "      <td>36.52</td>\n",
       "      <td>0.59</td>\n",
       "      <td>3.03e+08</td>\n",
       "      <td>Test</td>\n",
       "      <td>82</td>\n",
       "      <td>TUR</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>DI</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57843 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gvkey  fdateYQ  returns  volatility    MktCap  Split  \\\n",
       "0        1166  2010.25     2.15        0.48  1.06e+09  Train   \n",
       "1        1166  2010.50    -9.88        0.26  1.08e+09  Train   \n",
       "2        1166  2010.75    52.04        0.38  9.77e+08  Train   \n",
       "3        1166  2011.00     7.98        0.37  1.49e+09  Train   \n",
       "4        1166  2011.50    -1.52        0.55  1.09e+09  Train   \n",
       "...       ...      ...      ...         ...       ...    ...   \n",
       "57838  339371  2022.25   -18.66        0.37  2.15e+09   Test   \n",
       "57839  339371  2022.50     3.00        0.15  1.75e+09   Test   \n",
       "57840  339372  2022.50    -1.54        0.19  1.94e+09   Test   \n",
       "57841  341329  2022.50    29.78        0.59  8.33e+08   Test   \n",
       "57842  341563  2022.50    36.52        0.59  3.03e+08   Test   \n",
       "\n",
       "       TimeDifferenceInDays  loc             city acctstdq  ... 2Classes  \\\n",
       "0                        33  NLD           Almere       US  ...        2   \n",
       "1                        69  NLD           Almere       DI  ...        1   \n",
       "2                        36  NLD           Almere       US  ...        2   \n",
       "3                        89  NLD           Almere       US  ...        2   \n",
       "4                        42  NLD           Almere       DI  ...        2   \n",
       "...                     ...  ...              ...      ...  ...      ...   \n",
       "57838                    67  TWN           Taipei       DI  ...        1   \n",
       "57839                    67  TWN           Taipei       DI  ...        2   \n",
       "57840                    55  TWN  New Taipei City       DI  ...        1   \n",
       "57841                    82  TWN         Taichung       DI  ...        2   \n",
       "57842                    82  TUR         Istanbul       DI  ...        2   \n",
       "\n",
       "       4Classes  6Classes  8Classes  10Classes  Simple2Classes  \\\n",
       "0             3         4         5          6               1   \n",
       "1             1         1         2          2               0   \n",
       "2             4         6         8         10               1   \n",
       "3             3         4         5          6               1   \n",
       "4             4         6         7          9               1   \n",
       "...         ...       ...       ...        ...             ...   \n",
       "57838         1         1         1          2               0   \n",
       "57839         3         4         6          7               1   \n",
       "57840         2         3         4          5               0   \n",
       "57841         4         6         8         10               1   \n",
       "57842         4         6         8         10               1   \n",
       "\n",
       "       Simple4Classes  Simple6Classes  Simple8Classes  Simple10Classes  \n",
       "0                   1               1               1                1  \n",
       "1                   0               0               1                1  \n",
       "2                   2               2               2                2  \n",
       "3                   1               1               1                1  \n",
       "4                   2               2               1                1  \n",
       "...               ...             ...             ...              ...  \n",
       "57838               0               0               0                1  \n",
       "57839               1               1               1                1  \n",
       "57840               1               1               1                1  \n",
       "57841               2               2               2                2  \n",
       "57842               2               2               2                2  \n",
       "\n",
       "[57843 rows x 97 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "RData = pd.read_csv(data_file_path)\n",
    "finalData=RData\n",
    "finalData\n",
    "\n",
    "\n",
    "# finalData = dataset.map(..., num_parallel_calls=10)\n",
    "# finalData = dataset.prefetch(buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe\n",
    "# finalData = dask.dataframe.read_csv(data_file_path)\n",
    "# finalData\n",
    "#finalData.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainY = finalData[\"returns\"][0:20].compute()\n",
    "# trainY\n",
    "# trainX = finalData.loc[:, finalData.columns != \"returns\"]\n",
    "# trainX\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "descrNames = [\"gvkey\", \"fdateYQ\", \"Split\"] + [\"MktCap\"]\n",
    "dummyNames = [\"loc\", \"Sector\", \"acctstdq\", \"compstq\"] # \"bsprq\", \"scfq\", \"staltq\",\n",
    "detailedDummyNames = [\"city\", \"Subsector\", \"IndustryGroup\", \"Industry\", \"NationalIndustry\"]\n",
    "dependentNames = [\"returns\", \"volatility\",\n",
    "                  \"2Classes\", \"4Classes\", \"6Classes\", \"8Classes\", \"10Classes\",\n",
    "                  \"Simple2Classes\", \"Simple4Classes\", \"Simple6Classes\", \"Simple8Classes\", \"Simple10Classes\"]\n",
    "#finalData[factorCols] = finalData[factorCols].astype(\"category\")\n",
    "\n",
    "dontNormalizeCols = dependentNames + descrNames + dummyNames + detailedDummyNames\n",
    "dontCreateRatio = [\"TimeDifferenceInDays\",\n",
    "                   \"quarterlyReturns-1\", \"quarterlyReturns-2\", \"quarterlyReturns-3\", \"quarterlyReturns-4\",\n",
    "                   \"quarterlyVolatility-1\",  \"quarterlyVolatility-2\", \"quarterlyVolatility-3\", \"quarterlyVolatility-4\",\n",
    "                   \"past2YearReturn\", \"past3YearReturn\", \"past4YearReturn\", \"past5YearReturn\",\n",
    "                   \"past2YearVolatility\", \"past3YearVolatility\", \"past4YearVolatility\", \"past5YearVolatility\"]\n",
    "\n",
    "numCols = finalData.columns.difference(dontNormalizeCols)\n",
    "ratioCols = finalData.columns.difference(dontNormalizeCols + dontCreateRatio)\n",
    "\n",
    "\n",
    "#finalData[\"fdateq\"] = pd.to_datetime(finalData[\"fdateq\"], format = \"%Y%m%d\")\n",
    "#finalData[\"datadate\"] = pd.to_datetime(finalData[\"datadate\"], format = \"%Y%m%d\")\n",
    "#finalData[\"fdateYQ\"] = pd.to_datetime(finalData[\"fdateYQ\"], format = \"%Y%q\") #check quarter format\n",
    "\n",
    "\n",
    "# #Currently not grouped by quarter\n",
    "# finalData = finalData.sort_values(by=['datacqtr', \"fdateq\"])\n",
    "\n",
    "# trainSize = round(len(finalData.index)*0.4)\n",
    "# validationSize = round(len(finalData.index)*0.7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Y = finalData[\"returns\"]\n",
    "# Y = np.asarray(Y).astype('float32')\n",
    "# yTrain, yVal, yTest = Y[:trainSize], Y[trainSize:validationSize], Y[validationSize:]\n",
    "\n",
    "# X = finalData.loc[:, finalData.columns != \"returns\"]\n",
    "\n",
    "\n",
    "\n",
    "# X = X.select_dtypes(include=[np.number])\n",
    "#X = X.dropna()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeDifferenceInDays</th>\n",
       "      <th>accdq</th>\n",
       "      <th>acoq</th>\n",
       "      <th>acoxq</th>\n",
       "      <th>actq</th>\n",
       "      <th>ancq</th>\n",
       "      <th>aoq</th>\n",
       "      <th>apq</th>\n",
       "      <th>atq</th>\n",
       "      <th>capsq</th>\n",
       "      <th>...</th>\n",
       "      <th>revtq</th>\n",
       "      <th>saleq</th>\n",
       "      <th>sctq</th>\n",
       "      <th>seqq</th>\n",
       "      <th>teqq</th>\n",
       "      <th>txtq</th>\n",
       "      <th>xintq</th>\n",
       "      <th>xoproq</th>\n",
       "      <th>xoprq</th>\n",
       "      <th>xsgaq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>-1.64e+03</td>\n",
       "      <td>-1.92e+04</td>\n",
       "      <td>-1.93e+04</td>\n",
       "      <td>8.97e-01</td>\n",
       "      <td>6.32e-01</td>\n",
       "      <td>1.35e-01</td>\n",
       "      <td>-1.64e+03</td>\n",
       "      <td>8.18e+00</td>\n",
       "      <td>-9.42e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.92e+06</td>\n",
       "      <td>-2.92e+06</td>\n",
       "      <td>1.00e-03</td>\n",
       "      <td>-5.88e+06</td>\n",
       "      <td>-7.09e+06</td>\n",
       "      <td>-1.52e+06</td>\n",
       "      <td>-1.10e+04</td>\n",
       "      <td>-2.58e+04</td>\n",
       "      <td>-3.60e+06</td>\n",
       "      <td>-8.31e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>2.75e+07</td>\n",
       "      <td>4.21e+07</td>\n",
       "      <td>4.21e+07</td>\n",
       "      <td>1.75e+08</td>\n",
       "      <td>2.35e+08</td>\n",
       "      <td>1.48e+08</td>\n",
       "      <td>4.05e+07</td>\n",
       "      <td>3.93e+08</td>\n",
       "      <td>2.45e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>8.44e+07</td>\n",
       "      <td>8.44e+07</td>\n",
       "      <td>4.47e+07</td>\n",
       "      <td>1.84e+08</td>\n",
       "      <td>2.32e+08</td>\n",
       "      <td>5.31e+06</td>\n",
       "      <td>1.73e+06</td>\n",
       "      <td>8.23e+06</td>\n",
       "      <td>8.42e+07</td>\n",
       "      <td>5.47e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimeDifferenceInDays     accdq      acoq     acoxq      actq      ancq  \\\n",
       "0                     9 -1.64e+03 -1.92e+04 -1.93e+04  8.97e-01  6.32e-01   \n",
       "1                    99  2.75e+07  4.21e+07  4.21e+07  1.75e+08  2.35e+08   \n",
       "\n",
       "        aoq       apq       atq     capsq  ...     revtq     saleq      sctq  \\\n",
       "0  1.35e-01 -1.64e+03  8.18e+00 -9.42e+05  ... -2.92e+06 -2.92e+06  1.00e-03   \n",
       "1  1.48e+08  4.05e+07  3.93e+08  2.45e+07  ...  8.44e+07  8.44e+07  4.47e+07   \n",
       "\n",
       "       seqq      teqq      txtq     xintq    xoproq     xoprq     xsgaq  \n",
       "0 -5.88e+06 -7.09e+06 -1.52e+06 -1.10e+04 -2.58e+04 -3.60e+06 -8.31e+01  \n",
       "1  1.84e+08  2.32e+08  5.31e+06  1.73e+06  8.23e+06  8.42e+07  5.47e+06  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xLogData = finalData[numCols].apply(lambda x: np.log(x+0.001))\n",
    "\n",
    "finalData[numCols].apply(lambda x: (min(x), max(x)))\n",
    "#finalData[numCols].apply(lambda x: max(x))\n",
    "\n",
    "# plt.hist(xLogData, bins=1000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57843 entries, 0 to 57842\n",
      "Data columns (total 97 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   gvkey                  57843 non-null  int64  \n",
      " 1   fdateYQ                57843 non-null  float64\n",
      " 2   returns                57843 non-null  float64\n",
      " 3   volatility             57843 non-null  float64\n",
      " 4   MktCap                 57843 non-null  float64\n",
      " 5   Split                  57843 non-null  object \n",
      " 6   TimeDifferenceInDays   57843 non-null  int64  \n",
      " 7   loc                    57843 non-null  object \n",
      " 8   city                   57842 non-null  object \n",
      " 9   acctstdq               57842 non-null  object \n",
      " 10  compstq                17378 non-null  object \n",
      " 11  Sector                 57843 non-null  int64  \n",
      " 12  Subsector              57843 non-null  int64  \n",
      " 13  IndustryGroup          57843 non-null  int64  \n",
      " 14  Industry               57843 non-null  int64  \n",
      " 15  NationalIndustry       57843 non-null  int64  \n",
      " 16  accdq                  57843 non-null  float64\n",
      " 17  acoq                   57843 non-null  float64\n",
      " 18  acoxq                  57843 non-null  float64\n",
      " 19  actq                   57843 non-null  float64\n",
      " 20  ancq                   57843 non-null  float64\n",
      " 21  aoq                    57843 non-null  float64\n",
      " 22  apq                    57843 non-null  float64\n",
      " 23  atq                    57843 non-null  float64\n",
      " 24  capsq                  57843 non-null  float64\n",
      " 25  ceqq                   57843 non-null  float64\n",
      " 26  cheq                   57843 non-null  float64\n",
      " 27  cogsq                  57843 non-null  float64\n",
      " 28  cstkq                  57843 non-null  float64\n",
      " 29  dfxaq                  57843 non-null  float64\n",
      " 30  dlcq                   57843 non-null  float64\n",
      " 31  dlttq                  57843 non-null  float64\n",
      " 32  dpq                    57843 non-null  float64\n",
      " 33  eqrtq                  57843 non-null  float64\n",
      " 34  eroq                   57843 non-null  float64\n",
      " 35  gpq                    57843 non-null  float64\n",
      " 36  ibmiiq                 57843 non-null  float64\n",
      " 37  ibq                    57843 non-null  float64\n",
      " 38  iditq                  57843 non-null  float64\n",
      " 39  intanq                 57843 non-null  float64\n",
      " 40  invtq                  57843 non-null  float64\n",
      " 41  ivaoq                  57843 non-null  float64\n",
      " 42  lcoq                   57843 non-null  float64\n",
      " 43  lcoxq                  57843 non-null  float64\n",
      " 44  lctq                   57843 non-null  float64\n",
      " 45  lltq                   57843 non-null  float64\n",
      " 46  loq                    57843 non-null  float64\n",
      " 47  lseq                   57843 non-null  float64\n",
      " 48  ltmibq                 57843 non-null  float64\n",
      " 49  ltq                    57843 non-null  float64\n",
      " 50  nopioq                 57843 non-null  float64\n",
      " 51  nopiq                  57843 non-null  float64\n",
      " 52  oiadpq                 57843 non-null  float64\n",
      " 53  oibdpq                 57843 non-null  float64\n",
      " 54  piq                    57843 non-null  float64\n",
      " 55  ppentq                 57843 non-null  float64\n",
      " 56  reccoq                 57843 non-null  float64\n",
      " 57  rectoq                 57843 non-null  float64\n",
      " 58  rectq                  57843 non-null  float64\n",
      " 59  rectrq                 57843 non-null  float64\n",
      " 60  req                    57843 non-null  float64\n",
      " 61  revtq                  57843 non-null  float64\n",
      " 62  saleq                  57843 non-null  float64\n",
      " 63  sctq                   57843 non-null  float64\n",
      " 64  seqq                   57843 non-null  float64\n",
      " 65  teqq                   57843 non-null  float64\n",
      " 66  txtq                   57843 non-null  float64\n",
      " 67  xintq                  57843 non-null  float64\n",
      " 68  xoproq                 57843 non-null  float64\n",
      " 69  xoprq                  57843 non-null  float64\n",
      " 70  xsgaq                  57843 non-null  float64\n",
      " 71  quarterlyReturns-1     57843 non-null  float64\n",
      " 72  quarterlyReturns-2     57843 non-null  float64\n",
      " 73  quarterlyReturns-3     57843 non-null  float64\n",
      " 74  quarterlyReturns-4     57843 non-null  float64\n",
      " 75  quarterlyVolatility-1  57843 non-null  float64\n",
      " 76  quarterlyVolatility-2  57843 non-null  float64\n",
      " 77  quarterlyVolatility-3  57843 non-null  float64\n",
      " 78  quarterlyVolatility-4  57843 non-null  float64\n",
      " 79  past2YearReturn        57843 non-null  float64\n",
      " 80  past3YearReturn        57843 non-null  float64\n",
      " 81  past4YearReturn        57843 non-null  float64\n",
      " 82  past5YearReturn        57843 non-null  float64\n",
      " 83  past2YearVolatility    57843 non-null  float64\n",
      " 84  past3YearVolatility    57843 non-null  float64\n",
      " 85  past4YearVolatility    57843 non-null  float64\n",
      " 86  past5YearVolatility    57843 non-null  float64\n",
      " 87  2Classes               57843 non-null  int64  \n",
      " 88  4Classes               57843 non-null  int64  \n",
      " 89  6Classes               57843 non-null  int64  \n",
      " 90  8Classes               57843 non-null  int64  \n",
      " 91  10Classes              57843 non-null  int64  \n",
      " 92  Simple2Classes         57843 non-null  int64  \n",
      " 93  Simple4Classes         57843 non-null  int64  \n",
      " 94  Simple6Classes         57843 non-null  int64  \n",
      " 95  Simple8Classes         57843 non-null  int64  \n",
      " 96  Simple10Classes        57843 non-null  int64  \n",
      "dtypes: float64(75), int64(17), object(5)\n",
      "memory usage: 42.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#X.dtypes\n",
    "\n",
    "finalData.info(verbose=True)\n",
    "#finalData[numCols].info(verbose=True)\n",
    "#finalData.dtypes\n",
    "#print(finalData.dtypes)\n",
    "#finalData.columns\n",
    "\n",
    "#a = pd.get_dummies(finalData, columns = factorCols)\n",
    "#b = pd.get_dummies(finalData, columns = \"gvkey\")\n",
    "\n",
    "#a.iloc[1,:].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#xLogData = xRatioData[\"revtq\"]\n",
    "xLogData = finalData[\"revtq\"].apply(lambda x: np.log(x+0.0001))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(xLogData, bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio data\n",
    "#xRatioData = finalData.apply(lambda x: x/finalData[\"revtq\"])\n",
    "xRatioData = finalData.copy()\n",
    "xRatioData[ratioCols] = finalData[ratioCols].div(finalData[\"MktCap\"].values, axis=0) #This is an inplace operation if copy() is not used\n",
    "#xRatioData[numCols] = finalData[numCols].apply(lambda x: x/finalData[\"MktCap\"].values, axis=0)\n",
    "#xRatioData = X.div(finalData[\"MktCap\"].values, axis=0)\n",
    "#xRatioData = xRatioData.loc[:, xRatioData.columns != \"MktCap\"]\n",
    "\n",
    "\n",
    "#xRatioData = xRatioData.dropna()\n",
    "#xRatioData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsrUlEQVR4nO3de3CUVZ7/8U8DdgeQDhdJOtEMRFjCxQCDOiG7iLrGtG68ZGW9AAIyEcWCGSEzGlJeBnDLZKEiMq6Alhe0dBygClgkLhpCMCIBNBAQlIhcRId0cEHSXEMg5/fHVJ6fPVwT04k5vF9VT5HnnO/z9Dmnku4PT57uuIwxRgAAAJZp1dwDAAAACAdCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASm2aewDNqba2Vvv27VOHDh3kcrmaezgAAOAiGGN0+PBhxcbGqlWrc1+vuaRDzr59+xQXF9fcwwAAAA3w3Xff6aqrrjpn/yUdcjp06CDp74vk9XqbeTQAAOBiBINBxcXFOa/j53JJh5y6X1F5vV5CDgAALcyFbjXhxmMAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWKneIae4uFh33nmnYmNj5XK5tHTp0pB+l8t11m3mzJlOTffu3c/oz83NDTnPli1bdMMNNygiIkJxcXGaMWPGGWNZtGiRevfurYiICCUmJuqDDz6o73QAAICl6h1yjh49qgEDBujll18+a39FRUXI9sYbb8jlcmnYsGEhddOnTw+p+93vfuf0BYNBpaamqlu3biotLdXMmTM1depUvfrqq07N2rVrNXz4cGVkZGjTpk1KT09Xenq6tm7dWt8pAQAAC7mMMabBB7tcWrJkidLT089Zk56ersOHD6uwsNBp6969uyZNmqRJkyad9Zi5c+fqqaeeUiAQkNvtliRNmTJFS5cu1fbt2yVJ999/v44eParly5c7xw0ePFgDBw7UvHnzLmr8wWBQkZGRqqqq4q+QAwDQQlzs63dY78mprKxUfn6+MjIyzujLzc1Vly5d9Otf/1ozZ87UqVOnnL6SkhINHTrUCTiS5Pf7VV5erh9//NGpSUlJCTmn3+9XSUnJOcdTXV2tYDAYsgEAADu1CefJ33rrLXXo0EH33HNPSPvvf/97DRo0SJ07d9batWuVnZ2tiooKvfDCC5KkQCCg+Pj4kGOio6Odvk6dOikQCDhtP60JBALnHE9OTo6mTZvWGFMDAAC/cGENOW+88YZGjhypiIiIkPbMzEzn6/79+8vtduvRRx9VTk6OPB5P2MaTnZ0d8tjBYFBxcXFhezwAANB8whZyPvnkE5WXl2vBggUXrE1KStKpU6e0Z88eJSQkyOfzqbKyMqSmbt/n8zn/nq2mrv9sPB5PWEMUAAD45QjbPTmvv/66rr32Wg0YMOCCtWVlZWrVqpWioqIkScnJySouLlZNTY1TU1BQoISEBHXq1Mmp+enNzHU1ycnJjTgLAADQUtU75Bw5ckRlZWUqKyuTJO3evVtlZWXau3evUxMMBrVo0SI9/PDDZxxfUlKiF198UZs3b9auXbv07rvvavLkyXrwwQedADNixAi53W5lZGRo27ZtWrBggWbPnh3yq6bHH39cK1asUF5enrZv366pU6fq888/18SJE+s7JQAAYCNTT0VFRUbSGduYMWOcmldeecW0bdvWHDp06IzjS0tLTVJSkomMjDQRERGmT58+5vnnnzcnTpwIqdu8ebMZMmSI8Xg85sorrzS5ublnnGvhwoWmV69exu12m379+pn8/Px6zaWqqspIMlVVVfU6DgAANJ+Lff3+WZ+T09LxOTkAALQ8v4jPyQEAAGguhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAK9U75BQXF+vOO+9UbGysXC6Xli5dGtL/0EMPyeVyhWy33XZbSM3Bgwc1cuRIeb1edezYURkZGTpy5EhIzZYtW3TDDTcoIiJCcXFxmjFjxhljWbRokXr37q2IiAglJibqgw8+qO90AACApeodco4ePaoBAwbo5ZdfPmfNbbfdpoqKCmd77733QvpHjhypbdu2qaCgQMuXL1dxcbEeeeQRpz8YDCo1NVXdunVTaWmpZs6cqalTp+rVV191atauXavhw4crIyNDmzZtUnp6utLT07V169b6TgkAAFjIZYwxDT7Y5dKSJUuUnp7utD300EM6dOjQGVd46nz11Vfq27evPvvsM1133XWSpBUrVujf/u3f9P333ys2NlZz587VU089pUAgILfbLUmaMmWKli5dqu3bt0uS7r//fh09elTLly93zj148GANHDhQ8+bNu6jxB4NBRUZGqqqqSl6vtwErAAAAmtrFvn6H5Z6c1atXKyoqSgkJCXrsscd04MABp6+kpEQdO3Z0Ao4kpaSkqFWrVlq/fr1TM3ToUCfgSJLf71d5ebl+/PFHpyYlJSXkcf1+v0pKSs45rurqagWDwZANAADYqdFDzm233aa3335bhYWF+q//+i99/PHHuv3223X69GlJUiAQUFRUVMgxbdq0UefOnRUIBJya6OjokJq6/QvV1PWfTU5OjiIjI50tLi7u500WAAD8YrVp7BM+8MADzteJiYnq37+/evToodWrV+uWW25p7Ierl+zsbGVmZjr7wWCQoAMAgKXC/hbyq6++WldccYW++eYbSZLP59P+/ftDak6dOqWDBw/K5/M5NZWVlSE1dfsXqqnrPxuPxyOv1xuyAQAAO4U95Hz//fc6cOCAYmJiJEnJyck6dOiQSktLnZpVq1aptrZWSUlJTk1xcbFqamqcmoKCAiUkJKhTp05OTWFhYchjFRQUKDk5OdxTAgAALUC9Q86RI0dUVlamsrIySdLu3btVVlamvXv36siRI3riiSe0bt067dmzR4WFhbr77rvVs2dP+f1+SVKfPn102223ady4cdqwYYM+/fRTTZw4UQ888IBiY2MlSSNGjJDb7VZGRoa2bdumBQsWaPbs2SG/anr88ce1YsUK5eXlafv27Zo6dao+//xzTZw4sRGWBQAAtHimnoqKioykM7YxY8aYY8eOmdTUVNO1a1dz2WWXmW7duplx48aZQCAQco4DBw6Y4cOHm8svv9x4vV4zduxYc/jw4ZCazZs3myFDhhiPx2OuvPJKk5ube8ZYFi5caHr16mXcbrfp16+fyc/Pr9dcqqqqjCRTVVVV32UAAADN5GJfv3/W5+S0dHxODgAALU+zfk4OAABAcyPkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFip3iGnuLhYd955p2JjY+VyubR06VKnr6amRllZWUpMTFT79u0VGxur0aNHa9++fSHn6N69u1wuV8iWm5sbUrNlyxbdcMMNioiIUFxcnGbMmHHGWBYtWqTevXsrIiJCiYmJ+uCDD+o7HQAAYKl6h5yjR49qwIABevnll8/oO3bsmDZu3KhnnnlGGzdu1OLFi1VeXq677rrrjNrp06eroqLC2X73u985fcFgUKmpqerWrZtKS0s1c+ZMTZ06Va+++qpTs3btWg0fPlwZGRnatGmT0tPTlZ6erq1bt9Z3SgAAwEIuY4xp8MEul5YsWaL09PRz1nz22Wf6zW9+o2+//Va/+tWvJP39Ss6kSZM0adKksx4zd+5cPfXUUwoEAnK73ZKkKVOmaOnSpdq+fbsk6f7779fRo0e1fPly57jBgwdr4MCBmjdv3kWNPxgMKjIyUlVVVfJ6vRd1DAAAaF4X+/od9ntyqqqq5HK51LFjx5D23NxcdenSRb/+9a81c+ZMnTp1yukrKSnR0KFDnYAjSX6/X+Xl5frxxx+dmpSUlJBz+v1+lZSUnHMs1dXVCgaDIRsAALBTm3Ce/MSJE8rKytLw4cNDktbvf/97DRo0SJ07d9batWuVnZ2tiooKvfDCC5KkQCCg+Pj4kHNFR0c7fZ06dVIgEHDafloTCATOOZ6cnBxNmzatsaYHAAB+wcIWcmpqanTffffJGKO5c+eG9GVmZjpf9+/fX263W48++qhycnLk8XjCNSRlZ2eHPHYwGFRcXFzYHg8AADSfsIScuoDz7bffatWqVRe83yUpKUmnTp3Snj17lJCQIJ/Pp8rKypCaun2fz+f8e7aauv6z8Xg8YQ1RAADgl6PR78mpCzg7duzQypUr1aVLlwseU1ZWplatWikqKkqSlJycrOLiYtXU1Dg1BQUFSkhIUKdOnZyawsLCkPMUFBQoOTm5EWcDAABaqnpfyTly5Ii++eYbZ3/37t0qKytT586dFRMTo//4j//Qxo0btXz5cp0+fdq5R6Zz585yu90qKSnR+vXrdfPNN6tDhw4qKSnR5MmT9eCDDzoBZsSIEZo2bZoyMjKUlZWlrVu3avbs2Zo1a5bzuI8//rhuvPFG5eXlKS0tTX/961/1+eefh7zNHAAAXMJMPRUVFRlJZ2xjxowxu3fvPmufJFNUVGSMMaa0tNQkJSWZyMhIExERYfr06WOef/55c+LEiZDH2bx5sxkyZIjxeDzmyiuvNLm5uWeMZeHChaZXr17G7Xabfv36mfz8/HrNpaqqykgyVVVV9V0GAADQTC729ftnfU5OS8fn5AAA0PL8Yj4nBwAAoDkQcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkhFH3KfnNPQQAAC5ZhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACvVO+QUFxfrzjvvVGxsrFwul5YuXRrSb4zRs88+q5iYGLVt21YpKSnasWNHSM3Bgwc1cuRIeb1edezYURkZGTpy5EhIzZYtW3TDDTcoIiJCcXFxmjFjxhljWbRokXr37q2IiAglJibqgw8+qO90AACApeodco4ePaoBAwbo5ZdfPmv/jBkz9Oc//1nz5s3T+vXr1b59e/n9fp04ccKpGTlypLZt26aCggItX75cxcXFeuSRR5z+YDCo1NRUdevWTaWlpZo5c6amTp2qV1991alZu3athg8froyMDG3atEnp6elKT0/X1q1b6zslAABgI/MzSDJLlixx9mtra43P5zMzZ8502g4dOmQ8Ho957733jDHGfPnll0aS+eyzz5ya//3f/zUul8v87W9/M8YYM2fOHNOpUydTXV3t1GRlZZmEhARn/7777jNpaWkh40lKSjKPPvroRY+/qqrKSDJVVVUXfUx9dMtaHpbzAgBwKbvY1+9GvSdn9+7dCgQCSklJcdoiIyOVlJSkkpISSVJJSYk6duyo6667zqlJSUlRq1attH79eqdm6NChcrvdTo3f71d5ebl+/PFHp+anj1NXU/c4AADg0tamMU8WCAQkSdHR0SHt0dHRTl8gEFBUVFToINq0UefOnUNq4uPjzzhHXV+nTp0UCATO+zhnU11drerqamc/GAzWZ3oAAKAFuaTeXZWTk6PIyEhni4uLa+4hAQCAMGnUkOPz+SRJlZWVIe2VlZVOn8/n0/79+0P6T506pYMHD4bUnO0cP32Mc9XU9Z9Ndna2qqqqnO27776r7xQBAEAL0aghJz4+Xj6fT4WFhU5bMBjU+vXrlZycLElKTk7WoUOHVFpa6tSsWrVKtbW1SkpKcmqKi4tVU1Pj1BQUFCghIUGdOnVyan76OHU1dY9zNh6PR16vN2QDAAB2qnfIOXLkiMrKylRWVibp7zcbl5WVae/evXK5XJo0aZL+8z//U8uWLdMXX3yh0aNHKzY2Vunp6ZKkPn366LbbbtO4ceO0YcMGffrpp5o4caIeeOABxcbGSpJGjBght9utjIwMbdu2TQsWLNDs2bOVmZnpjOPxxx/XihUrlJeXp+3bt2vq1Kn6/PPPNXHixJ+/KgAAoOWr79u2ioqKjKQztjFjxhhj/v428meeecZER0cbj8djbrnlFlNeXh5yjgMHDpjhw4ebyy+/3Hi9XjN27Fhz+PDhkJrNmzebIUOGGI/HY6688kqTm5t7xlgWLlxoevXqZdxut+nXr5/Jz8+v11x4CzkAAC3Pxb5+u4wxphkzVrMKBoOKjIxUVVVVWH511X1KvvbkpjX6eQEAuJRd7Ov3JfXuKgAAcOkg5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACs1Oghp3v37nK5XGdsEyZMkCTddNNNZ/SNHz8+5Bx79+5VWlqa2rVrp6ioKD3xxBM6depUSM3q1as1aNAgeTwe9ezZU/Pnz2/sqQAAgBasTWOf8LPPPtPp06ed/a1bt+rWW2/Vvffe67SNGzdO06dPd/bbtWvnfH369GmlpaXJ5/Np7dq1qqio0OjRo3XZZZfp+eeflyTt3r1baWlpGj9+vN59910VFhbq4YcfVkxMjPx+f2NPCQAAtECNHnK6du0asp+bm6sePXroxhtvdNratWsnn8931uM/+ugjffnll1q5cqWio6M1cOBAPffcc8rKytLUqVPldrs1b948xcfHKy8vT5LUp08frVmzRrNmzSLkAAAASWG+J+fkyZN655139Nvf/lYul8tpf/fdd3XFFVfommuuUXZ2to4dO+b0lZSUKDExUdHR0U6b3+9XMBjUtm3bnJqUlJSQx/L7/SopKTnveKqrqxUMBkM2AABgp0a/kvNTS5cu1aFDh/TQQw85bSNGjFC3bt0UGxurLVu2KCsrS+Xl5Vq8eLEkKRAIhAQcSc5+IBA4b00wGNTx48fVtm3bs44nJydH06ZNa6zpAQCAX7CwhpzXX39dt99+u2JjY522Rx55xPk6MTFRMTExuuWWW7Rz50716NEjnMNRdna2MjMznf1gMKi4uLiwPiYAAGgeYQs53377rVauXOlcoTmXpKQkSdI333yjHj16yOfzacOGDSE1lZWVkuTcx+Pz+Zy2n9Z4vd5zXsWRJI/HI4/HU++5AACAlids9+S8+eabioqKUlpa2nnrysrKJEkxMTGSpOTkZH3xxRfav3+/U1NQUCCv16u+ffs6NYWFhSHnKSgoUHJyciPOAAAAtGRhCTm1tbV68803NWbMGLVp8/8vFu3cuVPPPfecSktLtWfPHi1btkyjR4/W0KFD1b9/f0lSamqq+vbtq1GjRmnz5s368MMP9fTTT2vChAnOVZjx48dr165devLJJ7V9+3bNmTNHCxcu1OTJk8MxHQAA0AKFJeSsXLlSe/fu1W9/+9uQdrfbrZUrVyo1NVW9e/fWH/7wBw0bNkzvv/++U9O6dWstX75crVu3VnJysh588EGNHj065HN14uPjlZ+fr4KCAg0YMEB5eXl67bXXePs4AABwuIwxprkH0VyCwaAiIyNVVVUlr9fb6OfvPiVfe3LP/+s6AABQPxf7+s3frgIAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYqdFDztSpU+VyuUK23r17O/0nTpzQhAkT1KVLF11++eUaNmyYKisrQ86xd+9epaWlqV27doqKitITTzyhU6dOhdSsXr1agwYNksfjUc+ePTV//vzGngoAAGjBwnIlp1+/fqqoqHC2NWvWOH2TJ0/W+++/r0WLFunjjz/Wvn37dM899zj9p0+fVlpamk6ePKm1a9fqrbfe0vz58/Xss886Nbt371ZaWppuvvlmlZWVadKkSXr44Yf14YcfhmM6AACgBWoTlpO2aSOfz3dGe1VVlV5//XX95S9/0b/+679Kkt5880316dNH69at0+DBg/XRRx/pyy+/1MqVKxUdHa2BAwfqueeeU1ZWlqZOnSq326158+YpPj5eeXl5kqQ+ffpozZo1mjVrlvx+fzimBAAAWpiwXMnZsWOHYmNjdfXVV2vkyJHau3evJKm0tFQ1NTVKSUlxanv37q1f/epXKikpkSSVlJQoMTFR0dHRTo3f71cwGNS2bducmp+eo66m7hznUl1drWAwGLIBAAA7NXrISUpK0vz587VixQrNnTtXu3fv1g033KDDhw8rEAjI7XarY8eOIcdER0crEAhIkgKBQEjAqeuv6ztfTTAY1PHjx885tpycHEVGRjpbXFzcz50uAAD4hWr0X1fdfvvtztf9+/dXUlKSunXrpoULF6pt27aN/XD1kp2drczMTGc/GAwSdAAAsFTY30LesWNH9erVS9988418Pp9OnjypQ4cOhdRUVlY69/D4fL4z3m1Vt3+hGq/Xe94g5fF45PV6QzYAAGCnsIecI0eOaOfOnYqJidG1116ryy67TIWFhU5/eXm59u7dq+TkZElScnKyvvjiC+3fv9+pKSgokNfrVd++fZ2an56jrqbuHAAAAI0ecv74xz/q448/1p49e7R27Vr9+7//u1q3bq3hw4crMjJSGRkZyszMVFFRkUpLSzV27FglJydr8ODBkqTU1FT17dtXo0aN0ubNm/Xhhx/q6aef1oQJE+TxeCRJ48eP165du/Tkk09q+/btmjNnjhYuXKjJkyc39nQAAEAL1ej35Hz//fcaPny4Dhw4oK5du2rIkCFat26dunbtKkmaNWuWWrVqpWHDhqm6ulp+v19z5sxxjm/durWWL1+uxx57TMnJyWrfvr3GjBmj6dOnOzXx8fHKz8/X5MmTNXv2bF111VV67bXXePs4AABwuIwxprkH0VyCwaAiIyNVVVUVlvtzuk/J157ctEY/LwAAl7KLff3mb1cBAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASISfMuk/Jb+4hAABwSSLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAArNXrIycnJ0fXXX68OHTooKipK6enpKi8vD6m56aab5HK5Qrbx48eH1Ozdu1dpaWlq166doqKi9MQTT+jUqVMhNatXr9agQYPk8XjUs2dPzZ8/v7GnAwAAWqhGDzkff/yxJkyYoHXr1qmgoEA1NTVKTU3V0aNHQ+rGjRuniooKZ5sxY4bTd/r0aaWlpenkyZNau3at3nrrLc2fP1/PPvusU7N7926lpaXp5ptvVllZmSZNmqSHH35YH374YWNPCQAAtEBtGvuEK1asCNmfP3++oqKiVFpaqqFDhzrt7dq1k8/nO+s5PvroI3355ZdauXKloqOjNXDgQD333HPKysrS1KlT5Xa7NW/ePMXHxysvL0+S1KdPH61Zs0azZs2S3+9v7GkBAIAWJuz35FRVVUmSOnfuHNL+7rvv6oorrtA111yj7OxsHTt2zOkrKSlRYmKioqOjnTa/369gMKht27Y5NSkpKSHn9Pv9KikpOedYqqurFQwGQzYAAGCnRr+S81O1tbWaNGmS/uVf/kXXXHON0z5ixAh169ZNsbGx2rJli7KyslReXq7FixdLkgKBQEjAkeTsBwKB89YEg0EdP35cbdu2PWM8OTk5mjZtWqPOEQAA/DKFNeRMmDBBW7du1Zo1a0LaH3nkEefrxMRExcTE6JZbbtHOnTvVo0ePsI0nOztbmZmZzn4wGFRcXFzYHg8AADSfsP26auLEiVq+fLmKiop01VVXnbc2KSlJkvTNN99Iknw+nyorK0Nq6vbr7uM5V43X6z3rVRxJ8ng88nq9IRsAALBTo4ccY4wmTpyoJUuWaNWqVYqPj7/gMWVlZZKkmJgYSVJycrK++OIL7d+/36kpKCiQ1+tV3759nZrCwsKQ8xQUFCg5ObmRZgIAAFqyRg85EyZM0DvvvKO//OUv6tChgwKBgAKBgI4fPy5J2rlzp5577jmVlpZqz549WrZsmUaPHq2hQ4eqf//+kqTU1FT17dtXo0aN0ubNm/Xhhx/q6aef1oQJE+TxeCRJ48eP165du/Tkk09q+/btmjNnjhYuXKjJkyc39pQAAEAL1OghZ+7cuaqqqtJNN92kmJgYZ1uwYIEkye12a+XKlUpNTVXv3r31hz/8QcOGDdP777/vnKN169Zavny5WrdureTkZD344IMaPXq0pk+f7tTEx8crPz9fBQUFGjBggPLy8vTaa6/x9nEAACBJchljTHMPorkEg0FFRkaqqqoqLPfndJ+SL0nak5vW6OcGAOBSdbGv3/ztKgAAYCVCDgAAsBIhBwAAWImQ0wTq7s0BAABNh5ADAACsRMgBAABWIuQAAAArEXIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOQAAwEqEHAAAYCVCDgAAsBIhBwAAWImQAwAArETIaSLdp+Q39xAAALikEHIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkAMAAKxEyAEAAFYi5AAAACsRcgAAgJUIOU2ITz0GAKDpEHIAAICVCDkAAMBKhBwAAGAlQg4AALASIQcAAFiJkNPEeIcVAABNg5ADAACs1OJDzssvv6zu3bsrIiJCSUlJ2rBhQ3MP6YK4mgMAQPi16JCzYMECZWZm6k9/+pM2btyoAQMGyO/3a//+/c09tAsi6AAAEF4tOuS88MILGjdunMaOHau+fftq3rx5ateund54443mHtpFIegAABA+bZp7AA118uRJlZaWKjs722lr1aqVUlJSVFJSctZjqqurVV1d7exXVVVJkoLBYFjGWFt97II1v5q8SJK0dZo/LGMAAMA2da/bxpjz1rXYkPN///d/On36tKKjo0Pao6OjtX379rMek5OTo2nTpp3RHhcXF5Yx1kfki809AgAAWpbDhw8rMjLynP0tNuQ0RHZ2tjIzM5392tpaHTx4UF26dJHL5QrrYweDQcXFxem7776T1+sN62O1VKzRhbFGF8YaXRzW6cJYowtrrjUyxujw4cOKjY09b12LDTlXXHGFWrdurcrKypD2yspK+Xy+sx7j8Xjk8XhC2jp27BiuIZ6V1+vlh+UCWKMLY40ujDW6OKzThbFGF9Yca3S+Kzh1WuyNx263W9dee60KCwudttraWhUWFio5ObkZRwYAAH4JWuyVHEnKzMzUmDFjdN111+k3v/mNXnzxRR09elRjx45t7qEBAIBm1qJDzv33368ffvhBzz77rAKBgAYOHKgVK1accTPyL4HH49Gf/vSnM35dhv+PNbow1ujCWKOLwzpdGGt0Yb/0NXKZC73/CgAAoAVqsffkAAAAnA8hBwAAWImQAwAArETIAQAAViLkhMnGjRt16623qmPHjurSpYseeeQRHTly5Jz1NTU1ysrKUmJiotq3b6/Y2FiNHj1a+/bta8JRN736rpP090+6fPbZZxUTE6O2bdsqJSVFO3bsaKIRN72vv/5ad999t6644gp5vV4NGTJERUVF5z3myJEjmjhxoq666iq1bdvW+QO2tmrIGknSV199pbvuukuRkZFq3769rr/+eu3du7cJRtz0GrpGdcaPHy+Xy6UXX3wxfIP8BajvOl2Kz90N+V5qrudtQk4Y7Nu3TykpKerZs6fWr1+vFStWaNu2bXrooYfOecyxY8e0ceNGPfPMM9q4caMWL16s8vJy3XXXXU038CbWkHWSpBkzZujPf/6z5s2bp/Xr16t9+/by+/06ceJE0wy8id1xxx06deqUVq1apdLSUg0YMEB33HGHAoHAOY/JzMzUihUr9M477+irr77SpEmTNHHiRC1btqwJR950GrJGO3fu1JAhQ9S7d2+tXr1aW7Zs0TPPPKOIiIgmHHnTacga1VmyZInWrVt3wY/Qt0F91+lSfO5uyPdSsz1vGzS6V155xURFRZnTp087bVu2bDGSzI4dOy76PBs2bDCSzLfffhuOYTa7hqxTbW2t8fl8ZubMmU7boUOHjMfjMe+9917Yx9zUfvjhByPJFBcXO23BYNBIMgUFBec8rl+/fmb69OkhbYMGDTJPPfVU2MbaXBq6Rvfff7958MEHm2KIza6ha2SMMd9//7258sorzdatW023bt3MrFmzwjza5vNz1umnbH7ubsgaNefzNldywqC6ulput1utWv3/5W3btq0kac2aNRd9nqqqKrlcrib/+1pNpSHrtHv3bgUCAaWkpDhtkZGRSkpKUklJSXgH3Ay6dOmihIQEvf322zp69KhOnTqlV155RVFRUbr22mvPedw///M/a9myZfrb3/4mY4yKior09ddfKzU1tQlH3zQaska1tbXKz89Xr1695Pf7FRUVpaSkJC1durRpB99EGvp9VFtbq1GjRumJJ55Qv379mnDEzaOh6/SPbH7ubsgaNevzdlgj1CVq69atpk2bNmbGjBmmurraHDx40AwbNsxIMs8///xFneP48eNm0KBBZsSIEWEebfNpyDp9+umnRpLZt29fSPu9995r7rvvvqYYdpP77rvvzLXXXmtcLpdp3bq1iYmJMRs3bjzvMSdOnDCjR482kkybNm2M2+02b731VhONuOnVd40qKiqMJNOuXTvzwgsvmE2bNpmcnBzjcrnM6tWrm3DkTach30fPP/+8ufXWW01tba0xxlh/JceYhq3TT10Kz931XaPmfN7mSk49TJkyRS6X67zb9u3b1a9fP7311lvKy8tTu3bt5PP5FB8fr+jo6JCrFudSU1Oj++67T8YYzZ07twlm1riaap1asotdI2OMJkyYoKioKH3yySfasGGD0tPTdeedd6qiouKc53/ppZe0bt06LVu2TKWlpcrLy9OECRO0cuXKJpzlzxPONaqtrZUk3X333Zo8ebIGDhyoKVOm6I477mhRN2iHc41KS0s1e/ZszZ8/Xy6Xq4ln1rjC/fNWpyU/dzfVGjU1/qxDPfzwww86cODAeWuuvvpqud1uZ7+yslLt27eXy+WS1+vVX//6V917773nPL7uh2TXrl1atWqVunTp0mjjbyrhXKddu3apR48e2rRpkwYOHOi033jjjRo4cKBmz57daPMIp4tdo08++USpqan68ccf5fV6nb5/+qd/UkZGhqZMmXLGccePH1dkZKSWLFmitLQ0p/3hhx/W999/rxUrVjTeRMIonGt08uRJtW/fXn/605/09NNPO+1ZWVlas2aNPv3008abSBiFc41efPFFZWZmhvyH4/Tp02rVqpXi4uK0Z8+eRptHuIVzneq09OfucK5Rcz5vt+g/0NnUunbtqq5du9brmLo/FvrGG28oIiJCt9566zlr635IduzYoaKiohb3Q1InnOsUHx8vn8+nwsJC54clGAxq/fr1euyxx37WuJvSxa7RsWPHJOmMK1utWrVyrkb8o5qaGtXU1JxxTOvWrc95zC9RONfI7Xbr+uuvV3l5eUj7119/rW7dujVwxE0vnGs0atSokHsoJMnv92vUqFEaO3ZsA0fcPMK5TpIdz93hXKNmfd4O6y/DLmEvvfSSKS0tNeXl5ea///u/Tdu2bc3s2bNDahISEszixYuNMcacPHnS3HXXXeaqq64yZWVlpqKiwtmqq6ubYwpNor7rZIwxubm5pmPHjuZ//ud/zJYtW8zdd99t4uPjzfHjx5t6+GH3ww8/mC5duph77rnHlJWVmfLycvPHP/7RXHbZZaasrMyp+8c1uvHGG02/fv1MUVGR2bVrl3nzzTdNRESEmTNnTnNMI6waukaLFy82l112mXn11VfNjh07zEsvvWRat25tPvnkk+aYRlg1dI3+ke335DRknS615+6Gfi811/M2ISdMRo0aZTp37mzcbrfp37+/efvtt8+okWTefPNNY4wxu3fvNpLOuhUVFTXt4JtQfdfJmL+/HfGZZ54x0dHRxuPxmFtuucWUl5c34aib1meffWZSU1NN586dTYcOHczgwYPNBx98EFLzj2tUUVFhHnroIRMbG2siIiJMQkKCycvLc24gtU1D1sgYY15//XXTs2dPExERYQYMGGCWLl3ahKNuWg1do5+yPeQYU/91uhSfuxvyvdRcz9vckwMAAKxk91tYAADAJYuQAwAArETIAQAAViLkAAAAKxFyAACAlQg5AADASoQcAABgJUIOAACwEiEHAABYiZADAACsRMgBAABWIuQAAAAr/T/bRFsfw4D3FQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import math\n",
    "#xLogData = math.log(xRatioData[\"returns\"])\n",
    "\n",
    "#xLogData = np.log(xRatioData[\"returns\"] + 105)\n",
    "\n",
    "#xLogData = np.log1p(xRatioData[\"returns\"]/105)\n",
    "\n",
    "#xLogData = xRatioData[numCols].apply(lambda x: np.log(x), axis=1)\n",
    "#xLogData = xRatioData[\"revtq\"]\n",
    "xLogData = xRatioData[\"revtq\"].apply(lambda x: np.log(x+0.0001))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(xLogData, bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winsorised data\n",
    "import scipy\n",
    "\n",
    "\n",
    "# XArray = np.asarray(xRatioData).astype('float32')\n",
    "# # numberOfVariables = XArray.shape[1]\n",
    "\n",
    "# xWinData = scipy.stats.mstats.winsorize(XArray, limits = (0.01, 0.01))\n",
    "# #yWinData = scipy.stats.mstats.winsorize(XArray, limits = (0.01, 0.01))\n",
    "\n",
    "\n",
    "xWinData=xRatioData.copy()\n",
    "xWinData[numCols] = xRatioData[numCols].apply(lambda x: scipy.stats.mstats.winsorize(x, limits = (0.01, 0.01))) #This is an inplace operation if copy() is not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scaled_X = scaler.fit_transform(XArray)\n",
    "# #scaled_X = np.apply_along_axis(func1d=scaler.fit_transform, axis=1, arr=X) #Why over rows??? prob axis=0 instead\n",
    "\n",
    "# xTrain, xVal, xTest = scaled_X[:trainSize,:], scaled_X[trainSize:validationSize,:], scaled_X[validationSize:, :]\n",
    "\n",
    "# scaled_winX = scaler.fit_transform(xWinData)\n",
    "# xWinTrain, xWinVal, xWinTest = scaled_winX[:trainSize,:], scaled_winX[trainSize:validationSize,:], scaled_winX[validationSize:, :]\n",
    "\n",
    "\n",
    "\n",
    "#My scaling and winsorizing is biased. They should be done based on the training data, not testing and validation\n",
    "xScaledData=xWinData.copy() \n",
    "#xScaledData[numCols] = xScaledData[numCols].apply(lambda x: scaler.fit_transform(x))\n",
    "xScaledData[numCols] = scaler.fit_transform(xScaledData[numCols]) #This is an inplace operation if copy() is not used\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#scaled_X = scaled_X.apply(lambda x : x.reshape(-1, 1))\n",
    "# droppedCols = [\"ajexdi\", \"prccd\", \"trfd\"]\n",
    "# trainX.drop(droppedCols, axis=1, inplace=True)\n",
    "# trainX['gvkey'] = trainX['gvkey'].astype(object)\n",
    "# trainX['gvkey'] = trainX['gvkey'].astype(object)\n",
    "\n",
    "#trainX.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xLogData = xScaledData[\"revtq\"].apply(lambda x: np.log(x)) \n",
    "#xLogData = xScaledData[\"revtq\"].apply(lambda x: np.log(x+0.005)) \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.hist(xLogData, bins=100)\n",
    "plt.hist(xScaledData[\"revtq\"], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>fdateYQ</th>\n",
       "      <th>returns</th>\n",
       "      <th>volatility</th>\n",
       "      <th>MktCap</th>\n",
       "      <th>TimeDifferenceInDays</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Subsector</th>\n",
       "      <th>IndustryGroup</th>\n",
       "      <th>Industry</th>\n",
       "      <th>...</th>\n",
       "      <th>2Classes</th>\n",
       "      <th>4Classes</th>\n",
       "      <th>6Classes</th>\n",
       "      <th>8Classes</th>\n",
       "      <th>10Classes</th>\n",
       "      <th>Simple2Classes</th>\n",
       "      <th>Simple4Classes</th>\n",
       "      <th>Simple6Classes</th>\n",
       "      <th>Simple8Classes</th>\n",
       "      <th>Simple10Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>5.78e+04</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>5.78e+04</td>\n",
       "      <td>5.78e+04</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>...</td>\n",
       "      <td>57843.0</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.0</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.00</td>\n",
       "      <td>57843.0</td>\n",
       "      <td>57843.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>249188.33</td>\n",
       "      <td>2018.04</td>\n",
       "      <td>2.34e+00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.42e+12</td>\n",
       "      <td>-2.22e-16</td>\n",
       "      <td>35.94</td>\n",
       "      <td>362.10</td>\n",
       "      <td>3316.14</td>\n",
       "      <td>27112.46</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55481.86</td>\n",
       "      <td>3.42</td>\n",
       "      <td>2.20e+01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.57e+13</td>\n",
       "      <td>1.00e+00</td>\n",
       "      <td>11.73</td>\n",
       "      <td>118.48</td>\n",
       "      <td>1543.70</td>\n",
       "      <td>19273.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.87</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2009.75</td>\n",
       "      <td>-9.41e+01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.42e+05</td>\n",
       "      <td>-1.85e+00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>213376.00</td>\n",
       "      <td>2015.75</td>\n",
       "      <td>-9.04e+00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.42e+09</td>\n",
       "      <td>-7.57e-01</td>\n",
       "      <td>32.00</td>\n",
       "      <td>325.00</td>\n",
       "      <td>3222.00</td>\n",
       "      <td>3344.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>260034.00</td>\n",
       "      <td>2018.75</td>\n",
       "      <td>-2.22e-14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6.71e+09</td>\n",
       "      <td>-2.78e-02</td>\n",
       "      <td>33.00</td>\n",
       "      <td>333.00</td>\n",
       "      <td>3333.00</td>\n",
       "      <td>32731.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>287313.00</td>\n",
       "      <td>2021.00</td>\n",
       "      <td>9.81e+00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.26e+10</td>\n",
       "      <td>7.01e-01</td>\n",
       "      <td>33.00</td>\n",
       "      <td>336.00</td>\n",
       "      <td>3363.00</td>\n",
       "      <td>33451.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>341563.00</td>\n",
       "      <td>2022.50</td>\n",
       "      <td>9.22e+02</td>\n",
       "      <td>16.79</td>\n",
       "      <td>5.56e+14</td>\n",
       "      <td>2.00e+00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>999.00</td>\n",
       "      <td>9999.00</td>\n",
       "      <td>99998.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gvkey   fdateYQ   returns  volatility    MktCap  \\\n",
       "count   57843.00  57843.00  5.78e+04    57843.00  5.78e+04   \n",
       "mean   249188.33   2018.04  2.34e+00        0.36  1.42e+12   \n",
       "std     55481.86      3.42  2.20e+01        0.20  1.57e+13   \n",
       "min      1166.00   2009.75 -9.41e+01        0.00  1.42e+05   \n",
       "25%    213376.00   2015.75 -9.04e+00        0.23  2.42e+09   \n",
       "50%    260034.00   2018.75 -2.22e-14        0.32  6.71e+09   \n",
       "75%    287313.00   2021.00  9.81e+00        0.44  2.26e+10   \n",
       "max    341563.00   2022.50  9.22e+02       16.79  5.56e+14   \n",
       "\n",
       "       TimeDifferenceInDays    Sector  Subsector  IndustryGroup  Industry  \\\n",
       "count              5.78e+04  57843.00   57843.00       57843.00  57843.00   \n",
       "mean              -2.22e-16     35.94     362.10        3316.14  27112.46   \n",
       "std                1.00e+00     11.73     118.48        1543.70  19273.53   \n",
       "min               -1.85e+00     11.00      11.00          11.00     11.00   \n",
       "25%               -7.57e-01     32.00     325.00        3222.00   3344.00   \n",
       "50%               -2.78e-02     33.00     333.00        3333.00  32731.00   \n",
       "75%                7.01e-01     33.00     336.00        3363.00  33451.00   \n",
       "max                2.00e+00     99.00     999.00        9999.00  99998.00   \n",
       "\n",
       "       ...  2Classes  4Classes  6Classes  8Classes  10Classes  Simple2Classes  \\\n",
       "count  ...   57843.0  57843.00  57843.00  57843.00   57843.00         57843.0   \n",
       "mean   ...       1.5      2.50      3.50      4.50       5.49             0.5   \n",
       "std    ...       0.5      1.12      1.71      2.29       2.87             0.5   \n",
       "min    ...       1.0      1.00      1.00      1.00       1.00             0.0   \n",
       "25%    ...       1.0      1.00      2.00      2.00       3.00             0.0   \n",
       "50%    ...       1.0      2.00      3.00      4.00       5.00             0.0   \n",
       "75%    ...       2.0      3.00      5.00      6.00       8.00             1.0   \n",
       "max    ...       2.0      4.00      6.00      8.00      10.00             1.0   \n",
       "\n",
       "       Simple4Classes  Simple6Classes  Simple8Classes  Simple10Classes  \n",
       "count        57843.00        57843.00         57843.0         57843.00  \n",
       "mean             1.00            1.00             1.0             1.00  \n",
       "std              0.71            0.58             0.5             0.45  \n",
       "min              0.00            0.00             0.0             0.00  \n",
       "25%              0.00            1.00             1.0             1.00  \n",
       "50%              1.00            1.00             1.0             1.00  \n",
       "75%              1.00            1.00             1.0             1.00  \n",
       "max              2.00            2.00             2.0             2.00  \n",
       "\n",
       "[8 rows x 92 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xScaledData\n",
    "xScaledData.describe().to_csv(\"Descr//FinalizedDesc.csv\")\n",
    "xScaledData.describe().to_html(\"Descr//FinalizedDesc.html\")\n",
    "xScaledData.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ScaledWinsRatioPath = os.path.join(os.getcwd(), \"Data\\ScaledWinsRatioData.csv\")\n",
    "\n",
    "\n",
    "# XOutputDF = pd.DataFrame(scaled_winX)\n",
    "# YOutputDF = pd.DataFrame(Y)\n",
    "\n",
    "# NNReadyDataWithLabels = XOutputDF.append(finalData[\"fdateq\"], finalData[\"datadate\"], finalData[\"datacqtr\"], YOutputDF)\n",
    "\n",
    "#np.savetxt(ScaledWinsRatioPath, xScaledData, delimiter=\",\")\n",
    "#pd.DataFrame(xScaledData).to_csv(ScaledWinsRatioPath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf.sparse.SparseTensor\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# np.set_printoptions(precision=3, suppress=True)\n",
    "# ###tf.enable_eager_execution()\n",
    "# #tf.keras.Model.run_eagerly\n",
    "\n",
    "# dataset = tf.data.experimental.make_csv_dataset(\n",
    "#     data_file_path, label_name=\"returns\", batch_size=2, num_epochs=1,\n",
    "#     shuffle=False, sloppy=True) # compression_type = GZIP #ZLIB\n",
    "# iterator = dataset.as_numpy_iterator()\n",
    "\n",
    "# #dataset.zip()\n",
    "# #dataset\n",
    "# #iterator.next()\n",
    "\n",
    "# # for batch, label in dataset.take(1):\n",
    "# #   for key, value in batch.items():\n",
    "# #     print(f\"{key:20s}: {value}\")\n",
    "# #   print()\n",
    "# #   print(f\"{'label':20s}: {label}\")\n",
    "\n",
    "# #b = dataset.map(lambda x: x*2)\n",
    "\n",
    "\n",
    "# dummyLayer = tf.keras.layers.StringLookup(\n",
    "#     mask_token=None,\n",
    "#     encoding=\"utf-8\",\n",
    "#     output_mode=\"one_hot\",\n",
    "#     sparse=True\n",
    "# )\n",
    "\n",
    "# # dummyDataset = dataset.map(lambda x, y: (\n",
    "# #     {n: x[n] for n in numCols} | {f: dummyLayer.adapt(x[f]) for f in factorCols},\n",
    "# #     y))\n",
    "\n",
    "\n",
    "\n",
    "# # feature_ds = dataset.map(lambda x, y: x[name])\n",
    "# # feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "# # # Learn the set of possible string values and assign them a fixed integer index\n",
    "# # lookup.adapt(feature_ds)\n",
    "\n",
    "\n",
    "\n",
    "# #dummyDataset = dataset.map(lambda x, y: ({f: x[f] for f in factorCols}))\n",
    "# #dummyDataset = dataset.map(lambda x, y: (x[f] for f in factorCols))\n",
    "# #dummyDataset = dataset.map(lambda x, y: x[factorCols])\n",
    "# #dummyDataset = dataset.map(lambda x, y: x[\"loc\"])\n",
    "\n",
    "# #dummyDataset.batch(32)\n",
    "\n",
    "# #d = dummyLayer.adapt(dummyDataset)\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder(categories='auto', sparse=False)\n",
    "# # ohe.fit_transform(dataset[['loc']])\n",
    "\n",
    "# dummyDataset = dataset.map(lambda x, y: ({f: ohe.fit_transform(x[f]) for f in factorCols}))\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# le.fit_transform(df['col1'])\n",
    "# dictionary_length = len(le.classes_)\n",
    "\n",
    "\n",
    "\n",
    "# #from sklearn.model_selection import TimeSeriesSplit\n",
    "# #tscv = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)\n",
    "\n",
    "\n",
    "\n",
    "# # dummyLayer = tf.keras.layers.StringLookup(\n",
    "# #     mask_token=None,\n",
    "# #     encoding=\"utf-8\",\n",
    "# #     output_mode=\"int\"\n",
    "# # )\n",
    "\n",
    "# # dummyDataset = dataset.map(lambda x, y: (\n",
    "# #     {n: x[n] for n in numCols} | {f: dummyLayer(x[f]) for f in factorCols},\n",
    "# #     y))\n",
    "\n",
    "\n",
    "# # for batch, label in dummyDataset.take(1):\n",
    "# #   for key, value in batch.items():\n",
    "# #     print(f\"{key:20s}: {value}\")\n",
    "# #     print()\n",
    "# #     print(f\"{'label':20s}: {label}\")\n",
    "\n",
    "\n",
    "\n",
    "# # embeddedDummies = tf.keras.layers.Embedding(\n",
    "# #     input_dim=2000,\n",
    "# #     output_dim=10,\n",
    "# #     activity_regularizer=None,\n",
    "# #     mask_zero=True,\n",
    "# # )\n",
    "\n",
    "# # dummyModel = tf.keras.Sequential()\n",
    "# # dummyModel.add(embeddedDummies)\n",
    "\n",
    "# # with tf.device('cpu:0'):\n",
    "# #   embedding_layer = Embedding(...)\n",
    "# #   embedding_layer.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file_path = os.path.join(os.getcwd(), \"Data\\YXWithSplit.csv\")\n",
    "# splittedData = pd.read_csv(data_file_path)\n",
    "\n",
    "# #Currently not grouped by quarter\n",
    "# splittedData = splittedData.sort_values(by=['datacqtr', \"fdateq\"])\n",
    "\n",
    "\n",
    "# # trainSize = round(len(xScaledData.columns)*0.4)\n",
    "# # validationSize = round(len(xScaledData.columns)*0.7)\n",
    "\n",
    "\n",
    "split = xScaledData[\"Split\"]\n",
    "# xWinTrain, xWinVal, xWinTest = splittedData.loc[split==\"Train\", :], splittedData.loc[split==\"Validation\", :], splittedData.loc[split==\"Test\", :]\n",
    "\n",
    "\n",
    "#Y = xScaledData[[\"returns\"]]\n",
    "#Y = xScaledData[[\"volatility\"]]\n",
    "#Y = xScaledData[[\"returns\", \"volatility\"]]\n",
    "Y = pd.get_dummies(xScaledData[[\"Simple2Classes\"]], dummy_na=False, sparse=False, drop_first=False,\n",
    "                         columns=[\"Simple2Classes\"])\n",
    "\n",
    "Y = np.asarray(Y).astype('float32')\n",
    "#yTrain, yVal, yTest = Y[split==\"Train\"], Y[split==\"Validation\"], Y[split==\"Test\"]\n",
    "yTrain, yVal, yTest = Y[split==\"Train\", ], Y[split==\"Validation\",] , Y[split==\"Test\", ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X = xScaledData.drop([\"returns\", \"MktCap\", \"Split\", \"fdateYQ\"], axis=1)\n",
    "# X = X.drop([\"gvkey\", \"naics\", \"loc\", \"city\", \"acctstdq\", \"bsprq\", \"compstq\", \"scfq\", \"staltq\"], axis=1)\n",
    "# #X = X.select_dtypes(include=[np.number])\n",
    "# #X = pd.concat([X, dummies], axis=1)\n",
    "# xWinTrain, xWinVal, xWinTest = X.loc[split==\"Train\", :], X.loc[split==\"Validation\", :], X.loc[split==\"Test\", :]\n",
    "\n",
    "dummies = pd.get_dummies(xScaledData, dummy_na=False, sparse=False, drop_first=False,\n",
    "                         columns=dummyNames)#, \"bsprq\", \"scfq\", \"staltq\"])  # , \"bsprq\", \"scfq\", \"staltq\"])\n",
    "dummiesClean = dummies.drop(descrNames + dependentNames + detailedDummyNames, axis=1) #, \"staltq\", \"bsprq\", \"scfq\"\n",
    "xWinTrain, xWinVal, xWinTest = dummiesClean.loc[split==\"Train\", :], dummiesClean.loc[split==\"Validation\", :], dummiesClean.loc[split==\"Test\", :]\n",
    "\n",
    "#xWinTrain, xWinVal, xWinTest = np.asarray(xWinTrain).astype('float32'), np.asarray(xWinVal).astype('float32'), np.asarray(xWinTest).astype('float32')\n",
    "\n",
    "# xWinTrain, xWinVal, xWinTest = X[:trainSize, :], X[trainSize:validationSize, :], X[validationSize:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(57843, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catEncodingLayer = tf.keras.layers.CategoryEncoding(\n",
    "#     num_tokens=3, output_mode=\"one_hot\", sparse=False\n",
    "# )\n",
    "\n",
    "# catEncodingLayer(xScaledData[[\"2Classes\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(57843, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intLookupLayer = tf.keras.layers.IntegerLookup(\n",
    "#     max_tokens=3,\n",
    "#     num_oov_indices=1,\n",
    "#     mask_token=None,\n",
    "#     vocabulary=[1,10],\n",
    "#     output_mode=\"one_hot\",\n",
    "#     sparse=False,\n",
    "#     pad_to_max_tokens=False\n",
    "# )\n",
    "\n",
    "# #intLookupLayer.adapt(xScaledData[[\"10Classes\"]])\n",
    "# intLookupLayer(xScaledData[[\"10Classes\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.to_csv(dummies, \"Data/dummiesData.csv\", index=False)\n",
    "# #dummies.to_hdf(r\"Data/dummiesData2.csv\", key='dummies', mode='w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57843 entries, 0 to 57842\n",
      "Data columns (total 173 columns):\n",
      " #    Column                 Dtype  \n",
      "---   ------                 -----  \n",
      " 0    TimeDifferenceInDays   float64\n",
      " 1    accdq                  float64\n",
      " 2    acoq                   float64\n",
      " 3    acoxq                  float64\n",
      " 4    actq                   float64\n",
      " 5    ancq                   float64\n",
      " 6    aoq                    float64\n",
      " 7    apq                    float64\n",
      " 8    atq                    float64\n",
      " 9    capsq                  float64\n",
      " 10   ceqq                   float64\n",
      " 11   cheq                   float64\n",
      " 12   cogsq                  float64\n",
      " 13   cstkq                  float64\n",
      " 14   dfxaq                  float64\n",
      " 15   dlcq                   float64\n",
      " 16   dlttq                  float64\n",
      " 17   dpq                    float64\n",
      " 18   eqrtq                  float64\n",
      " 19   eroq                   float64\n",
      " 20   gpq                    float64\n",
      " 21   ibmiiq                 float64\n",
      " 22   ibq                    float64\n",
      " 23   iditq                  float64\n",
      " 24   intanq                 float64\n",
      " 25   invtq                  float64\n",
      " 26   ivaoq                  float64\n",
      " 27   lcoq                   float64\n",
      " 28   lcoxq                  float64\n",
      " 29   lctq                   float64\n",
      " 30   lltq                   float64\n",
      " 31   loq                    float64\n",
      " 32   lseq                   float64\n",
      " 33   ltmibq                 float64\n",
      " 34   ltq                    float64\n",
      " 35   nopioq                 float64\n",
      " 36   nopiq                  float64\n",
      " 37   oiadpq                 float64\n",
      " 38   oibdpq                 float64\n",
      " 39   piq                    float64\n",
      " 40   ppentq                 float64\n",
      " 41   reccoq                 float64\n",
      " 42   rectoq                 float64\n",
      " 43   rectq                  float64\n",
      " 44   rectrq                 float64\n",
      " 45   req                    float64\n",
      " 46   revtq                  float64\n",
      " 47   saleq                  float64\n",
      " 48   sctq                   float64\n",
      " 49   seqq                   float64\n",
      " 50   teqq                   float64\n",
      " 51   txtq                   float64\n",
      " 52   xintq                  float64\n",
      " 53   xoproq                 float64\n",
      " 54   xoprq                  float64\n",
      " 55   xsgaq                  float64\n",
      " 56   quarterlyReturns-1     float64\n",
      " 57   quarterlyReturns-2     float64\n",
      " 58   quarterlyReturns-3     float64\n",
      " 59   quarterlyReturns-4     float64\n",
      " 60   quarterlyVolatility-1  float64\n",
      " 61   quarterlyVolatility-2  float64\n",
      " 62   quarterlyVolatility-3  float64\n",
      " 63   quarterlyVolatility-4  float64\n",
      " 64   past2YearReturn        float64\n",
      " 65   past3YearReturn        float64\n",
      " 66   past4YearReturn        float64\n",
      " 67   past5YearReturn        float64\n",
      " 68   past2YearVolatility    float64\n",
      " 69   past3YearVolatility    float64\n",
      " 70   past4YearVolatility    float64\n",
      " 71   past5YearVolatility    float64\n",
      " 72   loc_ARE                uint8  \n",
      " 73   loc_ARG                uint8  \n",
      " 74   loc_AUS                uint8  \n",
      " 75   loc_AUT                uint8  \n",
      " 76   loc_BEL                uint8  \n",
      " 77   loc_BGD                uint8  \n",
      " 78   loc_BGR                uint8  \n",
      " 79   loc_BMU                uint8  \n",
      " 80   loc_BRA                uint8  \n",
      " 81   loc_CHE                uint8  \n",
      " 82   loc_CHL                uint8  \n",
      " 83   loc_CHN                uint8  \n",
      " 84   loc_COL                uint8  \n",
      " 85   loc_CYM                uint8  \n",
      " 86   loc_CYP                uint8  \n",
      " 87   loc_DEU                uint8  \n",
      " 88   loc_DNK                uint8  \n",
      " 89   loc_EGY                uint8  \n",
      " 90   loc_ESP                uint8  \n",
      " 91   loc_EST                uint8  \n",
      " 92   loc_FIN                uint8  \n",
      " 93   loc_FRA                uint8  \n",
      " 94   loc_GBR                uint8  \n",
      " 95   loc_GGY                uint8  \n",
      " 96   loc_GRC                uint8  \n",
      " 97   loc_HKG                uint8  \n",
      " 98   loc_HRV                uint8  \n",
      " 99   loc_HUN                uint8  \n",
      " 100  loc_IDN                uint8  \n",
      " 101  loc_IND                uint8  \n",
      " 102  loc_IRL                uint8  \n",
      " 103  loc_ISL                uint8  \n",
      " 104  loc_ISR                uint8  \n",
      " 105  loc_ITA                uint8  \n",
      " 106  loc_JEY                uint8  \n",
      " 107  loc_KAZ                uint8  \n",
      " 108  loc_KOR                uint8  \n",
      " 109  loc_KWT                uint8  \n",
      " 110  loc_LKA                uint8  \n",
      " 111  loc_LTU                uint8  \n",
      " 112  loc_LUX                uint8  \n",
      " 113  loc_LVA                uint8  \n",
      " 114  loc_MAR                uint8  \n",
      " 115  loc_MEX                uint8  \n",
      " 116  loc_MYS                uint8  \n",
      " 117  loc_NGA                uint8  \n",
      " 118  loc_NLD                uint8  \n",
      " 119  loc_NOR                uint8  \n",
      " 120  loc_OMN                uint8  \n",
      " 121  loc_PAK                uint8  \n",
      " 122  loc_PER                uint8  \n",
      " 123  loc_PHL                uint8  \n",
      " 124  loc_POL                uint8  \n",
      " 125  loc_PRT                uint8  \n",
      " 126  loc_ROU                uint8  \n",
      " 127  loc_RUS                uint8  \n",
      " 128  loc_SAU                uint8  \n",
      " 129  loc_SGP                uint8  \n",
      " 130  loc_SRB                uint8  \n",
      " 131  loc_SVN                uint8  \n",
      " 132  loc_SWE                uint8  \n",
      " 133  loc_THA                uint8  \n",
      " 134  loc_TUN                uint8  \n",
      " 135  loc_TUR                uint8  \n",
      " 136  loc_TWN                uint8  \n",
      " 137  loc_UKR                uint8  \n",
      " 138  loc_USA                uint8  \n",
      " 139  loc_VNM                uint8  \n",
      " 140  loc_ZAF                uint8  \n",
      " 141  Sector_11              uint8  \n",
      " 142  Sector_21              uint8  \n",
      " 143  Sector_22              uint8  \n",
      " 144  Sector_23              uint8  \n",
      " 145  Sector_31              uint8  \n",
      " 146  Sector_32              uint8  \n",
      " 147  Sector_33              uint8  \n",
      " 148  Sector_42              uint8  \n",
      " 149  Sector_44              uint8  \n",
      " 150  Sector_45              uint8  \n",
      " 151  Sector_48              uint8  \n",
      " 152  Sector_49              uint8  \n",
      " 153  Sector_51              uint8  \n",
      " 154  Sector_52              uint8  \n",
      " 155  Sector_53              uint8  \n",
      " 156  Sector_54              uint8  \n",
      " 157  Sector_56              uint8  \n",
      " 158  Sector_61              uint8  \n",
      " 159  Sector_62              uint8  \n",
      " 160  Sector_71              uint8  \n",
      " 161  Sector_72              uint8  \n",
      " 162  Sector_81              uint8  \n",
      " 163  Sector_99              uint8  \n",
      " 164  acctstdq_DI            uint8  \n",
      " 165  acctstdq_DS            uint8  \n",
      " 166  acctstdq_ND            uint8  \n",
      " 167  acctstdq_US            uint8  \n",
      " 168  compstq_AC             uint8  \n",
      " 169  compstq_AD             uint8  \n",
      " 170  compstq_AQ             uint8  \n",
      " 171  compstq_DB             uint8  \n",
      " 172  compstq_SQ             uint8  \n",
      "dtypes: float64(72), uint8(101)\n",
      "memory usage: 37.3 MB\n"
     ]
    }
   ],
   "source": [
    "#xWinTrain, xWinVal, xWinTest = np.asarray(xWinTrain).astype('float32'), np.asarray(xWinVal).astype('float32'), np.asarray(xWinTest).astype('float32')\n",
    "\n",
    "\n",
    "# X = xScaledData.drop([\"returns\", \"MktCap\", \"Split\", \"fdateYQ\"], axis=1)\n",
    "# X = X.drop([\"gvkey\", \"naics\", \"loc\", \"city\", \"acctstdq\", \"bsprq\", \"compstq\", \"scfq\", \"staltq\"], axis=1)\n",
    "# X = pd.concat([X, dummies], axis=1)\n",
    "# X.info(verbose=True)\n",
    "\n",
    "\n",
    "dummiesClean.info(verbose=True)\n",
    "namesOfAllPredictorsAndDummies = list(dummiesClean.columns)\n",
    "\n",
    "\n",
    "#a = dummies.iloc[1:5,2975:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# np.set_printoptions(precision=3, suppress=True)\n",
    "# ###tf.enable_eager_execution()\n",
    "# #tf.keras.Model.run_eagerly\n",
    "\n",
    "# #xScaledDataWithDummies = pd.concat([xScaledData, dummies], axis=1) \n",
    "\n",
    "\n",
    "# #numeric_dict_ds = tf.data.Dataset.from_tensor_slices((dict(numeric_features), target))\n",
    "# categorical_feature_names = factorCols\n",
    "# binary_feature_names = []\n",
    "\n",
    "# inputs = {}\n",
    "# for name, column in xScaledData.items():\n",
    "#   if type(column[0]) == str:\n",
    "#     dtype = tf.string\n",
    "#   elif (name in categorical_feature_names or\n",
    "#         name in binary_feature_names):\n",
    "#     dtype = tf.int64\n",
    "#   else:\n",
    "#     dtype = tf.float32\n",
    "\n",
    "#   inputs[name] = tf.keras.Input(shape=(), name=name, dtype=dtype)\n",
    "\n",
    "\n",
    "# preprocessed = []\n",
    "# for name in categorical_feature_names:\n",
    "#   vocab = sorted(set(xScaledData[name]))\n",
    "#   #print(f'name: {name}')\n",
    "#   #print(f'vocab: {vocab}\\n')\n",
    "\n",
    "#   if type(vocab[0]) is str:\n",
    "#     lookup = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "#   else:\n",
    "#     lookup = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "\n",
    "#   x = inputs[name][:, tf.newaxis]\n",
    "#   x = lookup(x)\n",
    "#   preprocessed.append(x)\n",
    "\n",
    "\n",
    "# numeric_feature_names = numCols\n",
    "\n",
    "# def stack_dict(inputs, fun=tf.stack):\n",
    "#     values = []\n",
    "#     for key in sorted(inputs.keys()):\n",
    "#       values.append(tf.cast(inputs[key], tf.float32))\n",
    "\n",
    "#     return fun(values, axis=-1)\n",
    "# #normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "# #normalizer.adapt(numeric_features)\n",
    "\n",
    "# numeric_inputs = {}\n",
    "# for name in numeric_feature_names:\n",
    "#   numeric_inputs[name]=inputs[name]\n",
    "\n",
    "# numeric_inputs = stack_dict(numeric_inputs)\n",
    "# #numeric_normalized = normalizer(numeric_inputs)\n",
    "\n",
    "# #preprocessed.append(numeric_normalized)\n",
    "# preprocessed.append(numeric_inputs)\n",
    "# #preprocessed\n",
    "\n",
    "# preprocessed_result = tf.concat(preprocessed, axis=-1)\n",
    "# #preprocessed_result\n",
    "\n",
    "# preprocessor = tf.keras.Model(inputs, preprocessed_result)\n",
    "\n",
    "# tf.keras.utils.plot_model(preprocessor, rankdir=\"LR\", show_shapes=True)\n",
    "\n",
    "# preprocessor(dict(xScaledData.iloc[:1]))\n",
    "\n",
    "# xWinTrainDict, xWinValDict, xWinTestDict = xScaledData.loc[split==\"Train\", :], xScaledData.loc[split==\"Validation\", :], xScaledData.loc[split==\"Test\", :]\n",
    "# xWinTrainDict, xWinValDict, xWinTestDict = dict(xWinTrainDict), dict(xWinValDict), dict(xWinTestDict)\n",
    "# xWinTrainDict, xWinValDict, xWinTestDict = preprocessor(xWinTrainDict), preprocessor(xWinValDict), preprocessor(xWinTestDict)\n",
    "\n",
    "\n",
    "# # dataset = tf.data.experimental.make_csv_dataset(xScaledDataWithDummies, label_name=\"returns\", batch_size=2, num_epochs=1,\n",
    "# #     shuffle=False, sloppy=True) # compression_type = GZIP #ZLIB\n",
    "# # iterator = dataset.as_numpy_iterator()\n",
    "\n",
    "\n",
    "# # inputs = {}\n",
    "# # for name, column in df.items():\n",
    "# #   if type(column[0]) == str:\n",
    "# #     dtype = tf.string\n",
    "# #   elif (name in categorical_feature_names or\n",
    "# #         name in binary_feature_names):\n",
    "# #     dtype = tf.int64\n",
    "# #   else:\n",
    "# #     dtype = tf.float32\n",
    "\n",
    "# #   inputs[name] = tf.keras.Input(shape=(), name=name, dtype=dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57873 entries, 0 to 57872\n",
      "Data columns (total 2306 columns):\n",
      " #     Column                              Dtype  \n",
      "---    ------                              -----  \n",
      " 0     gvkey                               int64  \n",
      " 1     fdateYQ                             float64\n",
      " 2     returns                             float64\n",
      " 3     volatility                          float64\n",
      " 4     MktCap                              float64\n",
      " 5     Split                               object \n",
      " 6     accdq                               float64\n",
      " 7     acoq                                float64\n",
      " 8     acoxq                               float64\n",
      " 9     actq                                float64\n",
      " 10    ancq                                float64\n",
      " 11    aoq                                 float64\n",
      " 12    apq                                 float64\n",
      " 13    atq                                 float64\n",
      " 14    capsq                               float64\n",
      " 15    ceqq                                float64\n",
      " 16    cheq                                float64\n",
      " 17    cogsq                               float64\n",
      " 18    cstkq                               float64\n",
      " 19    dfxaq                               float64\n",
      " 20    dlcq                                float64\n",
      " 21    dlttq                               float64\n",
      " 22    dpq                                 float64\n",
      " 23    eqrtq                               float64\n",
      " 24    eroq                                float64\n",
      " 25    gpq                                 float64\n",
      " 26    ibmiiq                              float64\n",
      " 27    ibq                                 float64\n",
      " 28    iditq                               float64\n",
      " 29    intanq                              float64\n",
      " 30    invtq                               float64\n",
      " 31    ivaoq                               float64\n",
      " 32    lcoq                                float64\n",
      " 33    lcoxq                               float64\n",
      " 34    lctq                                float64\n",
      " 35    lltq                                float64\n",
      " 36    loq                                 float64\n",
      " 37    lseq                                float64\n",
      " 38    ltmibq                              float64\n",
      " 39    ltq                                 float64\n",
      " 40    nopioq                              float64\n",
      " 41    nopiq                               float64\n",
      " 42    oiadpq                              float64\n",
      " 43    oibdpq                              float64\n",
      " 44    piq                                 float64\n",
      " 45    ppentq                              float64\n",
      " 46    reccoq                              float64\n",
      " 47    rectoq                              float64\n",
      " 48    rectq                               float64\n",
      " 49    rectrq                              float64\n",
      " 50    req                                 float64\n",
      " 51    revtq                               float64\n",
      " 52    saleq                               float64\n",
      " 53    sctq                                float64\n",
      " 54    seqq                                float64\n",
      " 55    teqq                                float64\n",
      " 56    txtq                                float64\n",
      " 57    xintq                               float64\n",
      " 58    xoproq                              float64\n",
      " 59    xoprq                               float64\n",
      " 60    xsgaq                               float64\n",
      " 61    quarterlyReturns-1                  float64\n",
      " 62    quarterlyReturns-2                  float64\n",
      " 63    quarterlyReturns-3                  float64\n",
      " 64    quarterlyReturns-4                  float64\n",
      " 65    quarterlyVolatility-1               float64\n",
      " 66    quarterlyVolatility-2               float64\n",
      " 67    quarterlyVolatility-3               float64\n",
      " 68    quarterlyVolatility-4               float64\n",
      " 69    past2YearReturn                     float64\n",
      " 70    past3YearReturn                     float64\n",
      " 71    past4YearReturn                     float64\n",
      " 72    past5YearReturn                     float64\n",
      " 73    past2YearVolatility                 float64\n",
      " 74    past3YearVolatility                 float64\n",
      " 75    past4YearVolatility                 float64\n",
      " 76    past5YearVolatility                 float64\n",
      " 77    2Classes                            int64  \n",
      " 78    4Classes                            int64  \n",
      " 79    6Classes                            int64  \n",
      " 80    8Classes                            int64  \n",
      " 81    10Classes                           int64  \n",
      " 82    naics_11                            uint8  \n",
      " 83    naics_23                            uint8  \n",
      " 84    naics_42                            uint8  \n",
      " 85    naics_44                            uint8  \n",
      " 86    naics_45                            uint8  \n",
      " 87    naics_48                            uint8  \n",
      " 88    naics_54                            uint8  \n",
      " 89    naics_61                            uint8  \n",
      " 90    naics_62                            uint8  \n",
      " 91    naics_111                           uint8  \n",
      " 92    naics_112                           uint8  \n",
      " 93    naics_113                           uint8  \n",
      " 94    naics_114                           uint8  \n",
      " 95    naics_212                           uint8  \n",
      " 96    naics_236                           uint8  \n",
      " 97    naics_237                           uint8  \n",
      " 98    naics_238                           uint8  \n",
      " 99    naics_311                           uint8  \n",
      " 100   naics_313                           uint8  \n",
      " 101   naics_314                           uint8  \n",
      " 102   naics_315                           uint8  \n",
      " 103   naics_316                           uint8  \n",
      " 104   naics_321                           uint8  \n",
      " 105   naics_322                           uint8  \n",
      " 106   naics_325                           uint8  \n",
      " 107   naics_326                           uint8  \n",
      " 108   naics_327                           uint8  \n",
      " 109   naics_331                           uint8  \n",
      " 110   naics_332                           uint8  \n",
      " 111   naics_333                           uint8  \n",
      " 112   naics_334                           uint8  \n",
      " 113   naics_335                           uint8  \n",
      " 114   naics_336                           uint8  \n",
      " 115   naics_337                           uint8  \n",
      " 116   naics_423                           uint8  \n",
      " 117   naics_424                           uint8  \n",
      " 118   naics_441                           uint8  \n",
      " 119   naics_444                           uint8  \n",
      " 120   naics_445                           uint8  \n",
      " 121   naics_448                           uint8  \n",
      " 122   naics_451                           uint8  \n",
      " 123   naics_454                           uint8  \n",
      " 124   naics_483                           uint8  \n",
      " 125   naics_484                           uint8  \n",
      " 126   naics_485                           uint8  \n",
      " 127   naics_488                           uint8  \n",
      " 128   naics_511                           uint8  \n",
      " 129   naics_512                           uint8  \n",
      " 130   naics_517                           uint8  \n",
      " 131   naics_519                           uint8  \n",
      " 132   naics_531                           uint8  \n",
      " 133   naics_532                           uint8  \n",
      " 134   naics_561                           uint8  \n",
      " 135   naics_562                           uint8  \n",
      " 136   naics_621                           uint8  \n",
      " 137   naics_622                           uint8  \n",
      " 138   naics_623                           uint8  \n",
      " 139   naics_713                           uint8  \n",
      " 140   naics_722                           uint8  \n",
      " 141   naics_811                           uint8  \n",
      " 142   naics_1113                          uint8  \n",
      " 143   naics_1123                          uint8  \n",
      " 144   naics_1125                          uint8  \n",
      " 145   naics_1141                          uint8  \n",
      " 146   naics_2111                          uint8  \n",
      " 147   naics_2121                          uint8  \n",
      " 148   naics_2122                          uint8  \n",
      " 149   naics_2123                          uint8  \n",
      " 150   naics_2211                          uint8  \n",
      " 151   naics_2213                          uint8  \n",
      " 152   naics_2361                          uint8  \n",
      " 153   naics_2362                          uint8  \n",
      " 154   naics_2371                          uint8  \n",
      " 155   naics_2373                          uint8  \n",
      " 156   naics_3111                          uint8  \n",
      " 157   naics_3112                          uint8  \n",
      " 158   naics_3113                          uint8  \n",
      " 159   naics_3114                          uint8  \n",
      " 160   naics_3115                          uint8  \n",
      " 161   naics_3116                          uint8  \n",
      " 162   naics_3117                          uint8  \n",
      " 163   naics_3118                          uint8  \n",
      " 164   naics_3119                          uint8  \n",
      " 165   naics_3121                          uint8  \n",
      " 166   naics_3131                          uint8  \n",
      " 167   naics_3141                          uint8  \n",
      " 168   naics_3149                          uint8  \n",
      " 169   naics_3151                          uint8  \n",
      " 170   naics_3152                          uint8  \n",
      " 171   naics_3162                          uint8  \n",
      " 172   naics_3169                          uint8  \n",
      " 173   naics_3212                          uint8  \n",
      " 174   naics_3219                          uint8  \n",
      " 175   naics_3221                          uint8  \n",
      " 176   naics_3222                          uint8  \n",
      " 177   naics_3231                          uint8  \n",
      " 178   naics_3251                          uint8  \n",
      " 179   naics_3252                          uint8  \n",
      " 180   naics_3253                          uint8  \n",
      " 181   naics_3255                          uint8  \n",
      " 182   naics_3256                          uint8  \n",
      " 183   naics_3259                          uint8  \n",
      " 184   naics_3261                          uint8  \n",
      " 185   naics_3262                          uint8  \n",
      " 186   naics_3271                          uint8  \n",
      " 187   naics_3272                          uint8  \n",
      " 188   naics_3273                          uint8  \n",
      " 189   naics_3279                          uint8  \n",
      " 190   naics_3311                          uint8  \n",
      " 191   naics_3312                          uint8  \n",
      " 192   naics_3313                          uint8  \n",
      " 193   naics_3314                          uint8  \n",
      " 194   naics_3315                          uint8  \n",
      " 195   naics_3322                          uint8  \n",
      " 196   naics_3323                          uint8  \n",
      " 197   naics_3324                          uint8  \n",
      " 198   naics_3326                          uint8  \n",
      " 199   naics_3329                          uint8  \n",
      " 200   naics_3331                          uint8  \n",
      " 201   naics_3332                          uint8  \n",
      " 202   naics_3333                          uint8  \n",
      " 203   naics_3334                          uint8  \n",
      " 204   naics_3335                          uint8  \n",
      " 205   naics_3336                          uint8  \n",
      " 206   naics_3339                          uint8  \n",
      " 207   naics_3341                          uint8  \n",
      " 208   naics_3342                          uint8  \n",
      " 209   naics_3344                          uint8  \n",
      " 210   naics_3345                          uint8  \n",
      " 211   naics_3351                          uint8  \n",
      " 212   naics_3352                          uint8  \n",
      " 213   naics_3353                          uint8  \n",
      " 214   naics_3359                          uint8  \n",
      " 215   naics_3361                          uint8  \n",
      " 216   naics_3362                          uint8  \n",
      " 217   naics_3363                          uint8  \n",
      " 218   naics_3364                          uint8  \n",
      " 219   naics_3366                          uint8  \n",
      " 220   naics_3371                          uint8  \n",
      " 221   naics_3372                          uint8  \n",
      " 222   naics_3379                          uint8  \n",
      " 223   naics_3399                          uint8  \n",
      " 224   naics_4231                          uint8  \n",
      " 225   naics_4232                          uint8  \n",
      " 226   naics_4233                          uint8  \n",
      " 227   naics_4235                          uint8  \n",
      " 228   naics_4236                          uint8  \n",
      " 229   naics_4238                          uint8  \n",
      " 230   naics_4239                          uint8  \n",
      " 231   naics_4241                          uint8  \n",
      " 232   naics_4243                          uint8  \n",
      " 233   naics_4244                          uint8  \n",
      " 234   naics_4245                          uint8  \n",
      " 235   naics_4246                          uint8  \n",
      " 236   naics_4249                          uint8  \n",
      " 237   naics_4411                          uint8  \n",
      " 238   naics_4422                          uint8  \n",
      " 239   naics_4431                          uint8  \n",
      " 240   naics_4451                          uint8  \n",
      " 241   naics_4452                          uint8  \n",
      " 242   naics_4461                          uint8  \n",
      " 243   naics_4471                          uint8  \n",
      " 244   naics_4481                          uint8  \n",
      " 245   naics_4811                          uint8  \n",
      " 246   naics_4821                          uint8  \n",
      " 247   naics_4841                          uint8  \n",
      " 248   naics_4851                          uint8  \n",
      " 249   naics_4881                          uint8  \n",
      " 250   naics_4883                          uint8  \n",
      " 251   naics_4931                          uint8  \n",
      " 252   naics_5111                          uint8  \n",
      " 253   naics_5121                          uint8  \n",
      " 254   naics_5311                          uint8  \n",
      " 255   naics_5321                          uint8  \n",
      " 256   naics_5324                          uint8  \n",
      " 257   naics_5412                          uint8  \n",
      " 258   naics_5413                          uint8  \n",
      " 259   naics_5414                          uint8  \n",
      " 260   naics_5415                          uint8  \n",
      " 261   naics_5418                          uint8  \n",
      " 262   naics_5613                          uint8  \n",
      " 263   naics_5614                          uint8  \n",
      " 264   naics_5615                          uint8  \n",
      " 265   naics_5616                          uint8  \n",
      " 266   naics_5617                          uint8  \n",
      " 267   naics_6214                          uint8  \n",
      " 268   naics_6215                          uint8  \n",
      " 269   naics_6219                          uint8  \n",
      " 270   naics_7111                          uint8  \n",
      " 271   naics_7112                          uint8  \n",
      " 272   naics_7113                          uint8  \n",
      " 273   naics_7132                          uint8  \n",
      " 274   naics_7139                          uint8  \n",
      " 275   naics_7225                          uint8  \n",
      " 276   naics_11142                         uint8  \n",
      " 277   naics_21223                         uint8  \n",
      " 278   naics_21231                         uint8  \n",
      " 279   naics_22111                         uint8  \n",
      " 280   naics_31122                         uint8  \n",
      " 281   naics_31131                         uint8  \n",
      " 282   naics_31141                         uint8  \n",
      " 283   naics_31142                         uint8  \n",
      " 284   naics_31151                         uint8  \n",
      " 285   naics_31161                         uint8  \n",
      " 286   naics_31191                         uint8  \n",
      " 287   naics_31324                         uint8  \n",
      " 288   naics_31331                         uint8  \n",
      " 289   naics_31412                         uint8  \n",
      " 290   naics_31499                         uint8  \n",
      " 291   naics_31522                         uint8  \n",
      " 292   naics_31523                         uint8  \n",
      " 293   naics_32191                         uint8  \n",
      " 294   naics_32212                         uint8  \n",
      " 295   naics_32221                         uint8  \n",
      " 296   naics_32311                         uint8  \n",
      " 297   naics_32412                         uint8  \n",
      " 298   naics_32419                         uint8  \n",
      " 299   naics_32513                         uint8  \n",
      " 300   naics_32519                         uint8  \n",
      " 301   naics_32521                         uint8  \n",
      " 302   naics_32522                         uint8  \n",
      " 303   naics_32531                         uint8  \n",
      " 304   naics_32612                         uint8  \n",
      " 305   naics_32619                         uint8  \n",
      " 306   naics_32621                         uint8  \n",
      " 307   naics_32711                         uint8  \n",
      " 308   naics_32712                         uint8  \n",
      " 309   naics_33122                         uint8  \n",
      " 310   naics_33152                         uint8  \n",
      " 311   naics_33243                         uint8  \n",
      " 312   naics_33291                         uint8  \n",
      " 313   naics_33299                         uint8  \n",
      " 314   naics_33313                         uint8  \n",
      " 315   naics_33329                         uint8  \n",
      " 316   naics_33361                         uint8  \n",
      " 317   naics_33392                         uint8  \n",
      " 318   naics_33399                         uint8  \n",
      " 319   naics_33512                         uint8  \n",
      " 320   naics_33522                         uint8  \n",
      " 321   naics_33591                         uint8  \n",
      " 322   naics_33592                         uint8  \n",
      " 323   naics_33611                         uint8  \n",
      " 324   naics_33632                         uint8  \n",
      " 325   naics_33712                         uint8  \n",
      " 326   naics_33991                         uint8  \n",
      " 327   naics_33994                         uint8  \n",
      " 328   naics_33999                         uint8  \n",
      " 329   naics_48811                         uint8  \n",
      " 330   naics_51213                         uint8  \n",
      " 331   naics_51219                         uint8  \n",
      " 332   naics_51511                         uint8  \n",
      " 333   naics_52429                         uint8  \n",
      " 334   naics_54161                         uint8  \n",
      " 335   naics_54171                         uint8  \n",
      " 336   naics_56142                         uint8  \n",
      " 337   naics_56149                         uint8  \n",
      " 338   naics_81233                         uint8  \n",
      " 339   naics_111120                        uint8  \n",
      " 340   naics_111160                        uint8  \n",
      " 341   naics_111211                        uint8  \n",
      " 342   naics_111422                        uint8  \n",
      " 343   naics_111920                        uint8  \n",
      " 344   naics_112210                        uint8  \n",
      " 345   naics_112340                        uint8  \n",
      " 346   naics_112511                        uint8  \n",
      " 347   naics_112512                        uint8  \n",
      " 348   naics_113110                        uint8  \n",
      " 349   naics_113210                        uint8  \n",
      " 350   naics_113310                        uint8  \n",
      " 351   naics_115111                        uint8  \n",
      " 352   naics_115210                        uint8  \n",
      " 353   naics_211111                        uint8  \n",
      " 354   naics_212111                        uint8  \n",
      " 355   naics_212112                        uint8  \n",
      " 356   naics_212210                        uint8  \n",
      " 357   naics_212221                        uint8  \n",
      " 358   naics_212230                        uint8  \n",
      " 359   naics_212299                        uint8  \n",
      " 360   naics_212391                        uint8  \n",
      " 361   naics_212393                        uint8  \n",
      " 362   naics_212399                        uint8  \n",
      " 363   naics_213111                        uint8  \n",
      " 364   naics_213112                        uint8  \n",
      " 365   naics_221111                        uint8  \n",
      " 366   naics_221112                        uint8  \n",
      " 367   naics_221113                        uint8  \n",
      " 368   naics_221114                        uint8  \n",
      " 369   naics_221115                        uint8  \n",
      " 370   naics_221116                        uint8  \n",
      " 371   naics_221117                        uint8  \n",
      " 372   naics_221118                        uint8  \n",
      " 373   naics_221121                        uint8  \n",
      " 374   naics_221122                        uint8  \n",
      " 375   naics_221210                        uint8  \n",
      " 376   naics_221310                        uint8  \n",
      " 377   naics_221320                        uint8  \n",
      " 378   naics_221330                        uint8  \n",
      " 379   naics_234110                        uint8  \n",
      " 380   naics_236115                        uint8  \n",
      " 381   naics_236116                        uint8  \n",
      " 382   naics_236117                        uint8  \n",
      " 383   naics_236210                        uint8  \n",
      " 384   naics_236220                        uint8  \n",
      " 385   naics_237110                        uint8  \n",
      " 386   naics_237120                        uint8  \n",
      " 387   naics_237130                        uint8  \n",
      " 388   naics_237210                        uint8  \n",
      " 389   naics_237310                        uint8  \n",
      " 390   naics_237990                        uint8  \n",
      " 391   naics_238120                        uint8  \n",
      " 392   naics_238210                        uint8  \n",
      " 393   naics_238910                        uint8  \n",
      " 394   naics_238990                        uint8  \n",
      " 395   naics_311111                        uint8  \n",
      " 396   naics_311119                        uint8  \n",
      " 397   naics_311211                        uint8  \n",
      " 398   naics_311212                        uint8  \n",
      " 399   naics_311221                        uint8  \n",
      " 400   naics_311224                        uint8  \n",
      " 401   naics_311225                        uint8  \n",
      " 402   naics_311314                        uint8  \n",
      " 403   naics_311340                        uint8  \n",
      " 404   naics_311351                        uint8  \n",
      " 405   naics_311352                        uint8  \n",
      " 406   naics_311411                        uint8  \n",
      " 407   naics_311421                        uint8  \n",
      " 408   naics_311423                        uint8  \n",
      " 409   naics_311511                        uint8  \n",
      " 410   naics_311513                        uint8  \n",
      " 411   naics_311611                        uint8  \n",
      " 412   naics_311612                        uint8  \n",
      " 413   naics_311615                        uint8  \n",
      " 414   naics_311710                        uint8  \n",
      " 415   naics_311812                        uint8  \n",
      " 416   naics_311824                        uint8  \n",
      " 417   naics_311920                        uint8  \n",
      " 418   naics_311941                        uint8  \n",
      " 419   naics_311942                        uint8  \n",
      " 420   naics_311999                        uint8  \n",
      " 421   naics_312111                        uint8  \n",
      " 422   naics_312112                        uint8  \n",
      " 423   naics_312120                        uint8  \n",
      " 424   naics_312130                        uint8  \n",
      " 425   naics_312140                        uint8  \n",
      " 426   naics_312230                        uint8  \n",
      " 427   naics_313110                        uint8  \n",
      " 428   naics_313210                        uint8  \n",
      " 429   naics_313220                        uint8  \n",
      " 430   naics_313230                        uint8  \n",
      " 431   naics_313240                        uint8  \n",
      " 432   naics_313310                        uint8  \n",
      " 433   naics_313320                        uint8  \n",
      " 434   naics_314110                        uint8  \n",
      " 435   naics_314120                        uint8  \n",
      " 436   naics_314994                        uint8  \n",
      " 437   naics_314999                        uint8  \n",
      " 438   naics_315110                        uint8  \n",
      " 439   naics_315190                        uint8  \n",
      " 440   naics_315220                        uint8  \n",
      " 441   naics_315240                        uint8  \n",
      " 442   naics_315990                        uint8  \n",
      " 443   naics_316110                        uint8  \n",
      " 444   naics_316210                        uint8  \n",
      " 445   naics_316998                        uint8  \n",
      " 446   naics_321113                        uint8  \n",
      " 447   naics_321219                        uint8  \n",
      " 448   naics_321911                        uint8  \n",
      " 449   naics_321920                        uint8  \n",
      " 450   naics_321992                        uint8  \n",
      " 451   naics_321999                        uint8  \n",
      " 452   naics_322121                        uint8  \n",
      " 453   naics_322122                        uint8  \n",
      " 454   naics_322130                        uint8  \n",
      " 455   naics_322212                        uint8  \n",
      " 456   naics_322219                        uint8  \n",
      " 457   naics_322220                        uint8  \n",
      " 458   naics_322291                        uint8  \n",
      " 459   naics_322299                        uint8  \n",
      " 460   naics_323110                        uint8  \n",
      " 461   naics_323111                        uint8  \n",
      " 462   naics_324110                        uint8  \n",
      " 463   naics_324121                        uint8  \n",
      " 464   naics_324191                        uint8  \n",
      " 465   naics_324199                        uint8  \n",
      " 466   naics_325110                        uint8  \n",
      " 467   naics_325120                        uint8  \n",
      " 468   naics_325130                        uint8  \n",
      " 469   naics_325180                        uint8  \n",
      " 470   naics_325182                        uint8  \n",
      " 471   naics_325194                        uint8  \n",
      " 472   naics_325199                        uint8  \n",
      " 473   naics_325211                        uint8  \n",
      " 474   naics_325212                        uint8  \n",
      " 475   naics_325220                        uint8  \n",
      " 476   naics_325311                        uint8  \n",
      " 477   naics_325312                        uint8  \n",
      " 478   naics_325320                        uint8  \n",
      " 479   naics_325411                        uint8  \n",
      " 480   naics_325412                        uint8  \n",
      " 481   naics_325413                        uint8  \n",
      " 482   naics_325414                        uint8  \n",
      " 483   naics_325510                        uint8  \n",
      " 484   naics_325520                        uint8  \n",
      " 485   naics_325611                        uint8  \n",
      " 486   naics_325620                        uint8  \n",
      " 487   naics_325910                        uint8  \n",
      " 488   naics_325920                        uint8  \n",
      " 489   naics_325992                        uint8  \n",
      " 490   naics_325998                        uint8  \n",
      " 491   naics_326111                        uint8  \n",
      " 492   naics_326113                        uint8  \n",
      " 493   naics_326121                        uint8  \n",
      " 494   naics_326122                        uint8  \n",
      " 495   naics_326140                        uint8  \n",
      " 496   naics_326150                        uint8  \n",
      " 497   naics_326160                        uint8  \n",
      " 498   naics_326199                        uint8  \n",
      " 499   naics_326211                        uint8  \n",
      " 500   naics_326220                        uint8  \n",
      " 501   naics_326291                        uint8  \n",
      " 502   naics_326299                        uint8  \n",
      " 503   naics_327110                        uint8  \n",
      " 504   naics_327120                        uint8  \n",
      " 505   naics_327122                        uint8  \n",
      " 506   naics_327211                        uint8  \n",
      " 507   naics_327212                        uint8  \n",
      " 508   naics_327213                        uint8  \n",
      " 509   naics_327215                        uint8  \n",
      " 510   naics_327310                        uint8  \n",
      " 511   naics_327320                        uint8  \n",
      " 512   naics_327331                        uint8  \n",
      " 513   naics_327332                        uint8  \n",
      " 514   naics_327390                        uint8  \n",
      " 515   naics_327420                        uint8  \n",
      " 516   naics_327910                        uint8  \n",
      " 517   naics_327991                        uint8  \n",
      " 518   naics_327993                        uint8  \n",
      " 519   naics_327999                        uint8  \n",
      " 520   naics_331110                        uint8  \n",
      " 521   naics_331210                        uint8  \n",
      " 522   naics_331221                        uint8  \n",
      " 523   naics_331222                        uint8  \n",
      " 524   naics_331313                        uint8  \n",
      " 525   naics_331315                        uint8  \n",
      " 526   naics_331318                        uint8  \n",
      " 527   naics_331410                        uint8  \n",
      " 528   naics_331420                        uint8  \n",
      " 529   naics_331491                        uint8  \n",
      " 530   naics_331492                        uint8  \n",
      " 531   naics_331524                        uint8  \n",
      " 532   naics_331529                        uint8  \n",
      " 533   naics_332111                        uint8  \n",
      " 534   naics_332119                        uint8  \n",
      " 535   naics_332215                        uint8  \n",
      " 536   naics_332216                        uint8  \n",
      " 537   naics_332311                        uint8  \n",
      " 538   naics_332312                        uint8  \n",
      " 539   naics_332321                        uint8  \n",
      " 540   naics_332322                        uint8  \n",
      " 541   naics_332323                        uint8  \n",
      " 542   naics_332410                        uint8  \n",
      " 543   naics_332420                        uint8  \n",
      " 544   naics_332431                        uint8  \n",
      " 545   naics_332439                        uint8  \n",
      " 546   naics_332510                        uint8  \n",
      " 547   naics_332618                        uint8  \n",
      " 548   naics_332721                        uint8  \n",
      " 549   naics_332722                        uint8  \n",
      " 550   naics_332811                        uint8  \n",
      " 551   naics_332812                        uint8  \n",
      " 552   naics_332911                        uint8  \n",
      " 553   naics_332912                        uint8  \n",
      " 554   naics_332913                        uint8  \n",
      " 555   naics_332991                        uint8  \n",
      " 556   naics_332994                        uint8  \n",
      " 557   naics_332999                        uint8  \n",
      " 558   naics_333111                        uint8  \n",
      " 559   naics_333120                        uint8  \n",
      " 560   naics_333131                        uint8  \n",
      " 561   naics_333132                        uint8  \n",
      " 562   naics_333220                        uint8  \n",
      " 563   naics_333241                        uint8  \n",
      " 564   naics_333242                        uint8  \n",
      " 565   naics_333243                        uint8  \n",
      " 566   naics_333244                        uint8  \n",
      " 567   naics_333249                        uint8  \n",
      " 568   naics_333314                        uint8  \n",
      " 569   naics_333315                        uint8  \n",
      " 570   naics_333316                        uint8  \n",
      " 571   naics_333318                        uint8  \n",
      " 572   naics_333413                        uint8  \n",
      " 573   naics_333415                        uint8  \n",
      " 574   naics_333511                        uint8  \n",
      " 575   naics_333514                        uint8  \n",
      " 576   naics_333515                        uint8  \n",
      " 577   naics_333517                        uint8  \n",
      " 578   naics_333611                        uint8  \n",
      " 579   naics_333618                        uint8  \n",
      " 580   naics_333912                        uint8  \n",
      " 581   naics_333914                        uint8  \n",
      " 582   naics_333921                        uint8  \n",
      " 583   naics_333922                        uint8  \n",
      " 584   naics_333923                        uint8  \n",
      " 585   naics_333924                        uint8  \n",
      " 586   naics_333991                        uint8  \n",
      " 587   naics_333992                        uint8  \n",
      " 588   naics_333993                        uint8  \n",
      " 589   naics_333994                        uint8  \n",
      " 590   naics_333996                        uint8  \n",
      " 591   naics_333997                        uint8  \n",
      " 592   naics_333999                        uint8  \n",
      " 593   naics_334111                        uint8  \n",
      " 594   naics_334112                        uint8  \n",
      " 595   naics_334118                        uint8  \n",
      " 596   naics_334119                        uint8  \n",
      " 597   naics_334210                        uint8  \n",
      " 598   naics_334220                        uint8  \n",
      " 599   naics_334290                        uint8  \n",
      " 600   naics_334310                        uint8  \n",
      " 601   naics_334412                        uint8  \n",
      " 602   naics_334413                        uint8  \n",
      " 603   naics_334416                        uint8  \n",
      " 604   naics_334417                        uint8  \n",
      " 605   naics_334418                        uint8  \n",
      " 606   naics_334419                        uint8  \n",
      " 607   naics_334510                        uint8  \n",
      " 608   naics_334511                        uint8  \n",
      " 609   naics_334512                        uint8  \n",
      " 610   naics_334513                        uint8  \n",
      " 611   naics_334514                        uint8  \n",
      " 612   naics_334515                        uint8  \n",
      " 613   naics_334516                        uint8  \n",
      " 614   naics_334517                        uint8  \n",
      " 615   naics_334519                        uint8  \n",
      " 616   naics_334613                        uint8  \n",
      " 617   naics_334614                        uint8  \n",
      " 618   naics_335110                        uint8  \n",
      " 619   naics_335122                        uint8  \n",
      " 620   naics_335129                        uint8  \n",
      " 621   naics_335210                        uint8  \n",
      " 622   naics_335220                        uint8  \n",
      " 623   naics_335311                        uint8  \n",
      " 624   naics_335312                        uint8  \n",
      " 625   naics_335313                        uint8  \n",
      " 626   naics_335314                        uint8  \n",
      " 627   naics_335911                        uint8  \n",
      " 628   naics_335912                        uint8  \n",
      " 629   naics_335921                        uint8  \n",
      " 630   naics_335929                        uint8  \n",
      " 631   naics_335931                        uint8  \n",
      " 632   naics_335932                        uint8  \n",
      " 633   naics_335991                        uint8  \n",
      " 634   naics_335999                        uint8  \n",
      " 635   naics_336111                        uint8  \n",
      " 636   naics_336112                        uint8  \n",
      " 637   naics_336120                        uint8  \n",
      " 638   naics_336211                        uint8  \n",
      " 639   naics_336212                        uint8  \n",
      " 640   naics_336310                        uint8  \n",
      " 641   naics_336320                        uint8  \n",
      " 642   naics_336330                        uint8  \n",
      " 643   naics_336340                        uint8  \n",
      " 644   naics_336350                        uint8  \n",
      " 645   naics_336360                        uint8  \n",
      " 646   naics_336370                        uint8  \n",
      " 647   naics_336390                        uint8  \n",
      " 648   naics_336411                        uint8  \n",
      " 649   naics_336412                        uint8  \n",
      " 650   naics_336413                        uint8  \n",
      " 651   naics_336414                        uint8  \n",
      " 652   naics_336510                        uint8  \n",
      " 653   naics_336611                        uint8  \n",
      " 654   naics_336991                        uint8  \n",
      " 655   naics_337110                        uint8  \n",
      " 656   naics_337121                        uint8  \n",
      " 657   naics_337122                        uint8  \n",
      " 658   naics_337127                        uint8  \n",
      " 659   naics_337211                        uint8  \n",
      " 660   naics_337214                        uint8  \n",
      " 661   naics_337910                        uint8  \n",
      " 662   naics_339112                        uint8  \n",
      " 663   naics_339113                        uint8  \n",
      " 664   naics_339114                        uint8  \n",
      " 665   naics_339115                        uint8  \n",
      " 666   naics_339910                        uint8  \n",
      " 667   naics_339911                        uint8  \n",
      " 668   naics_339920                        uint8  \n",
      " 669   naics_339930                        uint8  \n",
      " 670   naics_339940                        uint8  \n",
      " 671   naics_339991                        uint8  \n",
      " 672   naics_339992                        uint8  \n",
      " 673   naics_339993                        uint8  \n",
      " 674   naics_339999                        uint8  \n",
      " 675   naics_423110                        uint8  \n",
      " 676   naics_423120                        uint8  \n",
      " 677   naics_423310                        uint8  \n",
      " 678   naics_423390                        uint8  \n",
      " 679   naics_423420                        uint8  \n",
      " 680   naics_423430                        uint8  \n",
      " 681   naics_423450                        uint8  \n",
      " 682   naics_423510                        uint8  \n",
      " 683   naics_423520                        uint8  \n",
      " 684   naics_423610                        uint8  \n",
      " 685   naics_423690                        uint8  \n",
      " 686   naics_423710                        uint8  \n",
      " 687   naics_423720                        uint8  \n",
      " 688   naics_423810                        uint8  \n",
      " 689   naics_423910                        uint8  \n",
      " 690   naics_423930                        uint8  \n",
      " 691   naics_423940                        uint8  \n",
      " 692   naics_423990                        uint8  \n",
      " 693   naics_424130                        uint8  \n",
      " 694   naics_424210                        uint8  \n",
      " 695   naics_424310                        uint8  \n",
      " 696   naics_424480                        uint8  \n",
      " 697   naics_424490                        uint8  \n",
      " 698   naics_424510                        uint8  \n",
      " 699   naics_424590                        uint8  \n",
      " 700   naics_424690                        uint8  \n",
      " 701   naics_424710                        uint8  \n",
      " 702   naics_424720                        uint8  \n",
      " 703   naics_424910                        uint8  \n",
      " 704   naics_424920                        uint8  \n",
      " 705   naics_424940                        uint8  \n",
      " 706   naics_424950                        uint8  \n",
      " 707   naics_425110                        uint8  \n",
      " 708   naics_441110                        uint8  \n",
      " 709   naics_441310                        uint8  \n",
      " 710   naics_442110                        uint8  \n",
      " 711   naics_443120                        uint8  \n",
      " 712   naics_443141                        uint8  \n",
      " 713   naics_443142                        uint8  \n",
      " 714   naics_444110                        uint8  \n",
      " 715   naics_445110                        uint8  \n",
      " 716   naics_445120                        uint8  \n",
      " 717   naics_445310                        uint8  \n",
      " 718   naics_446110                        uint8  \n",
      " 719   naics_446120                        uint8  \n",
      " 720   naics_446130                        uint8  \n",
      " 721   naics_446199                        uint8  \n",
      " 722   naics_447110                        uint8  \n",
      " 723   naics_447190                        uint8  \n",
      " 724   naics_448120                        uint8  \n",
      " 725   naics_448130                        uint8  \n",
      " 726   naics_448140                        uint8  \n",
      " 727   naics_448310                        uint8  \n",
      " 728   naics_451110                        uint8  \n",
      " 729   naics_451120                        uint8  \n",
      " 730   naics_452111                        uint8  \n",
      " 731   naics_452210                        uint8  \n",
      " 732   naics_452311                        uint8  \n",
      " 733   naics_452319                        uint8  \n",
      " 734   naics_452910                        uint8  \n",
      " 735   naics_452990                        uint8  \n",
      " 736   naics_453910                        uint8  \n",
      " 737   naics_453998                        uint8  \n",
      " 738   naics_454110                        uint8  \n",
      " 739   naics_454310                        uint8  \n",
      " 740   naics_458110                        uint8  \n",
      " 741   naics_459999                        uint8  \n",
      " 742   naics_481111                        uint8  \n",
      " 743   naics_481211                        uint8  \n",
      " 744   naics_482111                        uint8  \n",
      " 745   naics_483111                        uint8  \n",
      " 746   naics_483112                        uint8  \n",
      " 747   naics_483114                        uint8  \n",
      " 748   naics_483211                        uint8  \n",
      " 749   naics_484121                        uint8  \n",
      " 750   naics_484220                        uint8  \n",
      " 751   naics_485111                        uint8  \n",
      " 752   naics_485112                        uint8  \n",
      " 753   naics_485210                        uint8  \n",
      " 754   naics_485310                        uint8  \n",
      " 755   naics_486110                        uint8  \n",
      " 756   naics_486210                        uint8  \n",
      " 757   naics_486990                        uint8  \n",
      " 758   naics_488111                        uint8  \n",
      " 759   naics_488119                        uint8  \n",
      " 760   naics_488190                        uint8  \n",
      " 761   naics_488310                        uint8  \n",
      " 762   naics_488320                        uint8  \n",
      " 763   naics_488390                        uint8  \n",
      " 764   naics_488490                        uint8  \n",
      " 765   naics_488510                        uint8  \n",
      " 766   naics_492110                        uint8  \n",
      " 767   naics_511110                        uint8  \n",
      " 768   naics_511130                        uint8  \n",
      " 769   naics_511140                        uint8  \n",
      " 770   naics_511199                        uint8  \n",
      " 771   naics_511210                        uint8  \n",
      " 772   naics_512110                        uint8  \n",
      " 773   naics_512120                        uint8  \n",
      " 774   naics_512131                        uint8  \n",
      " 775   naics_512199                        uint8  \n",
      " 776   naics_512250                        uint8  \n",
      " 777   naics_515112                        uint8  \n",
      " 778   naics_515120                        uint8  \n",
      " 779   naics_515210                        uint8  \n",
      " 780   naics_516120                        uint8  \n",
      " 781   naics_516210                        uint8  \n",
      " 782   naics_517110                        uint8  \n",
      " 783   naics_517112                        uint8  \n",
      " 784   naics_517210                        uint8  \n",
      " 785   naics_517212                        uint8  \n",
      " 786   naics_517311                        uint8  \n",
      " 787   naics_517312                        uint8  \n",
      " 788   naics_517410                        uint8  \n",
      " 789   naics_517510                        uint8  \n",
      " 790   naics_517919                        uint8  \n",
      " 791   naics_518210                        uint8  \n",
      " 792   naics_519130                        uint8  \n",
      " 793   naics_522291                        uint8  \n",
      " 794   naics_532111                        uint8  \n",
      " 795   naics_532120                        uint8  \n",
      " 796   naics_532411                        uint8  \n",
      " 797   naics_532412                        uint8  \n",
      " 798   naics_532420                        uint8  \n",
      " 799   naics_533110                        uint8  \n",
      " 800   naics_541110                        uint8  \n",
      " 801   naics_541310                        uint8  \n",
      " 802   naics_541320                        uint8  \n",
      " 803   naics_541330                        uint8  \n",
      " 804   naics_541360                        uint8  \n",
      " 805   naics_541380                        uint8  \n",
      " 806   naics_541410                        uint8  \n",
      " 807   naics_541430                        uint8  \n",
      " 808   naics_541511                        uint8  \n",
      " 809   naics_541512                        uint8  \n",
      " 810   naics_541519                        uint8  \n",
      " 811   naics_541611                        uint8  \n",
      " 812   naics_541612                        uint8  \n",
      " 813   naics_541614                        uint8  \n",
      " 814   naics_541618                        uint8  \n",
      " 815   naics_541810                        uint8  \n",
      " 816   naics_541850                        uint8  \n",
      " 817   naics_561210                        uint8  \n",
      " 818   naics_561311                        uint8  \n",
      " 819   naics_561421                        uint8  \n",
      " 820   naics_561422                        uint8  \n",
      " 821   naics_561440                        uint8  \n",
      " 822   naics_561450                        uint8  \n",
      " 823   naics_561499                        uint8  \n",
      " 824   naics_561510                        uint8  \n",
      " 825   naics_561520                        uint8  \n",
      " 826   naics_561599                        uint8  \n",
      " 827   naics_561612                        uint8  \n",
      " 828   naics_561621                        uint8  \n",
      " 829   naics_561710                        uint8  \n",
      " 830   naics_561720                        uint8  \n",
      " 831   naics_561730                        uint8  \n",
      " 832   naics_561920                        uint8  \n",
      " 833   naics_561990                        uint8  \n",
      " 834   naics_562111                        uint8  \n",
      " 835   naics_562112                        uint8  \n",
      " 836   naics_562119                        uint8  \n",
      " 837   naics_562211                        uint8  \n",
      " 838   naics_562910                        uint8  \n",
      " 839   naics_562920                        uint8  \n",
      " 840   naics_611110                        uint8  \n",
      " 841   naics_611519                        uint8  \n",
      " 842   naics_611692                        uint8  \n",
      " 843   naics_621492                        uint8  \n",
      " 844   naics_621493                        uint8  \n",
      " 845   naics_621498                        uint8  \n",
      " 846   naics_621511                        uint8  \n",
      " 847   naics_621512                        uint8  \n",
      " 848   naics_621991                        uint8  \n",
      " 849   naics_622110                        uint8  \n",
      " 850   naics_622310                        uint8  \n",
      " 851   naics_623110                        uint8  \n",
      " 852   naics_623311                        uint8  \n",
      " 853   naics_623312                        uint8  \n",
      " 854   naics_711211                        uint8  \n",
      " 855   naics_711212                        uint8  \n",
      " 856   naics_711310                        uint8  \n",
      " 857   naics_711410                        uint8  \n",
      " 858   naics_713110                        uint8  \n",
      " 859   naics_713210                        uint8  \n",
      " 860   naics_713290                        uint8  \n",
      " 861   naics_713920                        uint8  \n",
      " 862   naics_713940                        uint8  \n",
      " 863   naics_713990                        uint8  \n",
      " 864   naics_721110                        uint8  \n",
      " 865   naics_721120                        uint8  \n",
      " 866   naics_721199                        uint8  \n",
      " 867   naics_722310                        uint8  \n",
      " 868   naics_722320                        uint8  \n",
      " 869   naics_722410                        uint8  \n",
      " 870   naics_722511                        uint8  \n",
      " 871   naics_722513                        uint8  \n",
      " 872   naics_811198                        uint8  \n",
      " 873   naics_811212                        uint8  \n",
      " 874   naics_811310                        uint8  \n",
      " 875   naics_812111                        uint8  \n",
      " 876   naics_812199                        uint8  \n",
      " 877   naics_812210                        uint8  \n",
      " 878   naics_812220                        uint8  \n",
      " 879   naics_812921                        uint8  \n",
      " 880   naics_999977                        uint8  \n",
      " 881   naics_999988                        uint8  \n",
      " 882   loc_ARE                             uint8  \n",
      " 883   loc_ARG                             uint8  \n",
      " 884   loc_AUS                             uint8  \n",
      " 885   loc_AUT                             uint8  \n",
      " 886   loc_BEL                             uint8  \n",
      " 887   loc_BGD                             uint8  \n",
      " 888   loc_BGR                             uint8  \n",
      " 889   loc_BMU                             uint8  \n",
      " 890   loc_BRA                             uint8  \n",
      " 891   loc_CHE                             uint8  \n",
      " 892   loc_CHL                             uint8  \n",
      " 893   loc_CHN                             uint8  \n",
      " 894   loc_COL                             uint8  \n",
      " 895   loc_CYM                             uint8  \n",
      " 896   loc_CYP                             uint8  \n",
      " 897   loc_DEU                             uint8  \n",
      " 898   loc_DNK                             uint8  \n",
      " 899   loc_EGY                             uint8  \n",
      " 900   loc_ESP                             uint8  \n",
      " 901   loc_EST                             uint8  \n",
      " 902   loc_FIN                             uint8  \n",
      " 903   loc_FRA                             uint8  \n",
      " 904   loc_GBR                             uint8  \n",
      " 905   loc_GGY                             uint8  \n",
      " 906   loc_GRC                             uint8  \n",
      " 907   loc_HKG                             uint8  \n",
      " 908   loc_HRV                             uint8  \n",
      " 909   loc_HUN                             uint8  \n",
      " 910   loc_IDN                             uint8  \n",
      " 911   loc_IND                             uint8  \n",
      " 912   loc_IRL                             uint8  \n",
      " 913   loc_ISL                             uint8  \n",
      " 914   loc_ISR                             uint8  \n",
      " 915   loc_ITA                             uint8  \n",
      " 916   loc_JEY                             uint8  \n",
      " 917   loc_KAZ                             uint8  \n",
      " 918   loc_KOR                             uint8  \n",
      " 919   loc_KWT                             uint8  \n",
      " 920   loc_LKA                             uint8  \n",
      " 921   loc_LTU                             uint8  \n",
      " 922   loc_LUX                             uint8  \n",
      " 923   loc_LVA                             uint8  \n",
      " 924   loc_MAR                             uint8  \n",
      " 925   loc_MEX                             uint8  \n",
      " 926   loc_MYS                             uint8  \n",
      " 927   loc_NGA                             uint8  \n",
      " 928   loc_NLD                             uint8  \n",
      " 929   loc_NOR                             uint8  \n",
      " 930   loc_OMN                             uint8  \n",
      " 931   loc_PAK                             uint8  \n",
      " 932   loc_PER                             uint8  \n",
      " 933   loc_PHL                             uint8  \n",
      " 934   loc_POL                             uint8  \n",
      " 935   loc_PRT                             uint8  \n",
      " 936   loc_ROU                             uint8  \n",
      " 937   loc_RUS                             uint8  \n",
      " 938   loc_SAU                             uint8  \n",
      " 939   loc_SGP                             uint8  \n",
      " 940   loc_SRB                             uint8  \n",
      " 941   loc_SVN                             uint8  \n",
      " 942   loc_SWE                             uint8  \n",
      " 943   loc_THA                             uint8  \n",
      " 944   loc_TUN                             uint8  \n",
      " 945   loc_TUR                             uint8  \n",
      " 946   loc_TWN                             uint8  \n",
      " 947   loc_UKR                             uint8  \n",
      " 948   loc_USA                             uint8  \n",
      " 949   loc_VNM                             uint8  \n",
      " 950   loc_ZAF                             uint8  \n",
      " 951   city_6th of October City            uint8  \n",
      " 952   city_ALesund                        uint8  \n",
      " 953   city_Aberdeen                       uint8  \n",
      " 954   city_Abingdon                       uint8  \n",
      " 955   city_Abu Dhabi                      uint8  \n",
      " 956   city_Abuja                          uint8  \n",
      " 957   city_Acharnes                       uint8  \n",
      " 958   city_Adana                          uint8  \n",
      " 959   city_Adelaide                       uint8  \n",
      " 960   city_Admiralty                      uint8  \n",
      " 961   city_Agia Paraskevi                 uint8  \n",
      " 962   city_Ahrensburg                     uint8  \n",
      " 963   city_Aimargues                      uint8  \n",
      " 964   city_Airport City                   uint8  \n",
      " 965   city_Aix-en-Provence                uint8  \n",
      " 966   city_Aksu                           uint8  \n",
      " 967   city_Alcobendas                     uint8  \n",
      " 968   city_Aldan                          uint8  \n",
      " 969   city_Alencon                        uint8  \n",
      " 970   city_Alesund                        uint8  \n",
      " 971   city_Alexandria                     uint8  \n",
      " 972   city_Alges                          uint8  \n",
      " 973   city_Alimos                         uint8  \n",
      " 974   city_Almelo                         uint8  \n",
      " 975   city_Almere                         uint8  \n",
      " 976   city_Almeria                        uint8  \n",
      " 977   city_Alphen aan den Rijn            uint8  \n",
      " 978   city_Altdorf                        uint8  \n",
      " 979   city_Alxa Zuoqi                     uint8  \n",
      " 980   city_Amaro                          uint8  \n",
      " 981   city_Amersfoort                     uint8  \n",
      " 982   city_Amersham                       uint8  \n",
      " 983   city_Amsterdam                      uint8  \n",
      " 984   city_Ancenis                        uint8  \n",
      " 985   city_Ankara                         uint8  \n",
      " 986   city_Anqing                         uint8  \n",
      " 987   city_Ansan                          uint8  \n",
      " 988   city_Ansan-Si                       uint8  \n",
      " 989   city_Anshan                         uint8  \n",
      " 990   city_Anshun                         uint8  \n",
      " 991   city_Anteuil                        uint8  \n",
      " 992   city_Antofagasta                    uint8  \n",
      " 993   city_Antwerp                        uint8  \n",
      " 994   city_Anyang                         uint8  \n",
      " 995   city_Anyang-Si                      uint8  \n",
      " 996   city_Arbon                          uint8  \n",
      " 997   city_Arco                           uint8  \n",
      " 998   city_Arica                          uint8  \n",
      " 999   city_Aschaffenburg                  uint8  \n",
      " 1000  city_Aseda                          uint8  \n",
      " 1001  city_Ashdod                         uint8  \n",
      " 1002  city_Aspropyrgos                    uint8  \n",
      " 1003  city_Assago                         uint8  \n",
      " 1004  city_Athens                         uint8  \n",
      " 1005  city_Augsburg                       uint8  \n",
      " 1006  city_Avlona                         uint8  \n",
      " 1007  city_Aydin                          uint8  \n",
      " 1008  city_Baar                           uint8  \n",
      " 1009  city_Bad Homburg                    uint8  \n",
      " 1010  city_Bad Homburg vor der Hohe       uint8  \n",
      " 1011  city_Bad Neustadt an der Saale      uint8  \n",
      " 1012  city_Bad Wurzach                    uint8  \n",
      " 1013  city_Badalona                       uint8  \n",
      " 1014  city_Baerum                         uint8  \n",
      " 1015  city_Bagneux                        uint8  \n",
      " 1016  city_Baiyin                         uint8  \n",
      " 1017  city_Ballerup                       uint8  \n",
      " 1018  city_Bandung                        uint8  \n",
      " 1019  city_Bang Bo                        uint8  \n",
      " 1020  city_Bang Bua Thong                 uint8  \n",
      " 1021  city_Bang Klam                      uint8  \n",
      " 1022  city_Bang Kruai                     uint8  \n",
      " 1023  city_Bang Phli                      uint8  \n",
      " 1024  city_Bangkok                        uint8  \n",
      " 1025  city_Bannu                          uint8  \n",
      " 1026  city_Baoding                        uint8  \n",
      " 1027  city_Baoji                          uint8  \n",
      " 1028  city_Baotou                         uint8  \n",
      " 1029  city_Baoying                        uint8  \n",
      " 1030  city_Barcelona                      uint8  \n",
      " 1031  city_Barranquilla                   uint8  \n",
      " 1032  city_Barrow-in-Furness              uint8  \n",
      " 1033  city_Barueri                        uint8  \n",
      " 1034  city_Basel                          uint8  \n",
      " 1035  city_Basingstoke                    uint8  \n",
      " 1036  city_Bastad                         uint8  \n",
      " 1037  city_Bat Yam                        uint8  \n",
      " 1038  city_Batu Caves                     uint8  \n",
      " 1039  city_Be'erot Yitzhak                uint8  \n",
      " 1040  city_Beasain                        uint8  \n",
      " 1041  city_Beihai                         uint8  \n",
      " 1042  city_Beijing                        uint8  \n",
      " 1043  city_Beinan                         uint8  \n",
      " 1044  city_Bekasi                         uint8  \n",
      " 1045  city_Belfort                        uint8  \n",
      " 1046  city_Belgrade                       uint8  \n",
      " 1047  city_Bello                          uint8  \n",
      " 1048  city_Bellville                      uint8  \n",
      " 1049  city_Belo Horizonte                 uint8  \n",
      " 1050  city_Ben Arous                      uint8  \n",
      " 1051  city_Ben Luc                        uint8  \n",
      " 1052  city_Bengaluru                      uint8  \n",
      " 1053  city_Bengbu                         uint8  \n",
      " 1054  city_Bergamo                        uint8  \n",
      " 1055  city_Bergen                         uint8  \n",
      " 1056  city_Bergheim                       uint8  \n",
      " 1057  city_Berlin                         uint8  \n",
      " 1058  city_Bialystok                      uint8  \n",
      " 1059  city_Bibbiano                       uint8  \n",
      " 1060  city_Bielany Wroclawskie            uint8  \n",
      " 1061  city_Bielefeld                      uint8  \n",
      " 1062  city_Bielsk Podlaski                uint8  \n",
      " 1063  city_Bielsko-Biala                  uint8  \n",
      " 1064  city_Bien Hoa                       uint8  \n",
      " 1065  city_Bierun                         uint8  \n",
      " 1066  city_Bietigheim-Bissingen           uint8  \n",
      " 1067  city_Bilbao                         uint8  \n",
      " 1068  city_Binh Xuyen                     uint8  \n",
      " 1069  city_Binzhou                        uint8  \n",
      " 1070  city_Birmingham                     uint8  \n",
      " 1071  city_Bistrita                       uint8  \n",
      " 1072  city_Bizerte                        uint8  \n",
      " 1073  city_Blagnac                        uint8  \n",
      " 1074  city_Bloemfontein                   uint8  \n",
      " 1075  city_Bnei Ayish                     uint8  \n",
      " 1076  city_Bnei Brak                      uint8  \n",
      " 1077  city_Bochnia                        uint8  \n",
      " 1078  city_Bogor                          uint8  \n",
      " 1079  city_Bogota                         uint8  \n",
      " 1080  city_Bollate                        uint8  \n",
      " 1081  city_Bologna                        uint8  \n",
      " 1082  city_Bordeaux                       uint8  \n",
      " 1083  city_Bornheim                       uint8  \n",
      " 1084  city_Boulogne                       uint8  \n",
      " 1085  city_Boulogne-Billancourt           uint8  \n",
      " 1086  city_Brackenfell                    uint8  \n",
      " 1087  city_Bradford                       uint8  \n",
      " 1088  city_Brasov                         uint8  \n",
      " 1089  city_Bremen                         uint8  \n",
      " 1090  city_Brentford                      uint8  \n",
      " 1091  city_Brescia                        uint8  \n",
      " 1092  city_Brilon                         uint8  \n",
      " 1093  city_Bristol                        uint8  \n",
      " 1094  city_Brunnthal                      uint8  \n",
      " 1095  city_Brussels                       uint8  \n",
      " 1096  city_Brwinow                        uint8  \n",
      " 1097  city_Bryanston                      uint8  \n",
      " 1098  city_Brzeg Dolny                    uint8  \n",
      " 1099  city_Bubendorf                      uint8  \n",
      " 1100  city_Bucharest                      uint8  \n",
      " 1101  city_Budapest                       uint8  \n",
      " 1102  city_Buenos Aires                   uint8  \n",
      " 1103  city_Bunnik                         uint8  \n",
      " 1104  city_Burgos                         uint8  \n",
      " 1105  city_Buriram                        uint8  \n",
      " 1106  city_Bursa                          uint8  \n",
      " 1107  city_Burton Upon Trent              uint8  \n",
      " 1108  city_Busan                          uint8  \n",
      " 1109  city_Buttrio                        uint8  \n",
      " 1110  city_Buzau                          uint8  \n",
      " 1111  city_Bydgoszcz                      uint8  \n",
      " 1112  city_Ca Mau                         uint8  \n",
      " 1113  city_Cairo                          uint8  \n",
      " 1114  city_Caissargues                    uint8  \n",
      " 1115  city_Calenzano                      uint8  \n",
      " 1116  city_Cali                           uint8  \n",
      " 1117  city_Camacari                       uint8  \n",
      " 1118  city_Camana Bay                     uint8  \n",
      " 1119  city_Cambiano                       uint8  \n",
      " 1120  city_Cambridge                      uint8  \n",
      " 1121  city_Campodarsego                   uint8  \n",
      " 1122  city_Can Tho                        uint8  \n",
      " 1123  city_Cangzhou                       uint8  \n",
      " 1124  city_Cannes                         uint8  \n",
      " 1125  city_Cao Lanh                       uint8  \n",
      " 1126  city_Cape Town                      uint8  \n",
      " 1127  city_Carbon-Blanc                   uint8  \n",
      " 1128  city_Carros                         uint8  \n",
      " 1129  city_Cartavio                       uint8  \n",
      " 1130  city_Casablanca                     uint8  \n",
      " 1131  city_Casale Monferrato              uint8  \n",
      " 1132  city_Cataguases                     uint8  \n",
      " 1133  city_Causeway Bay                   uint8  \n",
      " 1134  city_Cavite                         uint8  \n",
      " 1135  city_Cavriago                       uint8  \n",
      " 1136  city_Central                        uint8  \n",
      " 1137  city_Centurion                      uint8  \n",
      " 1138  city_Ceresara                       uint8  \n",
      " 1139  city_Cergy-Pontoise                 uint8  \n",
      " 1140  city_Cesena                         uint8  \n",
      " 1141  city_Chai Wan                       uint8  \n",
      " 1142  city_Chailley                       uint8  \n",
      " 1143  city_Chalandri                      uint8  \n",
      " 1144  city_Champfromier                   uint8  \n",
      " 1145  city_Changchun                      uint8  \n",
      " 1146  city_Changde                        uint8  \n",
      " 1147  city_Changhua                       uint8  \n",
      " 1148  city_Changhua City                  uint8  \n",
      " 1149  city_Changji                        uint8  \n",
      " 1150  city_Changsha                       uint8  \n",
      " 1151  city_Changshu                       uint8  \n",
      " 1152  city_Changwon-Si                    uint8  \n",
      " 1153  city_Changxing                      uint8  \n",
      " 1154  city_Changzhi                       uint8  \n",
      " 1155  city_Changzhou                      uint8  \n",
      " 1156  city_Chantepie                      uint8  \n",
      " 1157  city_Chaohu                         uint8  \n",
      " 1158  city_Chaoyang                       uint8  \n",
      " 1159  city_Chaozhou                       uint8  \n",
      " 1160  city_Charenton-le-Pont              uint8  \n",
      " 1161  city_Chatuchak                      uint8  \n",
      " 1162  city_Chengdu                        uint8  \n",
      " 1163  city_Chengxi                        uint8  \n",
      " 1164  city_Chennai                        uint8  \n",
      " 1165  city_Chenzhou                       uint8  \n",
      " 1166  city_Cheonan-si                     uint8  \n",
      " 1167  city_Cheongju                       uint8  \n",
      " 1168  city_Cheongju-Si                    uint8  \n",
      " 1169  city_Chertsey                       uint8  \n",
      " 1170  city_Cheseaux-sur-Lausanne          uint8  \n",
      " 1171  city_Cheung Sha Wan                 uint8  \n",
      " 1172  city_Chia-Yi                        uint8  \n",
      " 1173  city_Chiayi                         uint8  \n",
      " 1174  city_Chiayi City                    uint8  \n",
      " 1175  city_Chifeng                        uint8  \n",
      " 1176  city_Chihuahua                      uint8  \n",
      " 1177  city_Chippenham                     uint8  \n",
      " 1178  city_Chita                          uint8  \n",
      " 1179  city_Chittagong                     uint8  \n",
      " 1180  city_Chizhou                        uint8  \n",
      " 1181  city_Chojnice                       uint8  \n",
      " 1182  city_Chojnow                        uint8  \n",
      " 1183  city_Chonburi                       uint8  \n",
      " 1184  city_Chongqing                      uint8  \n",
      " 1185  city_Chu-Nan                        uint8  \n",
      " 1186  city_Chun'an                        uint8  \n",
      " 1187  city_Chuzhou                        uint8  \n",
      " 1188  city_Cimahi                         uint8  \n",
      " 1189  city_City Of Industry               uint8  \n",
      " 1190  city_Cixi                           uint8  \n",
      " 1191  city_Clamart                        uint8  \n",
      " 1192  city_Clermont-Ferrand               uint8  \n",
      " 1193  city_Clichy                         uint8  \n",
      " 1194  city_Cluj-Napoca                    uint8  \n",
      " 1195  city_Coalville                      uint8  \n",
      " 1196  city_Cognac                         uint8  \n",
      " 1197  city_Colleferro                     uint8  \n",
      " 1198  city_Collegno                       uint8  \n",
      " 1199  city_Cologne                        uint8  \n",
      " 1200  city_Colombes                       uint8  \n",
      " 1201  city_Colombo                        uint8  \n",
      " 1202  city_Como                           uint8  \n",
      " 1203  city_Concepcion                     uint8  \n",
      " 1204  city_Constanta                      uint8  \n",
      " 1205  city_Copenhagen                     uint8  \n",
      " 1206  city_Cornelio Procopio              uint8  \n",
      " 1207  city_Correggio                      uint8  \n",
      " 1208  city_Courbevoie                     uint8  \n",
      " 1209  city_Crawley                        uint8  \n",
      " 1210  city_Cruzeiro                       uint8  \n",
      " 1211  city_Cuautitlan                     uint8  \n",
      " 1212  city_Curitiba                       uint8  \n",
      " 1213  city_Czosnow                        uint8  \n",
      " 1214  city_Da Nang                        uint8  \n",
      " 1215  city_Daejeon                        uint8  \n",
      " 1216  city_Dalian                         uint8  \n",
      " 1217  city_Dandenong South                uint8  \n",
      " 1218  city_Dandong                        uint8  \n",
      " 1219  city_Dangyang                       uint8  \n",
      " 1220  city_Danyang                        uint8  \n",
      " 1221  city_Darica                         uint8  \n",
      " 1222  city_Darmstadt                      uint8  \n",
      " 1223  city_Datong                         uint8  \n",
      " 1224  city_Davao                          uint8  \n",
      " 1225  city_De Bilt                        uint8  \n",
      " 1226  city_Decines-Charpieu               uint8  \n",
      " 1227  city_Delbruck                       uint8  \n",
      " 1228  city_Delft                          uint8  \n",
      " 1229  city_Deqing                         uint8  \n",
      " 1230  city_Deyang                         uint8  \n",
      " 1231  city_Dhaka                          uint8  \n",
      " 1232  city_Di An                          uint8  \n",
      " 1233  city_Dilovasi                       uint8  \n",
      " 1234  city_Domat/Ems                      uint8  \n",
      " 1235  city_Dong Phu                       uint8  \n",
      " 1236  city_Dongguan                       uint8  \n",
      " 1237  city_Dongyang                       uint8  \n",
      " 1238  city_Dongying                       uint8  \n",
      " 1239  city_Dopiewo                        uint8  \n",
      " 1240  city_Dornbirn                       uint8  \n",
      " 1241  city_Dortmund                       uint8  \n",
      " 1242  city_Douliou                        uint8  \n",
      " 1243  city_Dreieich                       uint8  \n",
      " 1244  city_Dubai                          uint8  \n",
      " 1245  city_Dublin                         uint8  \n",
      " 1246  city_Duisburg                       uint8  \n",
      " 1247  city_Duiven                         uint8  \n",
      " 1248  city_Dunhua                         uint8  \n",
      " 1249  city_Dunstable                      uint8  \n",
      " 1250  city_Durham                         uint8  \n",
      " 1251  city_Dusseldorf                     uint8  \n",
      " 1252  city_Edinburgh                      uint8  \n",
      " 1253  city_Ehningen                       uint8  \n",
      " 1254  city_Eindhoven                      uint8  \n",
      " 1255  city_Eleusis                        uint8  \n",
      " 1256  city_Elliniko                       uint8  \n",
      " 1257  city_Empoli                         uint8  \n",
      " 1258  city_Enderby                        uint8  \n",
      " 1259  city_Envigado                       uint8  \n",
      " 1260  city_Epsom                          uint8  \n",
      " 1261  city_Escobar                        uint8  \n",
      " 1262  city_Esher                          uint8  \n",
      " 1263  city_Espoo                          uint8  \n",
      " 1264  city_Essen                          uint8  \n",
      " 1265  city_Etival-Clairefontaine          uint8  \n",
      " 1266  city_Exeter                         uint8  \n",
      " 1267  city_Eyguieres                      uint8  \n",
      " 1268  city_Fabriano                       uint8  \n",
      " 1269  city_Faisalabad                     uint8  \n",
      " 1270  city_Farnborough                    uint8  \n",
      " 1271  city_Faverges                       uint8  \n",
      " 1272  city_Fehraltorf                     uint8  \n",
      " 1273  city_Fengcheng                      uint8  \n",
      " 1274  city_Fenghua                        uint8  \n",
      " 1275  city_Fenyang                        uint8  \n",
      " 1276  city_Flamatt                        uint8  \n",
      " 1277  city_Flintshire                     uint8  \n",
      " 1278  city_Florence                       uint8  \n",
      " 1279  city_Fo Tan                         uint8  \n",
      " 1280  city_Formello                       uint8  \n",
      " 1281  city_Fornebu                        uint8  \n",
      " 1282  city_Forslov                        uint8  \n",
      " 1283  city_Foshan                         uint8  \n",
      " 1284  city_Fosnavag                       uint8  \n",
      " 1285  city_Fossalta Di Portogruaro        uint8  \n",
      " 1286  city_Frankenthal                    uint8  \n",
      " 1287  city_Frankfurt                      uint8  \n",
      " 1288  city_Frankfurt Am Main              uint8  \n",
      " 1289  city_Frankfurt am Main              uint8  \n",
      " 1290  city_Freiburg                       uint8  \n",
      " 1291  city_Freudenstadt                   uint8  \n",
      " 1292  city_Fuqing                         uint8  \n",
      " 1293  city_Fuquan                         uint8  \n",
      " 1294  city_Fushun                         uint8  \n",
      " 1295  city_Fuyang                         uint8  \n",
      " 1296  city_Fuzhou                         uint8  \n",
      " 1297  city_GOTeborg                       uint8  \n",
      " 1298  city_Galaxidi                       uint8  \n",
      " 1299  city_Ganzhou                        uint8  \n",
      " 1300  city_Gaomi                          uint8  \n",
      " 1301  city_Garcia                         uint8  \n",
      " 1302  city_Gaziantep                      uint8  \n",
      " 1303  city_Gdansk                         uint8  \n",
      " 1304  city_Gdynia                         uint8  \n",
      " 1305  city_Gebze                          uint8  \n",
      " 1306  city_Gejiu                          uint8  \n",
      " 1307  city_Gelsenkirchen                  uint8  \n",
      " 1308  city_Gennevilliers                  uint8  \n",
      " 1309  city_Genoa                          uint8  \n",
      " 1310  city_Geoje                          uint8  \n",
      " 1311  city_George Town                    uint8  \n",
      " 1312  city_Geschwenda                     uint8  \n",
      " 1313  city_Ghala                          uint8  \n",
      " 1314  city_Gits                           uint8  \n",
      " 1315  city_Giza                           uint8  \n",
      " 1316  city_Glasgow                        uint8  \n",
      " 1317  city_Gniezno                        uint8  \n",
      " 1318  city_Golmud                         uint8  \n",
      " 1319  city_Gonesse                        uint8  \n",
      " 1320  city_Gongyi                         uint8  \n",
      " 1321  city_Gothenburg                     uint8  \n",
      " 1322  city_Goyang-si                      uint8  \n",
      " 1323  city_Grajewo                        uint8  \n",
      " 1324  city_Granada                        uint8  \n",
      " 1325  city_Granarolo dell'Emilia          uint8  \n",
      " 1326  city_Grand Cayman                   uint8  \n",
      " 1327  city_Grassobbio                     uint8  \n",
      " 1328  city_Gresik                         uint8  \n",
      " 1329  city_Grevenmacher                   uint8  \n",
      " 1330  city_Grodzisk Mazowiecki            uint8  \n",
      " 1331  city_Grunwald                       uint8  \n",
      " 1332  city_Guadalajara                    uint8  \n",
      " 1333  city_Guangan                        uint8  \n",
      " 1334  city_Guangzhou                      uint8  \n",
      " 1335  city_Guanzate                       uint8  \n",
      " 1336  city_Guarulhos                      uint8  \n",
      " 1337  city_Guigang                        uint8  \n",
      " 1338  city_Guilin                         uint8  \n",
      " 1339  city_Guiyang                        uint8  \n",
      " 1340  city_Gumi-si                        uint8  \n",
      " 1341  city_Gummersbach                    uint8  \n",
      " 1342  city_Gunpo-si                       uint8  \n",
      " 1343  city_Gwangju                        uint8  \n",
      " 1344  city_Ha Long                        uint8  \n",
      " 1345  city_Haaksbergen                    uint8  \n",
      " 1346  city_Habo                           uint8  \n",
      " 1347  city_Hadera                         uint8  \n",
      " 1348  city_Hai Duong                      uint8  \n",
      " 1349  city_Hai phong                      uint8  \n",
      " 1350  city_Haifa                          uint8  \n",
      " 1351  city_Haikou                         uint8  \n",
      " 1352  city_Haimen                         uint8  \n",
      " 1353  city_Haining                        uint8  \n",
      " 1354  city_Halle                          uint8  \n",
      " 1355  city_Halmstad                       uint8  \n",
      " 1356  city_Halol                          uint8  \n",
      " 1357  city_Haman-myeon                    uint8  \n",
      " 1358  city_Hamburg                        uint8  \n",
      " 1359  city_Hancheng                       uint8  \n",
      " 1360  city_Hanchuan                       uint8  \n",
      " 1361  city_Hangzhou                       uint8  \n",
      " 1362  city_Hanoi                          uint8  \n",
      " 1363  city_Hanover                        uint8  \n",
      " 1364  city_Harbin                         uint8  \n",
      " 1365  city_Haselunne                      uint8  \n",
      " 1366  city_Hassleholm                     uint8  \n",
      " 1367  city_Hat Yai                        uint8  \n",
      " 1368  city_Hatay                          uint8  \n",
      " 1369  city_Hatfield                       uint8  \n",
      " 1370  city_Hauzenberg                     uint8  \n",
      " 1371  city_Heerenveen                     uint8  \n",
      " 1372  city_Heerlen                        uint8  \n",
      " 1373  city_Hefei                          uint8  \n",
      " 1374  city_Hefer Valley                   uint8  \n",
      " 1375  city_Heidelberg                     uint8  \n",
      " 1376  city_Heilbronn                      uint8  \n",
      " 1377  city_Helsinki                       uint8  \n",
      " 1378  city_Hemel Hempstead                uint8  \n",
      " 1379  city_Hengdong                       uint8  \n",
      " 1380  city_Hengshui                       uint8  \n",
      " 1381  city_Hengyang                       uint8  \n",
      " 1382  city_Heraklion                      uint8  \n",
      " 1383  city_Herby                          uint8  \n",
      " 1384  city_Herford                        uint8  \n",
      " 1385  city_Herzliya                       uint8  \n",
      " 1386  city_Herzogenaurach                 uint8  \n",
      " 1387  city_Herzogenrath                   uint8  \n",
      " 1388  city_Hessle                         uint8  \n",
      " 1389  city_Hetian                         uint8  \n",
      " 1390  city_Heze                           uint8  \n",
      " 1391  city_Hezhou                         uint8  \n",
      " 1392  city_High Wycombe                   uint8  \n",
      " 1393  city_Ho Chi Minh City               uint8  \n",
      " 1394  city_Hohhot                         uint8  \n",
      " 1395  city_Holon                          uint8  \n",
      " 1396  city_Hong Kong                      uint8  \n",
      " 1397  city_Hook                           uint8  \n",
      " 1398  city_Horsham                        uint8  \n",
      " 1399  city_Hovik                          uint8  \n",
      " 1400  city_Hsinchu                        uint8  \n",
      " 1401  city_Hsinchu City                   uint8  \n",
      " 1402  city_Huai'an                        uint8  \n",
      " 1403  city_Huaibei                        uint8  \n",
      " 1404  city_Huaiji                         uint8  \n",
      " 1405  city_Huainan                        uint8  \n",
      " 1406  city_Hualien City                   uint8  \n",
      " 1407  city_Huangshan                      uint8  \n",
      " 1408  city_Huangshi                       uint8  \n",
      " 1409  city_Huangyan                       uint8  \n",
      " 1410  city_Huizhou                        uint8  \n",
      " 1411  city_Hukou                          uint8  \n",
      " 1412  city_Hulin                          uint8  \n",
      " 1413  city_Hung Hom                       uint8  \n",
      " 1414  city_Hung Yen                       uint8  \n",
      " 1415  city_Huolin Gol                     uint8  \n",
      " 1416  city_Huzhou                         uint8  \n",
      " 1417  city_Hwaseong-si                    uint8  \n",
      " 1418  city_Hwasun-eup                     uint8  \n",
      " 1419  city_Hyderabad                      uint8  \n",
      " 1420  city_Hyvinkaa                       uint8  \n",
      " 1421  city_Igny                           uint8  \n",
      " 1422  city_Ikoyi                          uint8  \n",
      " 1423  city_Ilhavo                         uint8  \n",
      " 1424  city_Imola                          uint8  \n",
      " 1425  city_Incheon                        uint8  \n",
      " 1426  city_Ingolstadt                     uint8  \n",
      " 1427  city_Insjon                         uint8  \n",
      " 1428  city_Ipoh                           uint8  \n",
      " 1429  city_Iquique                        uint8  \n",
      " 1430  city_Islamabad                      uint8  \n",
      " 1431  city_Isleworth                      uint8  \n",
      " 1432  city_Ismaning                       uint8  \n",
      " 1433  city_Isparta                        uint8  \n",
      " 1434  city_Issoire                        uint8  \n",
      " 1435  city_Issy-les-Moulineaux            uint8  \n",
      " 1436  city_Istanbul                       uint8  \n",
      " 1437  city_Itajai                         uint8  \n",
      " 1438  city_Izmir                          uint8  \n",
      " 1439  city_Izmit                          uint8  \n",
      " 1440  city_Jakarta                        uint8  \n",
      " 1441  city_Jakarta Barat                  uint8  \n",
      " 1442  city_Jakarta Pusat                  uint8  \n",
      " 1443  city_Jakarta Selatan                uint8  \n",
      " 1444  city_Jakarta Timur                  uint8  \n",
      " 1445  city_Jakarta Utara                  uint8  \n",
      " 1446  city_Jaragua do Sul                 uint8  \n",
      " 1447  city_Jasionka                       uint8  \n",
      " 1448  city_Jastrzebie Zdroj               uint8  \n",
      " 1449  city_Jeddah                         uint8  \n",
      " 1450  city_Jena                           uint8  \n",
      " 1451  city_Jerusalem                      uint8  \n",
      " 1452  city_Jesi                           uint8  \n",
      " 1453  city_Jezreel Valley                 uint8  \n",
      " 1454  city_Jiande                         uint8  \n",
      " 1455  city_Jiangmen                       uint8  \n",
      " 1456  city_Jiangshan                      uint8  \n",
      " 1457  city_Jiangyin                       uint8  \n",
      " 1458  city_Jianyang                       uint8  \n",
      " 1459  city_Jiaojiang                      uint8  \n",
      " 1460  city_Jiaozhou                       uint8  \n",
      " 1461  city_Jiaozuo                        uint8  \n",
      " 1462  city_Jiashan                        uint8  \n",
      " 1463  city_Jiaxing                        uint8  \n",
      " 1464  city_Jiayuguan                      uint8  \n",
      " 1465  city_Jiedong                        uint8  \n",
      " 1466  city_Jiexiu                         uint8  \n",
      " 1467  city_Jilin                          uint8  \n",
      " 1468  city_Jinan                          uint8  \n",
      " 1469  city_Jincheng                       uint8  \n",
      " 1470  city_Jingdezhen                     uint8  \n",
      " 1471  city_Jingjiang                      uint8  \n",
      " 1472  city_Jingmen                        uint8  \n",
      " 1473  city_Jingzhou                       uint8  \n",
      " 1474  city_Jinhua                         uint8  \n",
      " 1475  city_Jining                         uint8  \n",
      " 1476  city_Jinjiang                       uint8  \n",
      " 1477  city_Jinzhou                        uint8  \n",
      " 1478  city_Jiuquan                        uint8  \n",
      " 1479  city_Jiyuan                         uint8  \n",
      " 1480  city_Joensuu                        uint8  \n",
      " 1481  city_Johannesburg                   uint8  \n",
      " 1482  city_Jonkoping                      uint8  \n",
      " 1483  city_Kaluga                         uint8  \n",
      " 1484  city_Kaohsiung                      uint8  \n",
      " 1485  city_Kaohsiung City                 uint8  \n",
      " 1486  city_Karabuk                        uint8  \n",
      " 1487  city_Karachi                        uint8  \n",
      " 1488  city_Karamay                        uint8  \n",
      " 1489  city_Karlsruhe                      uint8  \n",
      " 1490  city_Karmiel                        uint8  \n",
      " 1491  city_Karstula                       uint8  \n",
      " 1492  city_Kashi                          uint8  \n",
      " 1493  city_Kassel                         uint8  \n",
      " 1494  city_Katowice                       uint8  \n",
      " 1495  city_Kavala                         uint8  \n",
      " 1496  city_Kayseri                        uint8  \n",
      " 1497  city_Kazan                          uint8  \n",
      " 1498  city_Kazanlak                       uint8  \n",
      " 1499  city_Keelung                        uint8  \n",
      " 1500  city_Keila                          uint8  \n",
      " 1501  city_Kemalpasa                      uint8  \n",
      " 1502  city_Kety                           uint8  \n",
      " 1503  city_Khao Yoi                       uint8  \n",
      " 1504  city_Khon Kaen                      uint8  \n",
      " 1505  city_Kielce                         uint8  \n",
      " 1506  city_Kiev                           uint8  \n",
      " 1507  city_Kifissia                       uint8  \n",
      " 1508  city_Kilchberg                      uint8  \n",
      " 1509  city_Kilkenny                       uint8  \n",
      " 1510  city_Kilkis                         uint8  \n",
      " 1511  city_Kingscourt                     uint8  \n",
      " 1512  city_Kirn                           uint8  \n",
      " 1513  city_Kirsehir                       uint8  \n",
      " 1514  city_Kiryat Ata                     uint8  \n",
      " 1515  city_Kiryat Malakhi                 uint8  \n",
      " 1516  city_Kisaran                        uint8  \n",
      " 1517  city_Klaipeda                       uint8  \n",
      " 1518  city_Klang                          uint8  \n",
      " 1519  city_Kocaeli                        uint8  \n",
      " 1520  city_Kolkata                        uint8  \n",
      " 1521  city_Kolonowskie                    uint8  \n",
      " 1522  city_Komorniki                      uint8  \n",
      " 1523  city_Konin                          uint8  \n",
      " 1524  city_Konskie                        uint8  \n",
      " 1525  city_Konstanz                       uint8  \n",
      " 1526  city_Konya                          uint8  \n",
      " 1527  city_Kopavogur                      uint8  \n",
      " 1528  city_Koper                          uint8  \n",
      " 1529  city_Koprivnica                     uint8  \n",
      " 1530  city_Korla                          uint8  \n",
      " 1531  city_Korolev                        uint8  \n",
      " 1532  city_Koropi                         uint8  \n",
      " 1533  city_Kortrijk                       uint8  \n",
      " 1534  city_Koscian                        uint8  \n",
      " 1535  city_Kostanay                       uint8  \n",
      " 1536  city_Kostrzyn                       uint8  \n",
      " 1537  city_Kovrov                         uint8  \n",
      " 1538  city_Kowloon                        uint8  \n",
      " 1539  city_Kowloon Bay                    uint8  \n",
      " 1540  city_Krakow                         uint8  \n",
      " 1541  city_Krasnodar                      uint8  \n",
      " 1542  city_Krasnoyarsk                    uint8  \n",
      " 1543  city_Kruszwica                      uint8  \n",
      " 1544  city_Kuala Lumpur                   uint8  \n",
      " 1545  city_Kuching                        uint8  \n",
      " 1546  city_Kulmbach                       uint8  \n",
      " 1547  city_Kunming                        uint8  \n",
      " 1548  city_Kunshan                        uint8  \n",
      " 1549  city_Kuta                           uint8  \n",
      " 1550  city_Kutahya                        uint8  \n",
      " 1551  city_Kuwait City                    uint8  \n",
      " 1552  city_Kuznia Raciborska              uint8  \n",
      " 1553  city_Kwai Chung                     uint8  \n",
      " 1554  city_Kwun Tong                      uint8  \n",
      " 1555  city_La Chapelle-Saint-Mesmin       uint8  \n",
      " 1556  city_La Ciotat                      uint8  \n",
      " 1557  city_La Defense                     uint8  \n",
      " 1558  city_La Fouillouse                  uint8  \n",
      " 1559  city_La Garde                       uint8  \n",
      " 1560  city_La Motte                       uint8  \n",
      " 1561  city_Lagos                          uint8  \n",
      " 1562  city_Lahore                         uint8  \n",
      " 1563  city_Laiyang                        uint8  \n",
      " 1564  city_Lam Luk Ka                     uint8  \n",
      " 1565  city_Lammhult                       uint8  \n",
      " 1566  city_Lamphun                        uint8  \n",
      " 1567  city_Landskrona                     uint8  \n",
      " 1568  city_Langeais                       uint8  \n",
      " 1569  city_Langfang                       uint8  \n",
      " 1570  city_Lannion                        uint8  \n",
      " 1571  city_Lantau Island                  uint8  \n",
      " 1572  city_Lanzhou                        uint8  \n",
      " 1573  city_Lap Vo                         uint8  \n",
      " 1574  city_Las Condes                     uint8  \n",
      " 1575  city_Lasko                          uint8  \n",
      " 1576  city_Lausanne                       uint8  \n",
      " 1577  city_Laval                          uint8  \n",
      " 1578  city_Le Plessis Robinson            uint8  \n",
      " 1579  city_Leeds                          uint8  \n",
      " 1580  city_Leiden                         uint8  \n",
      " 1581  city_Leioa                          uint8  \n",
      " 1582  city_Leipzig                        uint8  \n",
      " 1583  city_Leling                         uint8  \n",
      " 1584  city_Lembeke                        uint8  \n",
      " 1585  city_Les Clayes-sous-Bois           uint8  \n",
      " 1586  city_Leshan                         uint8  \n",
      " 1587  city_Lesquin                        uint8  \n",
      " 1588  city_Leuven                         uint8  \n",
      " 1589  city_Levallois-Perret               uint8  \n",
      " 1590  city_Leverkusen                     uint8  \n",
      " 1591  city_Lhasa                          uint8  \n",
      " 1592  city_Lianyungang                    uint8  \n",
      " 1593  city_Liaocheng                      uint8  \n",
      " 1594  city_Liaoyang                       uint8  \n",
      " 1595  city_Lichtenau                      uint8  \n",
      " 1596  city_Lima                           uint8  \n",
      " 1597  city_Limassol                       uint8  \n",
      " 1598  city_Linfen                         uint8  \n",
      " 1599  city_Lingwu                         uint8  \n",
      " 1600  city_Lingyuan                       uint8  \n",
      " 1601  city_Linhai                         uint8  \n",
      " 1602  city_Linkoping                      uint8  \n",
      " 1603  city_Linyi                          uint8  \n",
      " 1604  city_Linzhou                        uint8  \n",
      " 1605  city_Lippstadt                      uint8  \n",
      " 1606  city_Lisbon                         uint8  \n",
      " 1607  city_Lishui                         uint8  \n",
      " 1608  city_Lissone                        uint8  \n",
      " 1609  city_Liszki                         uint8  \n",
      " 1610  city_Littoinen                      uint8  \n",
      " 1611  city_Liupanshui                     uint8  \n",
      " 1612  city_Liuyang                        uint8  \n",
      " 1613  city_Liuzhou                        uint8  \n",
      " 1614  city_Liyang                         uint8  \n",
      " 1615  city_Ljubljana                      uint8  \n",
      " 1616  city_Llansantffraid-ym-Mechain      uint8  \n",
      " 1617  city_Lod                            uint8  \n",
      " 1618  city_Lodz                           uint8  \n",
      " 1619  city_Lomza                          uint8  \n",
      " 1620  city_London                         uint8  \n",
      " 1621  city_Long Xuyen                     uint8  \n",
      " 1622  city_Longarone                      uint8  \n",
      " 1623  city_Longjumeau                     uint8  \n",
      " 1624  city_Longkou                        uint8  \n",
      " 1625  city_Longyan                        uint8  \n",
      " 1626  city_Loos                           uint8  \n",
      " 1627  city_Lorette                        uint8  \n",
      " 1628  city_Louvain-la-Neuve               uint8  \n",
      " 1629  city_Lubeck                         uint8  \n",
      " 1630  city_Lublin                         uint8  \n",
      " 1631  city_Lubliniec                      uint8  \n",
      " 1632  city_Ludwigshafen am Rhein          uint8  \n",
      " 1633  city_Lukang                         uint8  \n",
      " 1634  city_Lund                           uint8  \n",
      " 1635  city_Luohe                          uint8  \n",
      " 1636  city_Luoping                        uint8  \n",
      " 1637  city_Luoyang                        uint8  \n",
      " 1638  city_Luxembourg City                uint8  \n",
      " 1639  city_Luzhou                         uint8  \n",
      " 1640  city_Lyon                           uint8  \n",
      " 1641  city_Lysaker                        uint8  \n",
      " 1642  city_MUNchen                        uint8  \n",
      " 1643  city_Ma'anshan                      uint8  \n",
      " 1644  city_Maanshan                       uint8  \n",
      " 1645  city_Macclesfield                   uint8  \n",
      " 1646  city_Macul                          uint8  \n",
      " 1647  city_Madrid                         uint8  \n",
      " 1648  city_Magnice                        uint8  \n",
      " 1649  city_Magoula                        uint8  \n",
      " 1650  city_Maia                           uint8  \n",
      " 1651  city_Maidstone                      uint8  \n",
      " 1652  city_Mailiao                        uint8  \n",
      " 1653  city_Maintal                        uint8  \n",
      " 1654  city_Makati City                    uint8  \n",
      " 1655  city_Malmo                          uint8  \n",
      " 1656  city_Manchester                     uint8  \n",
      " 1657  city_Mandaluyong City               uint8  \n",
      " 1658  city_Mandra                         uint8  \n",
      " 1659  city_Manila                         uint8  \n",
      " 1660  city_Mannheim                       uint8  \n",
      " 1661  city_Mantua                         uint8  \n",
      " 1662  city_Maoming                        uint8  \n",
      " 1663  city_Maranello                      uint8  \n",
      " 1664  city_Marburg                        uint8  \n",
      " 1665  city_Marcille-la-Ville              uint8  \n",
      " 1666  city_Marcy l'Etoile                 uint8  \n",
      " 1667  city_Maria Enzersdorf               uint8  \n",
      " 1668  city_Marlenheim                     uint8  \n",
      " 1669  city_Marne-la-Vallee                uint8  \n",
      " 1670  city_Marousi                        uint8  \n",
      " 1671  city_Massy                          uint8  \n",
      " 1672  city_Mauguio                        uint8  \n",
      " 1673  city_Mechelen                       uint8  \n",
      " 1674  city_Medellin                       uint8  \n",
      " 1675  city_Medias                         uint8  \n",
      " 1676  city_Megrine                        uint8  \n",
      " 1677  city_Meihekou                       uint8  \n",
      " 1678  city_Meizhou                        uint8  \n",
      " 1679  city_Melfi                          uint8  \n",
      " 1680  city_Menashe                        uint8  \n",
      " 1681  city_Mengzhou                       uint8  \n",
      " 1682  city_Mersin                         uint8  \n",
      " 1683  city_Messimy                        uint8  \n",
      " 1684  city_Mestre                         uint8  \n",
      " 1685  city_Metamorfosi                    uint8  \n",
      " 1686  city_Mettlach                       uint8  \n",
      " 1687  city_Metz-Tessy                     uint8  \n",
      " 1688  city_Mexico City                    uint8  \n",
      " 1689  city_Mezhdurechensk                 uint8  \n",
      " 1690  city_Mianyang                       uint8  \n",
      " 1691  city_Miaoli                         uint8  \n",
      " 1692  city_Midrand                        uint8  \n",
      " 1693  city_Milan                          uint8  \n",
      " 1694  city_Milton Keynes                  uint8  \n",
      " 1695  city_Mirny                          uint8  \n",
      " 1696  city_Modena                         uint8  \n",
      " 1697  city_Modi'in-Maccabim-Re'ut         uint8  \n",
      " 1698  city_Moglingen                      uint8  \n",
      " 1699  city_Molfetta                       uint8  \n",
      " 1700  city_Molndal                        uint8  \n",
      " 1701  city_Monastir                       uint8  \n",
      " 1702  city_Mondsee                        uint8  \n",
      " 1703  city_Mong Kok                       uint8  \n",
      " 1704  city_Mont-Saint-Guibert             uint8  \n",
      " 1705  city_Montabaur                      uint8  \n",
      " 1706  city_Montebelluna                   uint8  \n",
      " 1707  city_Monterrey                      uint8  \n",
      " 1708  city_Monteveglio                    uint8  \n",
      " 1709  city_Mortsel                        uint8  \n",
      " 1710  city_Moschato                       uint8  \n",
      " 1711  city_Moscow                         uint8  \n",
      " 1712  city_Moutier                        uint8  \n",
      " 1713  city_Mouy                           uint8  \n",
      " 1714  city_Mozelos                        uint8  \n",
      " 1715  city_Muang                          uint8  \n",
      " 1716  city_Mueang Chumphon                uint8  \n",
      " 1717  city_Mueang Prachinburi             uint8  \n",
      " 1718  city_Mueang Samut Prakan            uint8  \n",
      " 1719  city_Mueang Samut Sakhon            uint8  \n",
      " 1720  city_Mumbai                         uint8  \n",
      " 1721  city_Munich                         uint8  \n",
      " 1722  city_Muscat                         uint8  \n",
      " 1723  city_Muttenz                        uint8  \n",
      " 1724  city_Muttrah                        uint8  \n",
      " 1725  city_My Tho                         uint8  \n",
      " 1726  city_Myslowice                      uint8  \n",
      " 1727  city_Nacka                          uint8  \n",
      " 1728  city_Nacka Strand                   uint8  \n",
      " 1729  city_Nakhon Pathom                  uint8  \n",
      " 1730  city_Nakhon Ratchasima              uint8  \n",
      " 1731  city_Nakhon Sawan                   uint8  \n",
      " 1732  city_Nanchang                       uint8  \n",
      " 1733  city_Nanjing                        uint8  \n",
      " 1734  city_Nanning                        uint8  \n",
      " 1735  city_Nanping                        uint8  \n",
      " 1736  city_Nanterre                       uint8  \n",
      " 1737  city_Nantong                        uint8  \n",
      " 1738  city_Nantou City                    uint8  \n",
      " 1739  city_Nanyang                        uint8  \n",
      " 1740  city_Naousa                         uint8  \n",
      " 1741  city_Nastola                        uint8  \n",
      " 1742  city_Navi Mumbai                    uint8  \n",
      " 1743  city_Nazareth Illit                 uint8  \n",
      " 1744  city_Neckarsulm                     uint8  \n",
      " 1745  city_Neo Faliro                     uint8  \n",
      " 1746  city_Netanya                        uint8  \n",
      " 1747  city_Neubiberg                      uint8  \n",
      " 1748  city_Neuilly-sur-Seine              uint8  \n",
      " 1749  city_New Delhi                      uint8  \n",
      " 1750  city_New Taipei                     uint8  \n",
      " 1751  city_New Taipei City                uint8  \n",
      " 1752  city_Newbury                        uint8  \n",
      " 1753  city_Newcastle upon Tyne            uint8  \n",
      " 1754  city_Nieporet                       uint8  \n",
      " 1755  city_Niestetal                      uint8  \n",
      " 1756  city_Nigde                          uint8  \n",
      " 1757  city_Ningbo                         uint8  \n",
      " 1758  city_Ningde                         uint8  \n",
      " 1759  city_Ningguo                        uint8  \n",
      " 1760  city_Nir Tzvi                       uint8  \n",
      " 1761  city_Nokia                          uint8  \n",
      " 1762  city_Nonthaburi                     uint8  \n",
      " 1763  city_North Point                    uint8  \n",
      " 1764  city_North Ryde                     uint8  \n",
      " 1765  city_Northampton                    uint8  \n",
      " 1766  city_Norwich                        uint8  \n",
      " 1767  city_Nottingham                     uint8  \n",
      " 1768  city_Novo Mesto                     uint8  \n",
      " 1769  city_Nowy Sacz                      uint8  \n",
      " 1770  city_Nowy Targ                      uint8  \n",
      " 1771  city_Nuremberg                      uint8  \n",
      " 1772  city_Nyingchi                       uint8  \n",
      " 1773  city_Odelzhausen                    uint8  \n",
      " 1774  city_Offenburg                      uint8  \n",
      " 1775  city_Ogrodzieniec                   uint8  \n",
      " 1776  city_Oinofyta                       uint8  \n",
      " 1777  city_Oldenburg                      uint8  \n",
      " 1778  city_Oliveira De Frades             uint8  \n",
      " 1779  city_Olsztyn                        uint8  \n",
      " 1780  city_Opfikon                        uint8  \n",
      " 1781  city_Or Yehuda                      uint8  \n",
      " 1782  city_Ordos                          uint8  \n",
      " 1783  city_Osan                           uint8  \n",
      " 1784  city_Oslo                           uint8  \n",
      " 1785  city_Ospitaletto                    uint8  \n",
      " 1786  city_Ossett                         uint8  \n",
      " 1787  city_Ostrow Mazowiecka              uint8  \n",
      " 1788  city_Ostrow Wielkopolski            uint8  \n",
      " 1789  city_Oswiecim                       uint8  \n",
      " 1790  city_Ourense                        uint8  \n",
      " 1791  city_Owerri                         uint8  \n",
      " 1792  city_Ozarow Mazowiecki              uint8  \n",
      " 1793  city_Ozzano Dell'emilia             uint8  \n",
      " 1794  city_Paderborn                      uint8  \n",
      " 1795  city_Padua                          uint8  \n",
      " 1796  city_Paiania                        uint8  \n",
      " 1797  city_Pak Kret                       uint8  \n",
      " 1798  city_Palembang                      uint8  \n",
      " 1799  city_Pallini                        uint8  \n",
      " 1800  city_Pamplona                       uint8  \n",
      " 1801  city_Pangkalan Bun                  uint8  \n",
      " 1802  city_Panjin                         uint8  \n",
      " 1803  city_Panshi                         uint8  \n",
      " 1804  city_Panzhihua                      uint8  \n",
      " 1805  city_Paranaque City                 uint8  \n",
      " 1806  city_Paris                          uint8  \n",
      " 1807  city_Pasay City                     uint8  \n",
      " 1808  city_Pasig                          uint8  \n",
      " 1809  city_Pathum Thani                   uint8  \n",
      " 1810  city_Pathumthani                    uint8  \n",
      " 1811  city_Perai                          uint8  \n",
      " 1812  city_Pero                           uint8  \n",
      " 1813  city_Perth                          uint8  \n",
      " 1814  city_Pesaro                         uint8  \n",
      " 1815  city_Pessac                         uint8  \n",
      " 1816  city_Petah Tikva                    uint8  \n",
      " 1817  city_Petaling Jaya                  uint8  \n",
      " 1818  city_Peterborough                   uint8  \n",
      " 1819  city_Pfaffikon                      uint8  \n",
      " 1820  city_Phan Thong                     uint8  \n",
      " 1821  city_Phra Nakhon Si Ayutthaya       uint8  \n",
      " 1822  city_Phra Pradaeng                  uint8  \n",
      " 1823  city_Pianezza                       uint8  \n",
      " 1824  city_Piaseczno                      uint8  \n",
      " 1825  city_Piekary Slaskie                uint8  \n",
      " 1826  city_Pingdingshan                   uint8  \n",
      " 1827  city_Pinghu                         uint8  \n",
      " 1828  city_Pingtung                       uint8  \n",
      " 1829  city_Pingzhen                       uint8  \n",
      " 1830  city_Piraeus                        uint8  \n",
      " 1831  city_Pirmasens                      uint8  \n",
      " 1832  city_Plaisir                        uint8  \n",
      " 1833  city_Planegg                        uint8  \n",
      " 1834  city_Pleiku                         uint8  \n",
      " 1835  city_Ploce                          uint8  \n",
      " 1836  city_Plock                          uint8  \n",
      " 1837  city_Poissy                         uint8  \n",
      " 1838  city_Police                         uint8  \n",
      " 1839  city_Polkowice                      uint8  \n",
      " 1840  city_Polykastro                     uint8  \n",
      " 1841  city_Ponte di Piave                 uint8  \n",
      " 1842  city_Pontedera                      uint8  \n",
      " 1843  city_Ponzano                        uint8  \n",
      " 1844  city_Poole                          uint8  \n",
      " 1845  city_Porto                          uint8  \n",
      " 1846  city_Porto Alegre                   uint8  \n",
      " 1847  city_Poschiavo                      uint8  \n",
      " 1848  city_Poznan                         uint8  \n",
      " 1849  city_Privas                         uint8  \n",
      " 1850  city_Provaglio D'iseo               uint8  \n",
      " 1851  city_Providencia                    uint8  \n",
      " 1852  city_Przezmierowo                   uint8  \n",
      " 1853  city_Pszczyna                       uint8  \n",
      " 1854  city_Pucheng                        uint8  \n",
      " 1855  city_Pulawy                         uint8  \n",
      " 1856  city_Pulilan                        uint8  \n",
      " 1857  city_Pune                           uint8  \n",
      " 1858  city_Puning                         uint8  \n",
      " 1859  city_Punta Arenas                   uint8  \n",
      " 1860  city_Puteaux                        uint8  \n",
      " 1861  city_Putian                         uint8  \n",
      " 1862  city_Putrajaya                      uint8  \n",
      " 1863  city_Puyang                         uint8  \n",
      " 1864  city_Pyatigorsk                     uint8  \n",
      " 1865  city_Qidong                         uint8  \n",
      " 1866  city_Qingdao                        uint8  \n",
      " 1867  city_Qiqihar                        uint8  \n",
      " 1868  city_Qitaihe                        uint8  \n",
      " 1869  city_Quanzhou                       uint8  \n",
      " 1870  city_Quarry Bay                     uint8  \n",
      " 1871  city_Quezon City                    uint8  \n",
      " 1872  city_Qufu                           uint8  \n",
      " 1873  city_Qujing                         uint8  \n",
      " 1874  city_Quy Nhon                       uint8  \n",
      " 1875  city_Quzhou                         uint8  \n",
      " 1876  city_Raciborz                       uint8  \n",
      " 1877  city_Raisio                         uint8  \n",
      " 1878  city_Ramat Gan                      uint8  \n",
      " 1879  city_Ras al-Khaimah                 uint8  \n",
      " 1880  city_Ravenna                        uint8  \n",
      " 1881  city_Rawalpindi                     uint8  \n",
      " 1882  city_Rayong                         uint8  \n",
      " 1883  city_Redditch                       uint8  \n",
      " 1884  city_Reggio Emilia                  uint8  \n",
      " 1885  city_Reims                          uint8  \n",
      " 1886  city_Reinach                        uint8  \n",
      " 1887  city_Renescure                      uint8  \n",
      " 1888  city_Reykjavik                      uint8  \n",
      " 1889  city_Rickmansworth                  uint8  \n",
      " 1890  city_Riga                           uint8  \n",
      " 1891  city_Rimini                         uint8  \n",
      " 1892  city_Rio De Janeiro                 uint8  \n",
      " 1893  city_Rio de Janeiro                 uint8  \n",
      " 1894  city_Rioz                           uint8  \n",
      " 1895  city_Rishon LeZion                  uint8  \n",
      " 1896  city_Riyadh                         uint8  \n",
      " 1897  city_Rizhao                         uint8  \n",
      " 1898  city_Rolvsoy                        uint8  \n",
      " 1899  city_Rome                           uint8  \n",
      " 1900  city_Rongcheng                      uint8  \n",
      " 1901  city_Roodepoort                     uint8  \n",
      " 1902  city_Rosmalen                       uint8  \n",
      " 1903  city_Rotterdam                      uint8  \n",
      " 1904  city_Roubaix                        uint8  \n",
      " 1905  city_Rozzano                        uint8  \n",
      " 1906  city_Rueil-Malmaison                uint8  \n",
      " 1907  city_Rugao                          uint8  \n",
      " 1908  city_Ruian                          uint8  \n",
      " 1909  city_Rumlang                        uint8  \n",
      " 1910  city_Rusayl                         uint8  \n",
      " 1911  city_Rushden                        uint8  \n",
      " 1912  city_Ruwi                           uint8  \n",
      " 1913  city_Rzeszow                        uint8  \n",
      " 1914  city_SaarbrUCken                    uint8  \n",
      " 1915  city_Sabie                          uint8  \n",
      " 1916  city_Sai Wan                        uint8  \n",
      " 1917  city_Saint Martin                   uint8  \n",
      " 1918  city_Saint Petersburg               uint8  \n",
      " 1919  city_Saint-Aunes                    uint8  \n",
      " 1920  city_Saint-Cloud                    uint8  \n",
      " 1921  city_Saint-Etienne                  uint8  \n",
      " 1922  city_Saint-Gregoire                 uint8  \n",
      " 1923  city_Saint-Herblain                 uint8  \n",
      " 1924  city_Saint-Jean-de-Soudain          uint8  \n",
      " 1925  city_Saint-Mande                    uint8  \n",
      " 1926  city_Saint-Petersburg               uint8  \n",
      " 1927  city_Salalah                        uint8  \n",
      " 1928  city_Salen                          uint8  \n",
      " 1929  city_Salford                        uint8  \n",
      " 1930  city_Salta                          uint8  \n",
      " 1931  city_Saltillo                       uint8  \n",
      " 1932  city_Saluggia                       uint8  \n",
      " 1933  city_Salzgitter                     uint8  \n",
      " 1934  city_Samsun                         uint8  \n",
      " 1935  city_Samut Prakan                   uint8  \n",
      " 1936  city_Samut Sakhon                   uint8  \n",
      " 1937  city_Samutprakarn                   uint8  \n",
      " 1938  city_San Bernardo                   uint8  \n",
      " 1939  city_San Donato Milanese            uint8  \n",
      " 1940  city_San Giovanni In Marignano      uint8  \n",
      " 1941  city_San Mauro Torinese             uint8  \n",
      " 1942  city_San Nicolas de los Garza       uint8  \n",
      " 1943  city_San Pedro Garza Garcia         uint8  \n",
      " 1944  city_San Po Kong                    uint8  \n",
      " 1945  city_San Potito Sannitico           uint8  \n",
      " 1946  city_Sandown                        uint8  \n",
      " 1947  city_Sandton                        uint8  \n",
      " 1948  city_Sanming                        uint8  \n",
      " 1949  city_Sanok                          uint8  \n",
      " 1950  city_Sant'Antonino                  uint8  \n",
      " 1951  city_Sant'Elpidio a Mare            uint8  \n",
      " 1952  city_Sant'agata Feltria             uint8  \n",
      " 1953  city_Sant'ambrogio Di Valpolicella  uint8  \n",
      " 1954  city_Sant'ilario D'enza             uint8  \n",
      " 1955  city_Santiago                       uint8  \n",
      " 1956  city_Santiago de Chile              uint8  \n",
      " 1957  city_Santo Andre                    uint8  \n",
      " 1958  city_Sanya                          uint8  \n",
      " 1959  city_Sao Bernardo do Campo          uint8  \n",
      " 1960  city_Sao Caetano do Sul             uint8  \n",
      " 1961  city_Sao Jose dos Pinhais           uint8  \n",
      " 1962  city_Sao Paulo                      uint8  \n",
      " 1963  city_Sarpsborg                      uint8  \n",
      " 1964  city_Sassenage                      uint8  \n",
      " 1965  city_Sassenberg                     uint8  \n",
      " 1966  city_Schaffhausen                   uint8  \n",
      " 1967  city_Schiphol                       uint8  \n",
      " 1968  city_Schlieren                      uint8  \n",
      " 1969  city_Schwechat                      uint8  \n",
      " 1970  city_Sderot                         uint8  \n",
      " 1971  city_Segrate                        uint8  \n",
      " 1972  city_Seinajoki                      uint8  \n",
      " 1973  city_Selb                           uint8  \n",
      " 1974  city_Selby                          uint8  \n",
      " 1975  city_Selcuklu                       uint8  \n",
      " 1976  city_Seneffe                        uint8  \n",
      " 1977  city_Sennwald                       uint8  \n",
      " 1978  city_Seongnam-si                    uint8  \n",
      " 1979  city_Seoul                          uint8  \n",
      " 1980  city_Sevenum                        uint8  \n",
      " 1981  city_Seville                        uint8  \n",
      " 1982  city_Sevres                         uint8  \n",
      " 1983  city_Sha Tin                        uint8  \n",
      " 1984  city_Sha'ar HaGolan                 uint8  \n",
      " 1985  city_Sha'ar HaNegev                 uint8  \n",
      " 1986  city_Shah Alam                      uint8  \n",
      " 1987  city_Shanghai                       uint8  \n",
      " 1988  city_Shangrao                       uint8  \n",
      " 1989  city_Shannan                        uint8  \n",
      " 1990  city_Shantou                        uint8  \n",
      " 1991  city_Shaoguan                       uint8  \n",
      " 1992  city_Shaoxing                       uint8  \n",
      " 1993  city_Shehong                        uint8  \n",
      " 1994  city_Shenyang                       uint8  \n",
      " 1995  city_Shenzhen                       uint8  \n",
      " 1996  city_Sheung Wan                     uint8  \n",
      " 1997  city_Shifang                        uint8  \n",
      " 1998  city_Shihezi                        uint8  \n",
      " 1999  city_Shijiazhuang                   uint8  \n",
      " 2000  city_Shilu                          uint8  \n",
      " 2001  city_Shirebrook                     uint8  \n",
      " 2002  city_Shiyan                         uint8  \n",
      " 2003  city_Shizuishan                     uint8  \n",
      " 2004  city_Shuanghe                       uint8  \n",
      " 2005  city_Si Racha                       uint8  \n",
      " 2006  city_Sidoarjo                       uint8  \n",
      " 2007  city_Siero                          uint8  \n",
      " 2008  city_Sievi                          uint8  \n",
      " 2009  city_Singapore                      uint8  \n",
      " 2010  city_Sint-Katelijne-Waver           uint8  \n",
      " 2011  city_Skaelskor                      uint8  \n",
      " 2012  city_Skien                          uint8  \n",
      " 2013  city_Skinnskatteberg                uint8  \n",
      " 2014  city_Skoyen                         uint8  \n",
      " 2015  city_Slatina                        uint8  \n",
      " 2016  city_Slough                         uint8  \n",
      " 2017  city_Slupsk                         uint8  \n",
      " 2018  city_Sodertalje                     uint8  \n",
      " 2019  city_Sofia                          uint8  \n",
      " 2020  city_Solna                          uint8  \n",
      " 2021  city_Solomeo                        uint8  \n",
      " 2022  city_Songkhla                       uint8  \n",
      " 2023  city_Sosnowiec                      uint8  \n",
      " 2024  city_Spanga                         uint8  \n",
      " 2025  city_Srem                           uint8  \n",
      " 2026  city_Sroda Wielkopolska             uint8  \n",
      " 2027  city_St Ouen                        uint8  \n",
      " 2028  city_Steinhausen                    uint8  \n",
      " 2029  city_Stellenbosch                   uint8  \n",
      " 2030  city_Stenungsund                    uint8  \n",
      " 2031  city_Stetten am kalten Markt        uint8  \n",
      " 2032  city_Stockholm                      uint8  \n",
      " 2033  city_Storebo                        uint8  \n",
      " 2034  city_Strasbourg                     uint8  \n",
      " 2035  city_Suchy Las                      uint8  \n",
      " 2036  city_Suining                        uint8  \n",
      " 2037  city_Suizhou                        uint8  \n",
      " 2038  city_Sulzemoos                      uint8  \n",
      " 2039  city_Sundsvall                      uint8  \n",
      " 2040  city_Suqian                         uint8  \n",
      " 2041  city_Surabaya                       uint8  \n",
      " 2042  city_Suresnes                       uint8  \n",
      " 2043  city_Surgut                         uint8  \n",
      " 2044  city_Surquillo                      uint8  \n",
      " 2045  city_Sutton Coldfield               uint8  \n",
      " 2046  city_Suwon                          uint8  \n",
      " 2047  city_Suwon-si                       uint8  \n",
      " 2048  city_Suzhou                         uint8  \n",
      " 2049  city_Swidnica                       uint8  \n",
      " 2050  city_Swiebodzin                     uint8  \n",
      " 2051  city_Swords                         uint8  \n",
      " 2052  city_Szczecin                       uint8  \n",
      " 2053  city_Taguig                         uint8  \n",
      " 2054  city_Taguig City                    uint8  \n",
      " 2055  city_Tai Po                         uint8  \n",
      " 2056  city_Taian                          uint8  \n",
      " 2057  city_Taicang                        uint8  \n",
      " 2058  city_Taichung                       uint8  \n",
      " 2059  city_Taichung City                  uint8  \n",
      " 2060  city_Tainan                         uint8  \n",
      " 2061  city_Tainan City                    uint8  \n",
      " 2062  city_Taipei                         uint8  \n",
      " 2063  city_Taipei City                    uint8  \n",
      " 2064  city_Taishan                        uint8  \n",
      " 2065  city_Taixing                        uint8  \n",
      " 2066  city_Taiyuan                        uint8  \n",
      " 2067  city_Taizhou                        uint8  \n",
      " 2068  city_Tallinn                        uint8  \n",
      " 2069  city_Tan Chau                       uint8  \n",
      " 2070  city_Tan Thanh                      uint8  \n",
      " 2071  city_Tan Uyen                       uint8  \n",
      " 2072  city_Tangerang                      uint8  \n",
      " 2073  city_Tangerang Selatan              uint8  \n",
      " 2074  city_Tangshan                       uint8  \n",
      " 2075  city_Taoyuan                        uint8  \n",
      " 2076  city_Taoyuan City                   uint8  \n",
      " 2077  city_Taoyuan Hsien                  uint8  \n",
      " 2078  city_Tarko-Sale                     uint8  \n",
      " 2079  city_Tarnow                         uint8  \n",
      " 2080  city_Taytay                         uint8  \n",
      " 2081  city_Tczew                          uint8  \n",
      " 2082  city_Tel Aviv                       uint8  \n",
      " 2083  city_Tha Sae                        uint8  \n",
      " 2084  city_Thalwil                        uint8  \n",
      " 2085  city_Thanh Hoa                      uint8  \n",
      " 2086  city_Thanyaburi                     uint8  \n",
      " 2087  city_Thessaloniki                   uint8  \n",
      " 2088  city_Thu Dau Mot                    uint8  \n",
      " 2089  city_Thuan An                       uint8  \n",
      " 2090  city_Tianjin                        uint8  \n",
      " 2091  city_Tianshui                       uint8  \n",
      " 2092  city_Tiantai                        uint8  \n",
      " 2093  city_Tiszaujvaros                   uint8  \n",
      " 2094  city_Tlalnepantla de Baz            uint8  \n",
      " 2095  city_Tolentino                      uint8  \n",
      " 2096  city_Tongcheng                      uint8  \n",
      " 2097  city_Tonghua                        uint8  \n",
      " 2098  city_Tongling                       uint8  \n",
      " 2099  city_Tonglu                         uint8  \n",
      " 2100  city_Tongxiang                      uint8  \n",
      " 2101  city_Tonneins                       uint8  \n",
      " 2102  city_Torun                          uint8  \n",
      " 2103  city_Toufen                         uint8  \n",
      " 2104  city_Toulouse                       uint8  \n",
      " 2105  city_Tours-en-Savoie                uint8  \n",
      " 2106  city_Tralee                         uint8  \n",
      " 2107  city_Trelleborg                     uint8  \n",
      " 2108  city_Tremblay-en-France             uint8  \n",
      " 2109  city_Treviso                        uint8  \n",
      " 2110  city_Trier                          uint8  \n",
      " 2111  city_Trieste                        uint8  \n",
      " 2112  city_Trujillo                       uint8  \n",
      " 2113  city_Trzebnica                      uint8  \n",
      " 2114  city_Tsim Sha Tsui                  uint8  \n",
      " 2115  city_Tsuen Wan                      uint8  \n",
      " 2116  city_Tuchola                        uint8  \n",
      " 2117  city_Tunis                          uint8  \n",
      " 2118  city_Turgutlu                       uint8  \n",
      " 2119  city_Turin                          uint8  \n",
      " 2120  city_Turku                          uint8  \n",
      " 2121  city_Uboldo                         uint8  \n",
      " 2122  city_Uijeongbu-si                   uint8  \n",
      " 2123  city_Ulm                            uint8  \n",
      " 2124  city_Ulsan                          uint8  \n",
      " 2125  city_UnterfOHring                   uint8  \n",
      " 2126  city_Unterneukirchen                uint8  \n",
      " 2127  city_Uppsala                        uint8  \n",
      " 2128  city_Ursensollen                    uint8  \n",
      " 2129  city_Urumqi                         uint8  \n",
      " 2130  city_Utrecht                        uint8  \n",
      " 2131  city_Vantaa                         uint8  \n",
      " 2132  city_Veghel                         uint8  \n",
      " 2133  city_Veldhoven                      uint8  \n",
      " 2134  city_Velenje                        uint8  \n",
      " 2135  city_Velizy-Villacoublay            uint8  \n",
      " 2136  city_Venlo                          uint8  \n",
      " 2137  city_Verac                          uint8  \n",
      " 2138  city_Verkhnyaya Salda               uint8  \n",
      " 2139  city_Verona                         uint8  \n",
      " 2140  city_Vertou                         uint8  \n",
      " 2141  city_Viadana                        uint8  \n",
      " 2142  city_Vicente Lopez                  uint8  \n",
      " 2143  city_Vicenza                        uint8  \n",
      " 2144  city_Victoria                       uint8  \n",
      " 2145  city_Vienna                         uint8  \n",
      " 2146  city_Vierema                        uint8  \n",
      " 2147  city_Villiers-sur-Marne             uint8  \n",
      " 2148  city_Villorba                       uint8  \n",
      " 2149  city_Vilnius                        uint8  \n",
      " 2150  city_Vimmerby                       uint8  \n",
      " 2151  city_Vina Del Mar                   uint8  \n",
      " 2152  city_Vinh                           uint8  \n",
      " 2153  city_Vung Tau                       uint8  \n",
      " 2154  city_Walldorf                       uint8  \n",
      " 2155  city_Wan Chai                       uint8  \n",
      " 2156  city_Warsaw                         uint8  \n",
      " 2157  city_Warszawa                       uint8  \n",
      " 2158  city_Washington                     uint8  \n",
      " 2159  city_Waterloo                       uint8  \n",
      " 2160  city_Weifang                        uint8  \n",
      " 2161  city_Weihai                         uint8  \n",
      " 2162  city_Weiyuan                        uint8  \n",
      " 2163  city_Wejherowo                      uint8  \n",
      " 2164  city_Wels                           uint8  \n",
      " 2165  city_Welwyn Garden City             uint8  \n",
      " 2166  city_Wenden                         uint8  \n",
      " 2167  city_Wendeng                        uint8  \n",
      " 2168  city_Wenling                        uint8  \n",
      " 2169  city_Wenzhou                        uint8  \n",
      " 2170  city_Werdohl                        uint8  \n",
      " 2171  city_West Drayton                   uint8  \n",
      " 2172  city_Wetteren                       uint8  \n",
      " 2173  city_Wielun                         uint8  \n",
      " 2174  city_Wiesbaden                      uint8  \n",
      " 2175  city_Windsor                        uint8  \n",
      " 2176  city_Wloszczowa                     uint8  \n",
      " 2177  city_Wokingham                      uint8  \n",
      " 2178  city_Wolfsburg                      uint8  \n",
      " 2179  city_Wolverhampton                  uint8  \n",
      " 2180  city_Wong Chuk Hang                 uint8  \n",
      " 2181  city_Wotton-under-Edge              uint8  \n",
      " 2182  city_Wroclaw                        uint8  \n",
      " 2183  city_Wronki                         uint8  \n",
      " 2184  city_Wuan                           uint8  \n",
      " 2185  city_Wuhai                          uint8  \n",
      " 2186  city_Wuhan                          uint8  \n",
      " 2187  city_Wuhu                           uint8  \n",
      " 2188  city_Wujiang                        uint8  \n",
      " 2189  city_Wujiaqu                        uint8  \n",
      " 2190  city_Wuppertal                      uint8  \n",
      " 2191  city_Wurzburg                       uint8  \n",
      " 2192  city_Wuxi                           uint8  \n",
      " 2193  city_Wuxue                          uint8  \n",
      " 2194  city_Wuzhou                         uint8  \n",
      " 2195  city_Xi'an                          uint8  \n",
      " 2196  city_Xiamen                         uint8  \n",
      " 2197  city_Xiangcheng                     uint8  \n",
      " 2198  city_Xiangtan                       uint8  \n",
      " 2199  city_Xiangyang                      uint8  \n",
      " 2200  city_Xianju                         uint8  \n",
      " 2201  city_Xianning                       uint8  \n",
      " 2202  city_Xianyang                       uint8  \n",
      " 2203  city_Xichang                        uint8  \n",
      " 2204  city_Xinchang                       uint8  \n",
      " 2205  city_Xingning                       uint8  \n",
      " 2206  city_Xingping                       uint8  \n",
      " 2207  city_Xingtai                        uint8  \n",
      " 2208  city_Xining                         uint8  \n",
      " 2209  city_Xinyang                        uint8  \n",
      " 2210  city_Xinyi                          uint8  \n",
      " 2211  city_Xinyu                          uint8  \n",
      " 2212  city_Xinzheng                       uint8  \n",
      " 2213  city_Xinzhou                        uint8  \n",
      " 2214  city_Xixia                          uint8  \n",
      " 2215  city_Xuancheng                      uint8  \n",
      " 2216  city_Xuchang                        uint8  \n",
      " 2217  city_Xuzhou                         uint8  \n",
      " 2218  city_Yakum                          uint8  \n",
      " 2219  city_Yalova                         uint8  \n",
      " 2220  city_Yancheng                       uint8  \n",
      " 2221  city_Yangmei                        uint8  \n",
      " 2222  city_Yangquan                       uint8  \n",
      " 2223  city_Yangzhou                       uint8  \n",
      " 2224  city_Yanshi                         uint8  \n",
      " 2225  city_Yantai                         uint8  \n",
      " 2226  city_Yavne                          uint8  \n",
      " 2227  city_Yeonggwang-eup                 uint8  \n",
      " 2228  city_Yeruham                        uint8  \n",
      " 2229  city_Yibin                          uint8  \n",
      " 2230  city_Yichang                        uint8  \n",
      " 2231  city_Yichun                         uint8  \n",
      " 2232  city_Yilan City                     uint8  \n",
      " 2233  city_Yima                           uint8  \n",
      " 2234  city_Yinchuan                       uint8  \n",
      " 2235  city_Yingcheng                      uint8  \n",
      " 2236  city_Yingkou                        uint8  \n",
      " 2237  city_Yingtan                        uint8  \n",
      " 2238  city_Yiwu                           uint8  \n",
      " 2239  city_Yixing                         uint8  \n",
      " 2240  city_Yiyang                         uint8  \n",
      " 2241  city_Yokne'am                       uint8  \n",
      " 2242  city_Yong'an                        uint8  \n",
      " 2243  city_Yongcheng                      uint8  \n",
      " 2244  city_Yongin-Si                      uint8  \n",
      " 2245  city_Yongkang                       uint8  \n",
      " 2246  city_York                           uint8  \n",
      " 2247  city_Yuanjiang                      uint8  \n",
      " 2248  city_Yuanlin                        uint8  \n",
      " 2249  city_Yucheng                        uint8  \n",
      " 2250  city_Yuen Long                      uint8  \n",
      " 2251  city_Yueqing                        uint8  \n",
      " 2252  city_Yueyang                        uint8  \n",
      " 2253  city_Yuhuan                         uint8  \n",
      " 2254  city_Yumbo                          uint8  \n",
      " 2255  city_Yuncheng                       uint8  \n",
      " 2256  city_Yunfu                          uint8  \n",
      " 2257  city_Yunlin                         uint8  \n",
      " 2258  city_Yuxi                           uint8  \n",
      " 2259  city_Yuyao                          uint8  \n",
      " 2260  city_Yverdon-les-Bains              uint8  \n",
      " 2261  city_Zaandam                        uint8  \n",
      " 2262  city_Zabrze                         uint8  \n",
      " 2263  city_Zalesie                        uint8  \n",
      " 2264  city_Zamudio                        uint8  \n",
      " 2265  city_Zaozhuang                      uint8  \n",
      " 2266  city_Zary                           uint8  \n",
      " 2267  city_Zawiercie                      uint8  \n",
      " 2268  city_Zblewo                         uint8  \n",
      " 2269  city_Zellik                         uint8  \n",
      " 2270  city_Zhangjiagang                   uint8  \n",
      " 2271  city_Zhangjiajie                    uint8  \n",
      " 2272  city_Zhangzhou                      uint8  \n",
      " 2273  city_Zhanjiang                      uint8  \n",
      " 2274  city_Zhaoqing                       uint8  \n",
      " 2275  city_Zhaoyuan                       uint8  \n",
      " 2276  city_Zhengzhou                      uint8  \n",
      " 2277  city_Zhenjiang                      uint8  \n",
      " 2278  city_Zhongshan                      uint8  \n",
      " 2279  city_Zhubei                         uint8  \n",
      " 2280  city_Zhucheng                       uint8  \n",
      " 2281  city_Zhuhai                         uint8  \n",
      " 2282  city_Zhuji                          uint8  \n",
      " 2283  city_Zhunan                         uint8  \n",
      " 2284  city_Zhuozhou                       uint8  \n",
      " 2285  city_Zhuzhou                        uint8  \n",
      " 2286  city_Zibo                           uint8  \n",
      " 2287  city_Zielona Gora                   uint8  \n",
      " 2288  city_Zigong                         uint8  \n",
      " 2289  city_Zofingen                       uint8  \n",
      " 2290  city_Zouping                        uint8  \n",
      " 2291  city_Zug                            uint8  \n",
      " 2292  city_Zunyi                          uint8  \n",
      " 2293  city_Zurich                         uint8  \n",
      " 2294  city_Zwevegem                       uint8  \n",
      " 2295  city_Zwolle                         uint8  \n",
      " 2296  city_lomianki                       uint8  \n",
      " 2297  acctstdq_DI                         uint8  \n",
      " 2298  acctstdq_DS                         uint8  \n",
      " 2299  acctstdq_ND                         uint8  \n",
      " 2300  acctstdq_US                         uint8  \n",
      " 2301  compstq_AC                          uint8  \n",
      " 2302  compstq_AD                          uint8  \n",
      " 2303  compstq_AQ                          uint8  \n",
      " 2304  compstq_DB                          uint8  \n",
      " 2305  compstq_SQ                          uint8  \n",
      "dtypes: float64(75), int64(6), object(1), uint8(2224)\n",
      "memory usage: 159.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dummies.info(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaledWinsRatioPathWithSplit = os.path.join(os.getcwd(), \"Data\\ScaledWinsRatioDataWithSplit.csv\")\n",
    "# pd.DataFrame(xScaledData).to_csv(scaledWinsRatioPathWithSplit, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# groupedY = Y.groupby([\"state\", \"gender\"])[\"last_name\"].count()\n",
    "# yTrain, yVal, yTest = Y[:trainSize], Y[trainSize:validationSize], Y[validationSize:]\n",
    "\n",
    "\n",
    "\n",
    "# groupedX = scaled_X.groupby([\"state\", \"gender\"])[\"last_name\"].count()\n",
    "# xTrain, xVal, xTest = scaled_X[:trainSize,:], scaled_X[trainSize:validationSize,:], scaled_X[validationSize:, :]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# print(\"Num GPUs Available: \", len(physical_devices))\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNfunction(modelType, layers, units, activation, dropout, L1, L2, batch_size, optimizer, learning_rate, runningDate):\n",
    "    \n",
    "    verbose = 1\n",
    "    patience = 1\n",
    "    epochs = 300\n",
    "    numberOfOutputs = yTrain.shape[1]\n",
    "    \n",
    "    if optimizer == \"RMSprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    #model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    if modelType == \"LSTM\":\n",
    "        model.add(tf.keras.layers.LSTM(units=units, input_shape=(2,)))\n",
    "    elif modelType == \"GRU\":\n",
    "        model.add(tf.keras.layers.GRU(units=units))\n",
    "    elif modelType == \"SimpleRNN\":\n",
    "        # keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "        model.add(tf.keras.layers.SimpleRNN(units=units))\n",
    "    elif modelType == \"RegularizedLinear\":\n",
    "        model.add(tf.keras.layers.Dense(units=numberOfOutputs,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2)))\n",
    "        print(\"RegularizedLinear\")\n",
    "    elif modelType == \"StandardLinear\":\n",
    "        model.add(tf.keras.layers.Dense(units=numberOfOutputs))\n",
    "        print(\"StandardLinear\")\n",
    "    # elif modelType == \"NaiveFirmMeanForecast\":\n",
    "    #     model.add(tf.keras.layers.Dense(units=1,\n",
    "    #                     kernel_constraint=tf.keras.constraints.MinMaxNorm(\n",
    "    #                         min_value=0,\n",
    "    #                         max_value=0,\n",
    "    #                         rate=1.0,\n",
    "    #                         axis=0)))\n",
    "    else:\n",
    "        try:\n",
    "            for n in range(0, layers):\n",
    "                model.add(tf.keras.layers.Dense(units=units,\n",
    "                                activation=activation,\n",
    "                                kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2)))\n",
    "                model.add(tf.keras.layers.Dropout(rate=dropout))\n",
    "                # scaler.fit_transform\n",
    "                # tf.keras.layers.BatchNormalization(\n",
    "            print(f\"NN{layers}Layer\")\n",
    "        except:\n",
    "            model.add(tf.keras.layers.Dense(units=units, activation=activation,\n",
    "                            kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2)))\n",
    "            model.add(tf.keras.layers.Dropout(rate=dropout))\n",
    "            print(\"NN1Layer_WhyDidWeEndUpHere?\")\n",
    "\n",
    "            \n",
    "        model.add(tf.keras.layers.Dense(units=numberOfOutputs,\n",
    "                            kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2)))\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(optimizer=optimizer,  # Adam(learning_rate=0.0001) #RMSprop #sgd\n",
    "                  loss=\"MeanAbsoluteError\",  # 'tf.keras.losses.MeanSquaredError()'  #Huber #MeanAbsoluteError #MeanSquaredError \n",
    "                  #metrics=[\"MeanSquaredError\", \"MeanAbsoluteError\"])\n",
    "                  metrics=[tf.keras.losses.MeanSquaredError(), tf.keras.losses.MeanAbsoluteError()])#, \"RootMeanSquaredError\"]) #accuracy #MeanSquaredLogarithmicError #RootMeanSquaredError #MeanAbsolutePercentageError \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # model.fit(x=xTrain, y=yTrain,\n",
    "    #           batch_size=16, epochs=epo, verbose=2)\n",
    "\n",
    "    #loss_and_metrics = model.evaluate(xVal, yVal, batch_size=128)\n",
    "    \n",
    "    performCV = False\n",
    "    loss_and_metrics_matrix = pd.DataFrame()\n",
    "    epochs_matrix = pd.DataFrame()\n",
    "    quarters = dummies[dummies[\"Split\"] == \"Validation\"][\"fdateYQ\"].unique()\n",
    "    quarters.sort()\n",
    "    if performCV:    \n",
    "        for q in quarters:\n",
    "            # Run cross validation through model fit and evaluate. \n",
    "            # Save all MSAs and MSEs from \"loss_and_metrics\" into a dataframe and take their average to obtain the best model\n",
    "            print(\"Quarter \" + str(q))\n",
    "            xT = dummies[dummies[\"fdateYQ\"] < q].drop([\"returns\", \"MktCap\", \"Split\", \"fdateYQ\", \"gvkey\"], axis=1)\n",
    "            yT = dummies[dummies[\"fdateYQ\"] < q][\"returns\"]\n",
    "            #A rolling window might be faster. E.g.: dummies[\"fdateYQ\"] == q - 0.25\n",
    "\n",
    "            xV = dummies[dummies[\"fdateYQ\"] == q].drop([\"returns\", \"MktCap\", \"Split\", \"fdateYQ\", \"gvkey\"], axis=1)\n",
    "            yV = dummies[dummies[\"fdateYQ\"] == q][\"returns\"]\n",
    "\n",
    "\n",
    "            earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_mean_absolute_error', patience=patience, verbose=1, restore_best_weights=True) #Can this be taken out from the loop? => Less computing\n",
    "\n",
    "            # tensorboardLogPath = f\"Results/logs/{runningDate}/{modelType}_{layers}L_{units}U_{activation}_{dropout}DO_{L1}L1_{L2}L2_{batch_size}Batch_{optimizer._name}_{learning_rate}LR_Q{q}\"\n",
    "            # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboardLogPath) #tensorboard --logdir=\"10-01-2023_1606\" #tensorboard --logdir=\"logs/\"\n",
    "            #BackupAndRestore_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=\"/tmp/backup\")\n",
    "\n",
    "            history = model.fit(x=xT, y=yT,\n",
    "                                batch_size=batch_size, epochs=epochs,\n",
    "                                callbacks=[earlystopping_callback], verbose=verbose, validation_data=(xV, yV))\n",
    "\n",
    "            loss_and_metrics = model.evaluate(xV, yV, batch_size=batch_size, return_dict=True)\n",
    "            epochs_EarlyStopping = len(history.history['loss']) - patience\n",
    "\n",
    "            loss_and_metrics_matrix = pd.concat((loss_and_metrics_matrix,\n",
    "                                                 pd.DataFrame(loss_and_metrics,\n",
    "                                                              index=[0])))\n",
    "\n",
    "            epochs_matrix = pd.concat((epochs_matrix, pd.DataFrame([epochs_EarlyStopping])))\n",
    "            print(loss_and_metrics_matrix, \"\\n\", epochs_matrix, \"\\n\")\n",
    "\n",
    "        loss_and_metrics = loss_and_metrics_matrix.mean()\n",
    "        epochs_EarlyStopping = epochs_matrix.mean()[0]\n",
    "\n",
    "    else:\n",
    "        earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_mean_absolute_error', patience=patience, verbose=1, restore_best_weights=True) #Can this be taken out from the loop? => Less computing\n",
    "\n",
    "        tensorboardLogPath = f\"Results/logs/{runningDate}/{modelType}_{layers}L_{units}U_{activation}_{dropout}DO_{L1}L1_{L2}L2_{batch_size}Batch_{optimizer._name}_{learning_rate}LR\"\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboardLogPath) #tensorboard --logdir=\"10-01-2023_1606\" #tensorboard --logdir=\"logs/\"\n",
    "        #BackupAndRestore_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=\"/tmp/backup\")\n",
    "        history = model.fit(x=xWinTrain, y=yTrain,\n",
    "                batch_size=batch_size, epochs=epochs,\n",
    "                callbacks=[earlystopping_callback, tensorboard_callback], verbose=verbose, validation_data = (xWinVal, yVal))\n",
    "        loss_and_metrics = model.evaluate(xWinVal, yVal, batch_size=batch_size, return_dict=True)\n",
    "        epochs_EarlyStopping = len(history.history['loss']) - patience\n",
    "        print(loss_and_metrics, \"\\n\", epochs_EarlyStopping, \"\\n\")\n",
    "        #history.history[]\n",
    "\n",
    "    # history = model.fit(x=xWinTrainDict, y=yTrain,\n",
    "    #           batch_size=16, epochs=300,\n",
    "    #           callbacks=[callback], verbose=1, validation_data = (xWinValDict, yVal))\n",
    "\n",
    "\n",
    "    # quarters = len(yVal)\n",
    "    # CV = []\n",
    "    # for q in range(0, quarters):\n",
    "\n",
    "    #     model.fit(x=xTrain, y=yTrain,\n",
    "    #           batch_size=16, epochs=epo, verbose=2)\n",
    "\n",
    "    #     validationError = model.evaluate(xVal, yVal, batch_size=128)\n",
    "    #     CV = [CV, validationError]\n",
    "\n",
    "\n",
    "    # try:\n",
    "    #     loss_and_metrics = [x for x in loss_and_metrics]\n",
    "    # except:     \n",
    "    #     print(loss_and_metrics)\n",
    "\n",
    "    # return loss_and_metrics, model, epochs_EarlyStopping\n",
    "    return loss_and_metrics, epochs_EarlyStopping, model\n",
    "\n",
    "    #model.predict(xVal, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNfunction(modelType, layers, units, activation, dropout, L1, L2, batch_size, optimizer, learning_rate, runningDate):\n",
    "    \n",
    "    verbose = 1\n",
    "    patience = 1\n",
    "    epochs = 300\n",
    "    numberOfOutputs = yTrain.shape[1]\n",
    "    classification = True\n",
    "    \n",
    "    if classification:\n",
    "        finalActivation=\"softmax\"\n",
    "        loss = \"categorical_crossentropy\"\n",
    "        metrics = [\"accuracy\"]\n",
    "        EarlyStopping_monitor = \"val_loss\"\n",
    "    else:\n",
    "        finalActivation=\"linear\"\n",
    "        loss = \"MeanAbsoluteError\"\n",
    "        metrics = [\"MeanAbsoluteError\", \"MeanSquaredError\"]\n",
    "        EarlyStopping_monitor = \"val_mean_absolute_error\"\n",
    "    \n",
    "\n",
    "    if optimizer == \"RMSprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "    #input1 = tf.keras.layers.Input(shape=(1,))\n",
    "    #input2 = tf.keras.layers.Input(shape=(1,))\n",
    "    #merged = tf.keras.layers.Concatenate(axis=1)([input1, input2])\n",
    "    #dense1 = tf.keras.layers.Dense(2, input_dim=2, activation=keras.activations.sigmoid, use_bias=True)(merged)\n",
    "\n",
    "    input = tf.keras.layers.Input(shape=(xWinTrain.shape[1],))\n",
    "    #model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    if modelType == \"LSTM\":\n",
    "        hiddenLayer = tf.keras.layers.LSTM(units=units)(input)\n",
    "        output = tf.keras.layers.Dense(units=numberOfOutputs, activation=finalActivation,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2))(hiddenLayer)\n",
    "    elif modelType == \"GRU\":\n",
    "        hiddenLayer = tf.keras.layers.GRU(units=units)(input)\n",
    "        output = tf.keras.layers.Dense(units=numberOfOutputs, activation=finalActivation,\n",
    "                                       kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2))(hiddenLayer)\n",
    "    elif modelType == \"SimpleRNN\":\n",
    "        hiddenLayer = tf.keras.layers.SimpleRNN(units=units)(input)\n",
    "        output = tf.keras.layers.Dense(units=numberOfOutputs, activation=finalActivation,\n",
    "                                       kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2))(hiddenLayer)\n",
    "    elif modelType == \"RegularizedLinear\":\n",
    "        output = tf.keras.layers.Dense(units=numberOfOutputs, activation=finalActivation,\n",
    "                                        kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2))(input)\n",
    "        print(\"RegularizedLinear\")\n",
    "    elif modelType == \"StandardLinear\":\n",
    "        output = tf.keras.layers.Dense(units=numberOfOutputs, activation=finalActivation)(input)\n",
    "        print(\"StandardLinear\")\n",
    "    else:\n",
    "        try:\n",
    "            hiddenLayer = tf.keras.layers.Dense(units=units,\n",
    "                                activation=activation,\n",
    "                                kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2))(input)\n",
    "            hiddenLayer = tf.keras.layers.Dropout(rate=dropout)(hiddenLayer)\n",
    "\n",
    "            for n in range(0, layers-1):\n",
    "                hiddenLayer = tf.keras.layers.Dense(units=units,\n",
    "                                activation=activation,\n",
    "                                kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2))(hiddenLayer)\n",
    "                hiddenLayer = tf.keras.layers.Dropout(rate=dropout)(hiddenLayer)\n",
    "                # scaler.fit_transform\n",
    "                # tf.keras.layers.BatchNormalization(\n",
    "            print(f\"NN{layers}Layer\")\n",
    "        except:\n",
    "            print(\"NN1Layer_WhyDidWeEndUpHere?\")\n",
    "\n",
    "        output = tf.keras.layers.Dense(units=numberOfOutputs, activation=finalActivation,\n",
    "                            kernel_regularizer=tf.keras.regularizers.L1L2(l1=L1, l2=L2))(hiddenLayer)\n",
    "\n",
    "    #model = tf.keras.models.Model(inputs=[input1, input2], output=output)\n",
    "    model = tf.keras.models.Model(inputs=[input], outputs=output, name=f\"{modelType}_{runningDate}\")\n",
    "\n",
    "    model.compile(optimizer=optimizer,  # Adam(learning_rate=0.0001) #RMSprop #sgd\n",
    "                loss=loss,  # 'tf.keras.losses.MeanSquaredError()'  #Huber #MeanAbsoluteError #MeanSquaredError \n",
    "                #metrics=[\"MeanSquaredError\", \"MeanAbsoluteError\"])\n",
    "                metrics=metrics)#, \"RootMeanSquaredError\"]) #accuracy #MeanSquaredLogarithmicError #RootMeanSquaredError #MeanAbsolutePercentageError \n",
    "\n",
    "\n",
    "    # model.fit(x=xTrain, y=yTrain,\n",
    "    #           batch_size=16, epochs=epo, verbose=2)\n",
    "\n",
    "    #loss_and_metrics = model.evaluate(xVal, yVal, batch_size=128)\n",
    "    \n",
    "    performCV = False\n",
    "    loss_and_metrics_matrix = pd.DataFrame()\n",
    "    epochs_matrix = pd.DataFrame()\n",
    "    quarters = dummies[dummies[\"Split\"] == \"Validation\"][\"fdateYQ\"].unique()\n",
    "    quarters.sort()\n",
    "    if performCV:    \n",
    "        for q in quarters:\n",
    "            # Run cross validation through model fit and evaluate. \n",
    "            # Save all MSAs and MSEs from \"loss_and_metrics\" into a dataframe and take their average to obtain the best model\n",
    "            print(\"Quarter \" + str(q))\n",
    "            xT = dummies[dummies[\"fdateYQ\"] < q].drop([\"returns\", \"MktCap\", \"Split\", \"fdateYQ\", \"gvkey\"], axis=1)\n",
    "            yT = dummies[dummies[\"fdateYQ\"] < q][\"returns\"]\n",
    "            #A rolling window might be faster. E.g.: dummies[\"fdateYQ\"] == q - 0.25\n",
    "\n",
    "            xV = dummies[dummies[\"fdateYQ\"] == q].drop([\"returns\", \"MktCap\", \"Split\", \"fdateYQ\", \"gvkey\"], axis=1)\n",
    "            yV = dummies[dummies[\"fdateYQ\"] == q][\"returns\"]\n",
    "\n",
    "            earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor=EarlyStopping_monitor, patience=patience, verbose=1, restore_best_weights=True) #Can this be taken out from the loop? => Less computing\n",
    "\n",
    "            # tensorboardLogPath = f\"Results/logs/{runningDate}/{modelType}_{layers}L_{units}U_{activation}_{dropout}DO_{L1}L1_{L2}L2_{batch_size}Batch_{optimizer._name}_{learning_rate}LR_Q{q}\"\n",
    "            # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboardLogPath) #tensorboard --logdir=\"10-01-2023_1606\" #tensorboard --logdir=\"logs/\"\n",
    "            #BackupAndRestore_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=\"/tmp/backup\")\n",
    "\n",
    "            history = model.fit(x=xT, y=yT,\n",
    "                                batch_size=batch_size, epochs=epochs,\n",
    "                                callbacks=[earlystopping_callback], verbose=verbose, validation_data=(xV, yV))\n",
    "\n",
    "            loss_and_metrics = model.evaluate(xV, yV, batch_size=batch_size, return_dict=True)\n",
    "            epochs_EarlyStopping = len(history.history['loss']) - patience\n",
    "\n",
    "            loss_and_metrics_matrix = pd.concat((loss_and_metrics_matrix,\n",
    "                                                 pd.DataFrame(loss_and_metrics,\n",
    "                                                              index=[0])))\n",
    "\n",
    "            epochs_matrix = pd.concat((epochs_matrix, pd.DataFrame([epochs_EarlyStopping])))\n",
    "            print(loss_and_metrics_matrix, \"\\n\", epochs_matrix, \"\\n\")\n",
    "\n",
    "        loss_and_metrics = loss_and_metrics_matrix.mean()\n",
    "        epochs_EarlyStopping = epochs_matrix.mean()[0]\n",
    "\n",
    "    else:\n",
    "        earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor=EarlyStopping_monitor, patience=patience, verbose=1, restore_best_weights=True) #Can this be taken out from the loop? => Less computing\n",
    "\n",
    "        tensorboardLogPath = f\"Results/logs/{runningDate}/{modelType}_{layers}L_{units}U_{activation}_{dropout}DO_{L1}L1_{L2}L2_{batch_size}Batch_{optimizer._name}_{learning_rate}LR\"\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboardLogPath) #tensorboard --logdir=\"10-01-2023_1606\" #tensorboard --logdir=\"logs/\"\n",
    "        #BackupAndRestore_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=\"/tmp/backup\")\n",
    "        history = model.fit(x=xWinTrain, y=yTrain,\n",
    "                batch_size=batch_size, epochs=epochs,\n",
    "                callbacks=[earlystopping_callback, tensorboard_callback], verbose=verbose, validation_data = (xWinVal, yVal))\n",
    "        loss_and_metrics = model.evaluate(xWinVal, yVal, batch_size=batch_size, return_dict=True)\n",
    "        epochs_EarlyStopping = len(history.history['loss']) - patience\n",
    "        print(loss_and_metrics, \"\\n\", epochs_EarlyStopping, \"\\n\")\n",
    "        #history.history[]\n",
    "\n",
    "    # history = model.fit(x=xWinTrainDict, y=yTrain,\n",
    "    #           batch_size=16, epochs=300,\n",
    "    #           callbacks=[callback], verbose=1, validation_data = (xWinValDict, yVal))\n",
    "\n",
    "\n",
    "    # quarters = len(yVal)\n",
    "    # CV = []\n",
    "    # for q in range(0, quarters):\n",
    "\n",
    "    #     model.fit(x=xTrain, y=yTrain,\n",
    "    #           batch_size=16, epochs=epo, verbose=2)\n",
    "\n",
    "    #     validationError = model.evaluate(xVal, yVal, batch_size=128)\n",
    "    #     CV = [CV, validationError]\n",
    "\n",
    "\n",
    "    # try:\n",
    "    #     loss_and_metrics = [x for x in loss_and_metrics]\n",
    "    # except:     \n",
    "    #     print(loss_and_metrics)\n",
    "\n",
    "    # return loss_and_metrics, model, epochs_EarlyStopping\n",
    "    return loss_and_metrics, epochs_EarlyStopping, model\n",
    "\n",
    "    #model.predict(xVal, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper-Parameters\n",
    "NNModelType = {\"FeedForward\"} #, \"LSTM\", \"GRU\"}\n",
    "hiddenLayers = {1, 2, 3, 4, 5}\n",
    "hiddenUnits = 2**np.arange(9)\n",
    "activationFunc = {\"linear\", \"relu\", \"sigmoid\", \"tanh\"} #etc. https://keras.io/api/layers/activations/ , \"selu\"\n",
    "dropOut = np.arange(start=0, stop=1, step=0.1)\n",
    "#epochs = [100] #Just choose best model. => Run for 100 epochs, but if 20th epoch is the best, choose it, i.e. early stopping\n",
    "#inputSize = numberOfVariables #ncol(trainXPools[[1]])\n",
    "#other parameters: loss func, node structure, location of the regularization function\n",
    "batchSize = 2**np.arange(start=4, stop=9)\n",
    "optim = {\"RMSprop\", \"Adam\"}#, \"sgd\"}\n",
    "learningRate = {0.01, 0.001, 0.0001}#, 0.00001}\n",
    "L1L2Grid = 10**np.arange(start=2, stop=-6, step=-1.0) #3 and -10\n",
    "L1L2Grid = np.append(0, L1L2Grid)\n",
    "none = {np.NaN}\n",
    "\n",
    "StandardLinearParams = {\n",
    "    \"Model type\": {\"StandardLinear\"},\n",
    "    \"Hidden layers\": none,\n",
    "    \"Hidden units\": none,\n",
    "    \"Activation function\": none,\n",
    "    \"Dropout\": none,\n",
    "    \"L1\": none,\n",
    "    \"L2\": none,\n",
    "    \"Batch size\": {32},\n",
    "    \"Optimizer\": {\"Adam\"},\n",
    "    \"Learning rate\": {0.001}\n",
    "}\n",
    "\n",
    "LinearParams = StandardLinearParams | {\n",
    "    \"Model type\": {\"RegularizedLinear\"},\n",
    "    \"L1\": L1L2Grid,\n",
    "    \"L2\": L1L2Grid,\n",
    "    \"Batch size\": batchSize,\n",
    "    \"Optimizer\": optim,\n",
    "    \"Learning rate\": learningRate\n",
    "}\n",
    "\n",
    "NNParams = LinearParams | {\n",
    "    \"Model type\": NNModelType,  # , \"LSTM\", \"GRU\"},\n",
    "    \"Hidden layers\": hiddenLayers,\n",
    "    \"Hidden units\": hiddenUnits,\n",
    "    \"Activation function\": activationFunc,\n",
    "    \"Dropout\": dropOut\n",
    "}\n",
    "\n",
    "NaiveZeroParams = StandardLinearParams | {\n",
    "    \"Model type\": {\"NaiveZeroForecast\"},\n",
    "    \"Batch size\": none,\n",
    "    \"Optimizer\": none,\n",
    "    \"Learning rate\": none,\n",
    "    \"Epochs\": none,\n",
    "    \"Training Time (minutes)\": none,\n",
    "    \"ModelPointer\": none\n",
    "}\n",
    "\n",
    "NaiveMeanParams = NaiveZeroParams | {\"Model type\": {\"NaiveMeanForecast\"}}\n",
    "NaiveFirmMeanParams = NaiveZeroParams| {\"Model type\": {\"NaiveFirmMeanForecast\"}}\n",
    "NaiveFiveYearParams = NaiveZeroParams| {\"Model type\": {\"NaiveFiveYearForecast\"}}\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "StandardLinearGrid = pd.DataFrame(itertools.product(\n",
    "    *StandardLinearParams.values()), columns=StandardLinearParams.keys())\n",
    "\n",
    "linearGrid = pd.DataFrame(itertools.product(\n",
    "    *LinearParams.values()), columns=LinearParams.keys())\n",
    "\n",
    "NNGrid = pd.DataFrame(itertools.product(\n",
    "    *NNParams.values()), columns=NNParams.keys())\n",
    "\n",
    "\n",
    "NaiveZeroGrid = pd.DataFrame(itertools.product(\n",
    "    *NaiveZeroParams.values()), columns=NaiveZeroParams.keys())\n",
    "\n",
    "NaiveMeanGrid = pd.DataFrame(itertools.product(\n",
    "    *NaiveMeanParams.values()), columns=NaiveMeanParams.keys())\n",
    "\n",
    "NaiveFirmMeanGrid = pd.DataFrame(itertools.product(\n",
    "    *NaiveFirmMeanParams.values()), columns=NaiveFirmMeanParams.keys())\n",
    "\n",
    "NaiveFiveYearGrid = pd.DataFrame(itertools.product(\n",
    "    *NaiveFiveYearParams.values()), columns=NaiveFiveYearParams.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Zero\n",
    "zeroForecastMSE = sum(yVal**2)/len(yVal)\n",
    "zeroForecastMAE = sum(abs(yVal))/len(yVal)\n",
    "\n",
    "# This works also:\n",
    "# tf.keras.losses.MeanSquaredError().call(y_true=yVal,\n",
    "#                                         y_pred=np.zeros(len(yVal)))\n",
    "# tf.keras.losses.MeanAbsoluteError().call(y_true=yVal,\n",
    "#                                          y_pred=np.zeros(len(yVal)))\n",
    "\n",
    "NaiveZeroGrid.loc[:,\"MAE\"] = zeroForecastMAE\n",
    "NaiveZeroGrid.loc[:,\"MSE\"] = zeroForecastMSE\n",
    "\n",
    "#Naive Mean\n",
    "naiveMean = sum(yTrain)/len(yTrain)\n",
    "meanForecastMSE = sum((yVal-naiveMean)**2)/len(yVal)\n",
    "meanForecastMAE = sum(abs(yVal-naiveMean))/len(yVal)\n",
    "\n",
    "NaiveMeanGrid.loc[:,\"MAE\"] = meanForecastMAE\n",
    "NaiveMeanGrid.loc[:,\"MSE\"] = meanForecastMSE\n",
    "\n",
    "# This works also:\n",
    "# tf.keras.losses.MeanSquaredError().call(y_true=yVal,\n",
    "#                                         y_pred=np.full(len(yVal), naiveMean)\n",
    "#                                         )\n",
    "# tf.keras.losses.MeanAbsoluteError().call(y_true=yVal,\n",
    "#                                          y_pred=np.full(len(yVal), naiveMean)\n",
    "#                                          )\n",
    "\n",
    "\n",
    "#Naive FirmMean\n",
    "naiveFirmMean = finalData.loc[split==\"Train\", [\"gvkey\", 'returns']].groupby(['gvkey'])['returns'].mean()\n",
    "\n",
    "naiveFirmMeanDF = pd.merge(naiveFirmMean, finalData.loc[split == \"Validation\", [\"gvkey\", 'returns']],\n",
    "                           on=\"gvkey\", suffixes=('_pred', '_real'))\n",
    "\n",
    "naiveFirmError = naiveFirmMeanDF[\"returns_pred\"] - naiveFirmMeanDF[\"returns_real\"]\n",
    "naiveFirmError = naiveFirmError.dropna() #I should maybe instead drop all firms without historical observations. Otherwise the models are not comparable. There will be a bias\n",
    "firmMeanForecastMSE = sum(naiveFirmError**2)/len(naiveFirmError)\n",
    "firmMeanForecastMAE = sum(abs(naiveFirmError))/len(naiveFirmError)\n",
    "\n",
    "NaiveFirmMeanGrid.loc[:,\"MAE\"] = firmMeanForecastMAE\n",
    "NaiveFirmMeanGrid.loc[:,\"MSE\"] = firmMeanForecastMSE\n",
    "\n",
    "#Naive FiveYearFirmMean\n",
    "naiveFiveYearError = finalData.loc[split==\"Validation\"][\"past5YearReturn\"]/(5*4) - finalData.loc[split==\"Validation\"]['returns']\n",
    "firmFiveYearForecastMSE = sum(naiveFiveYearError**2)/len(naiveFiveYearError)\n",
    "firmFiveYearForecastMAE = sum(abs(naiveFiveYearError))/len(naiveFiveYearError)\n",
    "\n",
    "NaiveFiveYearGrid.loc[:,\"MAE\"] = firmFiveYearForecastMAE\n",
    "NaiveFiveYearGrid.loc[:,\"MSE\"] = firmFiveYearForecastMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras_tuner.SklearnTuner(oracle, hypermodel, scoring=None, metrics=None, cv=None, **kwargs)\n",
    "\n",
    "# keras_tuner.RandomSearch(\n",
    "#     hypermodel=None,\n",
    "#     objective=None,\n",
    "#     max_trials=10,\n",
    "#     seed=None,\n",
    "#     hyperparameters=None,\n",
    "#     tune_new_entries=True,\n",
    "#     allow_new_entries=True,\n",
    "#     **kwargs\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  1  out of  121\n",
      "Model type             StandardLinear\n",
      "Hidden layers                    None\n",
      "Hidden units                     None\n",
      "Activation function              None\n",
      "Dropout                          None\n",
      "L1                               None\n",
      "L2                               None\n",
      "Batch size                         32\n",
      "Optimizer                        Adam\n",
      "Learning rate                   0.001\n",
      "Name: 0, dtype: object\n",
      "StandardLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 0.6898 - accuracy: 0.5838 - val_loss: 0.6636 - val_accuracy: 0.6101\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6520 - accuracy: 0.6248 - val_loss: 0.6569 - val_accuracy: 0.6166\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6488 - accuracy: 0.6327 - val_loss: 0.6567 - val_accuracy: 0.6211\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6477 - accuracy: 0.6330 - val_loss: 0.6532 - val_accuracy: 0.6235\n",
      "Epoch 5/300\n",
      "661/670 [============================>.] - ETA: 0s - loss: 0.6461 - accuracy: 0.6348Restoring model weights from the end of the best epoch: 4.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6465 - accuracy: 0.6341 - val_loss: 0.6542 - val_accuracy: 0.6204\n",
      "Epoch 5: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 0.6532 - accuracy: 0.6235\n",
      "{'loss': 0.6532175540924072, 'accuracy': 0.6234558820724487} \n",
      " 4 \n",
      "\n",
      "Model time: 0.3467678017914295 minutes\n",
      "\n",
      "Total time: 0.3467678017914295 minutes\n",
      "\n",
      "\n",
      "Model  2  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                 0.001\n",
      "L2                               0.00001\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 62, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 7ms/step - loss: 0.7054 - accuracy: 0.5918 - val_loss: 0.6798 - val_accuracy: 0.6084\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6654 - accuracy: 0.6270 - val_loss: 0.6696 - val_accuracy: 0.6211\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.6614 - accuracy: 0.6282 - val_loss: 0.6658 - val_accuracy: 0.6237\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6591 - accuracy: 0.6305 - val_loss: 0.6619 - val_accuracy: 0.6266\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6584 - accuracy: 0.6325 - val_loss: 0.6613 - val_accuracy: 0.6283\n",
      "Epoch 6/300\n",
      "668/670 [============================>.] - ETA: 0s - loss: 0.6577 - accuracy: 0.6287Restoring model weights from the end of the best epoch: 5.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6576 - accuracy: 0.6288 - val_loss: 0.6635 - val_accuracy: 0.6250\n",
      "Epoch 6: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.6613 - accuracy: 0.6283\n",
      "{'loss': 0.6612786650657654, 'accuracy': 0.6283466815948486} \n",
      " 5 \n",
      "\n",
      "Model time: 0.374719325453043 minutes\n",
      "\n",
      "Total time: 0.7216371148824692 minutes\n",
      "\n",
      "\n",
      "Model  3  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                   1.0\n",
      "L2                               0.00001\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 35, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 3.6082 - accuracy: 0.4949 - val_loss: 0.7345 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7353 - accuracy: 0.5001 - val_loss: 0.7340 - val_accuracy: 0.4897\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7348 - accuracy: 0.5008 - val_loss: 0.7340 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "657/670 [============================>.] - ETA: 0s - loss: 0.7343 - accuracy: 0.4966Restoring model weights from the end of the best epoch: 3.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7343 - accuracy: 0.4967 - val_loss: 0.7353 - val_accuracy: 0.5001\n",
      "Epoch 4: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.7340 - accuracy: 0.5001\n",
      "{'loss': 0.7339687943458557, 'accuracy': 0.5001260638237} \n",
      " 3 \n",
      "\n",
      "Model time: 0.2639862038195133 minutes\n",
      "\n",
      "Total time: 0.9857066571712494 minutes\n",
      "\n",
      "\n",
      "Model  4  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                               0.00001\n",
      "L2                                   1.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 75, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 1.0349 - accuracy: 0.5745 - val_loss: 0.6842 - val_accuracy: 0.6097\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6855 - accuracy: 0.5930 - val_loss: 0.6840 - val_accuracy: 0.6074\n",
      "Epoch 3/300\n",
      "655/670 [============================>.] - ETA: 0s - loss: 0.6850 - accuracy: 0.5888Restoring model weights from the end of the best epoch: 2.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6851 - accuracy: 0.5886 - val_loss: 0.6875 - val_accuracy: 0.6059\n",
      "Epoch 3: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.6840 - accuracy: 0.6074\n",
      "{'loss': 0.6839801669120789, 'accuracy': 0.6074219942092896} \n",
      " 2 \n",
      "\n",
      "Model time: 0.2096848338842392 minutes\n",
      "\n",
      "Total time: 1.19549048691988 minutes\n",
      "\n",
      "\n",
      "Model  5  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                  10.0\n",
      "L2                                   1.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 21, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 33.0134 - accuracy: 0.4957 - val_loss: 1.1057 - val_accuracy: 0.4955\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.1026 - accuracy: 0.4981 - val_loss: 1.1056 - val_accuracy: 0.4992\n",
      "Epoch 3/300\n",
      "663/670 [============================>.] - ETA: 0s - loss: 1.0996 - accuracy: 0.4981Restoring model weights from the end of the best epoch: 2.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.0996 - accuracy: 0.4985 - val_loss: 1.1183 - val_accuracy: 0.5049\n",
      "Epoch 3: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 1.1056 - accuracy: 0.4992\n",
      "{'loss': 1.105642318725586, 'accuracy': 0.4991680383682251} \n",
      " 2 \n",
      "\n",
      "Model time: 0.20518478378653526 minutes\n",
      "\n",
      "Total time: 1.4007586166262627 minutes\n",
      "\n",
      "\n",
      "Model  6  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                   0.1\n",
      "L2                                  0.01\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 41, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 1.0972 - accuracy: 0.5614 - val_loss: 0.7037 - val_accuracy: 0.5445\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7010 - accuracy: 0.5442 - val_loss: 0.7021 - val_accuracy: 0.5656\n",
      "Epoch 3/300\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.5447Restoring model weights from the end of the best epoch: 2.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7014 - accuracy: 0.5447 - val_loss: 0.7036 - val_accuracy: 0.5686\n",
      "Epoch 3: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.7021 - accuracy: 0.5656\n",
      "{'loss': 0.7021265029907227, 'accuracy': 0.5656229257583618} \n",
      " 2 \n",
      "\n",
      "Model time: 0.2143181972205639 minutes\n",
      "\n",
      "Total time: 1.6151601374149323 minutes\n",
      "\n",
      "\n",
      "Model  7  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                   0.1\n",
      "L2                               0.00001\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 44, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 5ms/step - loss: 1.1275 - accuracy: 0.5252 - val_loss: 0.7014 - val_accuracy: 0.5943\n",
      "Epoch 2/300\n",
      "658/670 [============================>.] - ETA: 0s - loss: 0.7011 - accuracy: 0.5380Restoring model weights from the end of the best epoch: 1.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7011 - accuracy: 0.5385 - val_loss: 0.7034 - val_accuracy: 0.5958\n",
      "Epoch 2: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.7014 - accuracy: 0.5943\n",
      "{'loss': 0.7014358639717102, 'accuracy': 0.5942620635032654} \n",
      " 1 \n",
      "\n",
      "Model time: 0.18916801735758781 minutes\n",
      "\n",
      "Total time: 1.8043948076665401 minutes\n",
      "\n",
      "\n",
      "Model  8  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                   1.0\n",
      "L2                                   1.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 30, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 4.4299 - accuracy: 0.4992 - val_loss: 0.7357 - val_accuracy: 0.4989\n",
      "Epoch 2/300\n",
      "651/670 [============================>.] - ETA: 0s - loss: 0.7341 - accuracy: 0.5031Restoring model weights from the end of the best epoch: 1.\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7341 - accuracy: 0.5027 - val_loss: 0.7362 - val_accuracy: 0.5006\n",
      "Epoch 2: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.7357 - accuracy: 0.4989\n",
      "{'loss': 0.7356547713279724, 'accuracy': 0.4989159405231476} \n",
      " 1 \n",
      "\n",
      "Model time: 0.1593344658613205 minutes\n",
      "\n",
      "Total time: 1.963795941323042 minutes\n",
      "\n",
      "\n",
      "Model  9  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                  0.01\n",
      "L2                               0.00001\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 53, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 0.7789 - accuracy: 0.5908 - val_loss: 0.6930 - val_accuracy: 0.6241\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6821 - accuracy: 0.6177 - val_loss: 0.6736 - val_accuracy: 0.6265\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6736 - accuracy: 0.6202 - val_loss: 0.6727 - val_accuracy: 0.6281\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6732 - accuracy: 0.6198 - val_loss: 0.6716 - val_accuracy: 0.6353\n",
      "Epoch 5/300\n",
      "664/670 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.6205Restoring model weights from the end of the best epoch: 4.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6727 - accuracy: 0.6210 - val_loss: 0.6777 - val_accuracy: 0.6080\n",
      "Epoch 5: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.6716 - accuracy: 0.6353\n",
      "{'loss': 0.6716246604919434, 'accuracy': 0.6353048086166382} \n",
      " 4 \n",
      "\n",
      "Model time: 0.3037854880094528 minutes\n",
      "\n",
      "Total time: 2.2676814272999763 minutes\n",
      "\n",
      "\n",
      "Model  10  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                  0.01\n",
      "L2                                   0.1\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 49, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 0.8008 - accuracy: 0.5972 - val_loss: 0.6828 - val_accuracy: 0.6071\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6808 - accuracy: 0.6082 - val_loss: 0.6792 - val_accuracy: 0.6377\n",
      "Epoch 3/300\n",
      "659/670 [============================>.] - ETA: 0s - loss: 0.6803 - accuracy: 0.6078Restoring model weights from the end of the best epoch: 2.\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.6803 - accuracy: 0.6077 - val_loss: 0.6794 - val_accuracy: 0.6087\n",
      "Epoch 3: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 0.6792 - accuracy: 0.6377\n",
      "{'loss': 0.6792147755622864, 'accuracy': 0.6377249956130981} \n",
      " 2 \n",
      "\n",
      "Model time: 0.21733664348721504 minutes\n",
      "\n",
      "Total time: 2.485101420432329 minutes\n",
      "\n",
      "\n",
      "Model  11  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                0.0001\n",
      "L2                               0.00001\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 71, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 0.6986 - accuracy: 0.5728 - val_loss: 0.6713 - val_accuracy: 0.5953\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6546 - accuracy: 0.6245 - val_loss: 0.6594 - val_accuracy: 0.6255\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6505 - accuracy: 0.6304 - val_loss: 0.6575 - val_accuracy: 0.6236\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6500 - accuracy: 0.6336 - val_loss: 0.6557 - val_accuracy: 0.6250\n",
      "Epoch 5/300\n",
      "657/670 [============================>.] - ETA: 0s - loss: 0.6480 - accuracy: 0.6340Restoring model weights from the end of the best epoch: 4.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6485 - accuracy: 0.6343 - val_loss: 0.6592 - val_accuracy: 0.6162\n",
      "Epoch 5: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 0.6557 - accuracy: 0.6250\n",
      "{'loss': 0.6557213664054871, 'accuracy': 0.6250188946723938} \n",
      " 4 \n",
      "\n",
      "Model time: 0.38468872755765915 minutes\n",
      "\n",
      "Total time: 2.8698900938034058 minutes\n",
      "\n",
      "\n",
      "Model  12  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                               0.00001\n",
      "L2                                  0.01\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 77, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 0.7154 - accuracy: 0.5725 - val_loss: 0.6736 - val_accuracy: 0.6143\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6649 - accuracy: 0.6248 - val_loss: 0.6675 - val_accuracy: 0.6201\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6597 - accuracy: 0.6296 - val_loss: 0.6601 - val_accuracy: 0.6295\n",
      "Epoch 4/300\n",
      "665/670 [============================>.] - ETA: 0s - loss: 0.6570 - accuracy: 0.6304Restoring model weights from the end of the best epoch: 3.\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.6570 - accuracy: 0.6306 - val_loss: 0.6631 - val_accuracy: 0.6233\n",
      "Epoch 4: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 0.6601 - accuracy: 0.6295\n",
      "{'loss': 0.6601085662841797, 'accuracy': 0.6295063495635986} \n",
      " 3 \n",
      "\n",
      "Model time: 0.29390212148427963 minutes\n",
      "\n",
      "Total time: 3.163858875632286 minutes\n",
      "\n",
      "\n",
      "Model  13  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                  10.0\n",
      "L2                                 100.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 19, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 67.3064 - accuracy: 0.4964 - val_loss: 1.0408 - val_accuracy: 0.4996\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - ETA: 0s - loss: 1.0685 - accuracy: 0.4999Restoring model weights from the end of the best epoch: 1.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0685 - accuracy: 0.4999 - val_loss: 1.0954 - val_accuracy: 0.4999\n",
      "Epoch 2: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 1.0408 - accuracy: 0.4996\n",
      "{'loss': 1.0408381223678589, 'accuracy': 0.49957141280174255} \n",
      " 1 \n",
      "\n",
      "Model time: 0.15725110843777657 minutes\n",
      "\n",
      "Total time: 3.321226641535759 minutes\n",
      "\n",
      "\n",
      "Model  14  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                 0.001\n",
      "L2                                  10.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 56, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 4s 4ms/step - loss: 3.8127 - accuracy: 0.5405 - val_loss: 0.6923 - val_accuracy: 0.5990\n",
      "Epoch 2/300\n",
      "667/670 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5653Restoring model weights from the end of the best epoch: 1.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6928 - accuracy: 0.5653 - val_loss: 0.6931 - val_accuracy: 0.5853\n",
      "Epoch 2: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.6923 - accuracy: 0.5990\n",
      "{'loss': 0.6922681927680969, 'accuracy': 0.5989512205123901} \n",
      " 1 \n",
      "\n",
      "Model time: 0.15241775289177895 minutes\n",
      "\n",
      "Total time: 3.4737277291715145 minutes\n",
      "\n",
      "\n",
      "Model  15  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                 100.0\n",
      "L2                                  10.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 11, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 8ms/step - loss: 319.0842 - accuracy: 0.4897 - val_loss: 4.7102 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.7870 - accuracy: 0.4925 - val_loss: 4.6957 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - ETA: 0s - loss: 4.7437 - accuracy: 0.5028Restoring model weights from the end of the best epoch: 2.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 4.7437 - accuracy: 0.5028 - val_loss: 4.6968 - val_accuracy: 0.5001\n",
      "Epoch 3: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 4.6957 - accuracy: 0.5001\n",
      "{'loss': 4.695741176605225, 'accuracy': 0.5001260638237} \n",
      " 2 \n",
      "\n",
      "Model time: 0.23910170048475266 minutes\n",
      "\n",
      "Total time: 3.712946094572544 minutes\n",
      "\n",
      "\n",
      "Model  16  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                 100.0\n",
      "L2                                   1.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 12, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 306.1962 - accuracy: 0.4945 - val_loss: 4.8204 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "663/670 [============================>.] - ETA: 0s - loss: 4.9532 - accuracy: 0.4922Restoring model weights from the end of the best epoch: 1.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 4.9538 - accuracy: 0.4924 - val_loss: 4.8229 - val_accuracy: 0.5003\n",
      "Epoch 2: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 4.8204 - accuracy: 0.5001\n",
      "{'loss': 4.820385456085205, 'accuracy': 0.5001260638237} \n",
      " 1 \n",
      "\n",
      "Model time: 0.16176877170801163 minutes\n",
      "\n",
      "Total time: 3.874781511723995 minutes\n",
      "\n",
      "\n",
      "Model  17  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                  0.01\n",
      "L2                                  0.01\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 50, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 5ms/step - loss: 0.7875 - accuracy: 0.6011 - val_loss: 0.7088 - val_accuracy: 0.6264\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6871 - accuracy: 0.6181 - val_loss: 0.6771 - val_accuracy: 0.6111\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6750 - accuracy: 0.6204 - val_loss: 0.6737 - val_accuracy: 0.6278\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6742 - accuracy: 0.6181 - val_loss: 0.6720 - val_accuracy: 0.6320\n",
      "Epoch 5/300\n",
      "658/670 [============================>.] - ETA: 0s - loss: 0.6742 - accuracy: 0.6185Restoring model weights from the end of the best epoch: 4.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6743 - accuracy: 0.6185 - val_loss: 0.6802 - val_accuracy: 0.6080\n",
      "Epoch 5: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 0.6720 - accuracy: 0.6320\n",
      "{'loss': 0.6720380783081055, 'accuracy': 0.6319770216941833} \n",
      " 4 \n",
      "\n",
      "Model time: 0.3172188997268677 minutes\n",
      "\n",
      "Total time: 4.192082799971104 minutes\n",
      "\n",
      "\n",
      "Model  18  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                   0.1\n",
      "L2                                 100.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 37, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 5s 6ms/step - loss: 31.4271 - accuracy: 0.5174 - val_loss: 0.6946 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "652/670 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.5004Restoring model weights from the end of the best epoch: 1.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6944 - accuracy: 0.4998 - val_loss: 0.6950 - val_accuracy: 0.5573\n",
      "Epoch 2: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.6946 - accuracy: 0.5001\n",
      "{'loss': 0.6945593357086182, 'accuracy': 0.5001260638237} \n",
      " 1 \n",
      "\n",
      "Model time: 0.17096788063645363 minutes\n",
      "\n",
      "Total time: 4.363134033977985 minutes\n",
      "\n",
      "\n",
      "Model  19  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                   1.0\n",
      "L2                                   0.0\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 27, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 3.8773 - accuracy: 0.4960 - val_loss: 0.7389 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7346 - accuracy: 0.4995 - val_loss: 0.7357 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7341 - accuracy: 0.4998 - val_loss: 0.7322 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.7337 - accuracy: 0.4978Restoring model weights from the end of the best epoch: 3.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7337 - accuracy: 0.4978 - val_loss: 0.7333 - val_accuracy: 0.5057\n",
      "Epoch 4: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 0.7322 - accuracy: 0.5001\n",
      "{'loss': 0.732150137424469, 'accuracy': 0.5001260638237} \n",
      " 3 \n",
      "\n",
      "Model time: 0.23785171285271645 minutes\n",
      "\n",
      "Total time: 4.6010690703988075 minutes\n",
      "\n",
      "\n",
      "Model  20  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                                   0.1\n",
      "L2                                0.0001\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 43, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.0266 - accuracy: 0.5401 - val_loss: 0.7013 - val_accuracy: 0.5264\n",
      "Epoch 2/300\n",
      "666/670 [============================>.] - ETA: 0s - loss: 0.7009 - accuracy: 0.5440Restoring model weights from the end of the best epoch: 1.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7009 - accuracy: 0.5440 - val_loss: 0.7021 - val_accuracy: 0.5542\n",
      "Epoch 2: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 0.7013 - accuracy: 0.5264\n",
      "{'loss': 0.701283872127533, 'accuracy': 0.5263953804969788} \n",
      " 1 \n",
      "\n",
      "Model time: 0.2053721807897091 minutes\n",
      "\n",
      "Total time: 4.806524574756622 minutes\n",
      "\n",
      "\n",
      "Model  21  out of  121\n",
      "Model type             RegularizedLinear\n",
      "Hidden layers                       None\n",
      "Hidden units                        None\n",
      "Activation function                 None\n",
      "Dropout                             None\n",
      "L1                               0.00001\n",
      "L2                               0.00001\n",
      "Batch size                            32\n",
      "Optimizer                           Adam\n",
      "Learning rate                      0.001\n",
      "Name: 80, dtype: object\n",
      "RegularizedLinear\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6849 - accuracy: 0.5916 - val_loss: 0.6603 - val_accuracy: 0.6151\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.6547 - accuracy: 0.6202 - val_loss: 0.6565 - val_accuracy: 0.6206\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6485 - accuracy: 0.6307 - val_loss: 0.6545 - val_accuracy: 0.6265\n",
      "Epoch 4/300\n",
      "657/670 [============================>.] - ETA: 0s - loss: 0.6469 - accuracy: 0.6325Restoring model weights from the end of the best epoch: 3.\n",
      "670/670 [==============================] - 2s 4ms/step - loss: 0.6467 - accuracy: 0.6329 - val_loss: 0.6563 - val_accuracy: 0.6221\n",
      "Epoch 4: early stopping\n",
      "620/620 [==============================] - 1s 2ms/step - loss: 0.6545 - accuracy: 0.6265\n",
      "{'loss': 0.6545316576957703, 'accuracy': 0.6264811158180237} \n",
      " 3 \n",
      "\n",
      "Model time: 0.23765169829130173 minutes\n",
      "\n",
      "Total time: 5.044242929667234 minutes\n",
      "\n",
      "\n",
      "Model  22  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     1\n",
      "Activation function           relu\n",
      "Dropout                        0.0\n",
      "L1                            0.01\n",
      "L2                         0.00001\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 41436, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 7s 4ms/step - loss: 0.8565 - accuracy: 0.4972 - val_loss: 0.8454 - val_accuracy: 0.4983\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.8416 - accuracy: 0.4975 - val_loss: 0.8315 - val_accuracy: 0.4998\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 5s 3ms/step - loss: 0.8277 - accuracy: 0.4988 - val_loss: 0.8187 - val_accuracy: 0.5043\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.8152 - accuracy: 0.5008 - val_loss: 0.8069 - val_accuracy: 0.5083\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8034 - accuracy: 0.5038 - val_loss: 0.7956 - val_accuracy: 0.5116\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7922 - accuracy: 0.5049 - val_loss: 0.7854 - val_accuracy: 0.5155\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7824 - accuracy: 0.5073 - val_loss: 0.7765 - val_accuracy: 0.5175\n",
      "Epoch 8/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7736 - accuracy: 0.5106 - val_loss: 0.7683 - val_accuracy: 0.5205\n",
      "Epoch 9/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.7659 - accuracy: 0.5137 - val_loss: 0.7613 - val_accuracy: 0.5218\n",
      "Epoch 10/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7592 - accuracy: 0.5177 - val_loss: 0.7553 - val_accuracy: 0.5249\n",
      "Epoch 11/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7536 - accuracy: 0.5217 - val_loss: 0.7505 - val_accuracy: 0.5288\n",
      "Epoch 12/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7493 - accuracy: 0.5254 - val_loss: 0.7469 - val_accuracy: 0.5303\n",
      "Epoch 13/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7460 - accuracy: 0.5280 - val_loss: 0.7440 - val_accuracy: 0.5319\n",
      "Epoch 14/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7430 - accuracy: 0.5319 - val_loss: 0.7413 - val_accuracy: 0.5349\n",
      "Epoch 15/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.7404 - accuracy: 0.5372 - val_loss: 0.7390 - val_accuracy: 0.5354\n",
      "Epoch 16/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.7381 - accuracy: 0.5403 - val_loss: 0.7370 - val_accuracy: 0.5371\n",
      "Epoch 17/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7361 - accuracy: 0.5438 - val_loss: 0.7352 - val_accuracy: 0.5390\n",
      "Epoch 18/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7342 - accuracy: 0.5457 - val_loss: 0.7335 - val_accuracy: 0.5409\n",
      "Epoch 19/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7325 - accuracy: 0.5476 - val_loss: 0.7320 - val_accuracy: 0.5433\n",
      "Epoch 20/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7309 - accuracy: 0.5507 - val_loss: 0.7305 - val_accuracy: 0.5462\n",
      "Epoch 21/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7293 - accuracy: 0.5541 - val_loss: 0.7291 - val_accuracy: 0.5485\n",
      "Epoch 22/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7278 - accuracy: 0.5562 - val_loss: 0.7277 - val_accuracy: 0.5497\n",
      "Epoch 23/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7264 - accuracy: 0.5588 - val_loss: 0.7263 - val_accuracy: 0.5519\n",
      "Epoch 24/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7249 - accuracy: 0.5635 - val_loss: 0.7250 - val_accuracy: 0.5557\n",
      "Epoch 25/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7234 - accuracy: 0.5672 - val_loss: 0.7236 - val_accuracy: 0.5588\n",
      "Epoch 26/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7220 - accuracy: 0.5724 - val_loss: 0.7223 - val_accuracy: 0.5638\n",
      "Epoch 27/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7206 - accuracy: 0.5747 - val_loss: 0.7209 - val_accuracy: 0.5690\n",
      "Epoch 28/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7192 - accuracy: 0.5777 - val_loss: 0.7195 - val_accuracy: 0.5717\n",
      "Epoch 29/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7177 - accuracy: 0.5791 - val_loss: 0.7182 - val_accuracy: 0.5739\n",
      "Epoch 30/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7164 - accuracy: 0.5818 - val_loss: 0.7169 - val_accuracy: 0.5768\n",
      "Epoch 31/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7152 - accuracy: 0.5851 - val_loss: 0.7157 - val_accuracy: 0.5803\n",
      "Epoch 32/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7139 - accuracy: 0.5871 - val_loss: 0.7146 - val_accuracy: 0.5833\n",
      "Epoch 33/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7128 - accuracy: 0.5883 - val_loss: 0.7134 - val_accuracy: 0.5862\n",
      "Epoch 34/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7117 - accuracy: 0.5891 - val_loss: 0.7125 - val_accuracy: 0.5876\n",
      "Epoch 35/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7107 - accuracy: 0.5906 - val_loss: 0.7116 - val_accuracy: 0.5881\n",
      "Epoch 36/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7097 - accuracy: 0.5926 - val_loss: 0.7107 - val_accuracy: 0.5886\n",
      "Epoch 37/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7088 - accuracy: 0.5933 - val_loss: 0.7099 - val_accuracy: 0.5892\n",
      "Epoch 38/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7080 - accuracy: 0.5954 - val_loss: 0.7092 - val_accuracy: 0.5896\n",
      "Epoch 39/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7072 - accuracy: 0.5947 - val_loss: 0.7085 - val_accuracy: 0.5897\n",
      "Epoch 40/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7065 - accuracy: 0.5966 - val_loss: 0.7079 - val_accuracy: 0.5898\n",
      "Epoch 41/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7059 - accuracy: 0.5969 - val_loss: 0.7072 - val_accuracy: 0.5909\n",
      "Epoch 42/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7052 - accuracy: 0.5969 - val_loss: 0.7066 - val_accuracy: 0.5910\n",
      "Epoch 43/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7046 - accuracy: 0.5978 - val_loss: 0.7059 - val_accuracy: 0.5917\n",
      "Epoch 44/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7040 - accuracy: 0.5981 - val_loss: 0.7053 - val_accuracy: 0.5920\n",
      "Epoch 45/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7033 - accuracy: 0.5988 - val_loss: 0.7047 - val_accuracy: 0.5929\n",
      "Epoch 46/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7028 - accuracy: 0.5986 - val_loss: 0.7041 - val_accuracy: 0.5946\n",
      "Epoch 47/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7022 - accuracy: 0.5995 - val_loss: 0.7036 - val_accuracy: 0.5956\n",
      "Epoch 48/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7017 - accuracy: 0.6000 - val_loss: 0.7030 - val_accuracy: 0.5965\n",
      "Epoch 49/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7012 - accuracy: 0.6003 - val_loss: 0.7026 - val_accuracy: 0.5970\n",
      "Epoch 50/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.7007 - accuracy: 0.6006 - val_loss: 0.7022 - val_accuracy: 0.5978\n",
      "Epoch 51/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.7002 - accuracy: 0.6005 - val_loss: 0.7018 - val_accuracy: 0.5968\n",
      "Epoch 52/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6998 - accuracy: 0.6012 - val_loss: 0.7013 - val_accuracy: 0.5969\n",
      "Epoch 53/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6994 - accuracy: 0.6016 - val_loss: 0.7009 - val_accuracy: 0.5980\n",
      "Epoch 54/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6990 - accuracy: 0.6019 - val_loss: 0.7005 - val_accuracy: 0.5985\n",
      "Epoch 55/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6986 - accuracy: 0.6013 - val_loss: 0.7001 - val_accuracy: 0.6002\n",
      "Epoch 56/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6982 - accuracy: 0.6021 - val_loss: 0.6997 - val_accuracy: 0.6010\n",
      "Epoch 57/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6978 - accuracy: 0.6023 - val_loss: 0.6993 - val_accuracy: 0.6023\n",
      "Epoch 58/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6974 - accuracy: 0.6031 - val_loss: 0.6989 - val_accuracy: 0.6030\n",
      "Epoch 59/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6971 - accuracy: 0.6026 - val_loss: 0.6985 - val_accuracy: 0.6040\n",
      "Epoch 60/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6967 - accuracy: 0.6028 - val_loss: 0.6981 - val_accuracy: 0.6050\n",
      "Epoch 61/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6964 - accuracy: 0.6025 - val_loss: 0.6978 - val_accuracy: 0.6053\n",
      "Epoch 62/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6961 - accuracy: 0.6027 - val_loss: 0.6974 - val_accuracy: 0.6060\n",
      "Epoch 63/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6957 - accuracy: 0.6027 - val_loss: 0.6971 - val_accuracy: 0.6071\n",
      "Epoch 64/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6954 - accuracy: 0.6033 - val_loss: 0.6967 - val_accuracy: 0.6082\n",
      "Epoch 65/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6951 - accuracy: 0.6032 - val_loss: 0.6964 - val_accuracy: 0.6091\n",
      "Epoch 66/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6948 - accuracy: 0.6034 - val_loss: 0.6960 - val_accuracy: 0.6098\n",
      "Epoch 67/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6945 - accuracy: 0.6031 - val_loss: 0.6957 - val_accuracy: 0.6098\n",
      "Epoch 68/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6941 - accuracy: 0.6033 - val_loss: 0.6953 - val_accuracy: 0.6107\n",
      "Epoch 69/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6938 - accuracy: 0.6038 - val_loss: 0.6950 - val_accuracy: 0.6111\n",
      "Epoch 70/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6935 - accuracy: 0.6034 - val_loss: 0.6947 - val_accuracy: 0.6115\n",
      "Epoch 71/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6932 - accuracy: 0.6039 - val_loss: 0.6944 - val_accuracy: 0.6116\n",
      "Epoch 72/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6929 - accuracy: 0.6046 - val_loss: 0.6940 - val_accuracy: 0.6124\n",
      "Epoch 73/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6926 - accuracy: 0.6041 - val_loss: 0.6937 - val_accuracy: 0.6132\n",
      "Epoch 74/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6923 - accuracy: 0.6043 - val_loss: 0.6934 - val_accuracy: 0.6137\n",
      "Epoch 75/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6920 - accuracy: 0.6042 - val_loss: 0.6931 - val_accuracy: 0.6144\n",
      "Epoch 76/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6917 - accuracy: 0.6053 - val_loss: 0.6929 - val_accuracy: 0.6143\n",
      "Epoch 77/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6914 - accuracy: 0.6057 - val_loss: 0.6926 - val_accuracy: 0.6148\n",
      "Epoch 78/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6911 - accuracy: 0.6062 - val_loss: 0.6922 - val_accuracy: 0.6154\n",
      "Epoch 79/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6908 - accuracy: 0.6062 - val_loss: 0.6919 - val_accuracy: 0.6163\n",
      "Epoch 80/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6906 - accuracy: 0.6071 - val_loss: 0.6916 - val_accuracy: 0.6164\n",
      "Epoch 81/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6903 - accuracy: 0.6069 - val_loss: 0.6914 - val_accuracy: 0.6171\n",
      "Epoch 82/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6900 - accuracy: 0.6077 - val_loss: 0.6911 - val_accuracy: 0.6176\n",
      "Epoch 83/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6897 - accuracy: 0.6080 - val_loss: 0.6908 - val_accuracy: 0.6176\n",
      "Epoch 84/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6894 - accuracy: 0.6086 - val_loss: 0.6905 - val_accuracy: 0.6178\n",
      "Epoch 85/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6892 - accuracy: 0.6093 - val_loss: 0.6903 - val_accuracy: 0.6179\n",
      "Epoch 86/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6889 - accuracy: 0.6097 - val_loss: 0.6900 - val_accuracy: 0.6182\n",
      "Epoch 87/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6886 - accuracy: 0.6094 - val_loss: 0.6898 - val_accuracy: 0.6182\n",
      "Epoch 88/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6884 - accuracy: 0.6100 - val_loss: 0.6896 - val_accuracy: 0.6180\n",
      "Epoch 89/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6882 - accuracy: 0.6104 - val_loss: 0.6893 - val_accuracy: 0.6186\n",
      "Epoch 90/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6880 - accuracy: 0.6108 - val_loss: 0.6891 - val_accuracy: 0.6192\n",
      "Epoch 91/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6877 - accuracy: 0.6117 - val_loss: 0.6888 - val_accuracy: 0.6192\n",
      "Epoch 92/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6875 - accuracy: 0.6116 - val_loss: 0.6886 - val_accuracy: 0.6193\n",
      "Epoch 93/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6873 - accuracy: 0.6116 - val_loss: 0.6884 - val_accuracy: 0.6196\n",
      "Epoch 94/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6870 - accuracy: 0.6115 - val_loss: 0.6882 - val_accuracy: 0.6198\n",
      "Epoch 95/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6868 - accuracy: 0.6120 - val_loss: 0.6880 - val_accuracy: 0.6201\n",
      "Epoch 96/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6866 - accuracy: 0.6122 - val_loss: 0.6878 - val_accuracy: 0.6201\n",
      "Epoch 97/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6864 - accuracy: 0.6120 - val_loss: 0.6875 - val_accuracy: 0.6204\n",
      "Epoch 98/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6862 - accuracy: 0.6124 - val_loss: 0.6873 - val_accuracy: 0.6208\n",
      "Epoch 99/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6860 - accuracy: 0.6121 - val_loss: 0.6872 - val_accuracy: 0.6209\n",
      "Epoch 100/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6860 - accuracy: 0.6139 - val_loss: 0.6872 - val_accuracy: 0.6201\n",
      "Epoch 101/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6859 - accuracy: 0.6140 - val_loss: 0.6872 - val_accuracy: 0.6206\n",
      "Epoch 102/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6858 - accuracy: 0.6138 - val_loss: 0.6871 - val_accuracy: 0.6202\n",
      "Epoch 103/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6857 - accuracy: 0.6150 - val_loss: 0.6871 - val_accuracy: 0.6200\n",
      "Epoch 104/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6856 - accuracy: 0.6147 - val_loss: 0.6870 - val_accuracy: 0.6201\n",
      "Epoch 105/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6855 - accuracy: 0.6150 - val_loss: 0.6869 - val_accuracy: 0.6204\n",
      "Epoch 106/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6855 - accuracy: 0.6153 - val_loss: 0.6869 - val_accuracy: 0.6202\n",
      "Epoch 107/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6854 - accuracy: 0.6157 - val_loss: 0.6868 - val_accuracy: 0.6207\n",
      "Epoch 108/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6853 - accuracy: 0.6156 - val_loss: 0.6867 - val_accuracy: 0.6210\n",
      "Epoch 109/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6852 - accuracy: 0.6152 - val_loss: 0.6867 - val_accuracy: 0.6208\n",
      "Epoch 110/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6852 - accuracy: 0.6156 - val_loss: 0.6866 - val_accuracy: 0.6206\n",
      "Epoch 111/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6851 - accuracy: 0.6153 - val_loss: 0.6865 - val_accuracy: 0.6210\n",
      "Epoch 112/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6850 - accuracy: 0.6156 - val_loss: 0.6865 - val_accuracy: 0.6212\n",
      "Epoch 113/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6850 - accuracy: 0.6155 - val_loss: 0.6864 - val_accuracy: 0.6210\n",
      "Epoch 114/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6849 - accuracy: 0.6165 - val_loss: 0.6864 - val_accuracy: 0.6209\n",
      "Epoch 115/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6848 - accuracy: 0.6164 - val_loss: 0.6863 - val_accuracy: 0.6208\n",
      "Epoch 116/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6848 - accuracy: 0.6162 - val_loss: 0.6862 - val_accuracy: 0.6208\n",
      "Epoch 117/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6847 - accuracy: 0.6162 - val_loss: 0.6862 - val_accuracy: 0.6206\n",
      "Epoch 118/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6846 - accuracy: 0.6166 - val_loss: 0.6862 - val_accuracy: 0.6207\n",
      "Epoch 119/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6846 - accuracy: 0.6163 - val_loss: 0.6861 - val_accuracy: 0.6210\n",
      "Epoch 120/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6845 - accuracy: 0.6165 - val_loss: 0.6860 - val_accuracy: 0.6208\n",
      "Epoch 121/300\n",
      "1318/1339 [============================>.] - ETA: 0s - loss: 0.6846 - accuracy: 0.6168Restoring model weights from the end of the best epoch: 120.\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 0.6844 - accuracy: 0.6171 - val_loss: 0.6860 - val_accuracy: 0.6208\n",
      "Epoch 121: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 0.6860 - accuracy: 0.6208\n",
      "{'loss': 0.6860226392745972, 'accuracy': 0.6207835674285889} \n",
      " 120 \n",
      "\n",
      "Model time: 10.82912964373827 minutes\n",
      "\n",
      "Total time: 15.873439244925976 minutes\n",
      "\n",
      "\n",
      "Model  23  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     8\n",
      "Activation function           tanh\n",
      "Dropout                        0.6\n",
      "L1                            10.0\n",
      "L2                          0.0001\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 491101, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 8s 5ms/step - loss: 596.6069 - accuracy: 0.4915 - val_loss: 116.8752 - val_accuracy: 0.4741\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 34.7549 - accuracy: 0.4957 - val_loss: 19.5141 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 14.8670 - accuracy: 0.5004 - val_loss: 10.4585 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 7.4900 - accuracy: 0.4982 - val_loss: 5.3155 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 3.7698 - accuracy: 0.4949 - val_loss: 2.3863 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 1.7734 - accuracy: 0.4941 - val_loss: 1.4220 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 1.3932 - accuracy: 0.4966 - val_loss: 1.3643 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "1317/1339 [============================>.] - ETA: 0s - loss: 1.3931 - accuracy: 0.4997Restoring model weights from the end of the best epoch: 7.\n",
      "1339/1339 [==============================] - 5s 4ms/step - loss: 1.3932 - accuracy: 0.4994 - val_loss: 1.4219 - val_accuracy: 0.5001\n",
      "Epoch 8: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 1.3643 - accuracy: 0.5001\n",
      "{'loss': 1.3643288612365723, 'accuracy': 0.5001260638237} \n",
      " 7 \n",
      "\n",
      "Model time: 1.4339111372828484 minutes\n",
      "\n",
      "Total time: 17.307433523237705 minutes\n",
      "\n",
      "\n",
      "Model  24  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                     2\n",
      "Activation function         linear\n",
      "Dropout                        0.4\n",
      "L1                           100.0\n",
      "L2                           100.0\n",
      "Batch size                     128\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 5848069, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 5s 10ms/step - loss: 5297.4727 - accuracy: 0.4910 - val_loss: 4934.5059 - val_accuracy: 0.5023\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4605.2632 - accuracy: 0.4893 - val_loss: 4279.3179 - val_accuracy: 0.5027\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3984.2966 - accuracy: 0.4909 - val_loss: 3696.8765 - val_accuracy: 0.5034\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3439.1018 - accuracy: 0.4934 - val_loss: 3186.9756 - val_accuracy: 0.5035\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2961.2957 - accuracy: 0.4940 - val_loss: 2743.1455 - val_accuracy: 0.5027\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2550.1804 - accuracy: 0.4886 - val_loss: 2362.8352 - val_accuracy: 0.5042\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2199.2944 - accuracy: 0.4896 - val_loss: 2041.6536 - val_accuracy: 0.4973\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1907.0970 - accuracy: 0.4900 - val_loss: 1780.3163 - val_accuracy: 0.4873\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1673.0529 - accuracy: 0.4940 - val_loss: 1573.8292 - val_accuracy: 0.4789\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1495.2460 - accuracy: 0.4882 - val_loss: 1425.0790 - val_accuracy: 0.4752\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1376.5339 - accuracy: 0.4956 - val_loss: 1338.8079 - val_accuracy: 0.4999\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1312.2223 - accuracy: 0.4944 - val_loss: 1285.2841 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1259.1481 - accuracy: 0.5010 - val_loss: 1232.6667 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1206.9751 - accuracy: 0.5003 - val_loss: 1180.9486 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1155.7045 - accuracy: 0.4999 - val_loss: 1130.1307 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1105.3356 - accuracy: 0.5012 - val_loss: 1080.2189 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1055.8712 - accuracy: 0.5010 - val_loss: 1031.2095 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1007.3091 - accuracy: 0.4966 - val_loss: 983.1029 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 959.6489 - accuracy: 0.4996 - val_loss: 935.8992 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 914.3312 - accuracy: 0.5013 - val_loss: 892.6859 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 871.7164 - accuracy: 0.5006 - val_loss: 850.4785 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 829.9028 - accuracy: 0.4976 - val_loss: 809.1115 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 790.2132 - accuracy: 0.4971 - val_loss: 771.3824 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 753.1796 - accuracy: 0.5003 - val_loss: 734.7420 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 716.8743 - accuracy: 0.4991 - val_loss: 698.7758 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 681.2450 - accuracy: 0.4960 - val_loss: 663.4903 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 646.3168 - accuracy: 0.4971 - val_loss: 629.1654 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 613.1226 - accuracy: 0.5003 - val_loss: 596.8727 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 581.1360 - accuracy: 0.5003 - val_loss: 565.1979 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 549.7691 - accuracy: 0.4948 - val_loss: 534.1437 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 519.0222 - accuracy: 0.4995 - val_loss: 503.7105 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 489.2602 - accuracy: 0.5003 - val_loss: 475.3879 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 462.4936 - accuracy: 0.5003 - val_loss: 449.4417 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 436.7985 - accuracy: 0.5003 - val_loss: 424.0030 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 411.6109 - accuracy: 0.5003 - val_loss: 399.0707 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 386.9309 - accuracy: 0.5003 - val_loss: 374.6474 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 362.7578 - accuracy: 0.4952 - val_loss: 350.7299 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 339.0920 - accuracy: 0.5003 - val_loss: 327.3199 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 315.9332 - accuracy: 0.5003 - val_loss: 304.4169 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 293.2818 - accuracy: 0.4975 - val_loss: 282.0209 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 271.1375 - accuracy: 0.5003 - val_loss: 260.1327 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 249.5000 - accuracy: 0.5003 - val_loss: 238.7512 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 228.3700 - accuracy: 0.5003 - val_loss: 217.8811 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 208.5747 - accuracy: 0.5003 - val_loss: 199.1632 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 190.3709 - accuracy: 0.4988 - val_loss: 181.8847 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 173.8313 - accuracy: 0.4971 - val_loss: 165.6836 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 157.8475 - accuracy: 0.5003 - val_loss: 150.1563 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 144.0287 - accuracy: 0.4956 - val_loss: 137.9265 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 132.0453 - accuracy: 0.4997 - val_loss: 126.0894 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 120.3833 - accuracy: 0.5003 - val_loss: 114.8922 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 110.1032 - accuracy: 0.4978 - val_loss: 105.2557 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 100.5783 - accuracy: 0.5003 - val_loss: 95.8447 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 91.2789 - accuracy: 0.4997 - val_loss: 86.6589 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 82.2047 - accuracy: 0.4988 - val_loss: 77.6990 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 73.3566 - accuracy: 0.4983 - val_loss: 68.9646 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 64.7339 - accuracy: 0.4986 - val_loss: 60.4555 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 56.3365 - accuracy: 0.4982 - val_loss: 52.1723 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 48.1648 - accuracy: 0.5006 - val_loss: 44.1142 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 40.2184 - accuracy: 0.4991 - val_loss: 36.2817 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 32.5985 - accuracy: 0.5003 - val_loss: 29.2698 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 26.4037 - accuracy: 0.4948 - val_loss: 23.5170 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 20.7366 - accuracy: 0.4990 - val_loss: 18.0227 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 16.1436 - accuracy: 0.5003 - val_loss: 14.2540 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.9841 - accuracy: 0.5003 - val_loss: 11.9566 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.9874 - accuracy: 0.4945 - val_loss: 10.0160 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 9.0748 - accuracy: 0.4958 - val_loss: 8.1318 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.2186 - accuracy: 0.5003 - val_loss: 6.3039 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.4187 - accuracy: 0.4986 - val_loss: 4.5324 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.6752 - accuracy: 0.5003 - val_loss: 2.8172 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5493 - accuracy: 0.4961 - val_loss: 2.5270 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.4991 - val_loss: 2.5269 - val_accuracy: 0.4999\n",
      "Epoch 72/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.4911 - val_loss: 2.5267 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.4973 - val_loss: 2.5266 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.4949 - val_loss: 2.5265 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5233 - accuracy: 0.4990 - val_loss: 2.5264 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.4991 - val_loss: 2.5263 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.4971 - val_loss: 2.5262 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.5003 - val_loss: 2.5261 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.5003 - val_loss: 2.5260 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.4956 - val_loss: 2.5260 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.5003 - val_loss: 2.5259 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.5003 - val_loss: 2.5258 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.5003 - val_loss: 2.5257 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.5003 - val_loss: 2.5256 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.4995 - val_loss: 2.5256 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5233 - accuracy: 0.5003 - val_loss: 2.5255 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.5000 - val_loss: 2.5254 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.5003 - val_loss: 2.5253 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.4946 - val_loss: 2.5253 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.4980 - val_loss: 2.5252 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5005 - val_loss: 2.5251 - val_accuracy: 0.4999\n",
      "Epoch 92/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.4973 - val_loss: 2.5251 - val_accuracy: 0.4999\n",
      "Epoch 93/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.4949 - val_loss: 2.5250 - val_accuracy: 0.4999\n",
      "Epoch 94/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.4981 - val_loss: 2.5250 - val_accuracy: 0.4999\n",
      "Epoch 95/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.4968 - val_loss: 2.5249 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5233 - accuracy: 0.4977 - val_loss: 2.5249 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4993 - val_loss: 2.5248 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5248 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5233 - accuracy: 0.4986 - val_loss: 2.5247 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4986 - val_loss: 2.5247 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5246 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5246 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4980 - val_loss: 2.5245 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4968 - val_loss: 2.5245 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4947 - val_loss: 2.5245 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4959 - val_loss: 2.5244 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5244 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4940 - val_loss: 2.5243 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4940 - val_loss: 2.5243 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5243 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5242 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4990 - val_loss: 2.5242 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5242 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.4976 - val_loss: 2.5242 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5241 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5241 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4975 - val_loss: 2.5241 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4974 - val_loss: 2.5240 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4956 - val_loss: 2.5240 - val_accuracy: 0.4999\n",
      "Epoch 120/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4980 - val_loss: 2.5240 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4972 - val_loss: 2.5240 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5239 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4961 - val_loss: 2.5239 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4981 - val_loss: 2.5239 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4968 - val_loss: 2.5239 - val_accuracy: 0.5001\n",
      "Epoch 126/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4975 - val_loss: 2.5239 - val_accuracy: 0.5001\n",
      "Epoch 127/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4982 - val_loss: 2.5238 - val_accuracy: 0.5001\n",
      "Epoch 128/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4979 - val_loss: 2.5238 - val_accuracy: 0.5001\n",
      "Epoch 129/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4941 - val_loss: 2.5238 - val_accuracy: 0.5001\n",
      "Epoch 130/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5238 - val_accuracy: 0.5001\n",
      "Epoch 131/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4957 - val_loss: 2.5238 - val_accuracy: 0.5001\n",
      "Epoch 132/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4947 - val_loss: 2.5237 - val_accuracy: 0.5001\n",
      "Epoch 133/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4977 - val_loss: 2.5237 - val_accuracy: 0.5001\n",
      "Epoch 134/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.4982 - val_loss: 2.5237 - val_accuracy: 0.5001\n",
      "Epoch 135/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5237 - val_accuracy: 0.5001\n",
      "Epoch 136/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4978 - val_loss: 2.5237 - val_accuracy: 0.5001\n",
      "Epoch 137/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4984 - val_loss: 2.5237 - val_accuracy: 0.5001\n",
      "Epoch 138/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4962 - val_loss: 2.5237 - val_accuracy: 0.5001\n",
      "Epoch 139/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4984 - val_loss: 2.5236 - val_accuracy: 0.5001\n",
      "Epoch 140/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5236 - val_accuracy: 0.5001\n",
      "Epoch 141/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5236 - val_accuracy: 0.5001\n",
      "Epoch 142/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5236 - val_accuracy: 0.5001\n",
      "Epoch 143/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.4988 - val_loss: 2.5236 - val_accuracy: 0.5001\n",
      "Epoch 144/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5236 - val_accuracy: 0.5001\n",
      "Epoch 145/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4989 - val_loss: 2.5236 - val_accuracy: 0.5001\n",
      "Epoch 146/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.4947 - val_loss: 2.5236 - val_accuracy: 0.5001\n",
      "Epoch 147/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4976 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 148/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 149/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4971 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 150/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4971 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 151/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4982 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 152/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.4969 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 153/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5004 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 154/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4989 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 155/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.4984 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 156/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 157/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 158/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4976 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 159/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5235 - val_accuracy: 0.5001\n",
      "Epoch 160/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4963 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 161/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4991 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 162/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.4989 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 163/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 164/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4978 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 165/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 166/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 167/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4954 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 168/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 169/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4997 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 170/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4996 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 171/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5232 - accuracy: 0.4982 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 172/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.5001 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 173/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5232 - accuracy: 0.4975 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 174/300\n",
      "155/168 [==========================>...] - ETA: 0s - loss: 2.5232 - accuracy: 0.4997Restoring model weights from the end of the best epoch: 173.\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5232 - accuracy: 0.5003 - val_loss: 2.5234 - val_accuracy: 0.5001\n",
      "Epoch 174: early stopping\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 2.5234 - accuracy: 0.5001\n",
      "{'loss': 2.5233707427978516, 'accuracy': 0.5001260638237} \n",
      " 173 \n",
      "\n",
      "Model time: 2.85363694652915 minutes\n",
      "\n",
      "Total time: 20.161137126386166 minutes\n",
      "\n",
      "\n",
      "Model  25  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                    32\n",
      "Activation function         linear\n",
      "Dropout                        0.4\n",
      "L1                          0.0001\n",
      "L2                             0.0\n",
      "Batch size                       8\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 5072978, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 15s 5ms/step - loss: 4.1862 - accuracy: 0.5230 - val_loss: 1.5713 - val_accuracy: 0.5533\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.1691 - accuracy: 0.5138 - val_loss: 0.8279 - val_accuracy: 0.5174\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.8354 - accuracy: 0.5356 - val_loss: 0.7827 - val_accuracy: 0.4998\n",
      "Epoch 4/300\n",
      "2663/2677 [============================>.] - ETA: 0s - loss: 2.7200 - accuracy: 0.5450Restoring model weights from the end of the best epoch: 3.\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 2.9209 - accuracy: 0.5446 - val_loss: 27.6760 - val_accuracy: 0.5266\n",
      "Epoch 4: early stopping\n",
      "2480/2480 [==============================] - 7s 3ms/step - loss: 0.7827 - accuracy: 0.4998\n",
      "{'loss': 0.7826595306396484, 'accuracy': 0.49982354044914246} \n",
      " 3 \n",
      "\n",
      "Model time: 1.0088904947042465 minutes\n",
      "\n",
      "Total time: 21.170110948383808 minutes\n",
      "\n",
      "\n",
      "Model  26  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     8\n",
      "Activation function           relu\n",
      "Dropout                        0.8\n",
      "L1                             0.0\n",
      "L2                           100.0\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 4735662, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 7ms/step - loss: 122.8375 - accuracy: 0.4980 - val_loss: 4.6734 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.6736 - accuracy: 0.4918 - val_loss: 4.6733 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.6734 - accuracy: 0.5025 - val_loss: 4.6733 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.6735 - accuracy: 0.5008 - val_loss: 4.6731 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "331/335 [============================>.] - ETA: 0s - loss: 4.6734 - accuracy: 0.5035Restoring model weights from the end of the best epoch: 4.\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.6734 - accuracy: 0.5029 - val_loss: 4.6731 - val_accuracy: 0.5001\n",
      "Epoch 5: early stopping\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 4.6731 - accuracy: 0.4999\n",
      "{'loss': 4.673146724700928, 'accuracy': 0.49987393617630005} \n",
      " 4 \n",
      "\n",
      "Model time: 0.21273484826087952 minutes\n",
      "\n",
      "Total time: 21.382929135113955 minutes\n",
      "\n",
      "\n",
      "Model  27  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                   256\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.7\n",
      "L1                          0.0001\n",
      "L2                          0.0001\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 2791090, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 5s 20ms/step - loss: 1.0241 - accuracy: 0.5338 - val_loss: 0.8352 - val_accuracy: 0.5327\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.8462 - accuracy: 0.5401 - val_loss: 0.8129 - val_accuracy: 0.6127\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.8474 - accuracy: 0.5468 - val_loss: 0.8110 - val_accuracy: 0.5659\n",
      "Epoch 4/300\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.8434 - accuracy: 0.5513Restoring model weights from the end of the best epoch: 3.\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.8436 - accuracy: 0.5510 - val_loss: 0.8149 - val_accuracy: 0.6133\n",
      "Epoch 4: early stopping\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.8110 - accuracy: 0.5659\n",
      "{'loss': 0.8109645247459412, 'accuracy': 0.5658750534057617} \n",
      " 3 \n",
      "\n",
      "Model time: 0.22916829958558083 minutes\n",
      "\n",
      "Total time: 21.612197432667017 minutes\n",
      "\n",
      "\n",
      "Model  28  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                    16\n",
      "Activation function         linear\n",
      "Dropout                        0.4\n",
      "L1                            0.01\n",
      "L2                             0.1\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 6316486, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 7s 6ms/step - loss: 1.1151 - accuracy: 0.5025 - val_loss: 0.8949 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "666/670 [============================>.] - ETA: 0s - loss: 0.8952 - accuracy: 0.4955Restoring model weights from the end of the best epoch: 1.\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.8952 - accuracy: 0.4954 - val_loss: 0.8973 - val_accuracy: 0.4999\n",
      "Epoch 2: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.8949 - accuracy: 0.5001\n",
      "{'loss': 0.8949006199836731, 'accuracy': 0.5001260638237} \n",
      " 1 \n",
      "\n",
      "Model time: 0.2503076530992985 minutes\n",
      "\n",
      "Total time: 21.86258840188384 minutes\n",
      "\n",
      "\n",
      "Model  29  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     2\n",
      "Activation function           relu\n",
      "Dropout                        0.7\n",
      "L1                           0.001\n",
      "L2                         0.00001\n",
      "Batch size                      16\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 1624282, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 8s 5ms/step - loss: 0.7135 - accuracy: 0.4994 - val_loss: 0.6970 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6950 - accuracy: 0.5013 - val_loss: 0.6948 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6940 - accuracy: 0.5018 - val_loss: 0.6941 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6940 - accuracy: 0.4976 - val_loss: 0.6937 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6943 - accuracy: 0.4951 - val_loss: 0.6937 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6941 - accuracy: 0.5005 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "1338/1339 [============================>.] - ETA: 0s - loss: 0.6942 - accuracy: 0.5019Restoring model weights from the end of the best epoch: 6.\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6942 - accuracy: 0.5018 - val_loss: 0.6937 - val_accuracy: 0.4999\n",
      "Epoch 7: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 0.6935 - accuracy: 0.5001\n",
      "{'loss': 0.6935200095176697, 'accuracy': 0.5001260638237} \n",
      " 6 \n",
      "\n",
      "Model time: 0.7830889001488686 minutes\n",
      "\n",
      "Total time: 22.64589335396886 minutes\n",
      "\n",
      "\n",
      "Model  30  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                    64\n",
      "Activation function           tanh\n",
      "Dropout                        0.1\n",
      "L1                           0.001\n",
      "L2                             0.1\n",
      "Batch size                      16\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 939800, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 8s 5ms/step - loss: 10.4744 - accuracy: 0.5027 - val_loss: 9.4632 - val_accuracy: 0.5012\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 8.5921 - accuracy: 0.5162 - val_loss: 7.7606 - val_accuracy: 0.5200\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 7.0300 - accuracy: 0.5300 - val_loss: 6.3352 - val_accuracy: 0.5352\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 5.7254 - accuracy: 0.5420 - val_loss: 5.1452 - val_accuracy: 0.5495\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 4.6393 - accuracy: 0.5533 - val_loss: 4.1608 - val_accuracy: 0.5627\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 3.7470 - accuracy: 0.5699 - val_loss: 3.3585 - val_accuracy: 0.5747\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 3.0250 - accuracy: 0.5814 - val_loss: 2.7158 - val_accuracy: 0.5855\n",
      "Epoch 8/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.4544 - accuracy: 0.5848 - val_loss: 2.2117 - val_accuracy: 0.5947\n",
      "Epoch 9/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.0108 - accuracy: 0.5920 - val_loss: 1.8262 - val_accuracy: 0.6023\n",
      "Epoch 10/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.6760 - accuracy: 0.5928 - val_loss: 1.5380 - val_accuracy: 0.6058\n",
      "Epoch 11/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.4267 - accuracy: 0.6011 - val_loss: 1.3274 - val_accuracy: 0.6091\n",
      "Epoch 12/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.2471 - accuracy: 0.6054 - val_loss: 1.1753 - val_accuracy: 0.6120\n",
      "Epoch 13/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.1173 - accuracy: 0.6029 - val_loss: 1.0659 - val_accuracy: 0.6144\n",
      "Epoch 14/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.0234 - accuracy: 0.6073 - val_loss: 0.9850 - val_accuracy: 0.6166\n",
      "Epoch 15/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.9519 - accuracy: 0.6083 - val_loss: 0.9220 - val_accuracy: 0.6141\n",
      "Epoch 16/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8953 - accuracy: 0.6069 - val_loss: 0.8711 - val_accuracy: 0.6167\n",
      "Epoch 17/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8496 - accuracy: 0.6074 - val_loss: 0.8299 - val_accuracy: 0.6154\n",
      "Epoch 18/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8126 - accuracy: 0.6072 - val_loss: 0.7969 - val_accuracy: 0.6168\n",
      "Epoch 19/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7832 - accuracy: 0.6096 - val_loss: 0.7709 - val_accuracy: 0.6200\n",
      "Epoch 20/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7602 - accuracy: 0.6070 - val_loss: 0.7504 - val_accuracy: 0.6180\n",
      "Epoch 21/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7422 - accuracy: 0.6051 - val_loss: 0.7345 - val_accuracy: 0.6173\n",
      "Epoch 22/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7285 - accuracy: 0.6029 - val_loss: 0.7225 - val_accuracy: 0.6174\n",
      "Epoch 23/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7180 - accuracy: 0.6027 - val_loss: 0.7136 - val_accuracy: 0.6180\n",
      "Epoch 24/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7105 - accuracy: 0.6017 - val_loss: 0.7073 - val_accuracy: 0.6176\n",
      "Epoch 25/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7051 - accuracy: 0.5990 - val_loss: 0.7029 - val_accuracy: 0.6172\n",
      "Epoch 26/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7015 - accuracy: 0.5983 - val_loss: 0.6999 - val_accuracy: 0.6175\n",
      "Epoch 27/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6990 - accuracy: 0.5971 - val_loss: 0.6980 - val_accuracy: 0.6182\n",
      "Epoch 28/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6974 - accuracy: 0.5975 - val_loss: 0.6967 - val_accuracy: 0.6168\n",
      "Epoch 29/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6964 - accuracy: 0.5969 - val_loss: 0.6958 - val_accuracy: 0.6161\n",
      "Epoch 30/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6956 - accuracy: 0.5953 - val_loss: 0.6952 - val_accuracy: 0.6149\n",
      "Epoch 31/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6951 - accuracy: 0.5948 - val_loss: 0.6948 - val_accuracy: 0.6137\n",
      "Epoch 32/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6948 - accuracy: 0.5949 - val_loss: 0.6945 - val_accuracy: 0.6137\n",
      "Epoch 33/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6945 - accuracy: 0.5951 - val_loss: 0.6943 - val_accuracy: 0.6128\n",
      "Epoch 34/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6944 - accuracy: 0.5934 - val_loss: 0.6942 - val_accuracy: 0.6126\n",
      "Epoch 35/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6942 - accuracy: 0.5938 - val_loss: 0.6941 - val_accuracy: 0.6132\n",
      "Epoch 36/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6941 - accuracy: 0.5933 - val_loss: 0.6940 - val_accuracy: 0.6125\n",
      "Epoch 37/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6940 - accuracy: 0.5929 - val_loss: 0.6939 - val_accuracy: 0.6127\n",
      "Epoch 38/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6939 - accuracy: 0.5919 - val_loss: 0.6938 - val_accuracy: 0.6116\n",
      "Epoch 39/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6938 - accuracy: 0.5927 - val_loss: 0.6938 - val_accuracy: 0.6118\n",
      "Epoch 40/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6938 - accuracy: 0.5926 - val_loss: 0.6937 - val_accuracy: 0.6116\n",
      "Epoch 41/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6937 - accuracy: 0.5936 - val_loss: 0.6937 - val_accuracy: 0.6117\n",
      "Epoch 42/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6937 - accuracy: 0.5933 - val_loss: 0.6937 - val_accuracy: 0.6111\n",
      "Epoch 43/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6937 - accuracy: 0.5927 - val_loss: 0.6936 - val_accuracy: 0.6110\n",
      "Epoch 44/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6936 - accuracy: 0.5930 - val_loss: 0.6936 - val_accuracy: 0.6111\n",
      "Epoch 45/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6936 - accuracy: 0.5921 - val_loss: 0.6936 - val_accuracy: 0.6110\n",
      "Epoch 46/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6936 - accuracy: 0.5920 - val_loss: 0.6936 - val_accuracy: 0.6113\n",
      "Epoch 47/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6935 - accuracy: 0.5937 - val_loss: 0.6935 - val_accuracy: 0.6106\n",
      "Epoch 48/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6936 - accuracy: 0.5931 - val_loss: 0.6935 - val_accuracy: 0.6104\n",
      "Epoch 49/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6935 - accuracy: 0.5926 - val_loss: 0.6935 - val_accuracy: 0.6115\n",
      "Epoch 50/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6936 - accuracy: 0.5921 - val_loss: 0.6935 - val_accuracy: 0.6112\n",
      "Epoch 51/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6935 - accuracy: 0.5921 - val_loss: 0.6935 - val_accuracy: 0.6119\n",
      "Epoch 52/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6935 - accuracy: 0.5917 - val_loss: 0.6935 - val_accuracy: 0.6114\n",
      "Epoch 53/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6935 - accuracy: 0.5919 - val_loss: 0.6934 - val_accuracy: 0.6113\n",
      "Epoch 54/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6934 - accuracy: 0.5928 - val_loss: 0.6934 - val_accuracy: 0.6114\n",
      "Epoch 55/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6935 - accuracy: 0.5921 - val_loss: 0.6934 - val_accuracy: 0.6119\n",
      "Epoch 56/300\n",
      "1327/1339 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5900Restoring model weights from the end of the best epoch: 55.\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6934 - accuracy: 0.5906 - val_loss: 0.6934 - val_accuracy: 0.6112\n",
      "Epoch 56: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 0.6934 - accuracy: 0.6119\n",
      "{'loss': 0.6934183835983276, 'accuracy': 0.6119094491004944} \n",
      " 55 \n",
      "\n",
      "Model time: 5.978359129279852 minutes\n",
      "\n",
      "Total time: 28.62435245513916 minutes\n",
      "\n",
      "\n",
      "Model  31  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                     1\n",
      "Activation function         linear\n",
      "Dropout                        0.3\n",
      "L1                             0.0\n",
      "L2                         0.00001\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 5688542, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 9s 5ms/step - loss: 0.6918 - accuracy: 0.5112 - val_loss: 0.6897 - val_accuracy: 0.5005\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6894 - accuracy: 0.5230 - val_loss: 0.6882 - val_accuracy: 0.5163\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6894 - accuracy: 0.5231 - val_loss: 0.6810 - val_accuracy: 0.5846\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6902 - accuracy: 0.5202 - val_loss: 0.6805 - val_accuracy: 0.6271\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6896 - accuracy: 0.5224 - val_loss: 0.6783 - val_accuracy: 0.5822\n",
      "Epoch 6/300\n",
      "1334/1339 [============================>.] - ETA: 0s - loss: 0.6888 - accuracy: 0.5153Restoring model weights from the end of the best epoch: 5.\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6889 - accuracy: 0.5153 - val_loss: 0.6878 - val_accuracy: 0.6208\n",
      "Epoch 6: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 0.6783 - accuracy: 0.5822\n",
      "{'loss': 0.6783438324928284, 'accuracy': 0.5821610689163208} \n",
      " 5 \n",
      "\n",
      "Model time: 0.7278718426823616 minutes\n",
      "\n",
      "Total time: 29.352324299514294 minutes\n",
      "\n",
      "\n",
      "Model  32  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     1\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.8\n",
      "L1                             0.0\n",
      "L2                             0.1\n",
      "Batch size                     256\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 147980, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 1.2293 - accuracy: 0.4973 - val_loss: 1.0729 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.2293 - accuracy: 0.4960 - val_loss: 1.0698 - val_accuracy: 0.4998\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.5011 - val_loss: 1.0668 - val_accuracy: 0.4997\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.2001 - accuracy: 0.5052 - val_loss: 1.0638 - val_accuracy: 0.4998\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.5003 - val_loss: 1.0608 - val_accuracy: 0.4996\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.2023 - accuracy: 0.5027 - val_loss: 1.0578 - val_accuracy: 0.4997\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.2054 - accuracy: 0.4996 - val_loss: 1.0549 - val_accuracy: 0.4997\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.2020 - accuracy: 0.4989 - val_loss: 1.0519 - val_accuracy: 0.4997\n",
      "Epoch 9/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1923 - accuracy: 0.4998 - val_loss: 1.0490 - val_accuracy: 0.4996\n",
      "Epoch 10/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1987 - accuracy: 0.5005 - val_loss: 1.0462 - val_accuracy: 0.4996\n",
      "Epoch 11/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1888 - accuracy: 0.5014 - val_loss: 1.0433 - val_accuracy: 0.4996\n",
      "Epoch 12/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.1895 - accuracy: 0.5004 - val_loss: 1.0404 - val_accuracy: 0.4997\n",
      "Epoch 13/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1822 - accuracy: 0.5011 - val_loss: 1.0377 - val_accuracy: 0.4998\n",
      "Epoch 14/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1932 - accuracy: 0.4962 - val_loss: 1.0349 - val_accuracy: 0.4997\n",
      "Epoch 15/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1882 - accuracy: 0.4968 - val_loss: 1.0321 - val_accuracy: 0.4997\n",
      "Epoch 16/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1816 - accuracy: 0.4971 - val_loss: 1.0293 - val_accuracy: 0.4999\n",
      "Epoch 17/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1707 - accuracy: 0.5019 - val_loss: 1.0266 - val_accuracy: 0.4999\n",
      "Epoch 18/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.1766 - accuracy: 0.4960 - val_loss: 1.0240 - val_accuracy: 0.5000\n",
      "Epoch 19/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1601 - accuracy: 0.5039 - val_loss: 1.0213 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1613 - accuracy: 0.5007 - val_loss: 1.0187 - val_accuracy: 0.4999\n",
      "Epoch 21/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1563 - accuracy: 0.5032 - val_loss: 1.0160 - val_accuracy: 0.4999\n",
      "Epoch 22/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.1637 - accuracy: 0.4957 - val_loss: 1.0134 - val_accuracy: 0.5000\n",
      "Epoch 23/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.1513 - accuracy: 0.5013 - val_loss: 1.0108 - val_accuracy: 0.4999\n",
      "Epoch 24/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1428 - accuracy: 0.5044 - val_loss: 1.0083 - val_accuracy: 0.4998\n",
      "Epoch 25/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.1501 - accuracy: 0.4998 - val_loss: 1.0057 - val_accuracy: 0.4998\n",
      "Epoch 26/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1600 - accuracy: 0.4946 - val_loss: 1.0032 - val_accuracy: 0.4999\n",
      "Epoch 27/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1567 - accuracy: 0.4941 - val_loss: 1.0007 - val_accuracy: 0.5000\n",
      "Epoch 28/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1336 - accuracy: 0.5008 - val_loss: 0.9982 - val_accuracy: 0.5000\n",
      "Epoch 29/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.1447 - accuracy: 0.4987 - val_loss: 0.9957 - val_accuracy: 0.5000\n",
      "Epoch 30/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1384 - accuracy: 0.4986 - val_loss: 0.9933 - val_accuracy: 0.4999\n",
      "Epoch 31/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1294 - accuracy: 0.5020 - val_loss: 0.9909 - val_accuracy: 0.4997\n",
      "Epoch 32/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1279 - accuracy: 0.5039 - val_loss: 0.9885 - val_accuracy: 0.4996\n",
      "Epoch 33/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1282 - accuracy: 0.4992 - val_loss: 0.9861 - val_accuracy: 0.4996\n",
      "Epoch 34/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.1287 - accuracy: 0.4967 - val_loss: 0.9837 - val_accuracy: 0.4995\n",
      "Epoch 35/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1298 - accuracy: 0.4972 - val_loss: 0.9813 - val_accuracy: 0.4994\n",
      "Epoch 36/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1241 - accuracy: 0.4969 - val_loss: 0.9790 - val_accuracy: 0.4994\n",
      "Epoch 37/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1138 - accuracy: 0.5016 - val_loss: 0.9767 - val_accuracy: 0.4994\n",
      "Epoch 38/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1228 - accuracy: 0.4958 - val_loss: 0.9744 - val_accuracy: 0.4994\n",
      "Epoch 39/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.1129 - accuracy: 0.4997 - val_loss: 0.9721 - val_accuracy: 0.4994\n",
      "Epoch 40/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1121 - accuracy: 0.4988 - val_loss: 0.9698 - val_accuracy: 0.4994\n",
      "Epoch 41/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1067 - accuracy: 0.4968 - val_loss: 0.9676 - val_accuracy: 0.4994\n",
      "Epoch 42/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1076 - accuracy: 0.4961 - val_loss: 0.9654 - val_accuracy: 0.4995\n",
      "Epoch 43/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.1013 - accuracy: 0.5014 - val_loss: 0.9632 - val_accuracy: 0.4995\n",
      "Epoch 44/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1018 - accuracy: 0.4979 - val_loss: 0.9610 - val_accuracy: 0.4995\n",
      "Epoch 45/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.0988 - accuracy: 0.4978 - val_loss: 0.9588 - val_accuracy: 0.4995\n",
      "Epoch 46/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0980 - accuracy: 0.4969 - val_loss: 0.9567 - val_accuracy: 0.4995\n",
      "Epoch 47/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.1000 - accuracy: 0.4975 - val_loss: 0.9546 - val_accuracy: 0.4995\n",
      "Epoch 48/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0790 - accuracy: 0.5034 - val_loss: 0.9525 - val_accuracy: 0.4996\n",
      "Epoch 49/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.0940 - accuracy: 0.4994 - val_loss: 0.9504 - val_accuracy: 0.4996\n",
      "Epoch 50/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0885 - accuracy: 0.4991 - val_loss: 0.9484 - val_accuracy: 0.4996\n",
      "Epoch 51/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0979 - accuracy: 0.4911 - val_loss: 0.9463 - val_accuracy: 0.4996\n",
      "Epoch 52/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.0785 - accuracy: 0.5024 - val_loss: 0.9443 - val_accuracy: 0.4997\n",
      "Epoch 53/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0771 - accuracy: 0.4993 - val_loss: 0.9423 - val_accuracy: 0.4996\n",
      "Epoch 54/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0667 - accuracy: 0.5036 - val_loss: 0.9403 - val_accuracy: 0.4996\n",
      "Epoch 55/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0725 - accuracy: 0.5003 - val_loss: 0.9383 - val_accuracy: 0.4997\n",
      "Epoch 56/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.0694 - accuracy: 0.4974 - val_loss: 0.9364 - val_accuracy: 0.4997\n",
      "Epoch 57/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0677 - accuracy: 0.4981 - val_loss: 0.9344 - val_accuracy: 0.4997\n",
      "Epoch 58/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0592 - accuracy: 0.5029 - val_loss: 0.9325 - val_accuracy: 0.4997\n",
      "Epoch 59/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0650 - accuracy: 0.4978 - val_loss: 0.9306 - val_accuracy: 0.4997\n",
      "Epoch 60/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.0570 - accuracy: 0.5020 - val_loss: 0.9287 - val_accuracy: 0.4997\n",
      "Epoch 61/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0598 - accuracy: 0.5013 - val_loss: 0.9268 - val_accuracy: 0.4997\n",
      "Epoch 62/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0530 - accuracy: 0.5009 - val_loss: 0.9250 - val_accuracy: 0.4996\n",
      "Epoch 63/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0472 - accuracy: 0.5028 - val_loss: 0.9231 - val_accuracy: 0.4997\n",
      "Epoch 64/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0505 - accuracy: 0.4996 - val_loss: 0.9213 - val_accuracy: 0.4997\n",
      "Epoch 65/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0561 - accuracy: 0.4980 - val_loss: 0.9195 - val_accuracy: 0.4997\n",
      "Epoch 66/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.0549 - accuracy: 0.4988 - val_loss: 0.9177 - val_accuracy: 0.4998\n",
      "Epoch 67/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0456 - accuracy: 0.5011 - val_loss: 0.9160 - val_accuracy: 0.4998\n",
      "Epoch 68/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0470 - accuracy: 0.4997 - val_loss: 0.9142 - val_accuracy: 0.4997\n",
      "Epoch 69/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0370 - accuracy: 0.5033 - val_loss: 0.9125 - val_accuracy: 0.4997\n",
      "Epoch 70/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0345 - accuracy: 0.5027 - val_loss: 0.9108 - val_accuracy: 0.4998\n",
      "Epoch 71/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0307 - accuracy: 0.5025 - val_loss: 0.9091 - val_accuracy: 0.4998\n",
      "Epoch 72/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.0387 - accuracy: 0.4989 - val_loss: 0.9074 - val_accuracy: 0.4998\n",
      "Epoch 73/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0243 - accuracy: 0.5058 - val_loss: 0.9057 - val_accuracy: 0.4997\n",
      "Epoch 74/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0321 - accuracy: 0.4999 - val_loss: 0.9041 - val_accuracy: 0.4997\n",
      "Epoch 75/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0306 - accuracy: 0.5001 - val_loss: 0.9024 - val_accuracy: 0.4996\n",
      "Epoch 76/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0307 - accuracy: 0.5004 - val_loss: 0.9008 - val_accuracy: 0.4996\n",
      "Epoch 77/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.0294 - accuracy: 0.4971 - val_loss: 0.8992 - val_accuracy: 0.4996\n",
      "Epoch 78/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0223 - accuracy: 0.5000 - val_loss: 0.8976 - val_accuracy: 0.4995\n",
      "Epoch 79/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0169 - accuracy: 0.5002 - val_loss: 0.8961 - val_accuracy: 0.4994\n",
      "Epoch 80/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0179 - accuracy: 0.5008 - val_loss: 0.8945 - val_accuracy: 0.4994\n",
      "Epoch 81/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.0196 - accuracy: 0.4967 - val_loss: 0.8930 - val_accuracy: 0.4994\n",
      "Epoch 82/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.0103 - accuracy: 0.5004 - val_loss: 0.8915 - val_accuracy: 0.4995\n",
      "Epoch 83/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0129 - accuracy: 0.5044 - val_loss: 0.8900 - val_accuracy: 0.4994\n",
      "Epoch 84/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0119 - accuracy: 0.4967 - val_loss: 0.8885 - val_accuracy: 0.4995\n",
      "Epoch 85/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.0127 - accuracy: 0.4978 - val_loss: 0.8870 - val_accuracy: 0.4995\n",
      "Epoch 86/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 1.0062 - accuracy: 0.4997 - val_loss: 0.8855 - val_accuracy: 0.4995\n",
      "Epoch 87/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9981 - accuracy: 0.5030 - val_loss: 0.8840 - val_accuracy: 0.4994\n",
      "Epoch 88/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9912 - accuracy: 0.5059 - val_loss: 0.8826 - val_accuracy: 0.4995\n",
      "Epoch 89/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9952 - accuracy: 0.5018 - val_loss: 0.8812 - val_accuracy: 0.4996\n",
      "Epoch 90/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9952 - accuracy: 0.5027 - val_loss: 0.8798 - val_accuracy: 0.4995\n",
      "Epoch 91/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9994 - accuracy: 0.4994 - val_loss: 0.8784 - val_accuracy: 0.4995\n",
      "Epoch 92/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9883 - accuracy: 0.5054 - val_loss: 0.8770 - val_accuracy: 0.4995\n",
      "Epoch 93/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9988 - accuracy: 0.4976 - val_loss: 0.8756 - val_accuracy: 0.4995\n",
      "Epoch 94/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9828 - accuracy: 0.5050 - val_loss: 0.8742 - val_accuracy: 0.4995\n",
      "Epoch 95/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9880 - accuracy: 0.5013 - val_loss: 0.8729 - val_accuracy: 0.4997\n",
      "Epoch 96/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9840 - accuracy: 0.5026 - val_loss: 0.8715 - val_accuracy: 0.4997\n",
      "Epoch 97/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9773 - accuracy: 0.5048 - val_loss: 0.8702 - val_accuracy: 0.4997\n",
      "Epoch 98/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9798 - accuracy: 0.5012 - val_loss: 0.8689 - val_accuracy: 0.4997\n",
      "Epoch 99/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9796 - accuracy: 0.5044 - val_loss: 0.8676 - val_accuracy: 0.4997\n",
      "Epoch 100/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9869 - accuracy: 0.4992 - val_loss: 0.8664 - val_accuracy: 0.4998\n",
      "Epoch 101/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9704 - accuracy: 0.5066 - val_loss: 0.8651 - val_accuracy: 0.4998\n",
      "Epoch 102/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9813 - accuracy: 0.4978 - val_loss: 0.8638 - val_accuracy: 0.4997\n",
      "Epoch 103/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9685 - accuracy: 0.5005 - val_loss: 0.8626 - val_accuracy: 0.4997\n",
      "Epoch 104/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9715 - accuracy: 0.5018 - val_loss: 0.8613 - val_accuracy: 0.4997\n",
      "Epoch 105/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9721 - accuracy: 0.4996 - val_loss: 0.8601 - val_accuracy: 0.4996\n",
      "Epoch 106/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9681 - accuracy: 0.5030 - val_loss: 0.8589 - val_accuracy: 0.4997\n",
      "Epoch 107/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9712 - accuracy: 0.5009 - val_loss: 0.8577 - val_accuracy: 0.4996\n",
      "Epoch 108/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9687 - accuracy: 0.5002 - val_loss: 0.8565 - val_accuracy: 0.4995\n",
      "Epoch 109/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9715 - accuracy: 0.4999 - val_loss: 0.8553 - val_accuracy: 0.4996\n",
      "Epoch 110/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9574 - accuracy: 0.5048 - val_loss: 0.8541 - val_accuracy: 0.4995\n",
      "Epoch 111/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9602 - accuracy: 0.5026 - val_loss: 0.8530 - val_accuracy: 0.4996\n",
      "Epoch 112/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9610 - accuracy: 0.5002 - val_loss: 0.8519 - val_accuracy: 0.4995\n",
      "Epoch 113/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9595 - accuracy: 0.4994 - val_loss: 0.8507 - val_accuracy: 0.4995\n",
      "Epoch 114/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9575 - accuracy: 0.5015 - val_loss: 0.8496 - val_accuracy: 0.4995\n",
      "Epoch 115/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9589 - accuracy: 0.4982 - val_loss: 0.8485 - val_accuracy: 0.4995\n",
      "Epoch 116/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9471 - accuracy: 0.5083 - val_loss: 0.8474 - val_accuracy: 0.4995\n",
      "Epoch 117/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9568 - accuracy: 0.4995 - val_loss: 0.8463 - val_accuracy: 0.4995\n",
      "Epoch 118/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9564 - accuracy: 0.4999 - val_loss: 0.8453 - val_accuracy: 0.4994\n",
      "Epoch 119/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9647 - accuracy: 0.4901 - val_loss: 0.8442 - val_accuracy: 0.4994\n",
      "Epoch 120/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9496 - accuracy: 0.5030 - val_loss: 0.8432 - val_accuracy: 0.4994\n",
      "Epoch 121/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9499 - accuracy: 0.4997 - val_loss: 0.8422 - val_accuracy: 0.4995\n",
      "Epoch 122/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9525 - accuracy: 0.4975 - val_loss: 0.8412 - val_accuracy: 0.4995\n",
      "Epoch 123/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9470 - accuracy: 0.4988 - val_loss: 0.8402 - val_accuracy: 0.4995\n",
      "Epoch 124/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9495 - accuracy: 0.4969 - val_loss: 0.8391 - val_accuracy: 0.4995\n",
      "Epoch 125/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9411 - accuracy: 0.5029 - val_loss: 0.8381 - val_accuracy: 0.4996\n",
      "Epoch 126/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9449 - accuracy: 0.4991 - val_loss: 0.8372 - val_accuracy: 0.4996\n",
      "Epoch 127/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9382 - accuracy: 0.5015 - val_loss: 0.8362 - val_accuracy: 0.4997\n",
      "Epoch 128/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9339 - accuracy: 0.5033 - val_loss: 0.8352 - val_accuracy: 0.4997\n",
      "Epoch 129/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9365 - accuracy: 0.5014 - val_loss: 0.8343 - val_accuracy: 0.4997\n",
      "Epoch 130/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9328 - accuracy: 0.5035 - val_loss: 0.8333 - val_accuracy: 0.4997\n",
      "Epoch 131/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9357 - accuracy: 0.4991 - val_loss: 0.8324 - val_accuracy: 0.5000\n",
      "Epoch 132/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9369 - accuracy: 0.4986 - val_loss: 0.8315 - val_accuracy: 0.4999\n",
      "Epoch 133/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9323 - accuracy: 0.5004 - val_loss: 0.8306 - val_accuracy: 0.5000\n",
      "Epoch 134/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9281 - accuracy: 0.5039 - val_loss: 0.8297 - val_accuracy: 0.4999\n",
      "Epoch 135/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9293 - accuracy: 0.4996 - val_loss: 0.8289 - val_accuracy: 0.4998\n",
      "Epoch 136/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9280 - accuracy: 0.5011 - val_loss: 0.8280 - val_accuracy: 0.4998\n",
      "Epoch 137/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9270 - accuracy: 0.5008 - val_loss: 0.8271 - val_accuracy: 0.4999\n",
      "Epoch 138/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9262 - accuracy: 0.4985 - val_loss: 0.8263 - val_accuracy: 0.4998\n",
      "Epoch 139/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9286 - accuracy: 0.4991 - val_loss: 0.8254 - val_accuracy: 0.4999\n",
      "Epoch 140/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9219 - accuracy: 0.5033 - val_loss: 0.8246 - val_accuracy: 0.4998\n",
      "Epoch 141/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9167 - accuracy: 0.5046 - val_loss: 0.8238 - val_accuracy: 0.4998\n",
      "Epoch 142/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9200 - accuracy: 0.5026 - val_loss: 0.8230 - val_accuracy: 0.4999\n",
      "Epoch 143/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9233 - accuracy: 0.5011 - val_loss: 0.8221 - val_accuracy: 0.4999\n",
      "Epoch 144/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9268 - accuracy: 0.4967 - val_loss: 0.8214 - val_accuracy: 0.4998\n",
      "Epoch 145/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9181 - accuracy: 0.5015 - val_loss: 0.8206 - val_accuracy: 0.4998\n",
      "Epoch 146/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9166 - accuracy: 0.5021 - val_loss: 0.8198 - val_accuracy: 0.4999\n",
      "Epoch 147/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9177 - accuracy: 0.4996 - val_loss: 0.8190 - val_accuracy: 0.4998\n",
      "Epoch 148/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9149 - accuracy: 0.5002 - val_loss: 0.8182 - val_accuracy: 0.4998\n",
      "Epoch 149/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9223 - accuracy: 0.4961 - val_loss: 0.8175 - val_accuracy: 0.4998\n",
      "Epoch 150/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9081 - accuracy: 0.5033 - val_loss: 0.8167 - val_accuracy: 0.4998\n",
      "Epoch 151/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9140 - accuracy: 0.4992 - val_loss: 0.8160 - val_accuracy: 0.4999\n",
      "Epoch 152/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9125 - accuracy: 0.4983 - val_loss: 0.8153 - val_accuracy: 0.4999\n",
      "Epoch 153/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9103 - accuracy: 0.5008 - val_loss: 0.8146 - val_accuracy: 0.4999\n",
      "Epoch 154/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9105 - accuracy: 0.4983 - val_loss: 0.8139 - val_accuracy: 0.4999\n",
      "Epoch 155/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.9041 - accuracy: 0.5015 - val_loss: 0.8132 - val_accuracy: 0.4998\n",
      "Epoch 156/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9034 - accuracy: 0.5032 - val_loss: 0.8124 - val_accuracy: 0.4998\n",
      "Epoch 157/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9055 - accuracy: 0.4998 - val_loss: 0.8118 - val_accuracy: 0.4997\n",
      "Epoch 158/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.9049 - accuracy: 0.5015 - val_loss: 0.8111 - val_accuracy: 0.4998\n",
      "Epoch 159/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9045 - accuracy: 0.5005 - val_loss: 0.8104 - val_accuracy: 0.4998\n",
      "Epoch 160/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9015 - accuracy: 0.5008 - val_loss: 0.8097 - val_accuracy: 0.4998\n",
      "Epoch 161/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8982 - accuracy: 0.5047 - val_loss: 0.8091 - val_accuracy: 0.4999\n",
      "Epoch 162/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9019 - accuracy: 0.4987 - val_loss: 0.8084 - val_accuracy: 0.5000\n",
      "Epoch 163/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8984 - accuracy: 0.5004 - val_loss: 0.8078 - val_accuracy: 0.5000\n",
      "Epoch 164/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8932 - accuracy: 0.5035 - val_loss: 0.8071 - val_accuracy: 0.5001\n",
      "Epoch 165/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8968 - accuracy: 0.5021 - val_loss: 0.8065 - val_accuracy: 0.5002\n",
      "Epoch 166/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9033 - accuracy: 0.4960 - val_loss: 0.8059 - val_accuracy: 0.5002\n",
      "Epoch 167/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8938 - accuracy: 0.5003 - val_loss: 0.8052 - val_accuracy: 0.5002\n",
      "Epoch 168/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8981 - accuracy: 0.4981 - val_loss: 0.8046 - val_accuracy: 0.5003\n",
      "Epoch 169/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8935 - accuracy: 0.5018 - val_loss: 0.8040 - val_accuracy: 0.5003\n",
      "Epoch 170/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8976 - accuracy: 0.4961 - val_loss: 0.8035 - val_accuracy: 0.5005\n",
      "Epoch 171/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8887 - accuracy: 0.5015 - val_loss: 0.8028 - val_accuracy: 0.5005\n",
      "Epoch 172/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8933 - accuracy: 0.5002 - val_loss: 0.8023 - val_accuracy: 0.5006\n",
      "Epoch 173/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8895 - accuracy: 0.5000 - val_loss: 0.8017 - val_accuracy: 0.5006\n",
      "Epoch 174/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.5058 - val_loss: 0.8011 - val_accuracy: 0.5006\n",
      "Epoch 175/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8907 - accuracy: 0.4990 - val_loss: 0.8005 - val_accuracy: 0.5005\n",
      "Epoch 176/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8915 - accuracy: 0.4978 - val_loss: 0.8000 - val_accuracy: 0.5006\n",
      "Epoch 177/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8911 - accuracy: 0.4970 - val_loss: 0.7994 - val_accuracy: 0.5006\n",
      "Epoch 178/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8862 - accuracy: 0.4974 - val_loss: 0.7989 - val_accuracy: 0.5006\n",
      "Epoch 179/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8850 - accuracy: 0.4994 - val_loss: 0.7984 - val_accuracy: 0.5006\n",
      "Epoch 180/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8860 - accuracy: 0.5007 - val_loss: 0.7978 - val_accuracy: 0.5005\n",
      "Epoch 181/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8795 - accuracy: 0.5010 - val_loss: 0.7973 - val_accuracy: 0.5006\n",
      "Epoch 182/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8819 - accuracy: 0.5009 - val_loss: 0.7968 - val_accuracy: 0.5008\n",
      "Epoch 183/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8856 - accuracy: 0.4988 - val_loss: 0.7963 - val_accuracy: 0.5007\n",
      "Epoch 184/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8841 - accuracy: 0.4982 - val_loss: 0.7958 - val_accuracy: 0.5007\n",
      "Epoch 185/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8842 - accuracy: 0.4977 - val_loss: 0.7953 - val_accuracy: 0.5010\n",
      "Epoch 186/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8848 - accuracy: 0.4962 - val_loss: 0.7948 - val_accuracy: 0.5010\n",
      "Epoch 187/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8772 - accuracy: 0.5004 - val_loss: 0.7943 - val_accuracy: 0.5011\n",
      "Epoch 188/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8784 - accuracy: 0.4995 - val_loss: 0.7938 - val_accuracy: 0.5011\n",
      "Epoch 189/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8755 - accuracy: 0.5008 - val_loss: 0.7933 - val_accuracy: 0.5011\n",
      "Epoch 190/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8686 - accuracy: 0.5073 - val_loss: 0.7929 - val_accuracy: 0.5010\n",
      "Epoch 191/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8722 - accuracy: 0.5020 - val_loss: 0.7924 - val_accuracy: 0.5009\n",
      "Epoch 192/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8738 - accuracy: 0.4995 - val_loss: 0.7919 - val_accuracy: 0.5010\n",
      "Epoch 193/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8740 - accuracy: 0.4985 - val_loss: 0.7915 - val_accuracy: 0.5010\n",
      "Epoch 194/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8744 - accuracy: 0.4994 - val_loss: 0.7910 - val_accuracy: 0.5011\n",
      "Epoch 195/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8694 - accuracy: 0.5027 - val_loss: 0.7905 - val_accuracy: 0.5011\n",
      "Epoch 196/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8717 - accuracy: 0.5009 - val_loss: 0.7901 - val_accuracy: 0.5012\n",
      "Epoch 197/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8700 - accuracy: 0.5017 - val_loss: 0.7897 - val_accuracy: 0.5012\n",
      "Epoch 198/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8727 - accuracy: 0.4967 - val_loss: 0.7892 - val_accuracy: 0.5014\n",
      "Epoch 199/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8700 - accuracy: 0.4982 - val_loss: 0.7888 - val_accuracy: 0.5014\n",
      "Epoch 200/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8710 - accuracy: 0.4981 - val_loss: 0.7884 - val_accuracy: 0.5015\n",
      "Epoch 201/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8656 - accuracy: 0.5031 - val_loss: 0.7880 - val_accuracy: 0.5016\n",
      "Epoch 202/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8674 - accuracy: 0.5000 - val_loss: 0.7875 - val_accuracy: 0.5015\n",
      "Epoch 203/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8662 - accuracy: 0.5000 - val_loss: 0.7871 - val_accuracy: 0.5018\n",
      "Epoch 204/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8651 - accuracy: 0.5014 - val_loss: 0.7867 - val_accuracy: 0.5019\n",
      "Epoch 205/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8647 - accuracy: 0.4999 - val_loss: 0.7863 - val_accuracy: 0.5021\n",
      "Epoch 206/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8621 - accuracy: 0.5027 - val_loss: 0.7859 - val_accuracy: 0.5021\n",
      "Epoch 207/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8660 - accuracy: 0.4961 - val_loss: 0.7855 - val_accuracy: 0.5022\n",
      "Epoch 208/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8626 - accuracy: 0.4991 - val_loss: 0.7852 - val_accuracy: 0.5023\n",
      "Epoch 209/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8621 - accuracy: 0.4987 - val_loss: 0.7848 - val_accuracy: 0.5024\n",
      "Epoch 210/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8602 - accuracy: 0.5007 - val_loss: 0.7844 - val_accuracy: 0.5024\n",
      "Epoch 211/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8576 - accuracy: 0.5018 - val_loss: 0.7840 - val_accuracy: 0.5025\n",
      "Epoch 212/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8616 - accuracy: 0.4977 - val_loss: 0.7836 - val_accuracy: 0.5027\n",
      "Epoch 213/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8619 - accuracy: 0.4975 - val_loss: 0.7833 - val_accuracy: 0.5027\n",
      "Epoch 214/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8597 - accuracy: 0.4995 - val_loss: 0.7829 - val_accuracy: 0.5029\n",
      "Epoch 215/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8608 - accuracy: 0.4986 - val_loss: 0.7825 - val_accuracy: 0.5029\n",
      "Epoch 216/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8570 - accuracy: 0.5009 - val_loss: 0.7822 - val_accuracy: 0.5031\n",
      "Epoch 217/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8552 - accuracy: 0.5012 - val_loss: 0.7818 - val_accuracy: 0.5027\n",
      "Epoch 218/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8525 - accuracy: 0.5030 - val_loss: 0.7815 - val_accuracy: 0.5028\n",
      "Epoch 219/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8522 - accuracy: 0.5040 - val_loss: 0.7811 - val_accuracy: 0.5026\n",
      "Epoch 220/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8544 - accuracy: 0.5008 - val_loss: 0.7807 - val_accuracy: 0.5024\n",
      "Epoch 221/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8548 - accuracy: 0.4990 - val_loss: 0.7804 - val_accuracy: 0.5024\n",
      "Epoch 222/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8503 - accuracy: 0.5041 - val_loss: 0.7800 - val_accuracy: 0.5026\n",
      "Epoch 223/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8472 - accuracy: 0.5078 - val_loss: 0.7797 - val_accuracy: 0.5028\n",
      "Epoch 224/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8513 - accuracy: 0.5032 - val_loss: 0.7793 - val_accuracy: 0.5031\n",
      "Epoch 225/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8507 - accuracy: 0.5017 - val_loss: 0.7790 - val_accuracy: 0.5031\n",
      "Epoch 226/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8505 - accuracy: 0.5016 - val_loss: 0.7786 - val_accuracy: 0.5033\n",
      "Epoch 227/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8448 - accuracy: 0.5058 - val_loss: 0.7783 - val_accuracy: 0.5032\n",
      "Epoch 228/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8475 - accuracy: 0.5034 - val_loss: 0.7780 - val_accuracy: 0.5033\n",
      "Epoch 229/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8513 - accuracy: 0.4974 - val_loss: 0.7776 - val_accuracy: 0.5035\n",
      "Epoch 230/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8440 - accuracy: 0.5032 - val_loss: 0.7773 - val_accuracy: 0.5037\n",
      "Epoch 231/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8481 - accuracy: 0.4998 - val_loss: 0.7770 - val_accuracy: 0.5036\n",
      "Epoch 232/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8491 - accuracy: 0.4975 - val_loss: 0.7766 - val_accuracy: 0.5037\n",
      "Epoch 233/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8452 - accuracy: 0.5021 - val_loss: 0.7763 - val_accuracy: 0.5043\n",
      "Epoch 234/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8459 - accuracy: 0.5011 - val_loss: 0.7760 - val_accuracy: 0.5043\n",
      "Epoch 235/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8375 - accuracy: 0.5072 - val_loss: 0.7757 - val_accuracy: 0.5045\n",
      "Epoch 236/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8512 - accuracy: 0.4953 - val_loss: 0.7753 - val_accuracy: 0.5044\n",
      "Epoch 237/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8432 - accuracy: 0.5025 - val_loss: 0.7750 - val_accuracy: 0.5048\n",
      "Epoch 238/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8425 - accuracy: 0.5012 - val_loss: 0.7747 - val_accuracy: 0.5045\n",
      "Epoch 239/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8436 - accuracy: 0.5003 - val_loss: 0.7744 - val_accuracy: 0.5046\n",
      "Epoch 240/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8457 - accuracy: 0.4978 - val_loss: 0.7741 - val_accuracy: 0.5048\n",
      "Epoch 241/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8421 - accuracy: 0.5004 - val_loss: 0.7738 - val_accuracy: 0.5049\n",
      "Epoch 242/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8392 - accuracy: 0.5028 - val_loss: 0.7735 - val_accuracy: 0.5052\n",
      "Epoch 243/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8421 - accuracy: 0.4994 - val_loss: 0.7732 - val_accuracy: 0.5051\n",
      "Epoch 244/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8437 - accuracy: 0.4970 - val_loss: 0.7729 - val_accuracy: 0.5050\n",
      "Epoch 245/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8427 - accuracy: 0.4983 - val_loss: 0.7726 - val_accuracy: 0.5053\n",
      "Epoch 246/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8366 - accuracy: 0.5029 - val_loss: 0.7723 - val_accuracy: 0.5057\n",
      "Epoch 247/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8425 - accuracy: 0.4976 - val_loss: 0.7720 - val_accuracy: 0.5060\n",
      "Epoch 248/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8355 - accuracy: 0.5035 - val_loss: 0.7717 - val_accuracy: 0.5061\n",
      "Epoch 249/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8378 - accuracy: 0.5009 - val_loss: 0.7714 - val_accuracy: 0.5062\n",
      "Epoch 250/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8386 - accuracy: 0.4995 - val_loss: 0.7711 - val_accuracy: 0.5061\n",
      "Epoch 251/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8409 - accuracy: 0.4970 - val_loss: 0.7708 - val_accuracy: 0.5060\n",
      "Epoch 252/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8337 - accuracy: 0.5020 - val_loss: 0.7705 - val_accuracy: 0.5064\n",
      "Epoch 253/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8372 - accuracy: 0.4991 - val_loss: 0.7703 - val_accuracy: 0.5065\n",
      "Epoch 254/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8339 - accuracy: 0.5012 - val_loss: 0.7700 - val_accuracy: 0.5068\n",
      "Epoch 255/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8374 - accuracy: 0.4972 - val_loss: 0.7697 - val_accuracy: 0.5069\n",
      "Epoch 256/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8392 - accuracy: 0.4970 - val_loss: 0.7694 - val_accuracy: 0.5073\n",
      "Epoch 257/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8377 - accuracy: 0.4964 - val_loss: 0.7691 - val_accuracy: 0.5076\n",
      "Epoch 258/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8360 - accuracy: 0.4975 - val_loss: 0.7689 - val_accuracy: 0.5075\n",
      "Epoch 259/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8344 - accuracy: 0.4995 - val_loss: 0.7686 - val_accuracy: 0.5082\n",
      "Epoch 260/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8344 - accuracy: 0.4965 - val_loss: 0.7683 - val_accuracy: 0.5085\n",
      "Epoch 261/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8300 - accuracy: 0.5019 - val_loss: 0.7680 - val_accuracy: 0.5088\n",
      "Epoch 262/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8321 - accuracy: 0.4996 - val_loss: 0.7678 - val_accuracy: 0.5092\n",
      "Epoch 263/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8319 - accuracy: 0.4972 - val_loss: 0.7675 - val_accuracy: 0.5092\n",
      "Epoch 264/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8342 - accuracy: 0.4961 - val_loss: 0.7672 - val_accuracy: 0.5092\n",
      "Epoch 265/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8318 - accuracy: 0.4976 - val_loss: 0.7670 - val_accuracy: 0.5092\n",
      "Epoch 266/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8289 - accuracy: 0.5003 - val_loss: 0.7667 - val_accuracy: 0.5094\n",
      "Epoch 267/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8265 - accuracy: 0.5016 - val_loss: 0.7664 - val_accuracy: 0.5091\n",
      "Epoch 268/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8284 - accuracy: 0.5011 - val_loss: 0.7661 - val_accuracy: 0.5096\n",
      "Epoch 269/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8279 - accuracy: 0.4997 - val_loss: 0.7659 - val_accuracy: 0.5096\n",
      "Epoch 270/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8254 - accuracy: 0.5032 - val_loss: 0.7656 - val_accuracy: 0.5101\n",
      "Epoch 271/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8186 - accuracy: 0.5088 - val_loss: 0.7653 - val_accuracy: 0.5104\n",
      "Epoch 272/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8254 - accuracy: 0.5018 - val_loss: 0.7651 - val_accuracy: 0.5102\n",
      "Epoch 273/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8277 - accuracy: 0.4985 - val_loss: 0.7648 - val_accuracy: 0.5106\n",
      "Epoch 274/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8263 - accuracy: 0.4993 - val_loss: 0.7646 - val_accuracy: 0.5104\n",
      "Epoch 275/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8245 - accuracy: 0.5009 - val_loss: 0.7643 - val_accuracy: 0.5104\n",
      "Epoch 276/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8239 - accuracy: 0.5001 - val_loss: 0.7640 - val_accuracy: 0.5112\n",
      "Epoch 277/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8226 - accuracy: 0.5022 - val_loss: 0.7638 - val_accuracy: 0.5116\n",
      "Epoch 278/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8242 - accuracy: 0.4990 - val_loss: 0.7635 - val_accuracy: 0.5116\n",
      "Epoch 279/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8242 - accuracy: 0.4994 - val_loss: 0.7632 - val_accuracy: 0.5111\n",
      "Epoch 280/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8228 - accuracy: 0.5017 - val_loss: 0.7630 - val_accuracy: 0.5113\n",
      "Epoch 281/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8213 - accuracy: 0.5013 - val_loss: 0.7627 - val_accuracy: 0.5117\n",
      "Epoch 282/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8219 - accuracy: 0.5005 - val_loss: 0.7625 - val_accuracy: 0.5119\n",
      "Epoch 283/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8200 - accuracy: 0.5017 - val_loss: 0.7622 - val_accuracy: 0.5125\n",
      "Epoch 284/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8165 - accuracy: 0.5046 - val_loss: 0.7620 - val_accuracy: 0.5123\n",
      "Epoch 285/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8237 - accuracy: 0.4967 - val_loss: 0.7617 - val_accuracy: 0.5126\n",
      "Epoch 286/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8181 - accuracy: 0.5014 - val_loss: 0.7615 - val_accuracy: 0.5131\n",
      "Epoch 287/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8196 - accuracy: 0.4979 - val_loss: 0.7612 - val_accuracy: 0.5132\n",
      "Epoch 288/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8125 - accuracy: 0.5056 - val_loss: 0.7609 - val_accuracy: 0.5134\n",
      "Epoch 289/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8136 - accuracy: 0.5054 - val_loss: 0.7607 - val_accuracy: 0.5139\n",
      "Epoch 290/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8194 - accuracy: 0.4989 - val_loss: 0.7604 - val_accuracy: 0.5141\n",
      "Epoch 291/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8145 - accuracy: 0.5039 - val_loss: 0.7602 - val_accuracy: 0.5142\n",
      "Epoch 292/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8209 - accuracy: 0.4970 - val_loss: 0.7600 - val_accuracy: 0.5148\n",
      "Epoch 293/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8093 - accuracy: 0.5080 - val_loss: 0.7597 - val_accuracy: 0.5156\n",
      "Epoch 294/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8168 - accuracy: 0.4995 - val_loss: 0.7594 - val_accuracy: 0.5160\n",
      "Epoch 295/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8163 - accuracy: 0.4998 - val_loss: 0.7592 - val_accuracy: 0.5164\n",
      "Epoch 296/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8141 - accuracy: 0.5014 - val_loss: 0.7589 - val_accuracy: 0.5163\n",
      "Epoch 297/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8173 - accuracy: 0.4982 - val_loss: 0.7587 - val_accuracy: 0.5168\n",
      "Epoch 298/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.8186 - accuracy: 0.4959 - val_loss: 0.7585 - val_accuracy: 0.5174\n",
      "Epoch 299/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8133 - accuracy: 0.5016 - val_loss: 0.7582 - val_accuracy: 0.5181\n",
      "Epoch 300/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.8150 - accuracy: 0.4990 - val_loss: 0.7580 - val_accuracy: 0.5182\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.7580 - accuracy: 0.5182\n",
      "{'loss': 0.7579626441001892, 'accuracy': 0.518176794052124} \n",
      " 299 \n",
      "\n",
      "Model time: 2.4599341303110123 minutes\n",
      "\n",
      "Total time: 31.812341757118702 minutes\n",
      "\n",
      "\n",
      "Model  33  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                    16\n",
      "Activation function         linear\n",
      "Dropout                        0.1\n",
      "L1                          0.0001\n",
      "L2                           100.0\n",
      "Batch size                     256\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 2106523, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 3s 17ms/step - loss: 3097.1562 - accuracy: 0.5108 - val_loss: 1746.0067 - val_accuracy: 0.5016\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1145.2977 - accuracy: 0.4951 - val_loss: 715.0905 - val_accuracy: 0.4961\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 503.6548 - accuracy: 0.4907 - val_loss: 340.8766 - val_accuracy: 0.4920\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 247.7167 - accuracy: 0.4885 - val_loss: 171.6822 - val_accuracy: 0.4942\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 124.8959 - accuracy: 0.4927 - val_loss: 86.2064 - val_accuracy: 0.4998\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 62.3164 - accuracy: 0.4984 - val_loss: 42.6659 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 30.7058 - accuracy: 0.4993 - val_loss: 20.9413 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 15.0799 - accuracy: 0.4970 - val_loss: 10.3226 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 7.4962 - accuracy: 0.4992 - val_loss: 5.2119 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.8654 - accuracy: 0.5004 - val_loss: 2.7811 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.1470 - accuracy: 0.4953 - val_loss: 1.6386 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.3444 - accuracy: 0.4989 - val_loss: 1.1100 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9764 - accuracy: 0.4952 - val_loss: 0.8709 - val_accuracy: 0.4999\n",
      "Epoch 14/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8120 - accuracy: 0.4960 - val_loss: 0.7660 - val_accuracy: 0.4999\n",
      "Epoch 15/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7410 - accuracy: 0.4989 - val_loss: 0.7217 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7115 - accuracy: 0.4973 - val_loss: 0.7038 - val_accuracy: 0.4999\n",
      "Epoch 17/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.6999 - accuracy: 0.5001 - val_loss: 0.6969 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6955 - accuracy: 0.5003 - val_loss: 0.6944 - val_accuracy: 0.4999\n",
      "Epoch 19/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6939 - accuracy: 0.4958 - val_loss: 0.6935 - val_accuracy: 0.4999\n",
      "Epoch 20/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6934 - accuracy: 0.4970 - val_loss: 0.6933 - val_accuracy: 0.4999\n",
      "Epoch 21/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6932 - val_accuracy: 0.4999\n",
      "Epoch 22/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4999\n",
      "Epoch 23/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.4999\n",
      "Epoch 25/300\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.4974Restoring model weights from the end of the best epoch: 24.\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5001\n",
      "Epoch 25: early stopping\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4999\n",
      "{'loss': 0.6931490302085876, 'accuracy': 0.49987393617630005} \n",
      " 24 \n",
      "\n",
      "Model time: 0.31211838498711586 minutes\n",
      "\n",
      "Total time: 32.124543972313404 minutes\n",
      "\n",
      "\n",
      "Model  34  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     8\n",
      "Activation function           tanh\n",
      "Dropout                        0.8\n",
      "L1                           0.001\n",
      "L2                           0.001\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 4699599, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 10s 6ms/step - loss: 0.9426 - accuracy: 0.4958 - val_loss: 0.7619 - val_accuracy: 0.5213\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7090 - accuracy: 0.4991 - val_loss: 0.6948 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6945 - accuracy: 0.4964 - val_loss: 0.6942 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6942 - accuracy: 0.5019 - val_loss: 0.6941 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "1323/1339 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.4986Restoring model weights from the end of the best epoch: 4.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6941 - accuracy: 0.4991 - val_loss: 0.6942 - val_accuracy: 0.5001\n",
      "Epoch 5: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 0.6941 - accuracy: 0.4999\n",
      "{'loss': 0.6940566301345825, 'accuracy': 0.49987393617630005} \n",
      " 4 \n",
      "\n",
      "Model time: 0.6596046872437 minutes\n",
      "\n",
      "Total time: 32.784215319901705 minutes\n",
      "\n",
      "\n",
      "Model  35  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                    64\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.2\n",
      "L1                             0.1\n",
      "L2                          0.0001\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 6658333, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 12s 7ms/step - loss: 125.1524 - accuracy: 0.4971 - val_loss: 28.6595 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 6.5106 - accuracy: 0.4977 - val_loss: 0.9954 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.8752 - accuracy: 0.5024 - val_loss: 0.8332 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.8314 - accuracy: 0.5003 - val_loss: 0.8332 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.8313 - accuracy: 0.5003 - val_loss: 0.8331 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.8312 - accuracy: 0.5003 - val_loss: 0.8324 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "1335/1339 [============================>.] - ETA: 0s - loss: 0.8312 - accuracy: 0.4982Restoring model weights from the end of the best epoch: 6.\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.8312 - accuracy: 0.4983 - val_loss: 0.8327 - val_accuracy: 0.4999\n",
      "Epoch 7: early stopping\n",
      "1240/1240 [==============================] - 4s 3ms/step - loss: 0.8324 - accuracy: 0.4999\n",
      "{'loss': 0.8324342370033264, 'accuracy': 0.49987393617630005} \n",
      " 6 \n",
      "\n",
      "Model time: 1.0872414782643318 minutes\n",
      "\n",
      "Total time: 33.87154012545943 minutes\n",
      "\n",
      "\n",
      "Model  36  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                     1\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.5\n",
      "L1                           100.0\n",
      "L2                            10.0\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 2935989, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 6ms/step - loss: 1474.4409 - accuracy: 0.5001 - val_loss: 991.9341 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 675.3077 - accuracy: 0.4950 - val_loss: 426.1166 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 315.2704 - accuracy: 0.4965 - val_loss: 272.7123 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 261.0414 - accuracy: 0.4997 - val_loss: 249.4424 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 237.9073 - accuracy: 0.4998 - val_loss: 226.4441 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 215.0445 - accuracy: 0.4955 - val_loss: 203.7184 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 192.4487 - accuracy: 0.5035 - val_loss: 181.2611 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 170.1252 - accuracy: 0.4993 - val_loss: 159.0731 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 148.0730 - accuracy: 0.4963 - val_loss: 137.1591 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 129.2707 - accuracy: 0.5021 - val_loss: 121.8131 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 114.3637 - accuracy: 0.5031 - val_loss: 107.0057 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 99.6459 - accuracy: 0.5031 - val_loss: 92.3778 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 85.1082 - accuracy: 0.5003 - val_loss: 77.9291 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 70.9550 - accuracy: 0.5003 - val_loss: 65.3306 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 61.5536 - accuracy: 0.5003 - val_loss: 57.8718 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 54.1406 - accuracy: 0.5003 - val_loss: 50.5018 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 46.8159 - accuracy: 0.5003 - val_loss: 43.2209 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 39.5806 - accuracy: 0.5003 - val_loss: 36.0298 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 32.4352 - accuracy: 0.5003 - val_loss: 28.9287 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 25.3796 - accuracy: 0.5003 - val_loss: 21.9172 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 18.4136 - accuracy: 0.5003 - val_loss: 14.9956 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 11.5377 - accuracy: 0.5003 - val_loss: 8.1643 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.7543 - accuracy: 0.5003 - val_loss: 1.6227 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.5003 - val_loss: 1.6224 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4975 - val_loss: 1.6220 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.5002 - val_loss: 1.6212 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4983 - val_loss: 1.6203 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.5003 - val_loss: 1.6199 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4940 - val_loss: 1.6197 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4977 - val_loss: 1.6189 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4988 - val_loss: 1.6185 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4996 - val_loss: 1.6181 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4974 - val_loss: 1.6178 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4950 - val_loss: 1.6175 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4997 - val_loss: 1.6173 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4942 - val_loss: 1.6166 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.5003 - val_loss: 1.6163 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4950 - val_loss: 1.6158 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.5782 - accuracy: 0.5003 - val_loss: 1.6149 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4958 - val_loss: 1.6141 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4992 - val_loss: 1.6138 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4932 - val_loss: 1.6136 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4985 - val_loss: 1.6131 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4965 - val_loss: 1.6124 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4947 - val_loss: 1.6118 - val_accuracy: 0.4999\n",
      "Epoch 46/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4979 - val_loss: 1.6115 - val_accuracy: 0.4999\n",
      "Epoch 47/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4992 - val_loss: 1.6110 - val_accuracy: 0.4999\n",
      "Epoch 48/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4984 - val_loss: 1.6109 - val_accuracy: 0.4999\n",
      "Epoch 49/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.5782 - accuracy: 0.4946 - val_loss: 1.6105 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4982 - val_loss: 1.6102 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.5010 - val_loss: 1.6095 - val_accuracy: 0.4999\n",
      "Epoch 52/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4968 - val_loss: 1.6091 - val_accuracy: 0.4999\n",
      "Epoch 53/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4976 - val_loss: 1.6086 - val_accuracy: 0.4999\n",
      "Epoch 54/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4931 - val_loss: 1.6082 - val_accuracy: 0.4999\n",
      "Epoch 55/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4982 - val_loss: 1.6080 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4986 - val_loss: 1.6079 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4933 - val_loss: 1.6074 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4987 - val_loss: 1.6072 - val_accuracy: 0.4999\n",
      "Epoch 59/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4965 - val_loss: 1.6067 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4989 - val_loss: 1.6065 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.5782 - accuracy: 0.4995 - val_loss: 1.6062 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4996 - val_loss: 1.6056 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.5782 - accuracy: 0.4987 - val_loss: 1.6053 - val_accuracy: 0.4999\n",
      "Epoch 64/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4961 - val_loss: 1.6051 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.5782 - accuracy: 0.4989 - val_loss: 1.6049 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4996 - val_loss: 1.6047 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.5782 - accuracy: 0.5003 - val_loss: 1.6043 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4994 - val_loss: 1.6039 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.5782 - accuracy: 0.5001 - val_loss: 1.6036 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.5003 - val_loss: 1.6033 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.5004 - val_loss: 1.6031 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4989 - val_loss: 1.6025 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5782 - accuracy: 0.4947 - val_loss: 1.6022 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "654/670 [============================>.] - ETA: 0s - loss: 1.5782 - accuracy: 0.4974Restoring model weights from the end of the best epoch: 73.\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.5782 - accuracy: 0.4970 - val_loss: 1.6023 - val_accuracy: 0.5001\n",
      "Epoch 74: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 1.6022 - accuracy: 0.5001\n",
      "{'loss': 1.6021653413772583, 'accuracy': 0.5001260638237} \n",
      " 73 \n",
      "\n",
      "Model time: 3.94356133043766 minutes\n",
      "\n",
      "Total time: 37.815184377133846 minutes\n",
      "\n",
      "\n",
      "Model  37  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                   128\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.1\n",
      "L1                         0.00001\n",
      "L2                          0.0001\n",
      "Batch size                       8\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 1212964, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 15s 5ms/step - loss: 0.7347 - accuracy: 0.5144 - val_loss: 0.7092 - val_accuracy: 0.5733\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7172 - accuracy: 0.5443 - val_loss: 0.6979 - val_accuracy: 0.6000\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7066 - accuracy: 0.5621 - val_loss: 0.6916 - val_accuracy: 0.6032\n",
      "Epoch 4/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6994 - accuracy: 0.5769 - val_loss: 0.6871 - val_accuracy: 0.6066\n",
      "Epoch 5/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6945 - accuracy: 0.5848 - val_loss: 0.6832 - val_accuracy: 0.6148\n",
      "Epoch 6/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6896 - accuracy: 0.5877 - val_loss: 0.6818 - val_accuracy: 0.6105\n",
      "Epoch 7/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6899 - accuracy: 0.5869 - val_loss: 0.6793 - val_accuracy: 0.6162\n",
      "Epoch 8/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6879 - accuracy: 0.5915 - val_loss: 0.6780 - val_accuracy: 0.6159\n",
      "Epoch 9/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6871 - accuracy: 0.5926 - val_loss: 0.6766 - val_accuracy: 0.6180\n",
      "Epoch 10/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6848 - accuracy: 0.5984 - val_loss: 0.6759 - val_accuracy: 0.6160\n",
      "Epoch 11/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.6830 - accuracy: 0.5961 - val_loss: 0.6738 - val_accuracy: 0.6211\n",
      "Epoch 12/300\n",
      "2677/2677 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.5979Restoring model weights from the end of the best epoch: 11.\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6826 - accuracy: 0.5979 - val_loss: 0.6756 - val_accuracy: 0.6116\n",
      "Epoch 12: early stopping\n",
      "2480/2480 [==============================] - 7s 3ms/step - loss: 0.6738 - accuracy: 0.6211\n",
      "{'loss': 0.6738327145576477, 'accuracy': 0.621086061000824} \n",
      " 11 \n",
      "\n",
      "Model time: 3.520967550575733 minutes\n",
      "\n",
      "Total time: 41.336235973984 minutes\n",
      "\n",
      "\n",
      "Model  38  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                     2\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.1\n",
      "L1                            10.0\n",
      "L2                          0.0001\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 3076640, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 4s 11ms/step - loss: 357.4016 - accuracy: 0.4995 - val_loss: 354.3740 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 351.4344 - accuracy: 0.4991 - val_loss: 348.4519 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 345.5428 - accuracy: 0.4998 - val_loss: 342.5723 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 339.6738 - accuracy: 0.4994 - val_loss: 336.7277 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 333.8546 - accuracy: 0.4996 - val_loss: 330.9305 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 328.0839 - accuracy: 0.4989 - val_loss: 325.1861 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 322.3784 - accuracy: 0.5001 - val_loss: 319.5239 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 316.7656 - accuracy: 0.4998 - val_loss: 313.9640 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 311.2294 - accuracy: 0.5008 - val_loss: 308.4386 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 305.7239 - accuracy: 0.4995 - val_loss: 302.9588 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 300.2722 - accuracy: 0.5001 - val_loss: 297.5367 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 294.8634 - accuracy: 0.5004 - val_loss: 292.1393 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 289.4792 - accuracy: 0.5018 - val_loss: 286.7633 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 284.1084 - accuracy: 0.5001 - val_loss: 281.4004 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 278.7579 - accuracy: 0.5005 - val_loss: 276.0703 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 273.4523 - accuracy: 0.5011 - val_loss: 270.7862 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 268.2049 - accuracy: 0.4998 - val_loss: 265.5825 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 263.0313 - accuracy: 0.4989 - val_loss: 260.4414 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 257.9328 - accuracy: 0.4994 - val_loss: 255.3770 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 252.8928 - accuracy: 0.5002 - val_loss: 250.3703 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 247.9244 - accuracy: 0.5004 - val_loss: 245.4349 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 243.0166 - accuracy: 0.4953 - val_loss: 240.5642 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 238.1773 - accuracy: 0.4954 - val_loss: 235.7522 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 233.4078 - accuracy: 0.4994 - val_loss: 231.0288 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 228.7118 - accuracy: 0.5015 - val_loss: 226.3531 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 224.0694 - accuracy: 0.5002 - val_loss: 221.7614 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 219.5371 - accuracy: 0.5017 - val_loss: 217.2718 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 215.0734 - accuracy: 0.4987 - val_loss: 212.8446 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 210.6816 - accuracy: 0.5011 - val_loss: 208.4794 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 206.3389 - accuracy: 0.4993 - val_loss: 204.1573 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 202.0368 - accuracy: 0.5009 - val_loss: 199.8899 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 197.8121 - accuracy: 0.4988 - val_loss: 195.7020 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 193.6488 - accuracy: 0.5013 - val_loss: 191.5523 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 189.5022 - accuracy: 0.5001 - val_loss: 187.4128 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 185.3681 - accuracy: 0.5019 - val_loss: 183.2804 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 181.2529 - accuracy: 0.5020 - val_loss: 179.1952 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 177.2169 - accuracy: 0.5008 - val_loss: 175.2113 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 173.2714 - accuracy: 0.4982 - val_loss: 171.2944 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 169.3782 - accuracy: 0.5018 - val_loss: 167.4293 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 165.5268 - accuracy: 0.5006 - val_loss: 163.5900 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 161.7201 - accuracy: 0.4976 - val_loss: 159.8186 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 157.9664 - accuracy: 0.4992 - val_loss: 156.0843 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 154.2823 - accuracy: 0.5002 - val_loss: 152.4539 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 150.6935 - accuracy: 0.4983 - val_loss: 148.9081 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 147.1875 - accuracy: 0.4983 - val_loss: 145.4392 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 143.7368 - accuracy: 0.5008 - val_loss: 142.0052 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 140.3193 - accuracy: 0.5034 - val_loss: 138.6063 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 136.9500 - accuracy: 0.5001 - val_loss: 135.2631 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 133.6230 - accuracy: 0.5010 - val_loss: 131.9553 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 130.3405 - accuracy: 0.5031 - val_loss: 128.6959 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 127.0972 - accuracy: 0.5014 - val_loss: 125.4702 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 123.8989 - accuracy: 0.4994 - val_loss: 122.3054 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 120.7597 - accuracy: 0.5005 - val_loss: 119.1931 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 117.6771 - accuracy: 0.5000 - val_loss: 116.1333 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 114.6288 - accuracy: 0.4999 - val_loss: 113.0924 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 111.6059 - accuracy: 0.4999 - val_loss: 110.0992 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 108.6516 - accuracy: 0.4995 - val_loss: 107.1745 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 105.7470 - accuracy: 0.5044 - val_loss: 104.2953 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 102.8988 - accuracy: 0.4968 - val_loss: 101.4936 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 100.1496 - accuracy: 0.5025 - val_loss: 98.7850 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 97.4767 - accuracy: 0.4996 - val_loss: 96.1524 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 94.8750 - accuracy: 0.4969 - val_loss: 93.5744 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 92.3029 - accuracy: 0.5017 - val_loss: 91.0070 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 89.7597 - accuracy: 0.5015 - val_loss: 88.4988 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 87.2852 - accuracy: 0.4999 - val_loss: 86.0553 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 84.8894 - accuracy: 0.5025 - val_loss: 83.7148 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 82.5990 - accuracy: 0.4992 - val_loss: 81.4707 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 80.4053 - accuracy: 0.4995 - val_loss: 79.3278 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 78.2905 - accuracy: 0.4983 - val_loss: 77.2471 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 76.2599 - accuracy: 0.4969 - val_loss: 75.2636 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 74.2993 - accuracy: 0.5013 - val_loss: 73.3147 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 72.3550 - accuracy: 0.4979 - val_loss: 71.3824 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 70.4513 - accuracy: 0.5016 - val_loss: 69.5032 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 68.5908 - accuracy: 0.5001 - val_loss: 67.6703 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 66.7904 - accuracy: 0.5022 - val_loss: 65.9026 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 65.0456 - accuracy: 0.4971 - val_loss: 64.1815 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 63.3544 - accuracy: 0.4982 - val_loss: 62.5129 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 61.7023 - accuracy: 0.4998 - val_loss: 60.8814 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 60.0885 - accuracy: 0.4967 - val_loss: 59.2845 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 58.5174 - accuracy: 0.5011 - val_loss: 57.7428 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 56.9955 - accuracy: 0.4987 - val_loss: 56.2418 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 55.5249 - accuracy: 0.4974 - val_loss: 54.7957 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 54.0917 - accuracy: 0.4988 - val_loss: 53.3798 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 52.6998 - accuracy: 0.5014 - val_loss: 52.0111 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 51.3382 - accuracy: 0.5002 - val_loss: 50.6564 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 50.0233 - accuracy: 0.4992 - val_loss: 49.3913 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 48.7846 - accuracy: 0.5003 - val_loss: 48.1666 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 47.5779 - accuracy: 0.5007 - val_loss: 46.9870 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 46.4148 - accuracy: 0.5014 - val_loss: 45.8371 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 45.2887 - accuracy: 0.4972 - val_loss: 44.7284 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 44.1872 - accuracy: 0.5004 - val_loss: 43.6460 - val_accuracy: 0.5001\n",
      "Epoch 92/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 43.1316 - accuracy: 0.4998 - val_loss: 42.6126 - val_accuracy: 0.5001\n",
      "Epoch 93/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 42.1190 - accuracy: 0.4995 - val_loss: 41.6216 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 41.1531 - accuracy: 0.4980 - val_loss: 40.6878 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 40.2673 - accuracy: 0.5019 - val_loss: 39.8472 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 39.4583 - accuracy: 0.5010 - val_loss: 39.0731 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 38.7155 - accuracy: 0.5016 - val_loss: 38.3505 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 37.9941 - accuracy: 0.5014 - val_loss: 37.6350 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 37.2984 - accuracy: 0.4983 - val_loss: 36.9587 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 36.6416 - accuracy: 0.5015 - val_loss: 36.3268 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 36.0343 - accuracy: 0.4985 - val_loss: 35.7468 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 35.4942 - accuracy: 0.4991 - val_loss: 35.2433 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 35.0038 - accuracy: 0.5020 - val_loss: 34.7665 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 34.5532 - accuracy: 0.4973 - val_loss: 34.3434 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 34.1556 - accuracy: 0.4977 - val_loss: 33.9683 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 33.8002 - accuracy: 0.5013 - val_loss: 33.6425 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 33.5020 - accuracy: 0.5056 - val_loss: 33.3630 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 33.2367 - accuracy: 0.4957 - val_loss: 33.1087 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 32.9920 - accuracy: 0.4976 - val_loss: 32.8820 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 32.7983 - accuracy: 0.4996 - val_loss: 32.7133 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 32.6450 - accuracy: 0.5011 - val_loss: 32.5768 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 32.5105 - accuracy: 0.4974 - val_loss: 32.4423 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 32.3759 - accuracy: 0.5004 - val_loss: 32.3078 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 32.2412 - accuracy: 0.5018 - val_loss: 32.1733 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 32.1070 - accuracy: 0.4973 - val_loss: 32.0387 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 31.9724 - accuracy: 0.4983 - val_loss: 31.9043 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 31.8378 - accuracy: 0.4998 - val_loss: 31.7697 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 31.7033 - accuracy: 0.5000 - val_loss: 31.6351 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 31.5687 - accuracy: 0.5004 - val_loss: 31.5007 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 31.4342 - accuracy: 0.5003 - val_loss: 31.3662 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 31.2997 - accuracy: 0.5003 - val_loss: 31.2316 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 31.1653 - accuracy: 0.4981 - val_loss: 31.0973 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 31.0308 - accuracy: 0.4990 - val_loss: 30.9626 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 30.8961 - accuracy: 0.5006 - val_loss: 30.8280 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 30.7615 - accuracy: 0.5019 - val_loss: 30.6938 - val_accuracy: 0.5001\n",
      "Epoch 126/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 30.6270 - accuracy: 0.5019 - val_loss: 30.5591 - val_accuracy: 0.5001\n",
      "Epoch 127/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 30.4925 - accuracy: 0.5015 - val_loss: 30.4244 - val_accuracy: 0.5001\n",
      "Epoch 128/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 30.3582 - accuracy: 0.4983 - val_loss: 30.2901 - val_accuracy: 0.5001\n",
      "Epoch 129/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 30.2235 - accuracy: 0.5021 - val_loss: 30.1556 - val_accuracy: 0.5001\n",
      "Epoch 130/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 30.0891 - accuracy: 0.5006 - val_loss: 30.0212 - val_accuracy: 0.5001\n",
      "Epoch 131/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 29.9547 - accuracy: 0.4992 - val_loss: 29.8867 - val_accuracy: 0.5001\n",
      "Epoch 132/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 29.8203 - accuracy: 0.4989 - val_loss: 29.7520 - val_accuracy: 0.5001\n",
      "Epoch 133/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 29.6856 - accuracy: 0.5006 - val_loss: 29.6176 - val_accuracy: 0.5001\n",
      "Epoch 134/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 29.5512 - accuracy: 0.4991 - val_loss: 29.4833 - val_accuracy: 0.5001\n",
      "Epoch 135/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 29.4169 - accuracy: 0.4982 - val_loss: 29.3488 - val_accuracy: 0.5001\n",
      "Epoch 136/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 29.2823 - accuracy: 0.4987 - val_loss: 29.2142 - val_accuracy: 0.5001\n",
      "Epoch 137/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 29.1478 - accuracy: 0.4997 - val_loss: 29.0798 - val_accuracy: 0.5001\n",
      "Epoch 138/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 29.0134 - accuracy: 0.4997 - val_loss: 28.9452 - val_accuracy: 0.5001\n",
      "Epoch 139/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 28.8789 - accuracy: 0.5005 - val_loss: 28.8108 - val_accuracy: 0.5001\n",
      "Epoch 140/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 28.7444 - accuracy: 0.5000 - val_loss: 28.6764 - val_accuracy: 0.5001\n",
      "Epoch 141/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 28.6101 - accuracy: 0.4989 - val_loss: 28.5421 - val_accuracy: 0.5001\n",
      "Epoch 142/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 28.4755 - accuracy: 0.5007 - val_loss: 28.4076 - val_accuracy: 0.5001\n",
      "Epoch 143/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 28.3412 - accuracy: 0.4982 - val_loss: 28.2732 - val_accuracy: 0.5001\n",
      "Epoch 144/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 28.2065 - accuracy: 0.5032 - val_loss: 28.1387 - val_accuracy: 0.5001\n",
      "Epoch 145/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 28.0721 - accuracy: 0.5014 - val_loss: 28.0042 - val_accuracy: 0.5001\n",
      "Epoch 146/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 27.9377 - accuracy: 0.5008 - val_loss: 27.8698 - val_accuracy: 0.5001\n",
      "Epoch 147/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 27.8033 - accuracy: 0.5006 - val_loss: 27.7353 - val_accuracy: 0.5001\n",
      "Epoch 148/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 27.6688 - accuracy: 0.5011 - val_loss: 27.6009 - val_accuracy: 0.5001\n",
      "Epoch 149/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 27.5343 - accuracy: 0.5028 - val_loss: 27.4666 - val_accuracy: 0.5001\n",
      "Epoch 150/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 27.4000 - accuracy: 0.5006 - val_loss: 27.3321 - val_accuracy: 0.5001\n",
      "Epoch 151/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 27.2654 - accuracy: 0.5021 - val_loss: 27.1974 - val_accuracy: 0.5001\n",
      "Epoch 152/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 27.1312 - accuracy: 0.4989 - val_loss: 27.0631 - val_accuracy: 0.5001\n",
      "Epoch 153/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 26.9967 - accuracy: 0.4996 - val_loss: 26.9286 - val_accuracy: 0.5001\n",
      "Epoch 154/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 26.8623 - accuracy: 0.4997 - val_loss: 26.7941 - val_accuracy: 0.5001\n",
      "Epoch 155/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 26.7277 - accuracy: 0.5018 - val_loss: 26.6599 - val_accuracy: 0.5001\n",
      "Epoch 156/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 26.5933 - accuracy: 0.5015 - val_loss: 26.5254 - val_accuracy: 0.5001\n",
      "Epoch 157/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 26.4590 - accuracy: 0.4985 - val_loss: 26.3908 - val_accuracy: 0.5001\n",
      "Epoch 158/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 26.3245 - accuracy: 0.4992 - val_loss: 26.2566 - val_accuracy: 0.5001\n",
      "Epoch 159/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 26.1899 - accuracy: 0.5025 - val_loss: 26.1220 - val_accuracy: 0.5001\n",
      "Epoch 160/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 26.0557 - accuracy: 0.4991 - val_loss: 25.9877 - val_accuracy: 0.5001\n",
      "Epoch 161/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 25.9210 - accuracy: 0.5025 - val_loss: 25.8533 - val_accuracy: 0.5001\n",
      "Epoch 162/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 25.7870 - accuracy: 0.4965 - val_loss: 25.7188 - val_accuracy: 0.5001\n",
      "Epoch 163/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 25.6524 - accuracy: 0.4978 - val_loss: 25.5841 - val_accuracy: 0.5001\n",
      "Epoch 164/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 25.5177 - accuracy: 0.5020 - val_loss: 25.4499 - val_accuracy: 0.5001\n",
      "Epoch 165/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 25.3837 - accuracy: 0.4962 - val_loss: 25.3154 - val_accuracy: 0.5001\n",
      "Epoch 166/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 25.2491 - accuracy: 0.4982 - val_loss: 25.1809 - val_accuracy: 0.5001\n",
      "Epoch 167/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 25.1146 - accuracy: 0.4990 - val_loss: 25.0467 - val_accuracy: 0.5001\n",
      "Epoch 168/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 24.9800 - accuracy: 0.5015 - val_loss: 24.9119 - val_accuracy: 0.5001\n",
      "Epoch 169/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 24.8457 - accuracy: 0.4988 - val_loss: 24.7776 - val_accuracy: 0.5001\n",
      "Epoch 170/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 24.7112 - accuracy: 0.5010 - val_loss: 24.6433 - val_accuracy: 0.5001\n",
      "Epoch 171/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 24.5767 - accuracy: 0.5007 - val_loss: 24.5087 - val_accuracy: 0.5001\n",
      "Epoch 172/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 24.4423 - accuracy: 0.5011 - val_loss: 24.3744 - val_accuracy: 0.5001\n",
      "Epoch 173/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 24.3081 - accuracy: 0.4964 - val_loss: 24.2399 - val_accuracy: 0.5001\n",
      "Epoch 174/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 24.1735 - accuracy: 0.4994 - val_loss: 24.1055 - val_accuracy: 0.5001\n",
      "Epoch 175/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 24.0390 - accuracy: 0.4993 - val_loss: 23.9710 - val_accuracy: 0.5001\n",
      "Epoch 176/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 23.9046 - accuracy: 0.5004 - val_loss: 23.8367 - val_accuracy: 0.5001\n",
      "Epoch 177/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 23.7701 - accuracy: 0.5008 - val_loss: 23.7021 - val_accuracy: 0.5001\n",
      "Epoch 178/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 23.6356 - accuracy: 0.5014 - val_loss: 23.5678 - val_accuracy: 0.5001\n",
      "Epoch 179/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 23.5013 - accuracy: 0.4997 - val_loss: 23.4333 - val_accuracy: 0.5001\n",
      "Epoch 180/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 23.3666 - accuracy: 0.5032 - val_loss: 23.2989 - val_accuracy: 0.5001\n",
      "Epoch 181/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 23.2324 - accuracy: 0.4998 - val_loss: 23.1644 - val_accuracy: 0.5001\n",
      "Epoch 182/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 23.0979 - accuracy: 0.5001 - val_loss: 23.0300 - val_accuracy: 0.5001\n",
      "Epoch 183/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 22.9634 - accuracy: 0.5014 - val_loss: 22.8954 - val_accuracy: 0.5001\n",
      "Epoch 184/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 22.8290 - accuracy: 0.5008 - val_loss: 22.7609 - val_accuracy: 0.5001\n",
      "Epoch 185/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 22.6945 - accuracy: 0.5013 - val_loss: 22.6267 - val_accuracy: 0.5001\n",
      "Epoch 186/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 22.5600 - accuracy: 0.5027 - val_loss: 22.4921 - val_accuracy: 0.5001\n",
      "Epoch 187/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 22.4256 - accuracy: 0.5029 - val_loss: 22.3575 - val_accuracy: 0.5001\n",
      "Epoch 188/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 22.2911 - accuracy: 0.5029 - val_loss: 22.2233 - val_accuracy: 0.5001\n",
      "Epoch 189/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 22.1568 - accuracy: 0.5006 - val_loss: 22.0888 - val_accuracy: 0.5001\n",
      "Epoch 190/300\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 22.0223 - accuracy: 0.5025 - val_loss: 21.9544 - val_accuracy: 0.5001\n",
      "Epoch 191/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 21.8879 - accuracy: 0.5012 - val_loss: 21.8201 - val_accuracy: 0.5001\n",
      "Epoch 192/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 21.7535 - accuracy: 0.4999 - val_loss: 21.6853 - val_accuracy: 0.5001\n",
      "Epoch 193/300\n",
      "168/168 [==============================] - 2s 9ms/step - loss: 21.6190 - accuracy: 0.5011 - val_loss: 21.5510 - val_accuracy: 0.5001\n",
      "Epoch 194/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 21.4846 - accuracy: 0.5018 - val_loss: 21.4167 - val_accuracy: 0.5001\n",
      "Epoch 195/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 21.3503 - accuracy: 0.4992 - val_loss: 21.2823 - val_accuracy: 0.5001\n",
      "Epoch 196/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 21.2156 - accuracy: 0.5025 - val_loss: 21.1477 - val_accuracy: 0.5001\n",
      "Epoch 197/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 21.0813 - accuracy: 0.5011 - val_loss: 21.0133 - val_accuracy: 0.5001\n",
      "Epoch 198/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 20.9469 - accuracy: 0.5002 - val_loss: 20.8787 - val_accuracy: 0.5001\n",
      "Epoch 199/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 20.8126 - accuracy: 0.4970 - val_loss: 20.7444 - val_accuracy: 0.5001\n",
      "Epoch 200/300\n",
      "168/168 [==============================] - 2s 9ms/step - loss: 20.6779 - accuracy: 0.5023 - val_loss: 20.6101 - val_accuracy: 0.5001\n",
      "Epoch 201/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 20.5434 - accuracy: 0.5021 - val_loss: 20.4755 - val_accuracy: 0.5001\n",
      "Epoch 202/300\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 20.4093 - accuracy: 0.4968 - val_loss: 20.3411 - val_accuracy: 0.5001\n",
      "Epoch 203/300\n",
      "168/168 [==============================] - 2s 10ms/step - loss: 20.2747 - accuracy: 0.4988 - val_loss: 20.2067 - val_accuracy: 0.5001\n",
      "Epoch 204/300\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 20.1401 - accuracy: 0.5029 - val_loss: 20.0721 - val_accuracy: 0.5001\n",
      "Epoch 205/300\n",
      "168/168 [==============================] - 2s 10ms/step - loss: 20.0059 - accuracy: 0.4987 - val_loss: 19.9378 - val_accuracy: 0.5001\n",
      "Epoch 206/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 19.8713 - accuracy: 0.5010 - val_loss: 19.8035 - val_accuracy: 0.5001\n",
      "Epoch 207/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 19.7368 - accuracy: 0.5028 - val_loss: 19.6688 - val_accuracy: 0.5001\n",
      "Epoch 208/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 19.6026 - accuracy: 0.4984 - val_loss: 19.5344 - val_accuracy: 0.5001\n",
      "Epoch 209/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 19.4682 - accuracy: 0.4976 - val_loss: 19.3999 - val_accuracy: 0.5001\n",
      "Epoch 210/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 19.3335 - accuracy: 0.5022 - val_loss: 19.2656 - val_accuracy: 0.5001\n",
      "Epoch 211/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 19.1991 - accuracy: 0.5009 - val_loss: 19.1312 - val_accuracy: 0.5001\n",
      "Epoch 212/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 19.0646 - accuracy: 0.5024 - val_loss: 18.9968 - val_accuracy: 0.5001\n",
      "Epoch 213/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 18.9303 - accuracy: 0.4997 - val_loss: 18.8622 - val_accuracy: 0.5001\n",
      "Epoch 214/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 18.7957 - accuracy: 0.5023 - val_loss: 18.7279 - val_accuracy: 0.5001\n",
      "Epoch 215/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 18.6613 - accuracy: 0.5007 - val_loss: 18.5935 - val_accuracy: 0.5001\n",
      "Epoch 216/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 18.5269 - accuracy: 0.5002 - val_loss: 18.4589 - val_accuracy: 0.5001\n",
      "Epoch 217/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 18.3924 - accuracy: 0.5007 - val_loss: 18.3244 - val_accuracy: 0.5001\n",
      "Epoch 218/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 18.2581 - accuracy: 0.4988 - val_loss: 18.1902 - val_accuracy: 0.5001\n",
      "Epoch 219/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 18.1235 - accuracy: 0.5015 - val_loss: 18.0557 - val_accuracy: 0.5001\n",
      "Epoch 220/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 17.9889 - accuracy: 0.5039 - val_loss: 17.9211 - val_accuracy: 0.5001\n",
      "Epoch 221/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 17.8548 - accuracy: 0.4982 - val_loss: 17.7868 - val_accuracy: 0.5001\n",
      "Epoch 222/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 17.7204 - accuracy: 0.4983 - val_loss: 17.6523 - val_accuracy: 0.5001\n",
      "Epoch 223/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 17.5858 - accuracy: 0.5002 - val_loss: 17.5178 - val_accuracy: 0.5001\n",
      "Epoch 224/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 17.4515 - accuracy: 0.4980 - val_loss: 17.3835 - val_accuracy: 0.5001\n",
      "Epoch 225/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 17.3170 - accuracy: 0.4994 - val_loss: 17.2490 - val_accuracy: 0.5001\n",
      "Epoch 226/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 17.1826 - accuracy: 0.4995 - val_loss: 17.1145 - val_accuracy: 0.5001\n",
      "Epoch 227/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 17.0480 - accuracy: 0.5014 - val_loss: 16.9800 - val_accuracy: 0.5001\n",
      "Epoch 228/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 16.9135 - accuracy: 0.5017 - val_loss: 16.8455 - val_accuracy: 0.5001\n",
      "Epoch 229/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 16.7790 - accuracy: 0.5033 - val_loss: 16.7112 - val_accuracy: 0.5001\n",
      "Epoch 230/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 16.6447 - accuracy: 0.5011 - val_loss: 16.5775 - val_accuracy: 0.5001\n",
      "Epoch 231/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 16.5190 - accuracy: 0.4994 - val_loss: 16.4594 - val_accuracy: 0.5001\n",
      "Epoch 232/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 16.4014 - accuracy: 0.4986 - val_loss: 16.3418 - val_accuracy: 0.5001\n",
      "Epoch 233/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 16.2834 - accuracy: 0.5042 - val_loss: 16.2242 - val_accuracy: 0.5001\n",
      "Epoch 234/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 16.1659 - accuracy: 0.5036 - val_loss: 16.1065 - val_accuracy: 0.5001\n",
      "Epoch 235/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 16.0485 - accuracy: 0.4992 - val_loss: 15.9890 - val_accuracy: 0.5001\n",
      "Epoch 236/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 15.9306 - accuracy: 0.5025 - val_loss: 15.8714 - val_accuracy: 0.5001\n",
      "Epoch 237/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 15.8132 - accuracy: 0.4994 - val_loss: 15.7535 - val_accuracy: 0.5001\n",
      "Epoch 238/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 15.6956 - accuracy: 0.4970 - val_loss: 15.6359 - val_accuracy: 0.5001\n",
      "Epoch 239/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 15.5777 - accuracy: 0.5019 - val_loss: 15.5183 - val_accuracy: 0.5001\n",
      "Epoch 240/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 15.4601 - accuracy: 0.5022 - val_loss: 15.4007 - val_accuracy: 0.5001\n",
      "Epoch 241/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 15.3424 - accuracy: 0.5035 - val_loss: 15.2831 - val_accuracy: 0.5001\n",
      "Epoch 242/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 15.2248 - accuracy: 0.5013 - val_loss: 15.1653 - val_accuracy: 0.5001\n",
      "Epoch 243/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 15.1073 - accuracy: 0.5003 - val_loss: 15.0477 - val_accuracy: 0.5001\n",
      "Epoch 244/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 14.9895 - accuracy: 0.5025 - val_loss: 14.9302 - val_accuracy: 0.5001\n",
      "Epoch 245/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 14.8718 - accuracy: 0.5038 - val_loss: 14.8126 - val_accuracy: 0.5001\n",
      "Epoch 246/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 14.7544 - accuracy: 0.4983 - val_loss: 14.6948 - val_accuracy: 0.5001\n",
      "Epoch 247/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 14.6369 - accuracy: 0.4973 - val_loss: 14.5771 - val_accuracy: 0.5001\n",
      "Epoch 248/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 14.5191 - accuracy: 0.4989 - val_loss: 14.4596 - val_accuracy: 0.5001\n",
      "Epoch 249/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 14.4016 - accuracy: 0.4969 - val_loss: 14.3419 - val_accuracy: 0.5001\n",
      "Epoch 250/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 14.2837 - accuracy: 0.5013 - val_loss: 14.2243 - val_accuracy: 0.5001\n",
      "Epoch 251/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 14.1662 - accuracy: 0.4991 - val_loss: 14.1067 - val_accuracy: 0.5001\n",
      "Epoch 252/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 14.0485 - accuracy: 0.5004 - val_loss: 13.9889 - val_accuracy: 0.4999\n",
      "Epoch 253/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 13.9308 - accuracy: 0.5011 - val_loss: 13.8713 - val_accuracy: 0.4999\n",
      "Epoch 254/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 13.8130 - accuracy: 0.5039 - val_loss: 13.7538 - val_accuracy: 0.4999\n",
      "Epoch 255/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 13.6955 - accuracy: 0.5006 - val_loss: 13.6361 - val_accuracy: 0.4999\n",
      "Epoch 256/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 13.5778 - accuracy: 0.5018 - val_loss: 13.5183 - val_accuracy: 0.4999\n",
      "Epoch 257/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 13.4602 - accuracy: 0.5017 - val_loss: 13.4008 - val_accuracy: 0.4999\n",
      "Epoch 258/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 13.3427 - accuracy: 0.4984 - val_loss: 13.2832 - val_accuracy: 0.4999\n",
      "Epoch 259/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 13.2252 - accuracy: 0.4964 - val_loss: 13.1655 - val_accuracy: 0.4999\n",
      "Epoch 260/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 13.1073 - accuracy: 0.5018 - val_loss: 13.0480 - val_accuracy: 0.4999\n",
      "Epoch 261/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.9896 - accuracy: 0.5028 - val_loss: 12.9302 - val_accuracy: 0.4999\n",
      "Epoch 262/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.8721 - accuracy: 0.4989 - val_loss: 12.8124 - val_accuracy: 0.4999\n",
      "Epoch 263/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 12.7543 - accuracy: 0.5031 - val_loss: 12.6950 - val_accuracy: 0.4999\n",
      "Epoch 264/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.6368 - accuracy: 0.4997 - val_loss: 12.5772 - val_accuracy: 0.4999\n",
      "Epoch 265/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.5191 - accuracy: 0.5014 - val_loss: 12.4596 - val_accuracy: 0.4999\n",
      "Epoch 266/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.4014 - accuracy: 0.5021 - val_loss: 12.3420 - val_accuracy: 0.4999\n",
      "Epoch 267/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 12.2840 - accuracy: 0.4977 - val_loss: 12.2243 - val_accuracy: 0.4999\n",
      "Epoch 268/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.1662 - accuracy: 0.4996 - val_loss: 12.1066 - val_accuracy: 0.4999\n",
      "Epoch 269/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.0486 - accuracy: 0.4994 - val_loss: 11.9891 - val_accuracy: 0.4999\n",
      "Epoch 270/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.9310 - accuracy: 0.4984 - val_loss: 11.8714 - val_accuracy: 0.4999\n",
      "Epoch 271/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 11.8184 - accuracy: 0.4984 - val_loss: 11.7669 - val_accuracy: 0.4999\n",
      "Epoch 272/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.7167 - accuracy: 0.5061 - val_loss: 11.6660 - val_accuracy: 0.4999\n",
      "Epoch 273/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.6163 - accuracy: 0.4987 - val_loss: 11.5651 - val_accuracy: 0.4999\n",
      "Epoch 274/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 11.5153 - accuracy: 0.5018 - val_loss: 11.4644 - val_accuracy: 0.4999\n",
      "Epoch 275/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 11.4150 - accuracy: 0.5017 - val_loss: 11.3678 - val_accuracy: 0.4999\n",
      "Epoch 276/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.3264 - accuracy: 0.4968 - val_loss: 11.2838 - val_accuracy: 0.4999\n",
      "Epoch 277/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.2422 - accuracy: 0.4997 - val_loss: 11.1996 - val_accuracy: 0.4999\n",
      "Epoch 278/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.1580 - accuracy: 0.5020 - val_loss: 11.1156 - val_accuracy: 0.4999\n",
      "Epoch 279/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.0742 - accuracy: 0.4985 - val_loss: 11.0315 - val_accuracy: 0.4999\n",
      "Epoch 280/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.9901 - accuracy: 0.4991 - val_loss: 10.9475 - val_accuracy: 0.4999\n",
      "Epoch 281/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.9059 - accuracy: 0.5009 - val_loss: 10.8635 - val_accuracy: 0.4999\n",
      "Epoch 282/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 10.8243 - accuracy: 0.5043 - val_loss: 10.7887 - val_accuracy: 0.4999\n",
      "Epoch 283/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 10.7555 - accuracy: 0.5021 - val_loss: 10.7215 - val_accuracy: 0.4999\n",
      "Epoch 284/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 10.6882 - accuracy: 0.4980 - val_loss: 10.6543 - val_accuracy: 0.4999\n",
      "Epoch 285/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 10.6211 - accuracy: 0.4997 - val_loss: 10.5870 - val_accuracy: 0.4999\n",
      "Epoch 286/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.5538 - accuracy: 0.4997 - val_loss: 10.5199 - val_accuracy: 0.4999\n",
      "Epoch 287/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.4867 - accuracy: 0.4997 - val_loss: 10.4527 - val_accuracy: 0.4999\n",
      "Epoch 288/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.4210 - accuracy: 0.4997 - val_loss: 10.3927 - val_accuracy: 0.4999\n",
      "Epoch 289/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 10.3679 - accuracy: 0.4997 - val_loss: 10.3423 - val_accuracy: 0.4999\n",
      "Epoch 290/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.3173 - accuracy: 0.4997 - val_loss: 10.2921 - val_accuracy: 0.4999\n",
      "Epoch 291/300\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 10.2671 - accuracy: 0.4997 - val_loss: 10.2416 - val_accuracy: 0.4999\n",
      "Epoch 292/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.2167 - accuracy: 0.4997 - val_loss: 10.1910 - val_accuracy: 0.4999\n",
      "Epoch 293/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.1660 - accuracy: 0.4997 - val_loss: 10.1406 - val_accuracy: 0.4999\n",
      "Epoch 294/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 10.1157 - accuracy: 0.4997 - val_loss: 10.0901 - val_accuracy: 0.4999\n",
      "Epoch 295/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.0651 - accuracy: 0.4997 - val_loss: 10.0398 - val_accuracy: 0.4999\n",
      "Epoch 296/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.0149 - accuracy: 0.4997 - val_loss: 9.9893 - val_accuracy: 0.4999\n",
      "Epoch 297/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.9643 - accuracy: 0.4997 - val_loss: 9.9387 - val_accuracy: 0.4999\n",
      "Epoch 298/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 9.9139 - accuracy: 0.4997 - val_loss: 9.8883 - val_accuracy: 0.4999\n",
      "Epoch 299/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.8635 - accuracy: 0.4997 - val_loss: 9.8380 - val_accuracy: 0.4999\n",
      "Epoch 300/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.8129 - accuracy: 0.4997 - val_loss: 9.7876 - val_accuracy: 0.4999\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 9.7876 - accuracy: 0.4999\n",
      "{'loss': 9.787551879882812, 'accuracy': 0.49987393617630005} \n",
      " 299 \n",
      "\n",
      "Model time: 5.599036663770676 minutes\n",
      "\n",
      "Total time: 46.93542233854532 minutes\n",
      "\n",
      "\n",
      "Model  39  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     8\n",
      "Activation function           tanh\n",
      "Dropout                        0.4\n",
      "L1                           100.0\n",
      "L2                             0.1\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 1882431, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 9s 5ms/step - loss: 955.7582 - accuracy: 0.4978 - val_loss: 75.1386 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 73.7934 - accuracy: 0.4977 - val_loss: 72.4514 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "1322/1339 [============================>.] - ETA: 0s - loss: 73.7934 - accuracy: 0.4952Restoring model weights from the end of the best epoch: 2.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 73.7933 - accuracy: 0.4955 - val_loss: 75.1303 - val_accuracy: 0.5001\n",
      "Epoch 3: early stopping\n",
      "1240/1240 [==============================] - 4s 3ms/step - loss: 72.4514 - accuracy: 0.4999\n",
      "{'loss': 72.45137786865234, 'accuracy': 0.49987393617630005} \n",
      " 2 \n",
      "\n",
      "Model time: 0.44280314445495605 minutes\n",
      "\n",
      "Total time: 47.378308814018965 minutes\n",
      "\n",
      "\n",
      "Model  40  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     2\n",
      "Activation function           tanh\n",
      "Dropout                        0.3\n",
      "L1                          0.0001\n",
      "L2                             0.0\n",
      "Batch size                     128\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 170245, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 6s 9ms/step - loss: 0.7577 - accuracy: 0.5176 - val_loss: 0.7134 - val_accuracy: 0.5409\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7409 - accuracy: 0.5284 - val_loss: 0.7006 - val_accuracy: 0.5562\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7265 - accuracy: 0.5401 - val_loss: 0.6912 - val_accuracy: 0.5675\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7161 - accuracy: 0.5475 - val_loss: 0.6852 - val_accuracy: 0.5763\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7092 - accuracy: 0.5530 - val_loss: 0.6800 - val_accuracy: 0.5839\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7044 - accuracy: 0.5503 - val_loss: 0.6761 - val_accuracy: 0.5892\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.5536 - val_loss: 0.6728 - val_accuracy: 0.5940\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6941 - accuracy: 0.5601 - val_loss: 0.6707 - val_accuracy: 0.5974\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.5625 - val_loss: 0.6685 - val_accuracy: 0.6007\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6852 - accuracy: 0.5689 - val_loss: 0.6668 - val_accuracy: 0.6030\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6823 - accuracy: 0.5770 - val_loss: 0.6655 - val_accuracy: 0.6062\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6795 - accuracy: 0.5752 - val_loss: 0.6639 - val_accuracy: 0.6100\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6769 - accuracy: 0.5830 - val_loss: 0.6626 - val_accuracy: 0.6128\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6752 - accuracy: 0.5848 - val_loss: 0.6620 - val_accuracy: 0.6127\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6740 - accuracy: 0.5818 - val_loss: 0.6610 - val_accuracy: 0.6155\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6710 - accuracy: 0.5926 - val_loss: 0.6603 - val_accuracy: 0.6181\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6696 - accuracy: 0.5935 - val_loss: 0.6597 - val_accuracy: 0.6197\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6680 - accuracy: 0.5940 - val_loss: 0.6590 - val_accuracy: 0.6222\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6680 - accuracy: 0.5954 - val_loss: 0.6582 - val_accuracy: 0.6244\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6659 - accuracy: 0.5997 - val_loss: 0.6581 - val_accuracy: 0.6250\n",
      "Epoch 21/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6661 - accuracy: 0.5983 - val_loss: 0.6575 - val_accuracy: 0.6264\n",
      "Epoch 22/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6628 - accuracy: 0.6039 - val_loss: 0.6573 - val_accuracy: 0.6265\n",
      "Epoch 23/300\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.6629 - accuracy: 0.6024Restoring model weights from the end of the best epoch: 22.\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6630 - accuracy: 0.6023 - val_loss: 0.6576 - val_accuracy: 0.6229\n",
      "Epoch 23: early stopping\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6265\n",
      "{'loss': 0.6572643518447876, 'accuracy': 0.6264811158180237} \n",
      " 22 \n",
      "\n",
      "Model time: 0.7198034003376961 minutes\n",
      "\n",
      "Total time: 48.09821221604943 minutes\n",
      "\n",
      "\n",
      "Model  41  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     8\n",
      "Activation function         linear\n",
      "Dropout                        0.1\n",
      "L1                            10.0\n",
      "L2                          0.0001\n",
      "Batch size                      32\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 1949104, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 6ms/step - loss: 1500.0297 - accuracy: 0.5256 - val_loss: 1451.8818 - val_accuracy: 0.5398\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1405.1819 - accuracy: 0.5230 - val_loss: 1358.6156 - val_accuracy: 0.5404\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1313.6094 - accuracy: 0.5250 - val_loss: 1268.8328 - val_accuracy: 0.5394\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1225.4573 - accuracy: 0.5250 - val_loss: 1182.3893 - val_accuracy: 0.5396\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1140.8164 - accuracy: 0.5243 - val_loss: 1099.4294 - val_accuracy: 0.5399\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1059.2993 - accuracy: 0.5198 - val_loss: 1019.3169 - val_accuracy: 0.5398\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 980.5736 - accuracy: 0.5182 - val_loss: 941.9239 - val_accuracy: 0.5396\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 904.5696 - accuracy: 0.5213 - val_loss: 867.4310 - val_accuracy: 0.5399\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 831.6635 - accuracy: 0.5216 - val_loss: 796.0721 - val_accuracy: 0.5412\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 761.7002 - accuracy: 0.5197 - val_loss: 727.7546 - val_accuracy: 0.5393\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 695.4603 - accuracy: 0.5235 - val_loss: 663.6177 - val_accuracy: 0.5386\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 633.3287 - accuracy: 0.5209 - val_loss: 603.4361 - val_accuracy: 0.5385\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 574.9891 - accuracy: 0.5174 - val_loss: 546.9529 - val_accuracy: 0.5392\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 520.2327 - accuracy: 0.5163 - val_loss: 493.9782 - val_accuracy: 0.5394\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 469.2126 - accuracy: 0.5152 - val_loss: 444.8534 - val_accuracy: 0.5403\n",
      "Epoch 16/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 421.6846 - accuracy: 0.5179 - val_loss: 399.0011 - val_accuracy: 0.5416\n",
      "Epoch 17/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 377.6806 - accuracy: 0.5154 - val_loss: 356.7312 - val_accuracy: 0.5426\n",
      "Epoch 18/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 336.9877 - accuracy: 0.5133 - val_loss: 317.8005 - val_accuracy: 0.5429\n",
      "Epoch 19/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 299.6722 - accuracy: 0.5126 - val_loss: 282.0028 - val_accuracy: 0.5377\n",
      "Epoch 20/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 265.6041 - accuracy: 0.5062 - val_loss: 249.6658 - val_accuracy: 0.5339\n",
      "Epoch 21/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 234.9782 - accuracy: 0.5119 - val_loss: 220.8217 - val_accuracy: 0.5323\n",
      "Epoch 22/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 207.8432 - accuracy: 0.5099 - val_loss: 195.3657 - val_accuracy: 0.5226\n",
      "Epoch 23/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 184.1252 - accuracy: 0.5087 - val_loss: 173.3694 - val_accuracy: 0.5166\n",
      "Epoch 24/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 164.1099 - accuracy: 0.5060 - val_loss: 155.4355 - val_accuracy: 0.5073\n",
      "Epoch 25/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 148.1164 - accuracy: 0.5039 - val_loss: 141.3608 - val_accuracy: 0.5003\n",
      "Epoch 26/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 135.8127 - accuracy: 0.5005 - val_loss: 130.9845 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 127.7345 - accuracy: 0.5003 - val_loss: 125.0397 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 123.0284 - accuracy: 0.5003 - val_loss: 121.0472 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 119.1199 - accuracy: 0.5003 - val_loss: 117.2249 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 115.3909 - accuracy: 0.5003 - val_loss: 113.5614 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 111.8252 - accuracy: 0.5003 - val_loss: 110.1247 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 108.4609 - accuracy: 0.5003 - val_loss: 106.8043 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 105.1667 - accuracy: 0.5003 - val_loss: 103.5196 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 101.8822 - accuracy: 0.5003 - val_loss: 100.2347 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 98.6585 - accuracy: 0.5003 - val_loss: 97.1246 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 95.6329 - accuracy: 0.5003 - val_loss: 94.1487 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 92.6805 - accuracy: 0.5003 - val_loss: 91.2173 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 89.7922 - accuracy: 0.5003 - val_loss: 88.3752 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 86.9716 - accuracy: 0.5003 - val_loss: 85.5597 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 84.1566 - accuracy: 0.5003 - val_loss: 82.7452 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 81.3417 - accuracy: 0.5003 - val_loss: 79.9301 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 78.5299 - accuracy: 0.5003 - val_loss: 77.1360 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 75.7658 - accuracy: 0.5003 - val_loss: 74.3880 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 73.0180 - accuracy: 0.5003 - val_loss: 71.6406 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 70.2706 - accuracy: 0.5003 - val_loss: 68.8928 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 67.5424 - accuracy: 0.5003 - val_loss: 66.1961 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 64.8673 - accuracy: 0.5003 - val_loss: 63.5510 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 62.2885 - accuracy: 0.5007 - val_loss: 61.0351 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 59.7989 - accuracy: 0.5002 - val_loss: 58.5553 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 57.3198 - accuracy: 0.4996 - val_loss: 56.0763 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 54.8439 - accuracy: 0.4999 - val_loss: 53.6228 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 52.4584 - accuracy: 0.5006 - val_loss: 51.3031 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 50.1941 - accuracy: 0.5003 - val_loss: 49.0843 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 47.9825 - accuracy: 0.5003 - val_loss: 46.8739 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 45.7997 - accuracy: 0.5003 - val_loss: 44.7245 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 43.6558 - accuracy: 0.5003 - val_loss: 42.5874 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 41.5513 - accuracy: 0.5003 - val_loss: 40.5096 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 39.4763 - accuracy: 0.5003 - val_loss: 38.4491 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 37.4485 - accuracy: 0.5003 - val_loss: 36.4535 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 35.4854 - accuracy: 0.5003 - val_loss: 34.5109 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 33.5423 - accuracy: 0.5003 - val_loss: 32.5683 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 31.6275 - accuracy: 0.5003 - val_loss: 30.6865 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 29.7513 - accuracy: 0.5003 - val_loss: 28.8106 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 27.9016 - accuracy: 0.5003 - val_loss: 27.0117 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 26.1644 - accuracy: 0.5003 - val_loss: 25.3575 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 24.6339 - accuracy: 0.5003 - val_loss: 23.9219 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 23.2206 - accuracy: 0.5003 - val_loss: 22.5151 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 21.8136 - accuracy: 0.5003 - val_loss: 21.1084 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 20.4099 - accuracy: 0.5003 - val_loss: 19.7225 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 19.0666 - accuracy: 0.5003 - val_loss: 18.4238 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 17.8090 - accuracy: 0.5003 - val_loss: 17.2024 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 16.6015 - accuracy: 0.5003 - val_loss: 15.9971 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 15.3955 - accuracy: 0.5003 - val_loss: 14.7910 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 14.1895 - accuracy: 0.5003 - val_loss: 13.5852 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 12.9962 - accuracy: 0.5003 - val_loss: 12.4196 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 11.8834 - accuracy: 0.5003 - val_loss: 11.3792 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 10.9143 - accuracy: 0.5003 - val_loss: 10.4613 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 10.0529 - accuracy: 0.5003 - val_loss: 9.6492 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 9.2485 - accuracy: 0.5003 - val_loss: 8.8451 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 8.4710 - accuracy: 0.5003 - val_loss: 8.1191 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 7.7910 - accuracy: 0.5003 - val_loss: 7.4768 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 7.2189 - accuracy: 0.5003 - val_loss: 6.9788 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 6.7446 - accuracy: 0.4976 - val_loss: 6.5092 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 6.2773 - accuracy: 0.5003 - val_loss: 6.0556 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.8552 - accuracy: 0.5003 - val_loss: 5.6542 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.4534 - accuracy: 0.5003 - val_loss: 5.2568 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.0892 - accuracy: 0.5003 - val_loss: 4.9212 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.7542 - accuracy: 0.5003 - val_loss: 4.5865 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.4193 - accuracy: 0.5001 - val_loss: 4.2509 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.1071 - accuracy: 0.5003 - val_loss: 3.9720 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.8381 - accuracy: 0.5003 - val_loss: 3.7040 - val_accuracy: 0.5001\n",
      "Epoch 92/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 3.5852 - accuracy: 0.5003 - val_loss: 3.4806 - val_accuracy: 0.5001\n",
      "Epoch 93/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.3807 - accuracy: 0.5003 - val_loss: 3.2795 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.1797 - accuracy: 0.5003 - val_loss: 3.0792 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.9787 - accuracy: 0.5003 - val_loss: 2.8774 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.7777 - accuracy: 0.5003 - val_loss: 2.6767 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.5767 - accuracy: 0.5003 - val_loss: 2.4760 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.3997 - accuracy: 0.5003 - val_loss: 2.3319 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.2649 - accuracy: 0.5003 - val_loss: 2.1975 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.1309 - accuracy: 0.5003 - val_loss: 2.0645 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.9969 - accuracy: 0.5003 - val_loss: 1.9297 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.8629 - accuracy: 0.5003 - val_loss: 1.7958 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.7290 - accuracy: 0.5003 - val_loss: 1.6620 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5950 - accuracy: 0.5003 - val_loss: 1.5285 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4610 - accuracy: 0.5003 - val_loss: 1.3938 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.3270 - accuracy: 0.5003 - val_loss: 1.2598 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1930 - accuracy: 0.5003 - val_loss: 1.1251 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0590 - accuracy: 0.5003 - val_loss: 0.9917 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9268 - accuracy: 0.5003 - val_loss: 0.8735 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.8400 - accuracy: 0.5003 - val_loss: 0.8064 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7730 - accuracy: 0.5003 - val_loss: 0.7390 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7166 - accuracy: 0.5003 - val_loss: 0.7109 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7101 - accuracy: 0.5003 - val_loss: 0.7106 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7101 - accuracy: 0.4982 - val_loss: 0.7099 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.7101 - accuracy: 0.5003Restoring model weights from the end of the best epoch: 114.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7101 - accuracy: 0.5003 - val_loss: 0.7102 - val_accuracy: 0.5001\n",
      "Epoch 115: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.7099 - accuracy: 0.5001\n",
      "{'loss': 0.7099257707595825, 'accuracy': 0.5001260638237} \n",
      " 114 \n",
      "\n",
      "Model time: 6.34656173363328 minutes\n",
      "\n",
      "Total time: 54.44487392529845 minutes\n",
      "\n",
      "\n",
      "Model  42  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                    16\n",
      "Activation function           tanh\n",
      "Dropout                        0.6\n",
      "L1                          0.0001\n",
      "L2                             1.0\n",
      "Batch size                     256\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 2048303, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 3s 14ms/step - loss: 27.2230 - accuracy: 0.5023 - val_loss: 14.2893 - val_accuracy: 0.5160\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 8.8256 - accuracy: 0.5155 - val_loss: 5.2069 - val_accuracy: 0.5737\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.6160 - accuracy: 0.5493 - val_loss: 2.3453 - val_accuracy: 0.5195\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.6404 - accuracy: 0.5188 - val_loss: 1.1216 - val_accuracy: 0.5006\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.9002 - accuracy: 0.5025 - val_loss: 0.7623 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.7241 - accuracy: 0.4999 - val_loss: 0.7025 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6966 - accuracy: 0.4973 - val_loss: 0.6941 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6941 - accuracy: 0.4920 - val_loss: 0.6941 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 0.6941 - accuracy: 0.4967Restoring model weights from the end of the best epoch: 8.\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6941 - accuracy: 0.4968 - val_loss: 0.6941 - val_accuracy: 0.5001\n",
      "Epoch 9: early stopping\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5001\n",
      "{'loss': 0.6940776705741882, 'accuracy': 0.5001260638237} \n",
      " 8 \n",
      "\n",
      "Model time: 0.15006771683692932 minutes\n",
      "\n",
      "Total time: 54.59505832567811 minutes\n",
      "\n",
      "\n",
      "Model  43  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                    16\n",
      "Activation function           relu\n",
      "Dropout                        0.0\n",
      "L1                           100.0\n",
      "L2                            10.0\n",
      "Batch size                     256\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 661530, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 3151.0420 - accuracy: 0.5060 - val_loss: 377.2729 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 364.3386 - accuracy: 0.4962 - val_loss: 366.0064 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 360.1059 - accuracy: 0.5022 - val_loss: 365.9015 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 358.4741 - accuracy: 0.5011 - val_loss: 356.8951 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 355.2032 - accuracy: 0.5021 - val_loss: 348.0334 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "74/84 [=========================>....] - ETA: 0s - loss: 354.4514 - accuracy: 0.4993Restoring model weights from the end of the best epoch: 5.\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 354.2759 - accuracy: 0.4998 - val_loss: 352.7712 - val_accuracy: 0.5001\n",
      "Epoch 6: early stopping\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 348.0334 - accuracy: 0.4999\n",
      "{'loss': 348.0334167480469, 'accuracy': 0.49987393617630005} \n",
      " 5 \n",
      "\n",
      "Model time: 0.09316733106970787 minutes\n",
      "\n",
      "Total time: 54.68835898116231 minutes\n",
      "\n",
      "\n",
      "Model  44  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                   128\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.8\n",
      "L1                            0.01\n",
      "L2                           100.0\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 5437663, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 7s 14ms/step - loss: 5369.2891 - accuracy: 0.5015 - val_loss: 2.8453 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 5s 14ms/step - loss: 2.8414 - accuracy: 0.4999 - val_loss: 2.8448 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "334/335 [============================>.] - ETA: 0s - loss: 2.8414 - accuracy: 0.4980Restoring model weights from the end of the best epoch: 2.\n",
      "335/335 [==============================] - 4s 12ms/step - loss: 2.8414 - accuracy: 0.4981 - val_loss: 2.8454 - val_accuracy: 0.5001\n",
      "Epoch 3: early stopping\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 2.8448 - accuracy: 0.4999\n",
      "{'loss': 2.8447513580322266, 'accuracy': 0.49987393617630005} \n",
      " 2 \n",
      "\n",
      "Model time: 0.2977021038532257 minutes\n",
      "\n",
      "Total time: 54.9861444234848 minutes\n",
      "\n",
      "\n",
      "Model  45  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     2\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.7\n",
      "L1                           0.001\n",
      "L2                             1.0\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 1701807, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 8s 5ms/step - loss: 1.4431 - accuracy: 0.5053 - val_loss: 0.6938 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6936 - accuracy: 0.4973 - val_loss: 0.6936 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6936 - accuracy: 0.4987 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 0.6936 - accuracy: 0.4993 - val_loss: 0.6934 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "1321/1339 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5022Restoring model weights from the end of the best epoch: 4.\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6935 - accuracy: 0.5019 - val_loss: 0.6936 - val_accuracy: 0.4999\n",
      "Epoch 5: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 0.6934 - accuracy: 0.4999\n",
      "{'loss': 0.6934313178062439, 'accuracy': 0.49987393617630005} \n",
      " 4 \n",
      "\n",
      "Model time: 0.6121043190360069 minutes\n",
      "\n",
      "Total time: 55.59836543723941 minutes\n",
      "\n",
      "\n",
      "Model  46  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     2\n",
      "Activation function         linear\n",
      "Dropout                        0.1\n",
      "L1                           0.001\n",
      "L2                           0.001\n",
      "Batch size                     256\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 4439130, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 3s 15ms/step - loss: 0.7207 - accuracy: 0.5618 - val_loss: 0.6880 - val_accuracy: 0.6231\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.6866 - accuracy: 0.6053 - val_loss: 0.6758 - val_accuracy: 0.6332\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.6808 - accuracy: 0.6139 - val_loss: 0.6716 - val_accuracy: 0.6389\n",
      "Epoch 4/300\n",
      "79/84 [===========================>..] - ETA: 0s - loss: 0.6804 - accuracy: 0.6102Restoring model weights from the end of the best epoch: 3.\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6802 - accuracy: 0.6127 - val_loss: 0.6726 - val_accuracy: 0.6400\n",
      "Epoch 4: early stopping\n",
      "78/78 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.6389\n",
      "{'loss': 0.6716330051422119, 'accuracy': 0.6388846635818481} \n",
      " 3 \n",
      "\n",
      "Model time: 0.1280270591378212 minutes\n",
      "\n",
      "Total time: 55.7265092022717 minutes\n",
      "\n",
      "\n",
      "Model  47  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                    16\n",
      "Activation function           relu\n",
      "Dropout                        0.6\n",
      "L1                             0.0\n",
      "L2                          0.0001\n",
      "Batch size                      16\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 4883672, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 9s 6ms/step - loss: 1.0156 - accuracy: 0.4973 - val_loss: 0.7078 - val_accuracy: 0.5047\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.9344 - accuracy: 0.5071 - val_loss: 0.7046 - val_accuracy: 0.5071\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.9178 - accuracy: 0.5060 - val_loss: 0.7024 - val_accuracy: 0.5109\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8900 - accuracy: 0.4976 - val_loss: 0.7013 - val_accuracy: 0.5139\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8658 - accuracy: 0.5031 - val_loss: 0.7007 - val_accuracy: 0.5169\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8510 - accuracy: 0.5063 - val_loss: 0.7004 - val_accuracy: 0.5161\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8293 - accuracy: 0.5094 - val_loss: 0.7004 - val_accuracy: 0.5128\n",
      "Epoch 8/300\n",
      "1331/1339 [============================>.] - ETA: 0s - loss: 0.8103 - accuracy: 0.5049Restoring model weights from the end of the best epoch: 7.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8099 - accuracy: 0.5052 - val_loss: 0.7004 - val_accuracy: 0.5086\n",
      "Epoch 8: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 0.7004 - accuracy: 0.5128\n",
      "{'loss': 0.7003782391548157, 'accuracy': 0.5127817392349243} \n",
      " 7 \n",
      "\n",
      "Model time: 0.9958737380802631 minutes\n",
      "\n",
      "Total time: 56.72263293340802 minutes\n",
      "\n",
      "\n",
      "Model  48  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     8\n",
      "Activation function         linear\n",
      "Dropout                        0.7\n",
      "L1                           100.0\n",
      "L2                         0.00001\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 572383, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 8ms/step - loss: 2420.7637 - accuracy: 0.5019 - val_loss: 257.7800 - val_accuracy: 0.5002\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 150.1865 - accuracy: 0.4957 - val_loss: 74.9609 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 70.3529 - accuracy: 0.4956 - val_loss: 68.9040 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "328/335 [============================>.] - ETA: 0s - loss: 70.3725 - accuracy: 0.4984Restoring model weights from the end of the best epoch: 3.\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 70.3714 - accuracy: 0.4986 - val_loss: 72.0402 - val_accuracy: 0.5001\n",
      "Epoch 4: early stopping\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 68.9040 - accuracy: 0.4999\n",
      "{'loss': 68.9040298461914, 'accuracy': 0.49987393617630005} \n",
      " 3 \n",
      "\n",
      "Model time: 0.16465117037296295 minutes\n",
      "\n",
      "Total time: 56.88735077902675 minutes\n",
      "\n",
      "\n",
      "Model  49  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                   256\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.1\n",
      "L1                             0.1\n",
      "L2                           100.0\n",
      "Batch size                      16\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 1366475, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 10s 7ms/step - loss: 548.2032 - accuracy: 0.5001 - val_loss: 0.8357 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "1329/1339 [============================>.] - ETA: 0s - loss: 0.8723 - accuracy: 0.4990Restoring model weights from the end of the best epoch: 1.\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.8726 - accuracy: 0.4992 - val_loss: 0.9074 - val_accuracy: 0.4999\n",
      "Epoch 2: early stopping\n",
      "1240/1240 [==============================] - 4s 3ms/step - loss: 0.8357 - accuracy: 0.5001\n",
      "{'loss': 0.8357276320457458, 'accuracy': 0.5001260638237} \n",
      " 1 \n",
      "\n",
      "Model time: 0.36833594366908073 minutes\n",
      "\n",
      "Total time: 57.25575338304043 minutes\n",
      "\n",
      "\n",
      "Model  50  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                   128\n",
      "Activation function           tanh\n",
      "Dropout                        0.8\n",
      "L1                          0.0001\n",
      "L2                         0.00001\n",
      "Batch size                       8\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 1123157, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 15s 5ms/step - loss: 1.0084 - accuracy: 0.5434 - val_loss: 0.7456 - val_accuracy: 0.6137\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.8494 - accuracy: 0.5707 - val_loss: 0.7336 - val_accuracy: 0.6198\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7824 - accuracy: 0.5864 - val_loss: 0.7168 - val_accuracy: 0.6290\n",
      "Epoch 4/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7504 - accuracy: 0.5978 - val_loss: 0.7134 - val_accuracy: 0.6283\n",
      "Epoch 5/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7280 - accuracy: 0.6068 - val_loss: 0.7080 - val_accuracy: 0.6292\n",
      "Epoch 6/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7176 - accuracy: 0.6125 - val_loss: 0.7048 - val_accuracy: 0.6249\n",
      "Epoch 7/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7095 - accuracy: 0.6181 - val_loss: 0.7006 - val_accuracy: 0.6215\n",
      "Epoch 8/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7028 - accuracy: 0.6186 - val_loss: 0.6965 - val_accuracy: 0.6247\n",
      "Epoch 9/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6986 - accuracy: 0.6233 - val_loss: 0.6921 - val_accuracy: 0.6294\n",
      "Epoch 10/300\n",
      "2662/2677 [============================>.] - ETA: 0s - loss: 0.6948 - accuracy: 0.6245Restoring model weights from the end of the best epoch: 9.\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6950 - accuracy: 0.6244 - val_loss: 0.6934 - val_accuracy: 0.6178\n",
      "Epoch 10: early stopping\n",
      "2480/2480 [==============================] - 7s 3ms/step - loss: 0.6921 - accuracy: 0.6294\n",
      "{'loss': 0.6921168565750122, 'accuracy': 0.6293551325798035} \n",
      " 9 \n",
      "\n",
      "Model time: 2.347384139895439 minutes\n",
      "\n",
      "Total time: 59.60323751345277 minutes\n",
      "\n",
      "\n",
      "Model  51  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     4\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.9\n",
      "L1                             1.0\n",
      "L2                            0.01\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 1863916, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 6s 7ms/step - loss: 77.3724 - accuracy: 0.4990 - val_loss: 75.8253 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 74.9620 - accuracy: 0.5059 - val_loss: 73.4844 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 72.6901 - accuracy: 0.4991 - val_loss: 71.1910 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 70.4055 - accuracy: 0.4997 - val_loss: 68.9373 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 68.2239 - accuracy: 0.4940 - val_loss: 66.7379 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 65.9909 - accuracy: 0.4977 - val_loss: 64.5885 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 63.8735 - accuracy: 0.5032 - val_loss: 62.4762 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 61.7912 - accuracy: 0.4966 - val_loss: 60.3917 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 59.6780 - accuracy: 0.5014 - val_loss: 58.3434 - val_accuracy: 0.4999\n",
      "Epoch 10/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 57.6860 - accuracy: 0.4981 - val_loss: 56.3323 - val_accuracy: 0.4999\n",
      "Epoch 11/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 55.6718 - accuracy: 0.4992 - val_loss: 54.3525 - val_accuracy: 0.4999\n",
      "Epoch 12/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 53.7487 - accuracy: 0.4937 - val_loss: 52.3919 - val_accuracy: 0.4999\n",
      "Epoch 13/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 51.7696 - accuracy: 0.4986 - val_loss: 50.4706 - val_accuracy: 0.4999\n",
      "Epoch 14/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 49.8845 - accuracy: 0.4966 - val_loss: 48.5786 - val_accuracy: 0.4999\n",
      "Epoch 15/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 47.9938 - accuracy: 0.4999 - val_loss: 46.7315 - val_accuracy: 0.4999\n",
      "Epoch 16/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 46.1741 - accuracy: 0.4998 - val_loss: 44.9370 - val_accuracy: 0.4999\n",
      "Epoch 17/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 44.4033 - accuracy: 0.5016 - val_loss: 43.2030 - val_accuracy: 0.4999\n",
      "Epoch 18/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 42.7110 - accuracy: 0.4994 - val_loss: 41.5157 - val_accuracy: 0.4999\n",
      "Epoch 19/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 41.0481 - accuracy: 0.4985 - val_loss: 39.8716 - val_accuracy: 0.4999\n",
      "Epoch 20/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 39.4037 - accuracy: 0.5003 - val_loss: 38.2501 - val_accuracy: 0.4999\n",
      "Epoch 21/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 37.7901 - accuracy: 0.5060 - val_loss: 36.6507 - val_accuracy: 0.4999\n",
      "Epoch 22/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 36.2074 - accuracy: 0.5037 - val_loss: 35.0898 - val_accuracy: 0.4999\n",
      "Epoch 23/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 34.6667 - accuracy: 0.5004 - val_loss: 33.5621 - val_accuracy: 0.4999\n",
      "Epoch 24/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 33.1720 - accuracy: 0.4954 - val_loss: 32.0716 - val_accuracy: 0.4999\n",
      "Epoch 25/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 31.7029 - accuracy: 0.4966 - val_loss: 30.6306 - val_accuracy: 0.4999\n",
      "Epoch 26/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 30.2501 - accuracy: 0.5076 - val_loss: 29.2302 - val_accuracy: 0.4999\n",
      "Epoch 27/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 28.8977 - accuracy: 0.4953 - val_loss: 27.8669 - val_accuracy: 0.4999\n",
      "Epoch 28/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 27.5330 - accuracy: 0.4992 - val_loss: 26.5327 - val_accuracy: 0.4999\n",
      "Epoch 29/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 26.2361 - accuracy: 0.4983 - val_loss: 25.2420 - val_accuracy: 0.4999\n",
      "Epoch 30/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.9566 - accuracy: 0.5021 - val_loss: 23.9885 - val_accuracy: 0.4999\n",
      "Epoch 31/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 23.7055 - accuracy: 0.4991 - val_loss: 22.7781 - val_accuracy: 0.4999\n",
      "Epoch 32/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 22.5460 - accuracy: 0.4949 - val_loss: 21.6102 - val_accuracy: 0.4999\n",
      "Epoch 33/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 21.4048 - accuracy: 0.4974 - val_loss: 20.4833 - val_accuracy: 0.4999\n",
      "Epoch 34/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 20.2824 - accuracy: 0.5017 - val_loss: 19.4124 - val_accuracy: 0.4999\n",
      "Epoch 35/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.2302 - accuracy: 0.5011 - val_loss: 18.3966 - val_accuracy: 0.4999\n",
      "Epoch 36/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.2688 - accuracy: 0.4990 - val_loss: 17.4512 - val_accuracy: 0.4999\n",
      "Epoch 37/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.3517 - accuracy: 0.5025 - val_loss: 16.5653 - val_accuracy: 0.4999\n",
      "Epoch 38/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.4588 - accuracy: 0.5016 - val_loss: 15.7198 - val_accuracy: 0.4999\n",
      "Epoch 39/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.6529 - accuracy: 0.5018 - val_loss: 14.9190 - val_accuracy: 0.4999\n",
      "Epoch 40/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.8743 - accuracy: 0.4996 - val_loss: 14.1755 - val_accuracy: 0.4999\n",
      "Epoch 41/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.1713 - accuracy: 0.5014 - val_loss: 13.4939 - val_accuracy: 0.4999\n",
      "Epoch 42/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 13.4985 - accuracy: 0.5010 - val_loss: 12.8624 - val_accuracy: 0.4999\n",
      "Epoch 43/300\n",
      "335/335 [==============================] - 2s 4ms/step - loss: 12.9190 - accuracy: 0.5034 - val_loss: 12.2878 - val_accuracy: 0.4999\n",
      "Epoch 44/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12.3556 - accuracy: 0.4997 - val_loss: 11.7626 - val_accuracy: 0.4999\n",
      "Epoch 45/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.8802 - accuracy: 0.4936 - val_loss: 11.2915 - val_accuracy: 0.4999\n",
      "Epoch 46/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.4172 - accuracy: 0.5014 - val_loss: 10.8598 - val_accuracy: 0.4999\n",
      "Epoch 47/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.0145 - accuracy: 0.4966 - val_loss: 10.4714 - val_accuracy: 0.4999\n",
      "Epoch 48/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.6397 - accuracy: 0.4996 - val_loss: 10.1279 - val_accuracy: 0.4999\n",
      "Epoch 49/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.3222 - accuracy: 0.4984 - val_loss: 9.8229 - val_accuracy: 0.4999\n",
      "Epoch 50/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.0266 - accuracy: 0.4975 - val_loss: 9.5489 - val_accuracy: 0.4999\n",
      "Epoch 51/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.7555 - accuracy: 0.5061 - val_loss: 9.3092 - val_accuracy: 0.4999\n",
      "Epoch 52/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.5466 - accuracy: 0.4941 - val_loss: 9.0986 - val_accuracy: 0.4999\n",
      "Epoch 53/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.3448 - accuracy: 0.4995 - val_loss: 8.9266 - val_accuracy: 0.4999\n",
      "Epoch 54/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.2019 - accuracy: 0.4973 - val_loss: 8.7957 - val_accuracy: 0.4999\n",
      "Epoch 55/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.1079 - accuracy: 0.5009 - val_loss: 8.7035 - val_accuracy: 0.4999\n",
      "Epoch 56/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.9969 - accuracy: 0.4999 - val_loss: 8.6300 - val_accuracy: 0.4999\n",
      "Epoch 57/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.9230 - accuracy: 0.5011 - val_loss: 8.5566 - val_accuracy: 0.4999\n",
      "Epoch 58/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 8.8507 - accuracy: 0.4979 - val_loss: 8.4833 - val_accuracy: 0.4999\n",
      "Epoch 59/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.7778 - accuracy: 0.4986 - val_loss: 8.4098 - val_accuracy: 0.4999\n",
      "Epoch 60/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.6989 - accuracy: 0.5002 - val_loss: 8.3365 - val_accuracy: 0.4999\n",
      "Epoch 61/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.6211 - accuracy: 0.4977 - val_loss: 8.2633 - val_accuracy: 0.4999\n",
      "Epoch 62/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.5638 - accuracy: 0.4964 - val_loss: 8.1901 - val_accuracy: 0.4999\n",
      "Epoch 63/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.4735 - accuracy: 0.5013 - val_loss: 8.1169 - val_accuracy: 0.4999\n",
      "Epoch 64/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.4018 - accuracy: 0.5011 - val_loss: 8.0438 - val_accuracy: 0.4999\n",
      "Epoch 65/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.3268 - accuracy: 0.4974 - val_loss: 7.9711 - val_accuracy: 0.4999\n",
      "Epoch 66/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.2537 - accuracy: 0.5010 - val_loss: 7.9013 - val_accuracy: 0.4999\n",
      "Epoch 67/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.1931 - accuracy: 0.4924 - val_loss: 7.8346 - val_accuracy: 0.4999\n",
      "Epoch 68/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.1223 - accuracy: 0.4978 - val_loss: 7.7682 - val_accuracy: 0.4999\n",
      "Epoch 69/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.0359 - accuracy: 0.4993 - val_loss: 7.7020 - val_accuracy: 0.4999\n",
      "Epoch 70/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.9808 - accuracy: 0.4999 - val_loss: 7.6389 - val_accuracy: 0.4999\n",
      "Epoch 71/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.9102 - accuracy: 0.4985 - val_loss: 7.5759 - val_accuracy: 0.4999\n",
      "Epoch 72/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.8519 - accuracy: 0.4959 - val_loss: 7.5129 - val_accuracy: 0.4999\n",
      "Epoch 73/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.7944 - accuracy: 0.4977 - val_loss: 7.4498 - val_accuracy: 0.4999\n",
      "Epoch 74/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 7.6955 - accuracy: 0.5034 - val_loss: 7.3870 - val_accuracy: 0.4999\n",
      "Epoch 75/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.6574 - accuracy: 0.4991 - val_loss: 7.3242 - val_accuracy: 0.4999\n",
      "Epoch 76/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.6056 - accuracy: 0.4999 - val_loss: 7.2614 - val_accuracy: 0.4999\n",
      "Epoch 77/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.5323 - accuracy: 0.5045 - val_loss: 7.1986 - val_accuracy: 0.4999\n",
      "Epoch 78/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.4657 - accuracy: 0.4997 - val_loss: 7.1358 - val_accuracy: 0.4999\n",
      "Epoch 79/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.4054 - accuracy: 0.4975 - val_loss: 7.0734 - val_accuracy: 0.4999\n",
      "Epoch 80/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.3447 - accuracy: 0.5022 - val_loss: 7.0106 - val_accuracy: 0.4999\n",
      "Epoch 81/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 7.2699 - accuracy: 0.4996 - val_loss: 6.9481 - val_accuracy: 0.4999\n",
      "Epoch 82/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.2025 - accuracy: 0.5042 - val_loss: 6.8857 - val_accuracy: 0.4999\n",
      "Epoch 83/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.1284 - accuracy: 0.5017 - val_loss: 6.8232 - val_accuracy: 0.4999\n",
      "Epoch 84/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 7.0915 - accuracy: 0.4999 - val_loss: 6.7607 - val_accuracy: 0.4999\n",
      "Epoch 85/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.0042 - accuracy: 0.5078 - val_loss: 6.7006 - val_accuracy: 0.4999\n",
      "Epoch 86/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.9400 - accuracy: 0.5041 - val_loss: 6.6413 - val_accuracy: 0.4999\n",
      "Epoch 87/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6.8878 - accuracy: 0.4984 - val_loss: 6.5837 - val_accuracy: 0.4999\n",
      "Epoch 88/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.8249 - accuracy: 0.5023 - val_loss: 6.5278 - val_accuracy: 0.4999\n",
      "Epoch 89/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.7792 - accuracy: 0.5034 - val_loss: 6.4721 - val_accuracy: 0.4999\n",
      "Epoch 90/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.7013 - accuracy: 0.5053 - val_loss: 6.4163 - val_accuracy: 0.4999\n",
      "Epoch 91/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.6662 - accuracy: 0.4997 - val_loss: 6.3607 - val_accuracy: 0.4999\n",
      "Epoch 92/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.6083 - accuracy: 0.4953 - val_loss: 6.3049 - val_accuracy: 0.4999\n",
      "Epoch 93/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.5341 - accuracy: 0.5031 - val_loss: 6.2495 - val_accuracy: 0.4999\n",
      "Epoch 94/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.4811 - accuracy: 0.4997 - val_loss: 6.1939 - val_accuracy: 0.4999\n",
      "Epoch 95/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.4309 - accuracy: 0.5010 - val_loss: 6.1386 - val_accuracy: 0.4999\n",
      "Epoch 96/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.3810 - accuracy: 0.5037 - val_loss: 6.0829 - val_accuracy: 0.4999\n",
      "Epoch 97/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.3058 - accuracy: 0.5012 - val_loss: 6.0278 - val_accuracy: 0.4999\n",
      "Epoch 98/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6.2749 - accuracy: 0.4948 - val_loss: 5.9722 - val_accuracy: 0.4999\n",
      "Epoch 99/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.1865 - accuracy: 0.5024 - val_loss: 5.9171 - val_accuracy: 0.4999\n",
      "Epoch 100/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.1407 - accuracy: 0.4997 - val_loss: 5.8617 - val_accuracy: 0.4999\n",
      "Epoch 101/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.0890 - accuracy: 0.4987 - val_loss: 5.8068 - val_accuracy: 0.4999\n",
      "Epoch 102/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.0150 - accuracy: 0.5014 - val_loss: 5.7514 - val_accuracy: 0.4999\n",
      "Epoch 103/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.9754 - accuracy: 0.4984 - val_loss: 5.6964 - val_accuracy: 0.4999\n",
      "Epoch 104/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.8980 - accuracy: 0.4990 - val_loss: 5.6414 - val_accuracy: 0.4999\n",
      "Epoch 105/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.8382 - accuracy: 0.5053 - val_loss: 5.5864 - val_accuracy: 0.4999\n",
      "Epoch 106/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.7907 - accuracy: 0.5017 - val_loss: 5.5314 - val_accuracy: 0.4999\n",
      "Epoch 107/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.7266 - accuracy: 0.5014 - val_loss: 5.4766 - val_accuracy: 0.4999\n",
      "Epoch 108/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.6747 - accuracy: 0.5055 - val_loss: 5.4215 - val_accuracy: 0.4999\n",
      "Epoch 109/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.6130 - accuracy: 0.5008 - val_loss: 5.3672 - val_accuracy: 0.4999\n",
      "Epoch 110/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.5596 - accuracy: 0.5004 - val_loss: 5.3156 - val_accuracy: 0.4999\n",
      "Epoch 111/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.4951 - accuracy: 0.5037 - val_loss: 5.2644 - val_accuracy: 0.4999\n",
      "Epoch 112/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.4541 - accuracy: 0.5037 - val_loss: 5.2128 - val_accuracy: 0.4999\n",
      "Epoch 113/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.4146 - accuracy: 0.4964 - val_loss: 5.1618 - val_accuracy: 0.4999\n",
      "Epoch 114/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.3419 - accuracy: 0.5014 - val_loss: 5.1139 - val_accuracy: 0.4999\n",
      "Epoch 115/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.3076 - accuracy: 0.4991 - val_loss: 5.0658 - val_accuracy: 0.4999\n",
      "Epoch 116/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.2581 - accuracy: 0.4952 - val_loss: 5.0181 - val_accuracy: 0.4999\n",
      "Epoch 117/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.1995 - accuracy: 0.4982 - val_loss: 4.9701 - val_accuracy: 0.4999\n",
      "Epoch 118/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.1584 - accuracy: 0.4985 - val_loss: 4.9225 - val_accuracy: 0.4999\n",
      "Epoch 119/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.1072 - accuracy: 0.4985 - val_loss: 4.8745 - val_accuracy: 0.4999\n",
      "Epoch 120/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.0373 - accuracy: 0.5033 - val_loss: 4.8269 - val_accuracy: 0.4999\n",
      "Epoch 121/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.9895 - accuracy: 0.5037 - val_loss: 4.7792 - val_accuracy: 0.4999\n",
      "Epoch 122/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.9483 - accuracy: 0.5003 - val_loss: 4.7315 - val_accuracy: 0.4999\n",
      "Epoch 123/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.8977 - accuracy: 0.4999 - val_loss: 4.6838 - val_accuracy: 0.4999\n",
      "Epoch 124/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.8569 - accuracy: 0.4983 - val_loss: 4.6362 - val_accuracy: 0.4999\n",
      "Epoch 125/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.7972 - accuracy: 0.5016 - val_loss: 4.5884 - val_accuracy: 0.4999\n",
      "Epoch 126/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.7495 - accuracy: 0.5007 - val_loss: 4.5410 - val_accuracy: 0.4999\n",
      "Epoch 127/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.6863 - accuracy: 0.5018 - val_loss: 4.4934 - val_accuracy: 0.4999\n",
      "Epoch 128/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.6612 - accuracy: 0.4912 - val_loss: 4.4459 - val_accuracy: 0.4999\n",
      "Epoch 129/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.6051 - accuracy: 0.4996 - val_loss: 4.3983 - val_accuracy: 0.4999\n",
      "Epoch 130/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.5634 - accuracy: 0.4932 - val_loss: 4.3508 - val_accuracy: 0.4999\n",
      "Epoch 131/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.5069 - accuracy: 0.4996 - val_loss: 4.3033 - val_accuracy: 0.4999\n",
      "Epoch 132/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.4475 - accuracy: 0.5039 - val_loss: 4.2559 - val_accuracy: 0.4999\n",
      "Epoch 133/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.3973 - accuracy: 0.4991 - val_loss: 4.2088 - val_accuracy: 0.4999\n",
      "Epoch 134/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.3607 - accuracy: 0.4959 - val_loss: 4.1648 - val_accuracy: 0.4999\n",
      "Epoch 135/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.3163 - accuracy: 0.4974 - val_loss: 4.1207 - val_accuracy: 0.4999\n",
      "Epoch 136/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.2455 - accuracy: 0.5067 - val_loss: 4.0767 - val_accuracy: 0.4999\n",
      "Epoch 137/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.2144 - accuracy: 0.4986 - val_loss: 4.0330 - val_accuracy: 0.4999\n",
      "Epoch 138/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.1641 - accuracy: 0.4992 - val_loss: 3.9924 - val_accuracy: 0.4999\n",
      "Epoch 139/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.1263 - accuracy: 0.4983 - val_loss: 3.9518 - val_accuracy: 0.4999\n",
      "Epoch 140/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.0756 - accuracy: 0.5038 - val_loss: 3.9112 - val_accuracy: 0.4999\n",
      "Epoch 141/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.0375 - accuracy: 0.4990 - val_loss: 3.8706 - val_accuracy: 0.4999\n",
      "Epoch 142/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.9945 - accuracy: 0.5001 - val_loss: 3.8301 - val_accuracy: 0.4999\n",
      "Epoch 143/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.9503 - accuracy: 0.5008 - val_loss: 3.7894 - val_accuracy: 0.4999\n",
      "Epoch 144/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.9059 - accuracy: 0.5039 - val_loss: 3.7490 - val_accuracy: 0.4999\n",
      "Epoch 145/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.8685 - accuracy: 0.4977 - val_loss: 3.7084 - val_accuracy: 0.4999\n",
      "Epoch 146/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.8276 - accuracy: 0.4980 - val_loss: 3.6680 - val_accuracy: 0.4999\n",
      "Epoch 147/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.7806 - accuracy: 0.4982 - val_loss: 3.6273 - val_accuracy: 0.4999\n",
      "Epoch 148/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.7411 - accuracy: 0.4938 - val_loss: 3.5871 - val_accuracy: 0.4999\n",
      "Epoch 149/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.6982 - accuracy: 0.4964 - val_loss: 3.5463 - val_accuracy: 0.4999\n",
      "Epoch 150/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.6515 - accuracy: 0.5037 - val_loss: 3.5062 - val_accuracy: 0.4999\n",
      "Epoch 151/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.6084 - accuracy: 0.5008 - val_loss: 3.4655 - val_accuracy: 0.4999\n",
      "Epoch 152/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.5593 - accuracy: 0.5057 - val_loss: 3.4252 - val_accuracy: 0.4999\n",
      "Epoch 153/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.5271 - accuracy: 0.4967 - val_loss: 3.3846 - val_accuracy: 0.4999\n",
      "Epoch 154/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.4753 - accuracy: 0.5010 - val_loss: 3.3444 - val_accuracy: 0.4999\n",
      "Epoch 155/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.4436 - accuracy: 0.5022 - val_loss: 3.3038 - val_accuracy: 0.4999\n",
      "Epoch 156/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.3964 - accuracy: 0.5031 - val_loss: 3.2636 - val_accuracy: 0.4999\n",
      "Epoch 157/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.3556 - accuracy: 0.5039 - val_loss: 3.2230 - val_accuracy: 0.4999\n",
      "Epoch 158/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.3118 - accuracy: 0.5055 - val_loss: 3.1838 - val_accuracy: 0.4999\n",
      "Epoch 159/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3.2676 - accuracy: 0.5002 - val_loss: 3.1467 - val_accuracy: 0.4999\n",
      "Epoch 160/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.2276 - accuracy: 0.5060 - val_loss: 3.1098 - val_accuracy: 0.4999\n",
      "Epoch 161/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.1978 - accuracy: 0.4954 - val_loss: 3.0727 - val_accuracy: 0.4999\n",
      "Epoch 162/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.1566 - accuracy: 0.5034 - val_loss: 3.0359 - val_accuracy: 0.4999\n",
      "Epoch 163/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.1129 - accuracy: 0.5010 - val_loss: 2.9987 - val_accuracy: 0.4999\n",
      "Epoch 164/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3.0759 - accuracy: 0.5026 - val_loss: 2.9619 - val_accuracy: 0.4999\n",
      "Epoch 165/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.0401 - accuracy: 0.5002 - val_loss: 2.9249 - val_accuracy: 0.4999\n",
      "Epoch 166/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.0010 - accuracy: 0.5047 - val_loss: 2.8880 - val_accuracy: 0.4999\n",
      "Epoch 167/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.9595 - accuracy: 0.5018 - val_loss: 2.8510 - val_accuracy: 0.4999\n",
      "Epoch 168/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.9226 - accuracy: 0.4975 - val_loss: 2.8141 - val_accuracy: 0.4999\n",
      "Epoch 169/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.8814 - accuracy: 0.4997 - val_loss: 2.7771 - val_accuracy: 0.4999\n",
      "Epoch 170/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.8445 - accuracy: 0.5022 - val_loss: 2.7403 - val_accuracy: 0.5001\n",
      "Epoch 171/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2.8073 - accuracy: 0.4981 - val_loss: 2.7033 - val_accuracy: 0.5001\n",
      "Epoch 172/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.7642 - accuracy: 0.5047 - val_loss: 2.6664 - val_accuracy: 0.5001\n",
      "Epoch 173/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.7230 - accuracy: 0.5036 - val_loss: 2.6295 - val_accuracy: 0.5001\n",
      "Epoch 174/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.6878 - accuracy: 0.5033 - val_loss: 2.5926 - val_accuracy: 0.5001\n",
      "Epoch 175/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.6496 - accuracy: 0.4988 - val_loss: 2.5557 - val_accuracy: 0.5001\n",
      "Epoch 176/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.6126 - accuracy: 0.5009 - val_loss: 2.5189 - val_accuracy: 0.5001\n",
      "Epoch 177/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.5787 - accuracy: 0.4968 - val_loss: 2.4820 - val_accuracy: 0.5001\n",
      "Epoch 178/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.5319 - accuracy: 0.5031 - val_loss: 2.4451 - val_accuracy: 0.5001\n",
      "Epoch 179/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2.4980 - accuracy: 0.4992 - val_loss: 2.4082 - val_accuracy: 0.5001\n",
      "Epoch 180/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.4619 - accuracy: 0.4980 - val_loss: 2.3732 - val_accuracy: 0.5001\n",
      "Epoch 181/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.4258 - accuracy: 0.4993 - val_loss: 2.3424 - val_accuracy: 0.5001\n",
      "Epoch 182/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.3947 - accuracy: 0.4972 - val_loss: 2.3123 - val_accuracy: 0.5001\n",
      "Epoch 183/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.3637 - accuracy: 0.4969 - val_loss: 2.2821 - val_accuracy: 0.5001\n",
      "Epoch 184/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.3307 - accuracy: 0.4976 - val_loss: 2.2519 - val_accuracy: 0.5001\n",
      "Epoch 185/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.3023 - accuracy: 0.4968 - val_loss: 2.2217 - val_accuracy: 0.5001\n",
      "Epoch 186/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.2638 - accuracy: 0.5023 - val_loss: 2.1916 - val_accuracy: 0.5001\n",
      "Epoch 187/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.2306 - accuracy: 0.5046 - val_loss: 2.1615 - val_accuracy: 0.5001\n",
      "Epoch 188/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.2036 - accuracy: 0.4988 - val_loss: 2.1314 - val_accuracy: 0.5001\n",
      "Epoch 189/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.1722 - accuracy: 0.5014 - val_loss: 2.1012 - val_accuracy: 0.5001\n",
      "Epoch 190/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2.1396 - accuracy: 0.4997 - val_loss: 2.0711 - val_accuracy: 0.5001\n",
      "Epoch 191/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.1079 - accuracy: 0.4997 - val_loss: 2.0409 - val_accuracy: 0.5001\n",
      "Epoch 192/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.0752 - accuracy: 0.5012 - val_loss: 2.0108 - val_accuracy: 0.5001\n",
      "Epoch 193/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.0404 - accuracy: 0.5041 - val_loss: 1.9807 - val_accuracy: 0.5001\n",
      "Epoch 194/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.0130 - accuracy: 0.5018 - val_loss: 1.9506 - val_accuracy: 0.5001\n",
      "Epoch 195/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.9825 - accuracy: 0.5001 - val_loss: 1.9204 - val_accuracy: 0.5001\n",
      "Epoch 196/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.9481 - accuracy: 0.5013 - val_loss: 1.8903 - val_accuracy: 0.5001\n",
      "Epoch 197/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.9179 - accuracy: 0.5004 - val_loss: 1.8602 - val_accuracy: 0.5001\n",
      "Epoch 198/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.8925 - accuracy: 0.4957 - val_loss: 1.8310 - val_accuracy: 0.5001\n",
      "Epoch 199/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.8625 - accuracy: 0.4956 - val_loss: 1.8042 - val_accuracy: 0.5001\n",
      "Epoch 200/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.8308 - accuracy: 0.5013 - val_loss: 1.7774 - val_accuracy: 0.5001\n",
      "Epoch 201/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.8026 - accuracy: 0.5022 - val_loss: 1.7520 - val_accuracy: 0.5001\n",
      "Epoch 202/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.7807 - accuracy: 0.4981 - val_loss: 1.7286 - val_accuracy: 0.5001\n",
      "Epoch 203/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.7560 - accuracy: 0.4982 - val_loss: 1.7051 - val_accuracy: 0.5001\n",
      "Epoch 204/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.7297 - accuracy: 0.4989 - val_loss: 1.6817 - val_accuracy: 0.5001\n",
      "Epoch 205/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.7067 - accuracy: 0.4987 - val_loss: 1.6582 - val_accuracy: 0.5001\n",
      "Epoch 206/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.6801 - accuracy: 0.4991 - val_loss: 1.6348 - val_accuracy: 0.5001\n",
      "Epoch 207/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.6553 - accuracy: 0.5007 - val_loss: 1.6113 - val_accuracy: 0.5001\n",
      "Epoch 208/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.6300 - accuracy: 0.5004 - val_loss: 1.5878 - val_accuracy: 0.5001\n",
      "Epoch 209/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.6053 - accuracy: 0.5026 - val_loss: 1.5644 - val_accuracy: 0.5001\n",
      "Epoch 210/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.5782 - accuracy: 0.5045 - val_loss: 1.5409 - val_accuracy: 0.5001\n",
      "Epoch 211/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.5565 - accuracy: 0.4996 - val_loss: 1.5175 - val_accuracy: 0.5001\n",
      "Epoch 212/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.5321 - accuracy: 0.5034 - val_loss: 1.4941 - val_accuracy: 0.5001\n",
      "Epoch 213/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.5082 - accuracy: 0.5004 - val_loss: 1.4706 - val_accuracy: 0.5001\n",
      "Epoch 214/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.4880 - accuracy: 0.4954 - val_loss: 1.4471 - val_accuracy: 0.5001\n",
      "Epoch 215/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.4579 - accuracy: 0.5059 - val_loss: 1.4237 - val_accuracy: 0.5001\n",
      "Epoch 216/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.4353 - accuracy: 0.4997 - val_loss: 1.4003 - val_accuracy: 0.5001\n",
      "Epoch 217/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.4133 - accuracy: 0.4977 - val_loss: 1.3768 - val_accuracy: 0.5001\n",
      "Epoch 218/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.3872 - accuracy: 0.4994 - val_loss: 1.3534 - val_accuracy: 0.5001\n",
      "Epoch 219/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.3616 - accuracy: 0.5021 - val_loss: 1.3299 - val_accuracy: 0.5001\n",
      "Epoch 220/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.3379 - accuracy: 0.5004 - val_loss: 1.3065 - val_accuracy: 0.5001\n",
      "Epoch 221/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.3164 - accuracy: 0.4948 - val_loss: 1.2832 - val_accuracy: 0.5001\n",
      "Epoch 222/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.2911 - accuracy: 0.5008 - val_loss: 1.2631 - val_accuracy: 0.5001\n",
      "Epoch 223/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.2723 - accuracy: 0.4985 - val_loss: 1.2430 - val_accuracy: 0.5001\n",
      "Epoch 224/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.2513 - accuracy: 0.4969 - val_loss: 1.2230 - val_accuracy: 0.5001\n",
      "Epoch 225/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.2281 - accuracy: 0.5024 - val_loss: 1.2029 - val_accuracy: 0.5001\n",
      "Epoch 226/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.2077 - accuracy: 0.5027 - val_loss: 1.1845 - val_accuracy: 0.5001\n",
      "Epoch 227/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1927 - accuracy: 0.4991 - val_loss: 1.1711 - val_accuracy: 0.5001\n",
      "Epoch 228/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1763 - accuracy: 0.5065 - val_loss: 1.1577 - val_accuracy: 0.5001\n",
      "Epoch 229/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1620 - accuracy: 0.5053 - val_loss: 1.1444 - val_accuracy: 0.5001\n",
      "Epoch 230/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1490 - accuracy: 0.5042 - val_loss: 1.1310 - val_accuracy: 0.5001\n",
      "Epoch 231/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1368 - accuracy: 0.5023 - val_loss: 1.1176 - val_accuracy: 0.5001\n",
      "Epoch 232/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1220 - accuracy: 0.5029 - val_loss: 1.1042 - val_accuracy: 0.5001\n",
      "Epoch 233/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1096 - accuracy: 0.4963 - val_loss: 1.0908 - val_accuracy: 0.5001\n",
      "Epoch 234/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0935 - accuracy: 0.5049 - val_loss: 1.0775 - val_accuracy: 0.5001\n",
      "Epoch 235/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.0806 - accuracy: 0.4995 - val_loss: 1.0641 - val_accuracy: 0.5001\n",
      "Epoch 236/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0673 - accuracy: 0.5028 - val_loss: 1.0536 - val_accuracy: 0.5001\n",
      "Epoch 237/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0583 - accuracy: 0.4988 - val_loss: 1.0436 - val_accuracy: 0.5001\n",
      "Epoch 238/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 1.0483 - accuracy: 0.4951 - val_loss: 1.0335 - val_accuracy: 0.5001\n",
      "Epoch 239/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0374 - accuracy: 0.4975 - val_loss: 1.0235 - val_accuracy: 0.5001\n",
      "Epoch 240/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0244 - accuracy: 0.5042 - val_loss: 1.0135 - val_accuracy: 0.5001\n",
      "Epoch 241/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0158 - accuracy: 0.4993 - val_loss: 1.0034 - val_accuracy: 0.5001\n",
      "Epoch 242/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0041 - accuracy: 0.5013 - val_loss: 0.9934 - val_accuracy: 0.5001\n",
      "Epoch 243/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9948 - accuracy: 0.5008 - val_loss: 0.9834 - val_accuracy: 0.5001\n",
      "Epoch 244/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9834 - accuracy: 0.4999 - val_loss: 0.9733 - val_accuracy: 0.5001\n",
      "Epoch 245/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9738 - accuracy: 0.4984 - val_loss: 0.9633 - val_accuracy: 0.5001\n",
      "Epoch 246/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9639 - accuracy: 0.4960 - val_loss: 0.9532 - val_accuracy: 0.5001\n",
      "Epoch 247/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9520 - accuracy: 0.5032 - val_loss: 0.9432 - val_accuracy: 0.5001\n",
      "Epoch 248/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9426 - accuracy: 0.4982 - val_loss: 0.9332 - val_accuracy: 0.5001\n",
      "Epoch 249/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9318 - accuracy: 0.5018 - val_loss: 0.9232 - val_accuracy: 0.5001\n",
      "Epoch 250/300\n",
      "335/335 [==============================] - 2s 4ms/step - loss: 0.9215 - accuracy: 0.5022 - val_loss: 0.9131 - val_accuracy: 0.5001\n",
      "Epoch 251/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9121 - accuracy: 0.4952 - val_loss: 0.9031 - val_accuracy: 0.5001\n",
      "Epoch 252/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9009 - accuracy: 0.4993 - val_loss: 0.8931 - val_accuracy: 0.5001\n",
      "Epoch 253/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.8906 - accuracy: 0.5020 - val_loss: 0.8831 - val_accuracy: 0.5001\n",
      "Epoch 254/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8807 - accuracy: 0.4976 - val_loss: 0.8730 - val_accuracy: 0.5001\n",
      "Epoch 255/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8697 - accuracy: 0.5018 - val_loss: 0.8630 - val_accuracy: 0.5001\n",
      "Epoch 256/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8611 - accuracy: 0.4937 - val_loss: 0.8529 - val_accuracy: 0.5001\n",
      "Epoch 257/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8495 - accuracy: 0.4998 - val_loss: 0.8429 - val_accuracy: 0.5001\n",
      "Epoch 258/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8392 - accuracy: 0.5010 - val_loss: 0.8346 - val_accuracy: 0.5001\n",
      "Epoch 259/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8324 - accuracy: 0.4983 - val_loss: 0.8279 - val_accuracy: 0.5001\n",
      "Epoch 260/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8256 - accuracy: 0.5020 - val_loss: 0.8212 - val_accuracy: 0.5001\n",
      "Epoch 261/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8190 - accuracy: 0.4998 - val_loss: 0.8145 - val_accuracy: 0.5001\n",
      "Epoch 262/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8124 - accuracy: 0.4968 - val_loss: 0.8078 - val_accuracy: 0.5001\n",
      "Epoch 263/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8051 - accuracy: 0.5016 - val_loss: 0.8011 - val_accuracy: 0.5001\n",
      "Epoch 264/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7988 - accuracy: 0.4987 - val_loss: 0.7943 - val_accuracy: 0.5001\n",
      "Epoch 265/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7913 - accuracy: 0.5035 - val_loss: 0.7876 - val_accuracy: 0.5001\n",
      "Epoch 266/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7851 - accuracy: 0.4980 - val_loss: 0.7809 - val_accuracy: 0.5001\n",
      "Epoch 267/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7776 - accuracy: 0.5049 - val_loss: 0.7742 - val_accuracy: 0.5001\n",
      "Epoch 268/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7713 - accuracy: 0.5004 - val_loss: 0.7675 - val_accuracy: 0.5001\n",
      "Epoch 269/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7647 - accuracy: 0.4979 - val_loss: 0.7608 - val_accuracy: 0.5001\n",
      "Epoch 270/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7580 - accuracy: 0.4971 - val_loss: 0.7540 - val_accuracy: 0.5001\n",
      "Epoch 271/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7508 - accuracy: 0.5020 - val_loss: 0.7474 - val_accuracy: 0.5001\n",
      "Epoch 272/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7447 - accuracy: 0.5004 - val_loss: 0.7424 - val_accuracy: 0.5001\n",
      "Epoch 273/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7412 - accuracy: 0.5003 - val_loss: 0.7391 - val_accuracy: 0.5001\n",
      "Epoch 274/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7375 - accuracy: 0.5003 - val_loss: 0.7356 - val_accuracy: 0.5001\n",
      "Epoch 275/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7339 - accuracy: 0.5003 - val_loss: 0.7322 - val_accuracy: 0.5001\n",
      "Epoch 276/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7308 - accuracy: 0.5003 - val_loss: 0.7288 - val_accuracy: 0.5001\n",
      "Epoch 277/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7270 - accuracy: 0.5003 - val_loss: 0.7254 - val_accuracy: 0.5001\n",
      "Epoch 278/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7237 - accuracy: 0.5003 - val_loss: 0.7220 - val_accuracy: 0.5001\n",
      "Epoch 279/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7203 - accuracy: 0.5003 - val_loss: 0.7186 - val_accuracy: 0.5001\n",
      "Epoch 280/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7169 - accuracy: 0.5003 - val_loss: 0.7152 - val_accuracy: 0.5001\n",
      "Epoch 281/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7136 - accuracy: 0.5003 - val_loss: 0.7119 - val_accuracy: 0.5001\n",
      "Epoch 282/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7102 - accuracy: 0.5003 - val_loss: 0.7085 - val_accuracy: 0.5001\n",
      "Epoch 283/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7068 - accuracy: 0.5003 - val_loss: 0.7051 - val_accuracy: 0.5001\n",
      "Epoch 284/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7034 - accuracy: 0.5003 - val_loss: 0.7017 - val_accuracy: 0.5001\n",
      "Epoch 285/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7000 - accuracy: 0.5003 - val_loss: 0.6983 - val_accuracy: 0.5001\n",
      "Epoch 286/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6982 - accuracy: 0.5003 - val_loss: 0.6982 - val_accuracy: 0.5001\n",
      "Epoch 287/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6981 - accuracy: 0.5003 - val_loss: 0.6981 - val_accuracy: 0.5001\n",
      "Epoch 288/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6981 - accuracy: 0.5003 - val_loss: 0.6980 - val_accuracy: 0.5001\n",
      "Epoch 289/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6980 - accuracy: 0.5003 - val_loss: 0.6980 - val_accuracy: 0.5001\n",
      "Epoch 290/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6979 - accuracy: 0.5003 - val_loss: 0.6979 - val_accuracy: 0.5001\n",
      "Epoch 291/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6979 - accuracy: 0.5003 - val_loss: 0.6979 - val_accuracy: 0.5001\n",
      "Epoch 292/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6978 - accuracy: 0.5003 - val_loss: 0.6978 - val_accuracy: 0.5001\n",
      "Epoch 293/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6978 - accuracy: 0.5003 - val_loss: 0.6978 - val_accuracy: 0.5001\n",
      "Epoch 294/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.6977 - accuracy: 0.5003 - val_loss: 0.6977 - val_accuracy: 0.5001\n",
      "Epoch 295/300\n",
      "321/335 [===========================>..] - ETA: 0s - loss: 0.6977 - accuracy: 0.5002Restoring model weights from the end of the best epoch: 294.\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6977 - accuracy: 0.5003 - val_loss: 0.6977 - val_accuracy: 0.5001\n",
      "Epoch 295: early stopping\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.6977 - accuracy: 0.5001\n",
      "{'loss': 0.6976945400238037, 'accuracy': 0.5001260638237} \n",
      " 294 \n",
      "\n",
      "Model time: 8.446593843400478 minutes\n",
      "\n",
      "Total time: 68.04989721998572 minutes\n",
      "\n",
      "\n",
      "Model  52  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                    32\n",
      "Activation function           relu\n",
      "Dropout                        0.5\n",
      "L1                           100.0\n",
      "L2                             0.0\n",
      "Batch size                       8\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 2236039, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 15s 5ms/step - loss: 1833.4536 - accuracy: 0.5011 - val_loss: 327.5081 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "2672/2677 [============================>.] - ETA: 0s - loss: 328.2266 - accuracy: 0.4958Restoring model weights from the end of the best epoch: 1.\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 328.2267 - accuracy: 0.4957 - val_loss: 328.6258 - val_accuracy: 0.5001\n",
      "Epoch 2: early stopping\n",
      "2480/2480 [==============================] - 7s 3ms/step - loss: 327.5081 - accuracy: 0.4999\n",
      "{'loss': 327.508056640625, 'accuracy': 0.49987393617630005} \n",
      " 1 \n",
      "\n",
      "Model time: 0.8377627395093441 minutes\n",
      "\n",
      "Total time: 68.88774275779724 minutes\n",
      "\n",
      "\n",
      "Model  53  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                   256\n",
      "Activation function           relu\n",
      "Dropout                        0.5\n",
      "L1                            0.01\n",
      "L2                            10.0\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 6903489, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 8s 37ms/step - loss: 10043.0479 - accuracy: 0.5031 - val_loss: 7849.5825 - val_accuracy: 0.4989\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 5s 33ms/step - loss: 6242.5381 - accuracy: 0.5053 - val_loss: 4825.2280 - val_accuracy: 0.4998\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 3793.0090 - accuracy: 0.5017 - val_loss: 2887.6565 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 2237.6313 - accuracy: 0.5025 - val_loss: 1672.3743 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 1274.4177 - accuracy: 0.4999 - val_loss: 932.1503 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 696.9698 - accuracy: 0.4945 - val_loss: 497.3625 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 364.0926 - accuracy: 0.5001 - val_loss: 252.7110 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 180.7669 - accuracy: 0.4966 - val_loss: 121.6844 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 84.9221 - accuracy: 0.4930 - val_loss: 55.3183 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 37.6498 - accuracy: 0.4975 - val_loss: 23.7265 - val_accuracy: 0.4999\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 15.7899 - accuracy: 0.4976 - val_loss: 9.6825 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 6.3734 - accuracy: 0.4914 - val_loss: 3.8930 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 2.6242 - accuracy: 0.4938 - val_loss: 1.7022 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 1.2636 - accuracy: 0.4971 - val_loss: 0.9584 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 0.8302 - accuracy: 0.5003 - val_loss: 0.7492 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.7250 - accuracy: 0.4949 - val_loss: 0.7107 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.7061 - accuracy: 0.5003 - val_loss: 0.7036 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.7026 - accuracy: 0.5003 - val_loss: 0.7018 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 0.7016 - accuracy: 0.4983 - val_loss: 0.7014 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.5002Restoring model weights from the end of the best epoch: 19.\n",
      "168/168 [==============================] - 5s 31ms/step - loss: 0.7015 - accuracy: 0.5003 - val_loss: 0.7016 - val_accuracy: 0.5001\n",
      "Epoch 20: early stopping\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 0.7014 - accuracy: 0.5001\n",
      "{'loss': 0.7014316320419312, 'accuracy': 0.5001260638237} \n",
      " 19 \n",
      "\n",
      "Model time: 1.7623458541929722 minutes\n",
      "\n",
      "Total time: 70.65015526860952 minutes\n",
      "\n",
      "\n",
      "Model  54  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                    32\n",
      "Activation function           relu\n",
      "Dropout                        0.8\n",
      "L1                             0.1\n",
      "L2                           100.0\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 6448093, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 13s 7ms/step - loss: 8747.4707 - accuracy: 0.4976 - val_loss: 2596.2483 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 863.0964 - accuracy: 0.5004 - val_loss: 55.2997 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 9.7890 - accuracy: 0.5003 - val_loss: 0.8145 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.7474 - accuracy: 0.5003 - val_loss: 0.7441 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 7s 6ms/step - loss: 0.7441 - accuracy: 0.5003 - val_loss: 0.7441 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.7441 - accuracy: 0.5003 - val_loss: 0.7441 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 7s 6ms/step - loss: 0.7441 - accuracy: 0.4990 - val_loss: 0.7441 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "1327/1339 [============================>.] - ETA: 0s - loss: 0.7441 - accuracy: 0.4968Restoring model weights from the end of the best epoch: 7.\n",
      "1339/1339 [==============================] - 7s 6ms/step - loss: 0.7441 - accuracy: 0.4971 - val_loss: 0.7441 - val_accuracy: 0.5001\n",
      "Epoch 8: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 0.7441 - accuracy: 0.5001\n",
      "{'loss': 0.7440521717071533, 'accuracy': 0.5001260638237} \n",
      " 7 \n",
      "\n",
      "Model time: 1.175041675567627 minutes\n",
      "\n",
      "Total time: 71.8253302834928 minutes\n",
      "\n",
      "\n",
      "Model  55  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     1\n",
      "Activation function           tanh\n",
      "Dropout                        0.7\n",
      "L1                            10.0\n",
      "L2                            10.0\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 28209, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 2s 9ms/step - loss: 193.7425 - accuracy: 0.4962 - val_loss: 177.5440 - val_accuracy: 0.4591\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 162.9149 - accuracy: 0.4937 - val_loss: 148.4165 - val_accuracy: 0.4565\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 135.3886 - accuracy: 0.4958 - val_loss: 122.7628 - val_accuracy: 0.4540\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 111.8249 - accuracy: 0.4929 - val_loss: 100.9743 - val_accuracy: 0.4529\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 91.0444 - accuracy: 0.4949 - val_loss: 81.2004 - val_accuracy: 0.4530\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 72.5132 - accuracy: 0.4944 - val_loss: 64.1414 - val_accuracy: 0.4530\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 57.0950 - accuracy: 0.4854 - val_loss: 50.2740 - val_accuracy: 0.4529\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 44.3609 - accuracy: 0.4848 - val_loss: 38.7789 - val_accuracy: 0.4532\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 34.2805 - accuracy: 0.4908 - val_loss: 30.0435 - val_accuracy: 0.4658\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 26.6257 - accuracy: 0.4895 - val_loss: 23.5531 - val_accuracy: 0.4933\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 21.8759 - accuracy: 0.4963 - val_loss: 20.6301 - val_accuracy: 0.5032\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 20.1667 - accuracy: 0.4998 - val_loss: 19.8715 - val_accuracy: 0.4999\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 19.6372 - accuracy: 0.4997 - val_loss: 19.4020 - val_accuracy: 0.4999\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 19.1711 - accuracy: 0.4997 - val_loss: 18.9393 - val_accuracy: 0.4999\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 18.7111 - accuracy: 0.4997 - val_loss: 18.4807 - val_accuracy: 0.4999\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 18.2567 - accuracy: 0.4997 - val_loss: 18.0296 - val_accuracy: 0.4999\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 17.8089 - accuracy: 0.4983 - val_loss: 17.5853 - val_accuracy: 0.4999\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 17.3666 - accuracy: 0.4995 - val_loss: 17.1468 - val_accuracy: 0.4998\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 16.9304 - accuracy: 0.4957 - val_loss: 16.7106 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 16.4998 - accuracy: 0.4961 - val_loss: 16.2836 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 16.0750 - accuracy: 0.4993 - val_loss: 15.8613 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 15.6556 - accuracy: 0.4982 - val_loss: 15.4449 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 15.2423 - accuracy: 0.5003 - val_loss: 15.0352 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 14.8339 - accuracy: 0.5004 - val_loss: 14.6306 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 14.4313 - accuracy: 0.5005 - val_loss: 14.2301 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 14.0342 - accuracy: 0.4976 - val_loss: 13.8364 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 13.6427 - accuracy: 0.4948 - val_loss: 13.4484 - val_accuracy: 0.4999\n",
      "Epoch 28/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 13.2562 - accuracy: 0.4938 - val_loss: 13.0631 - val_accuracy: 0.5000\n",
      "Epoch 29/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 12.8755 - accuracy: 0.4979 - val_loss: 12.6848 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.4996 - accuracy: 0.5007 - val_loss: 12.3136 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 12.1294 - accuracy: 0.5001 - val_loss: 11.9454 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 11.7644 - accuracy: 0.5003 - val_loss: 11.5844 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 11.4049 - accuracy: 0.4993 - val_loss: 11.2250 - val_accuracy: 0.5000\n",
      "Epoch 34/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.0503 - accuracy: 0.5027 - val_loss: 10.8743 - val_accuracy: 0.5003\n",
      "Epoch 35/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 10.7016 - accuracy: 0.4986 - val_loss: 10.5266 - val_accuracy: 0.5002\n",
      "Epoch 36/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 10.3575 - accuracy: 0.5054 - val_loss: 10.1848 - val_accuracy: 0.5003\n",
      "Epoch 37/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 10.0191 - accuracy: 0.4961 - val_loss: 9.8493 - val_accuracy: 0.4934\n",
      "Epoch 38/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 9.6859 - accuracy: 0.4945 - val_loss: 9.5194 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.3575 - accuracy: 0.4961 - val_loss: 9.1954 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 9.0343 - accuracy: 0.4977 - val_loss: 8.8736 - val_accuracy: 0.4978\n",
      "Epoch 41/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 8.7163 - accuracy: 0.4933 - val_loss: 8.5572 - val_accuracy: 0.5003\n",
      "Epoch 42/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 8.4036 - accuracy: 0.5033 - val_loss: 8.2472 - val_accuracy: 0.4999\n",
      "Epoch 43/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 8.0956 - accuracy: 0.5005 - val_loss: 7.9414 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 7.7932 - accuracy: 0.4999 - val_loss: 7.6428 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 7.4960 - accuracy: 0.5003 - val_loss: 7.3473 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 7.2035 - accuracy: 0.5003 - val_loss: 7.0587 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 6.9163 - accuracy: 0.4959 - val_loss: 6.7732 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 6.6341 - accuracy: 0.5004 - val_loss: 6.4952 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 6.3574 - accuracy: 0.5002 - val_loss: 6.2202 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 6.0855 - accuracy: 0.5003 - val_loss: 5.9491 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 5.8182 - accuracy: 0.5003 - val_loss: 5.6859 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 5.5561 - accuracy: 0.5003 - val_loss: 5.4251 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 5.2992 - accuracy: 0.5003 - val_loss: 5.1716 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.0473 - accuracy: 0.5004 - val_loss: 4.9215 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4.8004 - accuracy: 0.4994 - val_loss: 4.6780 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4.5589 - accuracy: 0.4981 - val_loss: 4.4379 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4.3217 - accuracy: 0.4993 - val_loss: 4.2046 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.0900 - accuracy: 0.5002 - val_loss: 3.9748 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.8630 - accuracy: 0.5003 - val_loss: 3.7513 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.6411 - accuracy: 0.5003 - val_loss: 3.5306 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.4241 - accuracy: 0.4921 - val_loss: 3.3174 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.2115 - accuracy: 0.4978 - val_loss: 3.1067 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.0046 - accuracy: 0.5003 - val_loss: 2.9032 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.8019 - accuracy: 0.4979 - val_loss: 2.7043 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.6041 - accuracy: 0.5004 - val_loss: 2.5069 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.4109 - accuracy: 0.4992 - val_loss: 2.3168 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.2230 - accuracy: 0.4988 - val_loss: 2.1321 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.0403 - accuracy: 0.4918 - val_loss: 1.9505 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.8619 - accuracy: 0.4999 - val_loss: 1.7755 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6883 - accuracy: 0.5003 - val_loss: 1.6045 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.5195 - accuracy: 0.4992 - val_loss: 1.4386 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 1.3554 - accuracy: 0.5004 - val_loss: 1.2745 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.1959 - accuracy: 0.5002 - val_loss: 1.1181 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0413 - accuracy: 0.4992 - val_loss: 0.9659 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.8913 - accuracy: 0.5003 - val_loss: 0.8174 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7511 - accuracy: 0.4961 - val_loss: 0.7142 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7128 - accuracy: 0.5003 - val_loss: 0.7127 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "159/168 [===========================>..] - ETA: 0s - loss: 0.7127 - accuracy: 0.4968Restoring model weights from the end of the best epoch: 77.\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7127 - accuracy: 0.4976 - val_loss: 0.7143 - val_accuracy: 0.5001\n",
      "Epoch 78: early stopping\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7127 - accuracy: 0.5001\n",
      "{'loss': 0.7126588821411133, 'accuracy': 0.5001260638237} \n",
      " 77 \n",
      "\n",
      "Model time: 1.1856417283415794 minutes\n",
      "\n",
      "Total time: 73.01105535030365 minutes\n",
      "\n",
      "\n",
      "Model  56  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                    16\n",
      "Activation function           relu\n",
      "Dropout                        0.9\n",
      "L1                            0.01\n",
      "L2                          0.0001\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 3497828, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 6ms/step - loss: 5.6723 - accuracy: 0.4960 - val_loss: 4.2667 - val_accuracy: 0.5549\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 5.6329 - accuracy: 0.5046 - val_loss: 4.1502 - val_accuracy: 0.5542\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 5.5513 - accuracy: 0.5009 - val_loss: 4.0374 - val_accuracy: 0.5543\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.3123 - accuracy: 0.4948 - val_loss: 3.9285 - val_accuracy: 0.5559\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.2133 - accuracy: 0.4986 - val_loss: 3.8218 - val_accuracy: 0.5559\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.0465 - accuracy: 0.4992 - val_loss: 3.7190 - val_accuracy: 0.5561\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.8491 - accuracy: 0.4966 - val_loss: 3.6194 - val_accuracy: 0.5559\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 4.6080 - accuracy: 0.4993 - val_loss: 3.5217 - val_accuracy: 0.5567\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 4.6250 - accuracy: 0.4988 - val_loss: 3.4281 - val_accuracy: 0.5573\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.4699 - accuracy: 0.4982 - val_loss: 3.3383 - val_accuracy: 0.5587\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.2999 - accuracy: 0.4986 - val_loss: 3.2520 - val_accuracy: 0.5594\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.2395 - accuracy: 0.5011 - val_loss: 3.1669 - val_accuracy: 0.5584\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.0510 - accuracy: 0.5008 - val_loss: 3.0845 - val_accuracy: 0.5587\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.8596 - accuracy: 0.4996 - val_loss: 3.0061 - val_accuracy: 0.5596\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.8782 - accuracy: 0.4971 - val_loss: 2.9311 - val_accuracy: 0.5598\n",
      "Epoch 16/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.6750 - accuracy: 0.5017 - val_loss: 2.8585 - val_accuracy: 0.5600\n",
      "Epoch 17/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.6364 - accuracy: 0.5001 - val_loss: 2.7898 - val_accuracy: 0.5599\n",
      "Epoch 18/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.4945 - accuracy: 0.5021 - val_loss: 2.7243 - val_accuracy: 0.5593\n",
      "Epoch 19/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.4348 - accuracy: 0.4990 - val_loss: 2.6628 - val_accuracy: 0.5591\n",
      "Epoch 20/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.3595 - accuracy: 0.4994 - val_loss: 2.6044 - val_accuracy: 0.5584\n",
      "Epoch 21/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.2250 - accuracy: 0.5033 - val_loss: 2.5488 - val_accuracy: 0.5595\n",
      "Epoch 22/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.1460 - accuracy: 0.4965 - val_loss: 2.4968 - val_accuracy: 0.5593\n",
      "Epoch 23/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.0655 - accuracy: 0.4990 - val_loss: 2.4485 - val_accuracy: 0.5584\n",
      "Epoch 24/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 3.0128 - accuracy: 0.4977 - val_loss: 2.4042 - val_accuracy: 0.5571\n",
      "Epoch 25/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.9428 - accuracy: 0.5010 - val_loss: 2.3633 - val_accuracy: 0.5553\n",
      "Epoch 26/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.9011 - accuracy: 0.5008 - val_loss: 2.3260 - val_accuracy: 0.5552\n",
      "Epoch 27/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.8054 - accuracy: 0.5021 - val_loss: 2.2921 - val_accuracy: 0.5537\n",
      "Epoch 28/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.7914 - accuracy: 0.4985 - val_loss: 2.2602 - val_accuracy: 0.5520\n",
      "Epoch 29/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.7248 - accuracy: 0.4995 - val_loss: 2.2288 - val_accuracy: 0.5498\n",
      "Epoch 30/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.6177 - accuracy: 0.5001 - val_loss: 2.1984 - val_accuracy: 0.5480\n",
      "Epoch 31/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.5850 - accuracy: 0.5014 - val_loss: 2.1652 - val_accuracy: 0.5473\n",
      "Epoch 32/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.5783 - accuracy: 0.4972 - val_loss: 2.1357 - val_accuracy: 0.5444\n",
      "Epoch 33/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.5384 - accuracy: 0.5009 - val_loss: 2.1053 - val_accuracy: 0.5428\n",
      "Epoch 34/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.4621 - accuracy: 0.4973 - val_loss: 2.0745 - val_accuracy: 0.5398\n",
      "Epoch 35/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.3735 - accuracy: 0.4985 - val_loss: 2.0437 - val_accuracy: 0.5380\n",
      "Epoch 36/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.3665 - accuracy: 0.4998 - val_loss: 2.0133 - val_accuracy: 0.5365\n",
      "Epoch 37/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.3070 - accuracy: 0.4995 - val_loss: 1.9838 - val_accuracy: 0.5342\n",
      "Epoch 38/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.3104 - accuracy: 0.4979 - val_loss: 1.9552 - val_accuracy: 0.5317\n",
      "Epoch 39/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.2648 - accuracy: 0.4982 - val_loss: 1.9255 - val_accuracy: 0.5300\n",
      "Epoch 40/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.1727 - accuracy: 0.5009 - val_loss: 1.8958 - val_accuracy: 0.5262\n",
      "Epoch 41/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.1602 - accuracy: 0.5009 - val_loss: 1.8665 - val_accuracy: 0.5254\n",
      "Epoch 42/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.1544 - accuracy: 0.5002 - val_loss: 1.8372 - val_accuracy: 0.5223\n",
      "Epoch 43/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.0939 - accuracy: 0.4996 - val_loss: 1.8072 - val_accuracy: 0.5209\n",
      "Epoch 44/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.0215 - accuracy: 0.4996 - val_loss: 1.7765 - val_accuracy: 0.5196\n",
      "Epoch 45/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.9553 - accuracy: 0.5016 - val_loss: 1.7456 - val_accuracy: 0.5176\n",
      "Epoch 46/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.9410 - accuracy: 0.4995 - val_loss: 1.7160 - val_accuracy: 0.5155\n",
      "Epoch 47/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.9856 - accuracy: 0.5000 - val_loss: 1.6874 - val_accuracy: 0.5149\n",
      "Epoch 48/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.8308 - accuracy: 0.4970 - val_loss: 1.6573 - val_accuracy: 0.5134\n",
      "Epoch 49/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.7842 - accuracy: 0.5011 - val_loss: 1.6254 - val_accuracy: 0.5118\n",
      "Epoch 50/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.7955 - accuracy: 0.4990 - val_loss: 1.5947 - val_accuracy: 0.5104\n",
      "Epoch 51/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.7249 - accuracy: 0.5009 - val_loss: 1.5628 - val_accuracy: 0.5084\n",
      "Epoch 52/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.7021 - accuracy: 0.4999 - val_loss: 1.5307 - val_accuracy: 0.5081\n",
      "Epoch 53/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.6700 - accuracy: 0.4973 - val_loss: 1.4992 - val_accuracy: 0.5076\n",
      "Epoch 54/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.5937 - accuracy: 0.4996 - val_loss: 1.4671 - val_accuracy: 0.5068\n",
      "Epoch 55/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.5703 - accuracy: 0.4996 - val_loss: 1.4381 - val_accuracy: 0.5063\n",
      "Epoch 56/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5418 - accuracy: 0.5017 - val_loss: 1.4087 - val_accuracy: 0.5057\n",
      "Epoch 57/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5227 - accuracy: 0.4986 - val_loss: 1.3788 - val_accuracy: 0.5054\n",
      "Epoch 58/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4483 - accuracy: 0.5006 - val_loss: 1.3483 - val_accuracy: 0.5041\n",
      "Epoch 59/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4247 - accuracy: 0.4993 - val_loss: 1.3205 - val_accuracy: 0.5039\n",
      "Epoch 60/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4003 - accuracy: 0.5002 - val_loss: 1.2921 - val_accuracy: 0.5029\n",
      "Epoch 61/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.3569 - accuracy: 0.4992 - val_loss: 1.2646 - val_accuracy: 0.5024\n",
      "Epoch 62/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.3073 - accuracy: 0.4997 - val_loss: 1.2364 - val_accuracy: 0.5029\n",
      "Epoch 63/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.2812 - accuracy: 0.4988 - val_loss: 1.2102 - val_accuracy: 0.5026\n",
      "Epoch 64/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.2460 - accuracy: 0.5010 - val_loss: 1.1844 - val_accuracy: 0.5020\n",
      "Epoch 65/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.2240 - accuracy: 0.5012 - val_loss: 1.1589 - val_accuracy: 0.5006\n",
      "Epoch 66/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.2012 - accuracy: 0.4990 - val_loss: 1.1357 - val_accuracy: 0.5009\n",
      "Epoch 67/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1625 - accuracy: 0.5011 - val_loss: 1.1126 - val_accuracy: 0.5003\n",
      "Epoch 68/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1423 - accuracy: 0.4985 - val_loss: 1.0907 - val_accuracy: 0.5002\n",
      "Epoch 69/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1105 - accuracy: 0.4992 - val_loss: 1.0682 - val_accuracy: 0.5000\n",
      "Epoch 70/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1020 - accuracy: 0.4997 - val_loss: 1.0489 - val_accuracy: 0.4998\n",
      "Epoch 71/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0623 - accuracy: 0.5003 - val_loss: 1.0287 - val_accuracy: 0.4998\n",
      "Epoch 72/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0451 - accuracy: 0.4996 - val_loss: 1.0098 - val_accuracy: 0.4999\n",
      "Epoch 73/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0287 - accuracy: 0.4992 - val_loss: 0.9923 - val_accuracy: 0.4998\n",
      "Epoch 74/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.0041 - accuracy: 0.4994 - val_loss: 0.9761 - val_accuracy: 0.4999\n",
      "Epoch 75/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9790 - accuracy: 0.4993 - val_loss: 0.9597 - val_accuracy: 0.4999\n",
      "Epoch 76/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9660 - accuracy: 0.4998 - val_loss: 0.9439 - val_accuracy: 0.4999\n",
      "Epoch 77/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.9501 - accuracy: 0.4994 - val_loss: 0.9295 - val_accuracy: 0.4999\n",
      "Epoch 78/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9290 - accuracy: 0.4998 - val_loss: 0.9131 - val_accuracy: 0.4999\n",
      "Epoch 79/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9147 - accuracy: 0.4991 - val_loss: 0.8991 - val_accuracy: 0.4999\n",
      "Epoch 80/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8981 - accuracy: 0.4998 - val_loss: 0.8846 - val_accuracy: 0.4999\n",
      "Epoch 81/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8827 - accuracy: 0.4999 - val_loss: 0.8705 - val_accuracy: 0.4999\n",
      "Epoch 82/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8691 - accuracy: 0.4997 - val_loss: 0.8567 - val_accuracy: 0.4999\n",
      "Epoch 83/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8557 - accuracy: 0.4999 - val_loss: 0.8436 - val_accuracy: 0.4999\n",
      "Epoch 84/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8442 - accuracy: 0.5000 - val_loss: 0.8322 - val_accuracy: 0.4999\n",
      "Epoch 85/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8317 - accuracy: 0.4998 - val_loss: 0.8218 - val_accuracy: 0.4999\n",
      "Epoch 86/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8196 - accuracy: 0.4990 - val_loss: 0.8115 - val_accuracy: 0.4999\n",
      "Epoch 87/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8071 - accuracy: 0.4996 - val_loss: 0.8017 - val_accuracy: 0.4999\n",
      "Epoch 88/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7986 - accuracy: 0.4996 - val_loss: 0.7928 - val_accuracy: 0.4999\n",
      "Epoch 89/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7894 - accuracy: 0.4997 - val_loss: 0.7846 - val_accuracy: 0.4999\n",
      "Epoch 90/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7812 - accuracy: 0.4993 - val_loss: 0.7769 - val_accuracy: 0.4999\n",
      "Epoch 91/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7731 - accuracy: 0.4997 - val_loss: 0.7694 - val_accuracy: 0.4999\n",
      "Epoch 92/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7666 - accuracy: 0.4998 - val_loss: 0.7633 - val_accuracy: 0.4999\n",
      "Epoch 93/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7607 - accuracy: 0.4996 - val_loss: 0.7578 - val_accuracy: 0.4999\n",
      "Epoch 94/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7552 - accuracy: 0.4997 - val_loss: 0.7526 - val_accuracy: 0.4999\n",
      "Epoch 95/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7505 - accuracy: 0.4997 - val_loss: 0.7477 - val_accuracy: 0.4999\n",
      "Epoch 96/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7454 - accuracy: 0.4998 - val_loss: 0.7432 - val_accuracy: 0.4999\n",
      "Epoch 97/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7410 - accuracy: 0.4996 - val_loss: 0.7389 - val_accuracy: 0.4999\n",
      "Epoch 98/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7369 - accuracy: 0.4998 - val_loss: 0.7350 - val_accuracy: 0.4999\n",
      "Epoch 99/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7332 - accuracy: 0.4997 - val_loss: 0.7315 - val_accuracy: 0.4999\n",
      "Epoch 100/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7298 - accuracy: 0.4997 - val_loss: 0.7281 - val_accuracy: 0.4999\n",
      "Epoch 101/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7265 - accuracy: 0.4997 - val_loss: 0.7249 - val_accuracy: 0.4999\n",
      "Epoch 102/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7234 - accuracy: 0.4997 - val_loss: 0.7220 - val_accuracy: 0.4999\n",
      "Epoch 103/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7206 - accuracy: 0.4997 - val_loss: 0.7192 - val_accuracy: 0.4999\n",
      "Epoch 104/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7179 - accuracy: 0.4997 - val_loss: 0.7168 - val_accuracy: 0.4999\n",
      "Epoch 105/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7157 - accuracy: 0.4997 - val_loss: 0.7147 - val_accuracy: 0.4999\n",
      "Epoch 106/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7137 - accuracy: 0.4997 - val_loss: 0.7127 - val_accuracy: 0.4999\n",
      "Epoch 107/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7117 - accuracy: 0.4997 - val_loss: 0.7108 - val_accuracy: 0.4999\n",
      "Epoch 108/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7099 - accuracy: 0.4997 - val_loss: 0.7091 - val_accuracy: 0.4999\n",
      "Epoch 109/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7083 - accuracy: 0.4997 - val_loss: 0.7076 - val_accuracy: 0.4999\n",
      "Epoch 110/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7070 - accuracy: 0.4997 - val_loss: 0.7063 - val_accuracy: 0.4999\n",
      "Epoch 111/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7057 - accuracy: 0.4997 - val_loss: 0.7050 - val_accuracy: 0.4999\n",
      "Epoch 112/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7045 - accuracy: 0.4997 - val_loss: 0.7039 - val_accuracy: 0.4999\n",
      "Epoch 113/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7034 - accuracy: 0.4997 - val_loss: 0.7030 - val_accuracy: 0.4999\n",
      "Epoch 114/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7025 - accuracy: 0.4997 - val_loss: 0.7021 - val_accuracy: 0.4999\n",
      "Epoch 115/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7017 - accuracy: 0.4997 - val_loss: 0.7013 - val_accuracy: 0.4999\n",
      "Epoch 116/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7010 - accuracy: 0.4997 - val_loss: 0.7006 - val_accuracy: 0.4999\n",
      "Epoch 117/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7002 - accuracy: 0.4977 - val_loss: 0.6998 - val_accuracy: 0.4999\n",
      "Epoch 118/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6995 - accuracy: 0.4997 - val_loss: 0.6992 - val_accuracy: 0.4999\n",
      "Epoch 119/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6988 - accuracy: 0.4997 - val_loss: 0.6985 - val_accuracy: 0.4999\n",
      "Epoch 120/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6982 - accuracy: 0.4997 - val_loss: 0.6979 - val_accuracy: 0.4999\n",
      "Epoch 121/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6976 - accuracy: 0.4997 - val_loss: 0.6973 - val_accuracy: 0.4999\n",
      "Epoch 122/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6971 - accuracy: 0.4997 - val_loss: 0.6968 - val_accuracy: 0.4999\n",
      "Epoch 123/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.6966 - accuracy: 0.4997 - val_loss: 0.6964 - val_accuracy: 0.4999\n",
      "Epoch 124/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6962 - accuracy: 0.4997 - val_loss: 0.6960 - val_accuracy: 0.4999\n",
      "Epoch 125/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6959 - accuracy: 0.4989 - val_loss: 0.6957 - val_accuracy: 0.4999\n",
      "Epoch 126/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6955 - accuracy: 0.4997 - val_loss: 0.6954 - val_accuracy: 0.4999\n",
      "Epoch 127/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6952 - accuracy: 0.4954 - val_loss: 0.6950 - val_accuracy: 0.4999\n",
      "Epoch 128/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6949 - accuracy: 0.4977 - val_loss: 0.6947 - val_accuracy: 0.5001\n",
      "Epoch 129/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6945 - accuracy: 0.5003 - val_loss: 0.6944 - val_accuracy: 0.5001\n",
      "Epoch 130/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6943 - accuracy: 0.5003 - val_loss: 0.6941 - val_accuracy: 0.5001\n",
      "Epoch 131/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6940 - accuracy: 0.5003 - val_loss: 0.6939 - val_accuracy: 0.5001\n",
      "Epoch 132/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.6938 - accuracy: 0.4994 - val_loss: 0.6937 - val_accuracy: 0.5001\n",
      "Epoch 133/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6937 - accuracy: 0.4982 - val_loss: 0.6936 - val_accuracy: 0.5001\n",
      "Epoch 134/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6936 - accuracy: 0.4946 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 135/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6935 - accuracy: 0.4981 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 136/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6934 - accuracy: 0.4991 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
      "Epoch 137/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6934 - accuracy: 0.4993 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 138/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6933 - accuracy: 0.4940 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 139/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 140/300\n",
      "667/670 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5002Restoring model weights from the end of the best epoch: 139.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6933 - accuracy: 0.5002 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 140: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.6933 - accuracy: 0.5001\n",
      "{'loss': 0.6933119297027588, 'accuracy': 0.5001260638237} \n",
      " 139 \n",
      "\n",
      "Model time: 8.43808887526393 minutes\n",
      "\n",
      "Total time: 81.44921090826392 minutes\n",
      "\n",
      "\n",
      "Model  57  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                    32\n",
      "Activation function         linear\n",
      "Dropout                        0.1\n",
      "L1                            10.0\n",
      "L2                          0.0001\n",
      "Batch size                       8\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 3659812, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 16s 5ms/step - loss: 6967.7510 - accuracy: 0.4768 - val_loss: 6036.1719 - val_accuracy: 0.4740\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 5200.7183 - accuracy: 0.4832 - val_loss: 4411.4243 - val_accuracy: 0.4710\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 3718.5322 - accuracy: 0.4854 - val_loss: 3073.0151 - val_accuracy: 0.4780\n",
      "Epoch 4/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 2523.8779 - accuracy: 0.4840 - val_loss: 2022.6694 - val_accuracy: 0.4819\n",
      "Epoch 5/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1616.9613 - accuracy: 0.4857 - val_loss: 1256.9370 - val_accuracy: 0.4893\n",
      "Epoch 6/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 990.1566 - accuracy: 0.4912 - val_loss: 768.6201 - val_accuracy: 0.5002\n",
      "Epoch 7/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 629.0170 - accuracy: 0.4995 - val_loss: 509.5001 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 407.7036 - accuracy: 0.5002 - val_loss: 313.9167 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 236.1391 - accuracy: 0.5004 - val_loss: 166.1226 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 112.9214 - accuracy: 0.4985 - val_loss: 67.3078 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 36.8338 - accuracy: 0.4965 - val_loss: 14.4457 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 8.4749 - accuracy: 0.4991 - val_loss: 6.1496 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 4.7251 - accuracy: 0.5003 - val_loss: 3.4777 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 2.6089 - accuracy: 0.5003 - val_loss: 1.8602 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.4737 - accuracy: 0.5003 - val_loss: 1.2152 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.1131 - accuracy: 0.5003 - val_loss: 1.0776 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.0756 - accuracy: 0.5003 - val_loss: 1.0735 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "2659/2677 [============================>.] - ETA: 0s - loss: 1.0755 - accuracy: 0.5002Restoring model weights from the end of the best epoch: 17.\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.0755 - accuracy: 0.5003 - val_loss: 1.0776 - val_accuracy: 0.5001\n",
      "Epoch 18: early stopping\n",
      "2480/2480 [==============================] - 7s 3ms/step - loss: 1.0735 - accuracy: 0.5001\n",
      "{'loss': 1.073476791381836, 'accuracy': 0.5001260638237} \n",
      " 17 \n",
      "\n",
      "Model time: 4.075945634394884 minutes\n",
      "\n",
      "Total time: 85.52525655180216 minutes\n",
      "\n",
      "\n",
      "Model  58  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                    64\n",
      "Activation function           tanh\n",
      "Dropout                        0.3\n",
      "L1                          0.0001\n",
      "L2                            0.01\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 5147102, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 11s 6ms/step - loss: 0.7601 - accuracy: 0.5037 - val_loss: 0.7192 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "1338/1339 [============================>.] - ETA: 0s - loss: 0.7163 - accuracy: 0.5028Restoring model weights from the end of the best epoch: 1.\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 0.7163 - accuracy: 0.5027 - val_loss: 0.7265 - val_accuracy: 0.4999\n",
      "Epoch 2: early stopping\n",
      "1240/1240 [==============================] - 4s 3ms/step - loss: 0.7192 - accuracy: 0.5001\n",
      "{'loss': 0.7192449569702148, 'accuracy': 0.5001260638237} \n",
      " 1 \n",
      "\n",
      "Model time: 0.45459331199526787 minutes\n",
      "\n",
      "Total time: 85.97993318364024 minutes\n",
      "\n",
      "\n",
      "Model  59  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                    16\n",
      "Activation function           tanh\n",
      "Dropout                        0.9\n",
      "L1                            0.01\n",
      "L2                          0.0001\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 2059260, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 9s 5ms/step - loss: 4.5409 - accuracy: 0.4986 - val_loss: 3.6088 - val_accuracy: 0.4861\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 4.2481 - accuracy: 0.5019 - val_loss: 3.4134 - val_accuracy: 0.4887\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 4.0419 - accuracy: 0.4984 - val_loss: 3.2312 - val_accuracy: 0.4896\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 3.8362 - accuracy: 0.4990 - val_loss: 3.0608 - val_accuracy: 0.4921\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 3.6609 - accuracy: 0.5005 - val_loss: 2.9031 - val_accuracy: 0.4933\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 3.5025 - accuracy: 0.4957 - val_loss: 2.7606 - val_accuracy: 0.4942\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 3.3269 - accuracy: 0.4934 - val_loss: 2.6334 - val_accuracy: 0.4952\n",
      "Epoch 8/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 3.1708 - accuracy: 0.5080 - val_loss: 2.5192 - val_accuracy: 0.4974\n",
      "Epoch 9/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 3.0642 - accuracy: 0.4996 - val_loss: 2.4169 - val_accuracy: 0.4983\n",
      "Epoch 10/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.9464 - accuracy: 0.4970 - val_loss: 2.3259 - val_accuracy: 0.4997\n",
      "Epoch 11/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.8010 - accuracy: 0.5028 - val_loss: 2.2476 - val_accuracy: 0.5019\n",
      "Epoch 12/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.7361 - accuracy: 0.4976 - val_loss: 2.1805 - val_accuracy: 0.5044\n",
      "Epoch 13/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.6394 - accuracy: 0.5007 - val_loss: 2.1276 - val_accuracy: 0.5060\n",
      "Epoch 14/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.5678 - accuracy: 0.4989 - val_loss: 2.0867 - val_accuracy: 0.5077\n",
      "Epoch 15/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.5173 - accuracy: 0.5004 - val_loss: 2.0501 - val_accuracy: 0.5088\n",
      "Epoch 16/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.4524 - accuracy: 0.4981 - val_loss: 2.0154 - val_accuracy: 0.5109\n",
      "Epoch 17/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.4081 - accuracy: 0.4971 - val_loss: 1.9834 - val_accuracy: 0.5126\n",
      "Epoch 18/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.3533 - accuracy: 0.5019 - val_loss: 1.9526 - val_accuracy: 0.5147\n",
      "Epoch 19/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.3089 - accuracy: 0.4984 - val_loss: 1.9220 - val_accuracy: 0.5158\n",
      "Epoch 20/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.2666 - accuracy: 0.4981 - val_loss: 1.8923 - val_accuracy: 0.5166\n",
      "Epoch 21/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.2074 - accuracy: 0.4994 - val_loss: 1.8629 - val_accuracy: 0.5178\n",
      "Epoch 22/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.1389 - accuracy: 0.5064 - val_loss: 1.8339 - val_accuracy: 0.5189\n",
      "Epoch 23/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.1019 - accuracy: 0.5037 - val_loss: 1.8046 - val_accuracy: 0.5206\n",
      "Epoch 24/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.0728 - accuracy: 0.4993 - val_loss: 1.7760 - val_accuracy: 0.5219\n",
      "Epoch 25/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2.0167 - accuracy: 0.5029 - val_loss: 1.7472 - val_accuracy: 0.5230\n",
      "Epoch 26/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.9848 - accuracy: 0.4952 - val_loss: 1.7187 - val_accuracy: 0.5253\n",
      "Epoch 27/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.9441 - accuracy: 0.4996 - val_loss: 1.6906 - val_accuracy: 0.5274\n",
      "Epoch 28/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.8914 - accuracy: 0.4991 - val_loss: 1.6619 - val_accuracy: 0.5292\n",
      "Epoch 29/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.8513 - accuracy: 0.4948 - val_loss: 1.6331 - val_accuracy: 0.5319\n",
      "Epoch 30/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.8000 - accuracy: 0.5005 - val_loss: 1.6050 - val_accuracy: 0.5336\n",
      "Epoch 31/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.7686 - accuracy: 0.4999 - val_loss: 1.5773 - val_accuracy: 0.5349\n",
      "Epoch 32/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.7219 - accuracy: 0.4969 - val_loss: 1.5496 - val_accuracy: 0.5390\n",
      "Epoch 33/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.6949 - accuracy: 0.4974 - val_loss: 1.5223 - val_accuracy: 0.5400\n",
      "Epoch 34/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.6477 - accuracy: 0.5005 - val_loss: 1.4945 - val_accuracy: 0.5415\n",
      "Epoch 35/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.6082 - accuracy: 0.4933 - val_loss: 1.4665 - val_accuracy: 0.5445\n",
      "Epoch 36/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.5692 - accuracy: 0.5000 - val_loss: 1.4393 - val_accuracy: 0.5458\n",
      "Epoch 37/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.5283 - accuracy: 0.4993 - val_loss: 1.4114 - val_accuracy: 0.5481\n",
      "Epoch 38/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.4934 - accuracy: 0.4987 - val_loss: 1.3847 - val_accuracy: 0.5491\n",
      "Epoch 39/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.4525 - accuracy: 0.5051 - val_loss: 1.3570 - val_accuracy: 0.5498\n",
      "Epoch 40/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.4281 - accuracy: 0.5000 - val_loss: 1.3296 - val_accuracy: 0.5524\n",
      "Epoch 41/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 1.3899 - accuracy: 0.4993 - val_loss: 1.3019 - val_accuracy: 0.5552\n",
      "Epoch 42/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.3520 - accuracy: 0.5040 - val_loss: 1.2748 - val_accuracy: 0.5561\n",
      "Epoch 43/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.3206 - accuracy: 0.5041 - val_loss: 1.2478 - val_accuracy: 0.5574\n",
      "Epoch 44/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.2866 - accuracy: 0.5007 - val_loss: 1.2208 - val_accuracy: 0.5601\n",
      "Epoch 45/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.2487 - accuracy: 0.5017 - val_loss: 1.1935 - val_accuracy: 0.5612\n",
      "Epoch 46/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.2202 - accuracy: 0.5026 - val_loss: 1.1663 - val_accuracy: 0.5626\n",
      "Epoch 47/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.1922 - accuracy: 0.4999 - val_loss: 1.1403 - val_accuracy: 0.5644\n",
      "Epoch 48/300\n",
      "1339/1339 [==============================] - 6s 4ms/step - loss: 1.1617 - accuracy: 0.4987 - val_loss: 1.1140 - val_accuracy: 0.5678\n",
      "Epoch 49/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.1265 - accuracy: 0.5058 - val_loss: 1.0879 - val_accuracy: 0.5696\n",
      "Epoch 50/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.1000 - accuracy: 0.4980 - val_loss: 1.0623 - val_accuracy: 0.5709\n",
      "Epoch 51/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.0683 - accuracy: 0.5020 - val_loss: 1.0363 - val_accuracy: 0.5725\n",
      "Epoch 52/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.0394 - accuracy: 0.5092 - val_loss: 1.0111 - val_accuracy: 0.5740\n",
      "Epoch 53/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.0141 - accuracy: 0.5061 - val_loss: 0.9864 - val_accuracy: 0.5728\n",
      "Epoch 54/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.9873 - accuracy: 0.5036 - val_loss: 0.9624 - val_accuracy: 0.5733\n",
      "Epoch 55/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.9599 - accuracy: 0.5004 - val_loss: 0.9386 - val_accuracy: 0.5726\n",
      "Epoch 56/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.9355 - accuracy: 0.5041 - val_loss: 0.9157 - val_accuracy: 0.5737\n",
      "Epoch 57/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.9121 - accuracy: 0.5028 - val_loss: 0.8939 - val_accuracy: 0.5723\n",
      "Epoch 58/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8877 - accuracy: 0.5044 - val_loss: 0.8730 - val_accuracy: 0.5754\n",
      "Epoch 59/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8689 - accuracy: 0.5031 - val_loss: 0.8530 - val_accuracy: 0.5761\n",
      "Epoch 60/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8469 - accuracy: 0.5062 - val_loss: 0.8337 - val_accuracy: 0.5746\n",
      "Epoch 61/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8267 - accuracy: 0.5050 - val_loss: 0.8149 - val_accuracy: 0.5731\n",
      "Epoch 62/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8083 - accuracy: 0.5032 - val_loss: 0.7972 - val_accuracy: 0.5692\n",
      "Epoch 63/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7903 - accuracy: 0.5010 - val_loss: 0.7815 - val_accuracy: 0.5658\n",
      "Epoch 64/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7756 - accuracy: 0.4975 - val_loss: 0.7672 - val_accuracy: 0.5615\n",
      "Epoch 65/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7611 - accuracy: 0.5069 - val_loss: 0.7539 - val_accuracy: 0.5578\n",
      "Epoch 66/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7484 - accuracy: 0.5011 - val_loss: 0.7425 - val_accuracy: 0.5555\n",
      "Epoch 67/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7380 - accuracy: 0.5046 - val_loss: 0.7330 - val_accuracy: 0.5480\n",
      "Epoch 68/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7289 - accuracy: 0.5059 - val_loss: 0.7248 - val_accuracy: 0.5438\n",
      "Epoch 69/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7213 - accuracy: 0.5049 - val_loss: 0.7180 - val_accuracy: 0.5397\n",
      "Epoch 70/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7152 - accuracy: 0.4987 - val_loss: 0.7124 - val_accuracy: 0.5345\n",
      "Epoch 71/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7102 - accuracy: 0.4989 - val_loss: 0.7081 - val_accuracy: 0.5325\n",
      "Epoch 72/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7064 - accuracy: 0.4993 - val_loss: 0.7048 - val_accuracy: 0.5074\n",
      "Epoch 73/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7033 - accuracy: 0.4975 - val_loss: 0.7019 - val_accuracy: 0.4999\n",
      "Epoch 74/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7008 - accuracy: 0.4900 - val_loss: 0.6997 - val_accuracy: 0.4999\n",
      "Epoch 75/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6987 - accuracy: 0.4979 - val_loss: 0.6979 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6971 - accuracy: 0.5002 - val_loss: 0.6963 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6957 - accuracy: 0.5028 - val_loss: 0.6951 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6947 - accuracy: 0.4947 - val_loss: 0.6943 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6935 - accuracy: 0.5003 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "1327/1339 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5006Restoring model weights from the end of the best epoch: 81.\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 82: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 0.6933 - accuracy: 0.5001\n",
      "{'loss': 0.693298876285553, 'accuracy': 0.5001260638237} \n",
      " 81 \n",
      "\n",
      "Model time: 8.725818000733852 minutes\n",
      "\n",
      "Total time: 94.7058678753674 minutes\n",
      "\n",
      "\n",
      "Model  60  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                   256\n",
      "Activation function         linear\n",
      "Dropout                        0.8\n",
      "L1                           100.0\n",
      "L2                           100.0\n",
      "Batch size                     256\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 2753227, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 4s 33ms/step - loss: 299893.8750 - accuracy: 0.4936 - val_loss: 51989.6836 - val_accuracy: 0.4401\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 10046.6104 - accuracy: 0.4995 - val_loss: 1479.8748 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 1421.0291 - accuracy: 0.4930 - val_loss: 1418.8809 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 1411.0957 - accuracy: 0.4957 - val_loss: 1398.8575 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 1403.2074 - accuracy: 0.4997 - val_loss: 1393.8145 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "80/84 [===========================>..] - ETA: 0s - loss: 1397.2037 - accuracy: 0.4948Restoring model weights from the end of the best epoch: 5.\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 1396.9695 - accuracy: 0.4955 - val_loss: 1393.8379 - val_accuracy: 0.5001\n",
      "Epoch 6: early stopping\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 1393.8145 - accuracy: 0.4999\n",
      "{'loss': 1393.814453125, 'accuracy': 0.49987393617630005} \n",
      " 5 \n",
      "\n",
      "Model time: 0.24490175023674965 minutes\n",
      "\n",
      "Total time: 94.95086963102221 minutes\n",
      "\n",
      "\n",
      "Model  61  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                     4\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.9\n",
      "L1                             1.0\n",
      "L2                            10.0\n",
      "Batch size                     256\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 3263467, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 3s 11ms/step - loss: 206.1473 - accuracy: 0.5009 - val_loss: 146.4407 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 115.2125 - accuracy: 0.5040 - val_loss: 90.3660 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 76.6338 - accuracy: 0.4995 - val_loss: 64.7539 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 56.8912 - accuracy: 0.4990 - val_loss: 48.9645 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 42.8579 - accuracy: 0.4972 - val_loss: 36.6690 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 31.9064 - accuracy: 0.4989 - val_loss: 27.1035 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 23.4352 - accuracy: 0.4969 - val_loss: 19.7806 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 16.9862 - accuracy: 0.5045 - val_loss: 14.2444 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 12.1526 - accuracy: 0.5008 - val_loss: 10.1143 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 8.5857 - accuracy: 0.5004 - val_loss: 7.1164 - val_accuracy: 0.4999\n",
      "Epoch 11/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 6.0118 - accuracy: 0.4998 - val_loss: 4.9600 - val_accuracy: 0.4999\n",
      "Epoch 12/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 4.1756 - accuracy: 0.5040 - val_loss: 3.4426 - val_accuracy: 0.4999\n",
      "Epoch 13/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 2.8890 - accuracy: 0.5010 - val_loss: 2.3810 - val_accuracy: 0.4999\n",
      "Epoch 14/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.0138 - accuracy: 0.5004 - val_loss: 1.6881 - val_accuracy: 0.4999\n",
      "Epoch 15/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4617 - accuracy: 0.5047 - val_loss: 1.2656 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.1230 - accuracy: 0.5021 - val_loss: 0.9977 - val_accuracy: 0.4999\n",
      "Epoch 17/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9163 - accuracy: 0.4946 - val_loss: 0.8546 - val_accuracy: 0.4999\n",
      "Epoch 18/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.8119 - accuracy: 0.5006 - val_loss: 0.7897 - val_accuracy: 0.4999\n",
      "Epoch 19/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7854 - accuracy: 0.4984 - val_loss: 0.7853 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 0.7856 - accuracy: 0.4995Restoring model weights from the end of the best epoch: 19.\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7856 - accuracy: 0.4976 - val_loss: 0.7869 - val_accuracy: 0.5001\n",
      "Epoch 20: early stopping\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.7853 - accuracy: 0.5001\n",
      "{'loss': 0.785346508026123, 'accuracy': 0.5001260638237} \n",
      " 19 \n",
      "\n",
      "Model time: 0.26125185191631317 minutes\n",
      "\n",
      "Total time: 95.21220479905605 minutes\n",
      "\n",
      "\n",
      "Model  62  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                   256\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.0\n",
      "L1                            10.0\n",
      "L2                            10.0\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 1361793, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 3s 13ms/step - loss: 24807.5078 - accuracy: 0.4897 - val_loss: 21021.9668 - val_accuracy: 0.4880\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 2s 9ms/step - loss: 17756.9082 - accuracy: 0.4854 - val_loss: 14642.7666 - val_accuracy: 0.4827\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 12005.9785 - accuracy: 0.4877 - val_loss: 9519.7021 - val_accuracy: 0.4973\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 2s 9ms/step - loss: 7475.7637 - accuracy: 0.4998 - val_loss: 5580.1201 - val_accuracy: 0.5011\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 4085.7390 - accuracy: 0.4947 - val_loss: 2740.9683 - val_accuracy: 0.4799\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 1758.4989 - accuracy: 0.4887 - val_loss: 922.8110 - val_accuracy: 0.4997\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 432.1872 - accuracy: 0.4997 - val_loss: 95.8378 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 32.3566 - accuracy: 0.4975 - val_loss: 16.8070 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 11.8648 - accuracy: 0.5003 - val_loss: 7.9553 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 6.6680 - accuracy: 0.5003 - val_loss: 6.3655 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "163/168 [============================>.] - ETA: 0s - loss: 6.3806 - accuracy: 0.5005Restoring model weights from the end of the best epoch: 10.\n",
      "168/168 [==============================] - 2s 9ms/step - loss: 6.3808 - accuracy: 0.5003 - val_loss: 6.3754 - val_accuracy: 0.5001\n",
      "Epoch 11: early stopping\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 6.3655 - accuracy: 0.5001\n",
      "{'loss': 6.3655171394348145, 'accuracy': 0.5001260638237} \n",
      " 10 \n",
      "\n",
      "Model time: 0.3069854900240898 minutes\n",
      "\n",
      "Total time: 95.51925699040294 minutes\n",
      "\n",
      "\n",
      "Model  63  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                    32\n",
      "Activation function           tanh\n",
      "Dropout                        0.9\n",
      "L1                         0.00001\n",
      "L2                            0.01\n",
      "Batch size                      32\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 6415025, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 7s 7ms/step - loss: 3.6313 - accuracy: 0.4961 - val_loss: 2.3758 - val_accuracy: 0.4700\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 3.2519 - accuracy: 0.5011 - val_loss: 2.2667 - val_accuracy: 0.4686\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 2.9394 - accuracy: 0.5012 - val_loss: 2.1925 - val_accuracy: 0.4695\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 2.6903 - accuracy: 0.4993 - val_loss: 2.1307 - val_accuracy: 0.4700\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 4s 7ms/step - loss: 2.4439 - accuracy: 0.5013 - val_loss: 2.0735 - val_accuracy: 0.4701\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 2.2683 - accuracy: 0.4978 - val_loss: 2.0144 - val_accuracy: 0.4704\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 2.0906 - accuracy: 0.5055 - val_loss: 1.9515 - val_accuracy: 0.4683\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 4s 7ms/step - loss: 1.9673 - accuracy: 0.4969 - val_loss: 1.8802 - val_accuracy: 0.4683\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 1.8593 - accuracy: 0.4918 - val_loss: 1.7974 - val_accuracy: 0.4673\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 1.7561 - accuracy: 0.4953 - val_loss: 1.7004 - val_accuracy: 0.4656\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 4s 7ms/step - loss: 1.6462 - accuracy: 0.5042 - val_loss: 1.5875 - val_accuracy: 0.4782\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 1.5254 - accuracy: 0.4974 - val_loss: 1.4596 - val_accuracy: 0.5501\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 4s 7ms/step - loss: 1.3914 - accuracy: 0.4959 - val_loss: 1.3213 - val_accuracy: 0.4838\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 1.2506 - accuracy: 0.5010 - val_loss: 1.1797 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 1.1116 - accuracy: 0.4982 - val_loss: 1.0450 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.9846 - accuracy: 0.5003 - val_loss: 0.9275 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "670/670 [==============================] - 4s 7ms/step - loss: 0.8792 - accuracy: 0.4973 - val_loss: 0.8350 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 0.8005 - accuracy: 0.4963 - val_loss: 0.7705 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7493 - accuracy: 0.4989 - val_loss: 0.7317 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7205 - accuracy: 0.5002 - val_loss: 0.7117 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 0.7066 - accuracy: 0.4961 - val_loss: 0.7027 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7005 - accuracy: 0.5015 - val_loss: 0.6988 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 0.6977 - accuracy: 0.4954 - val_loss: 0.6968 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6961 - accuracy: 0.4940 - val_loss: 0.6955 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 0.6950 - accuracy: 0.4958 - val_loss: 0.6946 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "670/670 [==============================] - 4s 7ms/step - loss: 0.6942 - accuracy: 0.5003 - val_loss: 0.6939 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6937 - accuracy: 0.4987 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "670/670 [==============================] - 4s 7ms/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6932 - accuracy: 0.4977 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.4999\n",
      "Epoch 31/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "659/670 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.4985Restoring model weights from the end of the best epoch: 32.\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6931 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 33: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "{'loss': 0.6931531429290771, 'accuracy': 0.5001260638237} \n",
      " 32 \n",
      "\n",
      "Model time: 2.4855343103408813 minutes\n",
      "\n",
      "Total time: 98.0048413015902 minutes\n",
      "\n",
      "\n",
      "Model  64  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                   128\n",
      "Activation function         linear\n",
      "Dropout                        0.8\n",
      "L1                         0.00001\n",
      "L2                          0.0001\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 4000685, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 6s 12ms/step - loss: 4.6637 - accuracy: 0.5020 - val_loss: 0.8016 - val_accuracy: 0.5767\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 4s 12ms/step - loss: 3.6079 - accuracy: 0.5054 - val_loss: 0.7631 - val_accuracy: 0.5938\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 3s 10ms/step - loss: 2.8803 - accuracy: 0.5064 - val_loss: 0.7466 - val_accuracy: 0.6029\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 4s 11ms/step - loss: 2.3665 - accuracy: 0.5051 - val_loss: 0.7418 - val_accuracy: 0.6067\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 3s 10ms/step - loss: 1.9212 - accuracy: 0.5060 - val_loss: 0.7396 - val_accuracy: 0.6137\n",
      "Epoch 6/300\n",
      "331/335 [============================>.] - ETA: 0s - loss: 1.5498 - accuracy: 0.5150Restoring model weights from the end of the best epoch: 5.\n",
      "335/335 [==============================] - 3s 10ms/step - loss: 1.5465 - accuracy: 0.5149 - val_loss: 0.7413 - val_accuracy: 0.6118\n",
      "Epoch 6: early stopping\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.7396 - accuracy: 0.6137\n",
      "{'loss': 0.7395886778831482, 'accuracy': 0.6137245893478394} \n",
      " 5 \n",
      "\n",
      "Model time: 0.4295197054743767 minutes\n",
      "\n",
      "Total time: 98.43442768231034 minutes\n",
      "\n",
      "\n",
      "Model  65  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     2\n",
      "Activation function         linear\n",
      "Dropout                        0.4\n",
      "L1                            10.0\n",
      "L2                         0.00001\n",
      "Batch size                      64\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 250104, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 7ms/step - loss: 343.1201 - accuracy: 0.4966 - val_loss: 337.2724 - val_accuracy: 0.4796\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 331.7052 - accuracy: 0.5016 - val_loss: 325.9682 - val_accuracy: 0.4794\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 320.5475 - accuracy: 0.4977 - val_loss: 314.9352 - val_accuracy: 0.4799\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 309.6488 - accuracy: 0.4905 - val_loss: 304.1861 - val_accuracy: 0.4797\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 299.0191 - accuracy: 0.4992 - val_loss: 293.7081 - val_accuracy: 0.4791\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 288.6527 - accuracy: 0.4957 - val_loss: 283.4319 - val_accuracy: 0.4785\n",
      "Epoch 7/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 278.4626 - accuracy: 0.4956 - val_loss: 273.3438 - val_accuracy: 0.4779\n",
      "Epoch 8/300\n",
      "335/335 [==============================] - 3s 8ms/step - loss: 268.4753 - accuracy: 0.4921 - val_loss: 263.4686 - val_accuracy: 0.4771\n",
      "Epoch 9/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 258.7556 - accuracy: 0.4961 - val_loss: 253.9021 - val_accuracy: 0.4771\n",
      "Epoch 10/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 249.3026 - accuracy: 0.4974 - val_loss: 244.5659 - val_accuracy: 0.4769\n",
      "Epoch 11/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 240.0501 - accuracy: 0.4958 - val_loss: 235.3835 - val_accuracy: 0.4754\n",
      "Epoch 12/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 230.9253 - accuracy: 0.4918 - val_loss: 226.3586 - val_accuracy: 0.4762\n",
      "Epoch 13/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 221.9738 - accuracy: 0.4930 - val_loss: 217.4737 - val_accuracy: 0.4770\n",
      "Epoch 14/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 213.1738 - accuracy: 0.4967 - val_loss: 208.7689 - val_accuracy: 0.4771\n",
      "Epoch 15/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 204.6070 - accuracy: 0.4925 - val_loss: 200.3218 - val_accuracy: 0.4797\n",
      "Epoch 16/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 196.2258 - accuracy: 0.4967 - val_loss: 192.0231 - val_accuracy: 0.4817\n",
      "Epoch 17/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 187.9967 - accuracy: 0.4949 - val_loss: 183.9038 - val_accuracy: 0.4836\n",
      "Epoch 18/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 179.9988 - accuracy: 0.4966 - val_loss: 176.0052 - val_accuracy: 0.4847\n",
      "Epoch 19/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 172.2222 - accuracy: 0.4959 - val_loss: 168.3616 - val_accuracy: 0.4857\n",
      "Epoch 20/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 164.6501 - accuracy: 0.4998 - val_loss: 160.9062 - val_accuracy: 0.4859\n",
      "Epoch 21/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 157.3383 - accuracy: 0.4969 - val_loss: 153.6991 - val_accuracy: 0.4870\n",
      "Epoch 22/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 150.2084 - accuracy: 0.5005 - val_loss: 146.6598 - val_accuracy: 0.4904\n",
      "Epoch 23/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 143.2553 - accuracy: 0.4981 - val_loss: 139.8097 - val_accuracy: 0.4920\n",
      "Epoch 24/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 136.4832 - accuracy: 0.4993 - val_loss: 133.1236 - val_accuracy: 0.4952\n",
      "Epoch 25/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 129.9580 - accuracy: 0.4996 - val_loss: 126.7574 - val_accuracy: 0.4962\n",
      "Epoch 26/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 123.6767 - accuracy: 0.4994 - val_loss: 120.5463 - val_accuracy: 0.4969\n",
      "Epoch 27/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 117.5519 - accuracy: 0.4956 - val_loss: 114.5335 - val_accuracy: 0.4990\n",
      "Epoch 28/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 111.6175 - accuracy: 0.4920 - val_loss: 108.6747 - val_accuracy: 0.5003\n",
      "Epoch 29/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 105.8748 - accuracy: 0.4966 - val_loss: 103.0617 - val_accuracy: 0.5013\n",
      "Epoch 30/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 100.3618 - accuracy: 0.4994 - val_loss: 97.6682 - val_accuracy: 0.5010\n",
      "Epoch 31/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 95.1124 - accuracy: 0.5004 - val_loss: 92.5486 - val_accuracy: 0.5009\n",
      "Epoch 32/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 90.0575 - accuracy: 0.4985 - val_loss: 87.5675 - val_accuracy: 0.5004\n",
      "Epoch 33/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 85.1904 - accuracy: 0.4989 - val_loss: 82.8105 - val_accuracy: 0.4980\n",
      "Epoch 34/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 80.5212 - accuracy: 0.5021 - val_loss: 78.2238 - val_accuracy: 0.4965\n",
      "Epoch 35/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 76.0083 - accuracy: 0.5028 - val_loss: 73.8210 - val_accuracy: 0.4947\n",
      "Epoch 36/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 71.7611 - accuracy: 0.5049 - val_loss: 69.7119 - val_accuracy: 0.4956\n",
      "Epoch 37/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 67.6998 - accuracy: 0.4982 - val_loss: 65.6784 - val_accuracy: 0.4949\n",
      "Epoch 38/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 63.7109 - accuracy: 0.4984 - val_loss: 61.7352 - val_accuracy: 0.4954\n",
      "Epoch 39/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 59.8496 - accuracy: 0.4985 - val_loss: 58.0207 - val_accuracy: 0.4948\n",
      "Epoch 40/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 56.3182 - accuracy: 0.5016 - val_loss: 54.6670 - val_accuracy: 0.4936\n",
      "Epoch 41/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 53.1400 - accuracy: 0.4940 - val_loss: 51.6258 - val_accuracy: 0.4937\n",
      "Epoch 42/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 50.1998 - accuracy: 0.4988 - val_loss: 48.7810 - val_accuracy: 0.4907\n",
      "Epoch 43/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 47.4371 - accuracy: 0.4978 - val_loss: 46.1346 - val_accuracy: 0.4904\n",
      "Epoch 44/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 44.9073 - accuracy: 0.4944 - val_loss: 43.6965 - val_accuracy: 0.4911\n",
      "Epoch 45/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 42.5752 - accuracy: 0.4964 - val_loss: 41.5015 - val_accuracy: 0.4917\n",
      "Epoch 46/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 40.5507 - accuracy: 0.4953 - val_loss: 39.6178 - val_accuracy: 0.4941\n",
      "Epoch 47/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 38.7067 - accuracy: 0.4972 - val_loss: 37.8087 - val_accuracy: 0.4938\n",
      "Epoch 48/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 36.9898 - accuracy: 0.4984 - val_loss: 36.2183 - val_accuracy: 0.4956\n",
      "Epoch 49/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 35.5526 - accuracy: 0.4976 - val_loss: 34.9124 - val_accuracy: 0.4974\n",
      "Epoch 50/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 34.3177 - accuracy: 0.4992 - val_loss: 33.7631 - val_accuracy: 0.4968\n",
      "Epoch 51/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 33.2553 - accuracy: 0.4983 - val_loss: 32.7536 - val_accuracy: 0.4977\n",
      "Epoch 52/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 32.3127 - accuracy: 0.4987 - val_loss: 31.9255 - val_accuracy: 0.4995\n",
      "Epoch 53/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 31.6248 - accuracy: 0.4995 - val_loss: 31.3365 - val_accuracy: 0.4999\n",
      "Epoch 54/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 31.0622 - accuracy: 0.4997 - val_loss: 30.8118 - val_accuracy: 0.4999\n",
      "Epoch 55/300\n",
      "335/335 [==============================] - 2s 4ms/step - loss: 30.6209 - accuracy: 0.4997 - val_loss: 30.4472 - val_accuracy: 0.4999\n",
      "Epoch 56/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 30.3670 - accuracy: 0.4997 - val_loss: 30.2985 - val_accuracy: 0.4999\n",
      "Epoch 57/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 30.2316 - accuracy: 0.4997 - val_loss: 30.1640 - val_accuracy: 0.4999\n",
      "Epoch 58/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 30.0973 - accuracy: 0.4997 - val_loss: 30.0301 - val_accuracy: 0.4999\n",
      "Epoch 59/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.9631 - accuracy: 0.4997 - val_loss: 29.8954 - val_accuracy: 0.4999\n",
      "Epoch 60/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.8288 - accuracy: 0.4997 - val_loss: 29.7613 - val_accuracy: 0.4999\n",
      "Epoch 61/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.6945 - accuracy: 0.4997 - val_loss: 29.6269 - val_accuracy: 0.4999\n",
      "Epoch 62/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 29.5602 - accuracy: 0.4997 - val_loss: 29.4928 - val_accuracy: 0.4999\n",
      "Epoch 63/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.4261 - accuracy: 0.4997 - val_loss: 29.3585 - val_accuracy: 0.4999\n",
      "Epoch 64/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.2919 - accuracy: 0.4997 - val_loss: 29.2242 - val_accuracy: 0.4999\n",
      "Epoch 65/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.1577 - accuracy: 0.4997 - val_loss: 29.0899 - val_accuracy: 0.4999\n",
      "Epoch 66/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.0233 - accuracy: 0.4997 - val_loss: 28.9559 - val_accuracy: 0.4999\n",
      "Epoch 67/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 28.8893 - accuracy: 0.4997 - val_loss: 28.8216 - val_accuracy: 0.4999\n",
      "Epoch 68/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 28.7551 - accuracy: 0.4997 - val_loss: 28.6876 - val_accuracy: 0.4999\n",
      "Epoch 69/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 28.6209 - accuracy: 0.4997 - val_loss: 28.5532 - val_accuracy: 0.4999\n",
      "Epoch 70/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 28.4867 - accuracy: 0.4997 - val_loss: 28.4190 - val_accuracy: 0.4999\n",
      "Epoch 71/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 28.3524 - accuracy: 0.4997 - val_loss: 28.2850 - val_accuracy: 0.4999\n",
      "Epoch 72/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 28.2183 - accuracy: 0.4997 - val_loss: 28.1509 - val_accuracy: 0.4999\n",
      "Epoch 73/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 28.0840 - accuracy: 0.4997 - val_loss: 28.0164 - val_accuracy: 0.4999\n",
      "Epoch 74/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 27.9498 - accuracy: 0.4997 - val_loss: 27.8825 - val_accuracy: 0.4999\n",
      "Epoch 75/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 27.8155 - accuracy: 0.4997 - val_loss: 27.7484 - val_accuracy: 0.4999\n",
      "Epoch 76/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 27.6814 - accuracy: 0.4997 - val_loss: 27.6141 - val_accuracy: 0.4999\n",
      "Epoch 77/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 27.5472 - accuracy: 0.4997 - val_loss: 27.4799 - val_accuracy: 0.4999\n",
      "Epoch 78/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 27.4131 - accuracy: 0.4997 - val_loss: 27.3454 - val_accuracy: 0.4999\n",
      "Epoch 79/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 27.2789 - accuracy: 0.4997 - val_loss: 27.2117 - val_accuracy: 0.4999\n",
      "Epoch 80/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 27.1447 - accuracy: 0.4990 - val_loss: 27.0773 - val_accuracy: 0.4999\n",
      "Epoch 81/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 27.0105 - accuracy: 0.4968 - val_loss: 26.9430 - val_accuracy: 0.4999\n",
      "Epoch 82/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 26.8762 - accuracy: 0.5017 - val_loss: 26.8088 - val_accuracy: 0.4999\n",
      "Epoch 83/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 26.7420 - accuracy: 0.5038 - val_loss: 26.6746 - val_accuracy: 0.4999\n",
      "Epoch 84/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 26.6079 - accuracy: 0.4982 - val_loss: 26.5405 - val_accuracy: 0.4999\n",
      "Epoch 85/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 26.4737 - accuracy: 0.5016 - val_loss: 26.4060 - val_accuracy: 0.4999\n",
      "Epoch 86/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 26.3395 - accuracy: 0.5006 - val_loss: 26.2719 - val_accuracy: 0.4999\n",
      "Epoch 87/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 26.2053 - accuracy: 0.4988 - val_loss: 26.1380 - val_accuracy: 0.4999\n",
      "Epoch 88/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 26.0713 - accuracy: 0.4936 - val_loss: 26.0037 - val_accuracy: 0.4999\n",
      "Epoch 89/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 25.9370 - accuracy: 0.5005 - val_loss: 25.8696 - val_accuracy: 0.4999\n",
      "Epoch 90/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 25.8028 - accuracy: 0.4983 - val_loss: 25.7353 - val_accuracy: 0.4999\n",
      "Epoch 91/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 25.6685 - accuracy: 0.4988 - val_loss: 25.6009 - val_accuracy: 0.4999\n",
      "Epoch 92/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 25.5344 - accuracy: 0.4945 - val_loss: 25.4671 - val_accuracy: 0.4999\n",
      "Epoch 93/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 25.4002 - accuracy: 0.5060 - val_loss: 25.3330 - val_accuracy: 0.4999\n",
      "Epoch 94/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 25.2660 - accuracy: 0.4949 - val_loss: 25.1985 - val_accuracy: 0.4999\n",
      "Epoch 95/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 25.1318 - accuracy: 0.5015 - val_loss: 25.0644 - val_accuracy: 0.4999\n",
      "Epoch 96/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.9976 - accuracy: 0.5071 - val_loss: 24.9303 - val_accuracy: 0.4999\n",
      "Epoch 97/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.8635 - accuracy: 0.4994 - val_loss: 24.7962 - val_accuracy: 0.4999\n",
      "Epoch 98/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.7294 - accuracy: 0.4980 - val_loss: 24.6617 - val_accuracy: 0.4999\n",
      "Epoch 99/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.5953 - accuracy: 0.4996 - val_loss: 24.5278 - val_accuracy: 0.4999\n",
      "Epoch 100/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 24.4611 - accuracy: 0.5027 - val_loss: 24.3935 - val_accuracy: 0.4999\n",
      "Epoch 101/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.3269 - accuracy: 0.5025 - val_loss: 24.2598 - val_accuracy: 0.4999\n",
      "Epoch 102/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.1929 - accuracy: 0.4964 - val_loss: 24.1255 - val_accuracy: 0.4999\n",
      "Epoch 103/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.0587 - accuracy: 0.5000 - val_loss: 23.9911 - val_accuracy: 0.4999\n",
      "Epoch 104/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 23.9245 - accuracy: 0.4982 - val_loss: 23.8571 - val_accuracy: 0.4999\n",
      "Epoch 105/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 23.7904 - accuracy: 0.5046 - val_loss: 23.7231 - val_accuracy: 0.4999\n",
      "Epoch 106/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 23.6563 - accuracy: 0.4929 - val_loss: 23.5891 - val_accuracy: 0.4999\n",
      "Epoch 107/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 23.5222 - accuracy: 0.4989 - val_loss: 23.4548 - val_accuracy: 0.4999\n",
      "Epoch 108/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 23.3880 - accuracy: 0.4980 - val_loss: 23.3207 - val_accuracy: 0.4999\n",
      "Epoch 109/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 23.2539 - accuracy: 0.4985 - val_loss: 23.1865 - val_accuracy: 0.4999\n",
      "Epoch 110/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 23.1197 - accuracy: 0.5006 - val_loss: 23.0524 - val_accuracy: 0.4999\n",
      "Epoch 111/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 22.9856 - accuracy: 0.4965 - val_loss: 22.9182 - val_accuracy: 0.4999\n",
      "Epoch 112/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 22.8515 - accuracy: 0.5013 - val_loss: 22.7841 - val_accuracy: 0.4999\n",
      "Epoch 113/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 22.7173 - accuracy: 0.4996 - val_loss: 22.6500 - val_accuracy: 0.4999\n",
      "Epoch 114/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 22.5832 - accuracy: 0.4977 - val_loss: 22.5157 - val_accuracy: 0.5002\n",
      "Epoch 115/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 22.4491 - accuracy: 0.4945 - val_loss: 22.3817 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 22.3149 - accuracy: 0.4936 - val_loss: 22.2474 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 22.1808 - accuracy: 0.5043 - val_loss: 22.1133 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 22.0466 - accuracy: 0.5006 - val_loss: 21.9792 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 21.9125 - accuracy: 0.5034 - val_loss: 21.8448 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 21.7783 - accuracy: 0.5006 - val_loss: 21.7108 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 21.6443 - accuracy: 0.5054 - val_loss: 21.5768 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 21.5102 - accuracy: 0.5040 - val_loss: 21.4428 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 21.3761 - accuracy: 0.4925 - val_loss: 21.3086 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 21.2420 - accuracy: 0.4988 - val_loss: 21.1747 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 21.1078 - accuracy: 0.4992 - val_loss: 21.0404 - val_accuracy: 0.5001\n",
      "Epoch 126/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 20.9737 - accuracy: 0.4985 - val_loss: 20.9063 - val_accuracy: 0.5001\n",
      "Epoch 127/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 20.8395 - accuracy: 0.4962 - val_loss: 20.7719 - val_accuracy: 0.5001\n",
      "Epoch 128/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 20.7054 - accuracy: 0.4955 - val_loss: 20.6381 - val_accuracy: 0.5001\n",
      "Epoch 129/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 20.5713 - accuracy: 0.5015 - val_loss: 20.5039 - val_accuracy: 0.5001\n",
      "Epoch 130/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 20.4372 - accuracy: 0.4937 - val_loss: 20.3696 - val_accuracy: 0.5001\n",
      "Epoch 131/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 20.3030 - accuracy: 0.4992 - val_loss: 20.2353 - val_accuracy: 0.5001\n",
      "Epoch 132/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 20.1688 - accuracy: 0.5030 - val_loss: 20.1016 - val_accuracy: 0.5001\n",
      "Epoch 133/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 20.0347 - accuracy: 0.5027 - val_loss: 19.9675 - val_accuracy: 0.5001\n",
      "Epoch 134/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.9006 - accuracy: 0.4988 - val_loss: 19.8332 - val_accuracy: 0.5001\n",
      "Epoch 135/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.7665 - accuracy: 0.4960 - val_loss: 19.6991 - val_accuracy: 0.5001\n",
      "Epoch 136/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 19.6323 - accuracy: 0.4995 - val_loss: 19.5650 - val_accuracy: 0.5001\n",
      "Epoch 137/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.4982 - accuracy: 0.5028 - val_loss: 19.4307 - val_accuracy: 0.5001\n",
      "Epoch 138/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.3640 - accuracy: 0.5032 - val_loss: 19.2964 - val_accuracy: 0.5001\n",
      "Epoch 139/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.2299 - accuracy: 0.4961 - val_loss: 19.1625 - val_accuracy: 0.5001\n",
      "Epoch 140/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 19.0958 - accuracy: 0.5012 - val_loss: 19.0283 - val_accuracy: 0.5001\n",
      "Epoch 141/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.9617 - accuracy: 0.4974 - val_loss: 18.8945 - val_accuracy: 0.5001\n",
      "Epoch 142/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.8276 - accuracy: 0.4943 - val_loss: 18.7603 - val_accuracy: 0.5001\n",
      "Epoch 143/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.6934 - accuracy: 0.4977 - val_loss: 18.6261 - val_accuracy: 0.5001\n",
      "Epoch 144/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 18.5593 - accuracy: 0.4948 - val_loss: 18.4919 - val_accuracy: 0.5001\n",
      "Epoch 145/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.4251 - accuracy: 0.5031 - val_loss: 18.3579 - val_accuracy: 0.5001\n",
      "Epoch 146/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.2910 - accuracy: 0.4969 - val_loss: 18.2238 - val_accuracy: 0.5001\n",
      "Epoch 147/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.1569 - accuracy: 0.4989 - val_loss: 18.0897 - val_accuracy: 0.5001\n",
      "Epoch 148/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.0227 - accuracy: 0.4999 - val_loss: 17.9554 - val_accuracy: 0.5001\n",
      "Epoch 149/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.8886 - accuracy: 0.5050 - val_loss: 17.8216 - val_accuracy: 0.5001\n",
      "Epoch 150/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 17.7545 - accuracy: 0.4955 - val_loss: 17.6870 - val_accuracy: 0.5001\n",
      "Epoch 151/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.6204 - accuracy: 0.4953 - val_loss: 17.5530 - val_accuracy: 0.5001\n",
      "Epoch 152/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.4862 - accuracy: 0.4987 - val_loss: 17.4189 - val_accuracy: 0.5001\n",
      "Epoch 153/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.3521 - accuracy: 0.4940 - val_loss: 17.2847 - val_accuracy: 0.5001\n",
      "Epoch 154/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.2179 - accuracy: 0.5000 - val_loss: 17.1506 - val_accuracy: 0.5001\n",
      "Epoch 155/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.0838 - accuracy: 0.4979 - val_loss: 17.0164 - val_accuracy: 0.5001\n",
      "Epoch 156/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 16.9497 - accuracy: 0.5000 - val_loss: 16.8820 - val_accuracy: 0.5001\n",
      "Epoch 157/300\n",
      "335/335 [==============================] - 2s 4ms/step - loss: 16.8156 - accuracy: 0.4955 - val_loss: 16.7484 - val_accuracy: 0.5001\n",
      "Epoch 158/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.6814 - accuracy: 0.5004 - val_loss: 16.6141 - val_accuracy: 0.5001\n",
      "Epoch 159/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.5473 - accuracy: 0.5091 - val_loss: 16.4797 - val_accuracy: 0.5001\n",
      "Epoch 160/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 16.4132 - accuracy: 0.5000 - val_loss: 16.3456 - val_accuracy: 0.5001\n",
      "Epoch 161/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.2790 - accuracy: 0.5063 - val_loss: 16.2115 - val_accuracy: 0.5001\n",
      "Epoch 162/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.1449 - accuracy: 0.5067 - val_loss: 16.0776 - val_accuracy: 0.5001\n",
      "Epoch 163/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.0107 - accuracy: 0.4992 - val_loss: 15.9432 - val_accuracy: 0.5001\n",
      "Epoch 164/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 15.8765 - accuracy: 0.4976 - val_loss: 15.8092 - val_accuracy: 0.5001\n",
      "Epoch 165/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.7424 - accuracy: 0.4980 - val_loss: 15.6750 - val_accuracy: 0.5001\n",
      "Epoch 166/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.6083 - accuracy: 0.4947 - val_loss: 15.5406 - val_accuracy: 0.5001\n",
      "Epoch 167/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.4741 - accuracy: 0.5045 - val_loss: 15.4068 - val_accuracy: 0.5001\n",
      "Epoch 168/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.3400 - accuracy: 0.5046 - val_loss: 15.2726 - val_accuracy: 0.5001\n",
      "Epoch 169/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.2059 - accuracy: 0.5039 - val_loss: 15.1387 - val_accuracy: 0.5001\n",
      "Epoch 170/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 15.0717 - accuracy: 0.5027 - val_loss: 15.0041 - val_accuracy: 0.5001\n",
      "Epoch 171/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.9534 - accuracy: 0.4982 - val_loss: 14.9029 - val_accuracy: 0.5001\n",
      "Epoch 172/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.8528 - accuracy: 0.5032 - val_loss: 14.8024 - val_accuracy: 0.5001\n",
      "Epoch 173/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.7522 - accuracy: 0.5026 - val_loss: 14.7017 - val_accuracy: 0.5001\n",
      "Epoch 174/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.6516 - accuracy: 0.4991 - val_loss: 14.6014 - val_accuracy: 0.5001\n",
      "Epoch 175/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.5510 - accuracy: 0.4990 - val_loss: 14.5007 - val_accuracy: 0.5001\n",
      "Epoch 176/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 14.4505 - accuracy: 0.5063 - val_loss: 14.3995 - val_accuracy: 0.5001\n",
      "Epoch 177/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.3498 - accuracy: 0.4961 - val_loss: 14.2990 - val_accuracy: 0.5001\n",
      "Epoch 178/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 14.2493 - accuracy: 0.4998 - val_loss: 14.1988 - val_accuracy: 0.5001\n",
      "Epoch 179/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.1488 - accuracy: 0.4984 - val_loss: 14.0984 - val_accuracy: 0.5001\n",
      "Epoch 180/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.0482 - accuracy: 0.5032 - val_loss: 13.9976 - val_accuracy: 0.5001\n",
      "Epoch 181/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.9476 - accuracy: 0.4951 - val_loss: 13.8969 - val_accuracy: 0.5001\n",
      "Epoch 182/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.8470 - accuracy: 0.5033 - val_loss: 13.7964 - val_accuracy: 0.5001\n",
      "Epoch 183/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.7464 - accuracy: 0.5033 - val_loss: 13.6957 - val_accuracy: 0.5001\n",
      "Epoch 184/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 13.6458 - accuracy: 0.5001 - val_loss: 13.5955 - val_accuracy: 0.5001\n",
      "Epoch 185/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.5452 - accuracy: 0.4952 - val_loss: 13.4946 - val_accuracy: 0.5001\n",
      "Epoch 186/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.4446 - accuracy: 0.4980 - val_loss: 13.3939 - val_accuracy: 0.5001\n",
      "Epoch 187/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.3440 - accuracy: 0.5015 - val_loss: 13.2937 - val_accuracy: 0.5001\n",
      "Epoch 188/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.2434 - accuracy: 0.4967 - val_loss: 13.1926 - val_accuracy: 0.5001\n",
      "Epoch 189/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.1428 - accuracy: 0.5025 - val_loss: 13.0921 - val_accuracy: 0.5001\n",
      "Epoch 190/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 13.0422 - accuracy: 0.4976 - val_loss: 12.9916 - val_accuracy: 0.5001\n",
      "Epoch 191/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12.9417 - accuracy: 0.5015 - val_loss: 12.8912 - val_accuracy: 0.5001\n",
      "Epoch 192/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 12.8410 - accuracy: 0.5036 - val_loss: 12.7907 - val_accuracy: 0.5001\n",
      "Epoch 193/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12.7405 - accuracy: 0.4998 - val_loss: 12.6899 - val_accuracy: 0.5001\n",
      "Epoch 194/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12.6398 - accuracy: 0.4949 - val_loss: 12.5893 - val_accuracy: 0.5001\n",
      "Epoch 195/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12.5392 - accuracy: 0.4988 - val_loss: 12.4889 - val_accuracy: 0.5001\n",
      "Epoch 196/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 12.4387 - accuracy: 0.5026 - val_loss: 12.3880 - val_accuracy: 0.5001\n",
      "Epoch 197/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 12.3381 - accuracy: 0.4992 - val_loss: 12.2877 - val_accuracy: 0.5001\n",
      "Epoch 198/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 12.2375 - accuracy: 0.4968 - val_loss: 12.1870 - val_accuracy: 0.5001\n",
      "Epoch 199/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12.1369 - accuracy: 0.4979 - val_loss: 12.0863 - val_accuracy: 0.5001\n",
      "Epoch 200/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 12.0363 - accuracy: 0.5004 - val_loss: 11.9857 - val_accuracy: 0.5001\n",
      "Epoch 201/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 11.9358 - accuracy: 0.4979 - val_loss: 11.8851 - val_accuracy: 0.5001\n",
      "Epoch 202/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.8352 - accuracy: 0.5003 - val_loss: 11.7848 - val_accuracy: 0.5001\n",
      "Epoch 203/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.7346 - accuracy: 0.5003 - val_loss: 11.6845 - val_accuracy: 0.5001\n",
      "Epoch 204/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 11.6340 - accuracy: 0.5004 - val_loss: 11.5834 - val_accuracy: 0.5001\n",
      "Epoch 205/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.5334 - accuracy: 0.5015 - val_loss: 11.4829 - val_accuracy: 0.5001\n",
      "Epoch 206/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.4328 - accuracy: 0.4994 - val_loss: 11.3822 - val_accuracy: 0.5001\n",
      "Epoch 207/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.3322 - accuracy: 0.4975 - val_loss: 11.2815 - val_accuracy: 0.5001\n",
      "Epoch 208/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 11.2316 - accuracy: 0.5003 - val_loss: 11.1812 - val_accuracy: 0.5001\n",
      "Epoch 209/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 11.1311 - accuracy: 0.5016 - val_loss: 11.0806 - val_accuracy: 0.5001\n",
      "Epoch 210/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 11.0305 - accuracy: 0.4988 - val_loss: 10.9799 - val_accuracy: 0.5001\n",
      "Epoch 211/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.9300 - accuracy: 0.5001 - val_loss: 10.8795 - val_accuracy: 0.5001\n",
      "Epoch 212/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 10.8293 - accuracy: 0.5000 - val_loss: 10.7789 - val_accuracy: 0.5001\n",
      "Epoch 213/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.7287 - accuracy: 0.4998 - val_loss: 10.6785 - val_accuracy: 0.5001\n",
      "Epoch 214/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.6281 - accuracy: 0.5003 - val_loss: 10.5777 - val_accuracy: 0.5001\n",
      "Epoch 215/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.5275 - accuracy: 0.5003 - val_loss: 10.4772 - val_accuracy: 0.5001\n",
      "Epoch 216/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 10.4269 - accuracy: 0.5003 - val_loss: 10.3764 - val_accuracy: 0.5001\n",
      "Epoch 217/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.3264 - accuracy: 0.5003 - val_loss: 10.2757 - val_accuracy: 0.5001\n",
      "Epoch 218/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 10.2258 - accuracy: 0.5003 - val_loss: 10.1752 - val_accuracy: 0.5001\n",
      "Epoch 219/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 10.1252 - accuracy: 0.5003 - val_loss: 10.0747 - val_accuracy: 0.5001\n",
      "Epoch 220/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 10.0246 - accuracy: 0.4989 - val_loss: 9.9745 - val_accuracy: 0.5001\n",
      "Epoch 221/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.9240 - accuracy: 0.5003 - val_loss: 9.8736 - val_accuracy: 0.5001\n",
      "Epoch 222/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.8234 - accuracy: 0.5003 - val_loss: 9.7729 - val_accuracy: 0.5001\n",
      "Epoch 223/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.7228 - accuracy: 0.5003 - val_loss: 9.6724 - val_accuracy: 0.5001\n",
      "Epoch 224/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 9.6223 - accuracy: 0.5003 - val_loss: 9.5716 - val_accuracy: 0.5001\n",
      "Epoch 225/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.5216 - accuracy: 0.5003 - val_loss: 9.4709 - val_accuracy: 0.5001\n",
      "Epoch 226/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.4211 - accuracy: 0.5003 - val_loss: 9.3705 - val_accuracy: 0.5001\n",
      "Epoch 227/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.3205 - accuracy: 0.5003 - val_loss: 9.2702 - val_accuracy: 0.5001\n",
      "Epoch 228/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 9.2199 - accuracy: 0.5003 - val_loss: 9.1694 - val_accuracy: 0.5001\n",
      "Epoch 229/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 9.1193 - accuracy: 0.5003 - val_loss: 9.0688 - val_accuracy: 0.5001\n",
      "Epoch 230/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 9.0187 - accuracy: 0.5003 - val_loss: 8.9680 - val_accuracy: 0.5001\n",
      "Epoch 231/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.9181 - accuracy: 0.5003 - val_loss: 8.8678 - val_accuracy: 0.5001\n",
      "Epoch 232/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 8.8176 - accuracy: 0.5003 - val_loss: 8.7672 - val_accuracy: 0.5001\n",
      "Epoch 233/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.7170 - accuracy: 0.5003 - val_loss: 8.6664 - val_accuracy: 0.5001\n",
      "Epoch 234/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.6164 - accuracy: 0.5003 - val_loss: 8.5659 - val_accuracy: 0.5001\n",
      "Epoch 235/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.5159 - accuracy: 0.5003 - val_loss: 8.4650 - val_accuracy: 0.5001\n",
      "Epoch 236/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 8.4152 - accuracy: 0.5003 - val_loss: 8.3646 - val_accuracy: 0.5001\n",
      "Epoch 237/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.3146 - accuracy: 0.5003 - val_loss: 8.2643 - val_accuracy: 0.5001\n",
      "Epoch 238/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 8.2141 - accuracy: 0.5003 - val_loss: 8.1637 - val_accuracy: 0.5001\n",
      "Epoch 239/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.1135 - accuracy: 0.5003 - val_loss: 8.0628 - val_accuracy: 0.5001\n",
      "Epoch 240/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 8.0129 - accuracy: 0.5003 - val_loss: 7.9623 - val_accuracy: 0.5001\n",
      "Epoch 241/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 7.9123 - accuracy: 0.5003 - val_loss: 7.8618 - val_accuracy: 0.5001\n",
      "Epoch 242/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.8117 - accuracy: 0.5003 - val_loss: 7.7610 - val_accuracy: 0.5001\n",
      "Epoch 243/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.7111 - accuracy: 0.5003 - val_loss: 7.6608 - val_accuracy: 0.5001\n",
      "Epoch 244/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 7.6105 - accuracy: 0.5003 - val_loss: 7.5601 - val_accuracy: 0.5001\n",
      "Epoch 245/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.5099 - accuracy: 0.5003 - val_loss: 7.4594 - val_accuracy: 0.5001\n",
      "Epoch 246/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.4093 - accuracy: 0.5003 - val_loss: 7.3587 - val_accuracy: 0.5001\n",
      "Epoch 247/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.3088 - accuracy: 0.5003 - val_loss: 7.2587 - val_accuracy: 0.5001\n",
      "Epoch 248/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.2253 - accuracy: 0.5003 - val_loss: 7.1914 - val_accuracy: 0.5001\n",
      "Epoch 249/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 7.1582 - accuracy: 0.5003 - val_loss: 7.1246 - val_accuracy: 0.5001\n",
      "Epoch 250/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.0911 - accuracy: 0.5003 - val_loss: 7.0574 - val_accuracy: 0.5001\n",
      "Epoch 251/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7.0240 - accuracy: 0.5003 - val_loss: 6.9904 - val_accuracy: 0.5001\n",
      "Epoch 252/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6.9569 - accuracy: 0.5003 - val_loss: 6.9234 - val_accuracy: 0.5001\n",
      "Epoch 253/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.8898 - accuracy: 0.5003 - val_loss: 6.8561 - val_accuracy: 0.5001\n",
      "Epoch 254/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.8227 - accuracy: 0.5003 - val_loss: 6.7889 - val_accuracy: 0.5001\n",
      "Epoch 255/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.7556 - accuracy: 0.5003 - val_loss: 6.7220 - val_accuracy: 0.5001\n",
      "Epoch 256/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.6886 - accuracy: 0.5003 - val_loss: 6.6550 - val_accuracy: 0.5001\n",
      "Epoch 257/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.6214 - accuracy: 0.5003 - val_loss: 6.5878 - val_accuracy: 0.5001\n",
      "Epoch 258/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.5544 - accuracy: 0.5003 - val_loss: 6.5205 - val_accuracy: 0.5001\n",
      "Epoch 259/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.4873 - accuracy: 0.5003 - val_loss: 6.4536 - val_accuracy: 0.5001\n",
      "Epoch 260/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6.4201 - accuracy: 0.5003 - val_loss: 6.3865 - val_accuracy: 0.5001\n",
      "Epoch 261/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.3531 - accuracy: 0.5003 - val_loss: 6.3194 - val_accuracy: 0.5001\n",
      "Epoch 262/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.2860 - accuracy: 0.5003 - val_loss: 6.2523 - val_accuracy: 0.5001\n",
      "Epoch 263/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6.2189 - accuracy: 0.5003 - val_loss: 6.1853 - val_accuracy: 0.5001\n",
      "Epoch 264/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.1518 - accuracy: 0.5003 - val_loss: 6.1183 - val_accuracy: 0.5001\n",
      "Epoch 265/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6.0848 - accuracy: 0.5003 - val_loss: 6.0509 - val_accuracy: 0.5001\n",
      "Epoch 266/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.0177 - accuracy: 0.5003 - val_loss: 5.9837 - val_accuracy: 0.5001\n",
      "Epoch 267/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.9505 - accuracy: 0.5003 - val_loss: 5.9168 - val_accuracy: 0.5001\n",
      "Epoch 268/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.8835 - accuracy: 0.5003 - val_loss: 5.8498 - val_accuracy: 0.5001\n",
      "Epoch 269/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.8164 - accuracy: 0.5003 - val_loss: 5.7827 - val_accuracy: 0.5001\n",
      "Epoch 270/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.7493 - accuracy: 0.5003 - val_loss: 5.7156 - val_accuracy: 0.5001\n",
      "Epoch 271/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.6823 - accuracy: 0.5003 - val_loss: 5.6489 - val_accuracy: 0.5001\n",
      "Epoch 272/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.6152 - accuracy: 0.5003 - val_loss: 5.5815 - val_accuracy: 0.5001\n",
      "Epoch 273/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.5482 - accuracy: 0.5003 - val_loss: 5.5144 - val_accuracy: 0.5001\n",
      "Epoch 274/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.4812 - accuracy: 0.5003 - val_loss: 5.4475 - val_accuracy: 0.5001\n",
      "Epoch 275/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.4143 - accuracy: 0.5003 - val_loss: 5.3807 - val_accuracy: 0.5001\n",
      "Epoch 276/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.3473 - accuracy: 0.5003 - val_loss: 5.3136 - val_accuracy: 0.5001\n",
      "Epoch 277/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.2803 - accuracy: 0.5003 - val_loss: 5.2466 - val_accuracy: 0.5001\n",
      "Epoch 278/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.2133 - accuracy: 0.5003 - val_loss: 5.1794 - val_accuracy: 0.5001\n",
      "Epoch 279/300\n",
      "335/335 [==============================] - 3s 8ms/step - loss: 5.1463 - accuracy: 0.5003 - val_loss: 5.1127 - val_accuracy: 0.5001\n",
      "Epoch 280/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.0793 - accuracy: 0.5003 - val_loss: 5.0457 - val_accuracy: 0.5001\n",
      "Epoch 281/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.0123 - accuracy: 0.5003 - val_loss: 4.9787 - val_accuracy: 0.5001\n",
      "Epoch 282/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.9453 - accuracy: 0.5003 - val_loss: 4.9118 - val_accuracy: 0.5001\n",
      "Epoch 283/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.8783 - accuracy: 0.5003 - val_loss: 4.8446 - val_accuracy: 0.5001\n",
      "Epoch 284/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.8113 - accuracy: 0.5003 - val_loss: 4.7776 - val_accuracy: 0.5001\n",
      "Epoch 285/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.7443 - accuracy: 0.5003 - val_loss: 4.7106 - val_accuracy: 0.5001\n",
      "Epoch 286/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.6773 - accuracy: 0.5003 - val_loss: 4.6437 - val_accuracy: 0.5001\n",
      "Epoch 287/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.6103 - accuracy: 0.5003 - val_loss: 4.5768 - val_accuracy: 0.5001\n",
      "Epoch 288/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.5433 - accuracy: 0.5003 - val_loss: 4.5098 - val_accuracy: 0.5001\n",
      "Epoch 289/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.4764 - accuracy: 0.5003 - val_loss: 4.4427 - val_accuracy: 0.5001\n",
      "Epoch 290/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.4095 - accuracy: 0.5003 - val_loss: 4.3761 - val_accuracy: 0.5001\n",
      "Epoch 291/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.3425 - accuracy: 0.5003 - val_loss: 4.3087 - val_accuracy: 0.5001\n",
      "Epoch 292/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.2754 - accuracy: 0.5003 - val_loss: 4.2418 - val_accuracy: 0.5001\n",
      "Epoch 293/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.2084 - accuracy: 0.5003 - val_loss: 4.1747 - val_accuracy: 0.5001\n",
      "Epoch 294/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.1414 - accuracy: 0.5003 - val_loss: 4.1078 - val_accuracy: 0.5001\n",
      "Epoch 295/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.0744 - accuracy: 0.5003 - val_loss: 4.0409 - val_accuracy: 0.5001\n",
      "Epoch 296/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.0073 - accuracy: 0.5003 - val_loss: 3.9735 - val_accuracy: 0.5001\n",
      "Epoch 297/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.9404 - accuracy: 0.5003 - val_loss: 3.9066 - val_accuracy: 0.5001\n",
      "Epoch 298/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3.8734 - accuracy: 0.5003 - val_loss: 3.8396 - val_accuracy: 0.5001\n",
      "Epoch 299/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3.8064 - accuracy: 0.5003 - val_loss: 3.7728 - val_accuracy: 0.5001\n",
      "Epoch 300/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.7395 - accuracy: 0.5003 - val_loss: 3.7057 - val_accuracy: 0.5001\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 3.7057 - accuracy: 0.5001\n",
      "{'loss': 3.7056918144226074, 'accuracy': 0.5001260638237} \n",
      " 299 \n",
      "\n",
      "Model time: 8.846446719020605 minutes\n",
      "\n",
      "Total time: 107.2809577435255 minutes\n",
      "\n",
      "\n",
      "Model  66  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                   256\n",
      "Activation function         linear\n",
      "Dropout                        0.7\n",
      "L1                            0.01\n",
      "L2                          0.0001\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 5550707, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 7s 30ms/step - loss: 76.3359 - accuracy: 0.5200 - val_loss: 28.6297 - val_accuracy: 0.5432\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 10.3562 - accuracy: 0.5057 - val_loss: 2.1751 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 4s 25ms/step - loss: 1.3091 - accuracy: 0.5000 - val_loss: 1.0621 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 4s 23ms/step - loss: 1.0335 - accuracy: 0.5003 - val_loss: 1.0063 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 4s 24ms/step - loss: 0.9823 - accuracy: 0.5024 - val_loss: 0.9609 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.9454 - accuracy: 0.4978 - val_loss: 0.9333 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 4s 24ms/step - loss: 0.9280 - accuracy: 0.4939 - val_loss: 0.9265 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.9277 - accuracy: 0.4973Restoring model weights from the end of the best epoch: 7.\n",
      "168/168 [==============================] - 4s 22ms/step - loss: 0.9278 - accuracy: 0.4970 - val_loss: 0.9299 - val_accuracy: 0.5001\n",
      "Epoch 8: early stopping\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.9265 - accuracy: 0.5001\n",
      "{'loss': 0.92654949426651, 'accuracy': 0.5001260638237} \n",
      " 7 \n",
      "\n",
      "Model time: 0.7383385896682739 minutes\n",
      "\n",
      "Total time: 108.01937907189131 minutes\n",
      "\n",
      "\n",
      "Model  67  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     4\n",
      "Activation function           tanh\n",
      "Dropout                        0.9\n",
      "L1                             0.1\n",
      "L2                           100.0\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 4546883, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 4s 12ms/step - loss: 1637.1353 - accuracy: 0.4947 - val_loss: 1066.3652 - val_accuracy: 0.4992\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 800.7056 - accuracy: 0.4942 - val_loss: 583.9368 - val_accuracy: 0.5032\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 438.8503 - accuracy: 0.4990 - val_loss: 315.5963 - val_accuracy: 0.5002\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 232.7551 - accuracy: 0.4977 - val_loss: 163.1724 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 117.6812 - accuracy: 0.4962 - val_loss: 80.0735 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 56.3560 - accuracy: 0.4986 - val_loss: 37.1341 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 25.5232 - accuracy: 0.4944 - val_loss: 16.3238 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 11.0261 - accuracy: 0.4978 - val_loss: 6.9297 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 4.6875 - accuracy: 0.4992 - val_loss: 2.9976 - val_accuracy: 0.4999\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.1212 - accuracy: 0.4969 - val_loss: 1.4782 - val_accuracy: 0.4999\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.1631 - accuracy: 0.4944 - val_loss: 0.9385 - val_accuracy: 0.4999\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.8351 - accuracy: 0.4968 - val_loss: 0.7636 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7329 - accuracy: 0.4966 - val_loss: 0.7124 - val_accuracy: 0.4999\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7042 - accuracy: 0.4983 - val_loss: 0.6990 - val_accuracy: 0.4999\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6972 - accuracy: 0.5004 - val_loss: 0.6962 - val_accuracy: 0.4999\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6958 - accuracy: 0.4972 - val_loss: 0.6956 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "154/168 [==========================>...] - ETA: 0s - loss: 0.6956 - accuracy: 0.4959Restoring model weights from the end of the best epoch: 16.\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6956 - accuracy: 0.4947 - val_loss: 0.6957 - val_accuracy: 0.5001\n",
      "Epoch 17: early stopping\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.6956 - accuracy: 0.5001\n",
      "{'loss': 0.6955714225769043, 'accuracy': 0.5001260638237} \n",
      " 16 \n",
      "\n",
      "Model time: 0.38306937366724014 minutes\n",
      "\n",
      "Total time: 108.4025317914784 minutes\n",
      "\n",
      "\n",
      "Model  68  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                    16\n",
      "Activation function         linear\n",
      "Dropout                        0.7\n",
      "L1                             0.0\n",
      "L2                          0.0001\n",
      "Batch size                      32\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 4926448, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 7ms/step - loss: 6.2736 - accuracy: 0.5014 - val_loss: 1.0866 - val_accuracy: 0.4686\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 5.9633 - accuracy: 0.4973 - val_loss: 1.0246 - val_accuracy: 0.4687\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 5.6001 - accuracy: 0.5040 - val_loss: 0.9754 - val_accuracy: 0.4697\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 5.2706 - accuracy: 0.4997 - val_loss: 0.9329 - val_accuracy: 0.4714\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.1056 - accuracy: 0.4968 - val_loss: 0.8972 - val_accuracy: 0.4705\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 4.7283 - accuracy: 0.4993 - val_loss: 0.8668 - val_accuracy: 0.4733\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 4.5084 - accuracy: 0.5016 - val_loss: 0.8405 - val_accuracy: 0.4748\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 4.2655 - accuracy: 0.5016 - val_loss: 0.8210 - val_accuracy: 0.4755\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.0413 - accuracy: 0.5007 - val_loss: 0.8031 - val_accuracy: 0.4765\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 3.9283 - accuracy: 0.5007 - val_loss: 0.7887 - val_accuracy: 0.4775\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 3.6943 - accuracy: 0.5014 - val_loss: 0.7744 - val_accuracy: 0.4781\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.5188 - accuracy: 0.4961 - val_loss: 0.7635 - val_accuracy: 0.4798\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 3.3708 - accuracy: 0.4974 - val_loss: 0.7535 - val_accuracy: 0.4812\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 3.2830 - accuracy: 0.4990 - val_loss: 0.7446 - val_accuracy: 0.4823\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 3.1119 - accuracy: 0.4983 - val_loss: 0.7383 - val_accuracy: 0.4838\n",
      "Epoch 16/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.0276 - accuracy: 0.5032 - val_loss: 0.7318 - val_accuracy: 0.4862\n",
      "Epoch 17/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.9367 - accuracy: 0.4977 - val_loss: 0.7267 - val_accuracy: 0.4883\n",
      "Epoch 18/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.8123 - accuracy: 0.4982 - val_loss: 0.7220 - val_accuracy: 0.4891\n",
      "Epoch 19/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.6151 - accuracy: 0.5003 - val_loss: 0.7181 - val_accuracy: 0.4895\n",
      "Epoch 20/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.5998 - accuracy: 0.4959 - val_loss: 0.7150 - val_accuracy: 0.4907\n",
      "Epoch 21/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.4096 - accuracy: 0.5039 - val_loss: 0.7122 - val_accuracy: 0.4923\n",
      "Epoch 22/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.3273 - accuracy: 0.5050 - val_loss: 0.7102 - val_accuracy: 0.4935\n",
      "Epoch 23/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.3051 - accuracy: 0.4984 - val_loss: 0.7082 - val_accuracy: 0.4944\n",
      "Epoch 24/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.2059 - accuracy: 0.5023 - val_loss: 0.7067 - val_accuracy: 0.4967\n",
      "Epoch 25/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.1106 - accuracy: 0.5028 - val_loss: 0.7052 - val_accuracy: 0.4986\n",
      "Epoch 26/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.0392 - accuracy: 0.4966 - val_loss: 0.7040 - val_accuracy: 0.5002\n",
      "Epoch 27/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 2.0144 - accuracy: 0.5039 - val_loss: 0.7030 - val_accuracy: 0.5010\n",
      "Epoch 28/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.9112 - accuracy: 0.4994 - val_loss: 0.7022 - val_accuracy: 0.5034\n",
      "Epoch 29/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.8171 - accuracy: 0.5021 - val_loss: 0.7015 - val_accuracy: 0.5037\n",
      "Epoch 30/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.8100 - accuracy: 0.4960 - val_loss: 0.7008 - val_accuracy: 0.5053\n",
      "Epoch 31/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.7461 - accuracy: 0.4985 - val_loss: 0.7002 - val_accuracy: 0.5061\n",
      "Epoch 32/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.6968 - accuracy: 0.5072 - val_loss: 0.6997 - val_accuracy: 0.5084\n",
      "Epoch 33/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 1.6442 - accuracy: 0.5011 - val_loss: 0.6993 - val_accuracy: 0.5091\n",
      "Epoch 34/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.6151 - accuracy: 0.5062 - val_loss: 0.6989 - val_accuracy: 0.5101\n",
      "Epoch 35/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.5529 - accuracy: 0.4959 - val_loss: 0.6986 - val_accuracy: 0.5111\n",
      "Epoch 36/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4969 - accuracy: 0.5020 - val_loss: 0.6985 - val_accuracy: 0.5109\n",
      "Epoch 37/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.4806 - accuracy: 0.4959 - val_loss: 0.6983 - val_accuracy: 0.5121\n",
      "Epoch 38/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.4183 - accuracy: 0.5049 - val_loss: 0.6982 - val_accuracy: 0.5111\n",
      "Epoch 39/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4107 - accuracy: 0.5001 - val_loss: 0.6981 - val_accuracy: 0.5114\n",
      "Epoch 40/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.3552 - accuracy: 0.4998 - val_loss: 0.6981 - val_accuracy: 0.5116\n",
      "Epoch 41/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.3112 - accuracy: 0.4979 - val_loss: 0.6980 - val_accuracy: 0.5128\n",
      "Epoch 42/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.2891 - accuracy: 0.4980 - val_loss: 0.6980 - val_accuracy: 0.5124\n",
      "Epoch 43/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.2511 - accuracy: 0.5017 - val_loss: 0.6979 - val_accuracy: 0.5134\n",
      "Epoch 44/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.2183 - accuracy: 0.5046 - val_loss: 0.6979 - val_accuracy: 0.5155\n",
      "Epoch 45/300\n",
      "657/670 [============================>.] - ETA: 0s - loss: 1.2103 - accuracy: 0.5055Restoring model weights from the end of the best epoch: 44.\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 1.2100 - accuracy: 0.5056 - val_loss: 0.6979 - val_accuracy: 0.5148\n",
      "Epoch 45: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.6979 - accuracy: 0.5155\n",
      "{'loss': 0.697899341583252, 'accuracy': 0.5155044794082642} \n",
      " 44 \n",
      "\n",
      "Model time: 3.431527905166149 minutes\n",
      "\n",
      "Total time: 111.8342096991837 minutes\n",
      "\n",
      "\n",
      "Model  69  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                    16\n",
      "Activation function           tanh\n",
      "Dropout                        0.0\n",
      "L1                            0.01\n",
      "L2                          0.0001\n",
      "Batch size                       8\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 624581, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 1.7920 - accuracy: 0.5635 - val_loss: 1.1544 - val_accuracy: 0.6097\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 1.0044 - accuracy: 0.6070 - val_loss: 0.8921 - val_accuracy: 0.6193\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.8229 - accuracy: 0.6194 - val_loss: 0.7754 - val_accuracy: 0.6179\n",
      "Epoch 4/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.7443 - accuracy: 0.6224 - val_loss: 0.7274 - val_accuracy: 0.6153\n",
      "Epoch 5/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.7159 - accuracy: 0.6189 - val_loss: 0.7089 - val_accuracy: 0.6202\n",
      "Epoch 6/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.7050 - accuracy: 0.6159 - val_loss: 0.7022 - val_accuracy: 0.6205\n",
      "Epoch 7/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6974 - accuracy: 0.6125 - val_loss: 0.6932 - val_accuracy: 0.6197\n",
      "Epoch 8/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6917 - accuracy: 0.6129 - val_loss: 0.6900 - val_accuracy: 0.6153\n",
      "Epoch 9/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6876 - accuracy: 0.6136 - val_loss: 0.6863 - val_accuracy: 0.6177\n",
      "Epoch 10/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6850 - accuracy: 0.6143 - val_loss: 0.6830 - val_accuracy: 0.6206\n",
      "Epoch 11/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6827 - accuracy: 0.6172 - val_loss: 0.6816 - val_accuracy: 0.6219\n",
      "Epoch 12/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6820 - accuracy: 0.6195 - val_loss: 0.6809 - val_accuracy: 0.6231\n",
      "Epoch 13/300\n",
      "2660/2677 [============================>.] - ETA: 0s - loss: 0.6814 - accuracy: 0.6219Restoring model weights from the end of the best epoch: 12.\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6814 - accuracy: 0.6218 - val_loss: 0.6818 - val_accuracy: 0.6181\n",
      "Epoch 13: early stopping\n",
      "2480/2480 [==============================] - 6s 3ms/step - loss: 0.6809 - accuracy: 0.6231\n",
      "{'loss': 0.6808668375015259, 'accuracy': 0.6230524778366089} \n",
      " 12 \n",
      "\n",
      "Model time: 2.7107017040252686 minutes\n",
      "\n",
      "Total time: 114.5450122654438 minutes\n",
      "\n",
      "\n",
      "Model  70  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                   128\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.5\n",
      "L1                           0.001\n",
      "L2                           0.001\n",
      "Batch size                     256\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 6826362, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 5s 36ms/step - loss: 1.6353 - accuracy: 0.5031 - val_loss: 0.8275 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.8209 - accuracy: 0.5016 - val_loss: 0.8141 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "83/84 [============================>.] - ETA: 0s - loss: 0.8163 - accuracy: 0.4934Restoring model weights from the end of the best epoch: 2.\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.8164 - accuracy: 0.4932 - val_loss: 0.8162 - val_accuracy: 0.5001\n",
      "Epoch 3: early stopping\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.8141 - accuracy: 0.4999\n",
      "{'loss': 0.8141312599182129, 'accuracy': 0.49987393617630005} \n",
      " 2 \n",
      "\n",
      "Model time: 0.1882513202726841 minutes\n",
      "\n",
      "Total time: 114.7333302795887 minutes\n",
      "\n",
      "\n",
      "Model  71  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                    16\n",
      "Activation function           relu\n",
      "Dropout                        0.9\n",
      "L1                             0.0\n",
      "L2                           0.001\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 4895310, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 5s 7ms/step - loss: 0.7784 - accuracy: 0.5036 - val_loss: 0.6936 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 0.6936 - accuracy: 0.5054 - val_loss: 0.6933 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "329/335 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.4976Restoring model weights from the end of the best epoch: 2.\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.6936 - accuracy: 0.4969 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 3: early stopping\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4999\n",
      "{'loss': 0.6932568550109863, 'accuracy': 0.49987393617630005} \n",
      " 2 \n",
      "\n",
      "Model time: 0.18375131487846375 minutes\n",
      "\n",
      "Total time: 114.91714825108647 minutes\n",
      "\n",
      "\n",
      "Model  72  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     2\n",
      "Activation function         linear\n",
      "Dropout                        0.2\n",
      "L1                         0.00001\n",
      "L2                             1.0\n",
      "Batch size                       8\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 4443698, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 16s 5ms/step - loss: 0.7826 - accuracy: 0.5024 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6942 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6944 - accuracy: 0.5021 - val_loss: 0.6933 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6951 - accuracy: 0.5002 - val_loss: 0.6933 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "2664/2677 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.5006Restoring model weights from the end of the best epoch: 4.\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6946 - accuracy: 0.5004 - val_loss: 0.6949 - val_accuracy: 0.5001\n",
      "Epoch 5: early stopping\n",
      "2480/2480 [==============================] - 7s 3ms/step - loss: 0.6933 - accuracy: 0.4999\n",
      "{'loss': 0.6932516098022461, 'accuracy': 0.49987393617630005} \n",
      " 4 \n",
      "\n",
      "Model time: 1.2685256637632847 minutes\n",
      "\n",
      "Total time: 116.18577392026782 minutes\n",
      "\n",
      "\n",
      "Model  73  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                    64\n",
      "Activation function           relu\n",
      "Dropout                        0.5\n",
      "L1                           0.001\n",
      "L2                             0.0\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 3793426, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 4s 13ms/step - loss: 1.0656 - accuracy: 0.5388 - val_loss: 0.7255 - val_accuracy: 0.6076\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7257 - accuracy: 0.5514 - val_loss: 0.7178 - val_accuracy: 0.6241\n",
      "Epoch 3/300\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.7231 - accuracy: 0.5563Restoring model weights from the end of the best epoch: 2.\n",
      "168/168 [==============================] - 2s 10ms/step - loss: 0.7233 - accuracy: 0.5565 - val_loss: 0.7203 - val_accuracy: 0.5671\n",
      "Epoch 3: early stopping\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.7178 - accuracy: 0.6241\n",
      "{'loss': 0.7178244590759277, 'accuracy': 0.6241113543510437} \n",
      " 2 \n",
      "\n",
      "Model time: 0.14351768419146538 minutes\n",
      "\n",
      "Total time: 116.32939161732793 minutes\n",
      "\n",
      "\n",
      "Model  74  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                     1\n",
      "Activation function         linear\n",
      "Dropout                        0.6\n",
      "L1                             0.1\n",
      "L2                            0.01\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 5701798, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 7s 6ms/step - loss: 0.8313 - accuracy: 0.4950 - val_loss: 0.7889 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7832 - accuracy: 0.5013 - val_loss: 0.7846 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7831 - accuracy: 0.5002 - val_loss: 0.7831 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "660/670 [============================>.] - ETA: 0s - loss: 0.7830 - accuracy: 0.5018Restoring model weights from the end of the best epoch: 3.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7830 - accuracy: 0.5021 - val_loss: 0.7858 - val_accuracy: 0.5001\n",
      "Epoch 4: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.7831 - accuracy: 0.4999\n",
      "{'loss': 0.7831443548202515, 'accuracy': 0.49987393617630005} \n",
      " 3 \n",
      "\n",
      "Model time: 0.42857590317726135 minutes\n",
      "\n",
      "Total time: 116.75805085152388 minutes\n",
      "\n",
      "\n",
      "Model  75  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                     8\n",
      "Activation function           relu\n",
      "Dropout                        0.6\n",
      "L1                             0.0\n",
      "L2                         0.00001\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 6127907, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 4s 11ms/step - loss: 0.7598 - accuracy: 0.4929 - val_loss: 0.6936 - val_accuracy: 0.4998\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7017 - accuracy: 0.4978 - val_loss: 0.6936 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "164/168 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.5029Restoring model weights from the end of the best epoch: 2.\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6961 - accuracy: 0.5029 - val_loss: 0.6936 - val_accuracy: 0.5001\n",
      "Epoch 3: early stopping\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5001\n",
      "{'loss': 0.6935856342315674, 'accuracy': 0.50007563829422} \n",
      " 2 \n",
      "\n",
      "Model time: 0.12361752986907959 minutes\n",
      "\n",
      "Total time: 116.88175170123577 minutes\n",
      "\n",
      "\n",
      "Model  76  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                    64\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.5\n",
      "L1                             1.0\n",
      "L2                             0.0\n",
      "Batch size                     256\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 5269580, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 4s 19ms/step - loss: 2210.6050 - accuracy: 0.5060 - val_loss: 2200.3325 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2190.7888 - accuracy: 0.5016 - val_loss: 2180.7195 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 2171.2227 - accuracy: 0.4959 - val_loss: 2161.1963 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 2151.7332 - accuracy: 0.5025 - val_loss: 2141.7659 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 2132.3606 - accuracy: 0.4968 - val_loss: 2122.4402 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2113.0732 - accuracy: 0.5032 - val_loss: 2103.2087 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 2093.8843 - accuracy: 0.5004 - val_loss: 2084.0583 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2074.7842 - accuracy: 0.4994 - val_loss: 2065.0066 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2055.7769 - accuracy: 0.4971 - val_loss: 2046.0465 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2036.8627 - accuracy: 0.4979 - val_loss: 2027.1752 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2018.0269 - accuracy: 0.4998 - val_loss: 2008.3844 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1999.2766 - accuracy: 0.5038 - val_loss: 1989.6835 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1980.6235 - accuracy: 0.4999 - val_loss: 1971.0747 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1962.0575 - accuracy: 0.4986 - val_loss: 1952.5505 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1943.5732 - accuracy: 0.4975 - val_loss: 1934.1146 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1925.1849 - accuracy: 0.5049 - val_loss: 1915.7780 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1906.8945 - accuracy: 0.4989 - val_loss: 1897.5341 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1888.6895 - accuracy: 0.5021 - val_loss: 1879.3787 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1870.5801 - accuracy: 0.4993 - val_loss: 1861.3127 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1852.5613 - accuracy: 0.4999 - val_loss: 1843.3416 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "84/84 [==============================] - 1s 18ms/step - loss: 1834.6309 - accuracy: 0.4986 - val_loss: 1825.4581 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1816.7954 - accuracy: 0.4956 - val_loss: 1807.6691 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1799.0537 - accuracy: 0.4988 - val_loss: 1789.9760 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "84/84 [==============================] - 2s 19ms/step - loss: 1781.4104 - accuracy: 0.5010 - val_loss: 1772.3894 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1763.8715 - accuracy: 0.4987 - val_loss: 1754.8970 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1746.4301 - accuracy: 0.5015 - val_loss: 1737.5172 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1729.0986 - accuracy: 0.5023 - val_loss: 1720.2378 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1711.8683 - accuracy: 0.5011 - val_loss: 1703.0531 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1694.7245 - accuracy: 0.5039 - val_loss: 1685.9608 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1677.6726 - accuracy: 0.5045 - val_loss: 1668.9520 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1660.7012 - accuracy: 0.5039 - val_loss: 1652.0226 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1643.8173 - accuracy: 0.5036 - val_loss: 1635.1792 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1627.0171 - accuracy: 0.4989 - val_loss: 1618.4187 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1610.2963 - accuracy: 0.4983 - val_loss: 1601.7456 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1593.6682 - accuracy: 0.5001 - val_loss: 1585.1691 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1577.1396 - accuracy: 0.4987 - val_loss: 1568.6854 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1560.7034 - accuracy: 0.4940 - val_loss: 1552.2933 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1544.3436 - accuracy: 0.5039 - val_loss: 1535.9852 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1528.0841 - accuracy: 0.4933 - val_loss: 1519.7677 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1511.9073 - accuracy: 0.5033 - val_loss: 1503.6417 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1495.8251 - accuracy: 0.4991 - val_loss: 1487.6066 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1479.8398 - accuracy: 0.4924 - val_loss: 1471.6605 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1463.9221 - accuracy: 0.5029 - val_loss: 1455.7927 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1448.0992 - accuracy: 0.4997 - val_loss: 1440.0090 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1432.3615 - accuracy: 0.5017 - val_loss: 1424.3202 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1416.7135 - accuracy: 0.4990 - val_loss: 1408.7200 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1401.1581 - accuracy: 0.5007 - val_loss: 1393.2112 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1385.6953 - accuracy: 0.4973 - val_loss: 1377.7936 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1370.3250 - accuracy: 0.4971 - val_loss: 1362.4626 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1355.0239 - accuracy: 0.5051 - val_loss: 1347.2104 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1339.8193 - accuracy: 0.4983 - val_loss: 1332.0475 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1324.6968 - accuracy: 0.5037 - val_loss: 1316.9773 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1309.6672 - accuracy: 0.5050 - val_loss: 1301.9950 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1294.7301 - accuracy: 0.4987 - val_loss: 1287.0983 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1279.8737 - accuracy: 0.5010 - val_loss: 1272.2856 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1265.1042 - accuracy: 0.4975 - val_loss: 1257.5574 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1250.4205 - accuracy: 0.5005 - val_loss: 1242.9188 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1235.8180 - accuracy: 0.5021 - val_loss: 1228.3667 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1221.3185 - accuracy: 0.4931 - val_loss: 1213.9067 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1206.8894 - accuracy: 0.5030 - val_loss: 1199.5193 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1192.5419 - accuracy: 0.4997 - val_loss: 1185.2135 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1178.2780 - accuracy: 0.4996 - val_loss: 1170.9978 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1164.1096 - accuracy: 0.4971 - val_loss: 1156.8746 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1150.0328 - accuracy: 0.4989 - val_loss: 1142.8450 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1136.0475 - accuracy: 0.4997 - val_loss: 1128.9116 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1122.1483 - accuracy: 0.5028 - val_loss: 1115.0560 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1108.3375 - accuracy: 0.4990 - val_loss: 1101.2839 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1094.6072 - accuracy: 0.5043 - val_loss: 1087.6066 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1080.9843 - accuracy: 0.4939 - val_loss: 1074.0277 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1067.4491 - accuracy: 0.4966 - val_loss: 1060.5446 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1054.0040 - accuracy: 0.5019 - val_loss: 1047.1427 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1040.6461 - accuracy: 0.5010 - val_loss: 1033.8297 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1027.3810 - accuracy: 0.4961 - val_loss: 1020.6135 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 1014.2162 - accuracy: 0.4955 - val_loss: 1007.4980 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1001.1426 - accuracy: 0.4980 - val_loss: 994.4698 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 988.1505 - accuracy: 0.5035 - val_loss: 981.5262 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 975.2478 - accuracy: 0.4998 - val_loss: 968.6667 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 962.4343 - accuracy: 0.4969 - val_loss: 955.9006 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 949.7131 - accuracy: 0.5006 - val_loss: 943.2285 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 937.0851 - accuracy: 0.4994 - val_loss: 930.6447 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 924.5416 - accuracy: 0.4983 - val_loss: 918.1487 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 912.0892 - accuracy: 0.4987 - val_loss: 905.7325 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 899.7153 - accuracy: 0.4991 - val_loss: 893.4064 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 887.4380 - accuracy: 0.4956 - val_loss: 881.1747 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 875.2410 - accuracy: 0.5019 - val_loss: 869.0277 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 863.1432 - accuracy: 0.4971 - val_loss: 856.9755 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 851.1399 - accuracy: 0.4946 - val_loss: 845.0190 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 839.2228 - accuracy: 0.4985 - val_loss: 833.1479 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 827.3914 - accuracy: 0.5030 - val_loss: 821.3604 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 815.6433 - accuracy: 0.5019 - val_loss: 809.6560 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 803.9826 - accuracy: 0.5028 - val_loss: 798.0407 - val_accuracy: 0.5001\n",
      "Epoch 92/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 792.4128 - accuracy: 0.4934 - val_loss: 786.5046 - val_accuracy: 0.5001\n",
      "Epoch 93/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 780.9112 - accuracy: 0.5003 - val_loss: 775.0505 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 769.4988 - accuracy: 0.4996 - val_loss: 763.6847 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 758.1750 - accuracy: 0.4992 - val_loss: 752.3982 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 746.9260 - accuracy: 0.4979 - val_loss: 741.1985 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 735.7813 - accuracy: 0.4908 - val_loss: 730.0950 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 724.7149 - accuracy: 0.5020 - val_loss: 719.0814 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 713.7455 - accuracy: 0.5000 - val_loss: 708.1564 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 702.8643 - accuracy: 0.4976 - val_loss: 697.3168 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 692.0679 - accuracy: 0.5013 - val_loss: 686.5660 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 681.3549 - accuracy: 0.5012 - val_loss: 675.9017 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 670.7415 - accuracy: 0.4977 - val_loss: 665.3365 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 660.2217 - accuracy: 0.5008 - val_loss: 654.8699 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 649.7974 - accuracy: 0.5025 - val_loss: 644.4927 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 639.4717 - accuracy: 0.4912 - val_loss: 634.2086 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 629.2262 - accuracy: 0.5011 - val_loss: 624.0127 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 619.0750 - accuracy: 0.5022 - val_loss: 613.9163 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 609.0330 - accuracy: 0.4975 - val_loss: 603.9146 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 599.0667 - accuracy: 0.5001 - val_loss: 593.9980 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 589.1943 - accuracy: 0.4984 - val_loss: 584.1682 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 579.4089 - accuracy: 0.4964 - val_loss: 574.4287 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 569.7137 - accuracy: 0.4946 - val_loss: 564.7794 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 560.1082 - accuracy: 0.4969 - val_loss: 555.2151 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 550.5813 - accuracy: 0.5019 - val_loss: 545.7394 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 541.1551 - accuracy: 0.4981 - val_loss: 536.3649 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 531.8309 - accuracy: 0.5004 - val_loss: 527.0938 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 522.6067 - accuracy: 0.5075 - val_loss: 517.9222 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 513.4843 - accuracy: 0.4992 - val_loss: 508.8420 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 504.4418 - accuracy: 0.5011 - val_loss: 499.8439 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 495.4871 - accuracy: 0.4999 - val_loss: 490.9261 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 486.6133 - accuracy: 0.4993 - val_loss: 482.1002 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 477.8261 - accuracy: 0.5009 - val_loss: 473.3628 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 469.1359 - accuracy: 0.5078 - val_loss: 464.7226 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 460.5430 - accuracy: 0.5019 - val_loss: 456.1772 - val_accuracy: 0.5006\n",
      "Epoch 126/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 452.0466 - accuracy: 0.5009 - val_loss: 447.7206 - val_accuracy: 0.4999\n",
      "Epoch 127/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 443.6262 - accuracy: 0.5057 - val_loss: 439.3558 - val_accuracy: 0.4999\n",
      "Epoch 128/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 435.3098 - accuracy: 0.5017 - val_loss: 431.0858 - val_accuracy: 0.4999\n",
      "Epoch 129/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 427.0920 - accuracy: 0.4972 - val_loss: 422.9147 - val_accuracy: 0.4999\n",
      "Epoch 130/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 418.9601 - accuracy: 0.5043 - val_loss: 414.8292 - val_accuracy: 0.4999\n",
      "Epoch 131/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 410.9185 - accuracy: 0.5016 - val_loss: 406.8341 - val_accuracy: 0.4999\n",
      "Epoch 132/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 402.9680 - accuracy: 0.5008 - val_loss: 398.9333 - val_accuracy: 0.4999\n",
      "Epoch 133/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 395.1187 - accuracy: 0.4961 - val_loss: 391.1281 - val_accuracy: 0.4999\n",
      "Epoch 134/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 387.3613 - accuracy: 0.4970 - val_loss: 383.4228 - val_accuracy: 0.4999\n",
      "Epoch 135/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 379.7024 - accuracy: 0.4944 - val_loss: 375.8102 - val_accuracy: 0.4999\n",
      "Epoch 136/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 372.1289 - accuracy: 0.5004 - val_loss: 368.2801 - val_accuracy: 0.4999\n",
      "Epoch 137/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 364.6320 - accuracy: 0.4994 - val_loss: 360.8223 - val_accuracy: 0.4999\n",
      "Epoch 138/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 357.2133 - accuracy: 0.5050 - val_loss: 353.4469 - val_accuracy: 0.4999\n",
      "Epoch 139/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 349.8783 - accuracy: 0.4947 - val_loss: 346.1464 - val_accuracy: 0.4999\n",
      "Epoch 140/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 342.6189 - accuracy: 0.4988 - val_loss: 338.9348 - val_accuracy: 0.4999\n",
      "Epoch 141/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 335.4538 - accuracy: 0.4968 - val_loss: 331.8202 - val_accuracy: 0.4999\n",
      "Epoch 142/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 328.3831 - accuracy: 0.5011 - val_loss: 324.7981 - val_accuracy: 0.4999\n",
      "Epoch 143/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 321.4146 - accuracy: 0.4928 - val_loss: 317.8759 - val_accuracy: 0.4999\n",
      "Epoch 144/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 314.5272 - accuracy: 0.5054 - val_loss: 311.0351 - val_accuracy: 0.4999\n",
      "Epoch 145/300\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 307.7295 - accuracy: 0.5012 - val_loss: 304.2817 - val_accuracy: 0.4999\n",
      "Epoch 146/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 301.0302 - accuracy: 0.4954 - val_loss: 297.6319 - val_accuracy: 0.4999\n",
      "Epoch 147/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 294.4229 - accuracy: 0.5014 - val_loss: 291.0750 - val_accuracy: 0.4999\n",
      "Epoch 148/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 287.9125 - accuracy: 0.5044 - val_loss: 284.6110 - val_accuracy: 0.4999\n",
      "Epoch 149/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 281.4985 - accuracy: 0.4948 - val_loss: 278.2464 - val_accuracy: 0.4999\n",
      "Epoch 150/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 275.1821 - accuracy: 0.4998 - val_loss: 271.9849 - val_accuracy: 0.4999\n",
      "Epoch 151/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 268.9641 - accuracy: 0.5015 - val_loss: 265.8077 - val_accuracy: 0.4999\n",
      "Epoch 152/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 262.8338 - accuracy: 0.4945 - val_loss: 259.7260 - val_accuracy: 0.4999\n",
      "Epoch 153/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 256.7954 - accuracy: 0.5025 - val_loss: 253.7411 - val_accuracy: 0.4999\n",
      "Epoch 154/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 250.8551 - accuracy: 0.4982 - val_loss: 247.8398 - val_accuracy: 0.4999\n",
      "Epoch 155/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 244.9996 - accuracy: 0.5014 - val_loss: 242.0340 - val_accuracy: 0.4999\n",
      "Epoch 156/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 239.2363 - accuracy: 0.4955 - val_loss: 236.3154 - val_accuracy: 0.4999\n",
      "Epoch 157/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 233.5592 - accuracy: 0.5011 - val_loss: 230.6857 - val_accuracy: 0.4999\n",
      "Epoch 158/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 227.9703 - accuracy: 0.5021 - val_loss: 225.1342 - val_accuracy: 0.4999\n",
      "Epoch 159/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 222.4546 - accuracy: 0.4998 - val_loss: 219.6612 - val_accuracy: 0.4999\n",
      "Epoch 160/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 217.0253 - accuracy: 0.5018 - val_loss: 214.2732 - val_accuracy: 0.4999\n",
      "Epoch 161/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 211.6791 - accuracy: 0.5011 - val_loss: 208.9765 - val_accuracy: 0.4999\n",
      "Epoch 162/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 206.4299 - accuracy: 0.4937 - val_loss: 203.7675 - val_accuracy: 0.4999\n",
      "Epoch 163/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 201.2619 - accuracy: 0.5016 - val_loss: 198.6490 - val_accuracy: 0.4999\n",
      "Epoch 164/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 196.1860 - accuracy: 0.4934 - val_loss: 193.6148 - val_accuracy: 0.4999\n",
      "Epoch 165/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 191.1955 - accuracy: 0.4968 - val_loss: 188.6690 - val_accuracy: 0.4999\n",
      "Epoch 166/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 186.2872 - accuracy: 0.4954 - val_loss: 183.8020 - val_accuracy: 0.4999\n",
      "Epoch 167/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 181.4671 - accuracy: 0.4991 - val_loss: 179.0324 - val_accuracy: 0.4999\n",
      "Epoch 168/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 176.7421 - accuracy: 0.4948 - val_loss: 174.3517 - val_accuracy: 0.4999\n",
      "Epoch 169/300\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 172.1011 - accuracy: 0.5051 - val_loss: 169.7580 - val_accuracy: 0.4999\n",
      "Epoch 170/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 167.5546 - accuracy: 0.4971 - val_loss: 165.2541 - val_accuracy: 0.4999\n",
      "Epoch 171/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 163.0939 - accuracy: 0.4941 - val_loss: 160.8389 - val_accuracy: 0.4999\n",
      "Epoch 172/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 158.7204 - accuracy: 0.5020 - val_loss: 156.5163 - val_accuracy: 0.4999\n",
      "Epoch 173/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 154.4441 - accuracy: 0.4992 - val_loss: 152.2857 - val_accuracy: 0.4999\n",
      "Epoch 174/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 150.2534 - accuracy: 0.4957 - val_loss: 148.1346 - val_accuracy: 0.4999\n",
      "Epoch 175/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 146.1424 - accuracy: 0.5036 - val_loss: 144.0740 - val_accuracy: 0.4999\n",
      "Epoch 176/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 142.1324 - accuracy: 0.5023 - val_loss: 140.1095 - val_accuracy: 0.4999\n",
      "Epoch 177/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 138.2122 - accuracy: 0.5004 - val_loss: 136.2386 - val_accuracy: 0.4999\n",
      "Epoch 178/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 134.3911 - accuracy: 0.5002 - val_loss: 132.4637 - val_accuracy: 0.4999\n",
      "Epoch 179/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 130.6564 - accuracy: 0.4990 - val_loss: 128.7737 - val_accuracy: 0.4999\n",
      "Epoch 180/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 127.0126 - accuracy: 0.4982 - val_loss: 125.1755 - val_accuracy: 0.4999\n",
      "Epoch 181/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 123.4517 - accuracy: 0.5047 - val_loss: 121.6602 - val_accuracy: 0.4999\n",
      "Epoch 182/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 119.9779 - accuracy: 0.4973 - val_loss: 118.2242 - val_accuracy: 0.4999\n",
      "Epoch 183/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 116.5814 - accuracy: 0.4964 - val_loss: 114.8698 - val_accuracy: 0.4999\n",
      "Epoch 184/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 113.2735 - accuracy: 0.4968 - val_loss: 111.6085 - val_accuracy: 0.4999\n",
      "Epoch 185/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 110.0504 - accuracy: 0.4979 - val_loss: 108.4279 - val_accuracy: 0.4999\n",
      "Epoch 186/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 106.9097 - accuracy: 0.4991 - val_loss: 105.3297 - val_accuracy: 0.4999\n",
      "Epoch 187/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 103.8549 - accuracy: 0.5023 - val_loss: 102.3226 - val_accuracy: 0.4999\n",
      "Epoch 188/300\n",
      "84/84 [==============================] - 1s 17ms/step - loss: 100.8976 - accuracy: 0.4999 - val_loss: 99.4135 - val_accuracy: 0.4999\n",
      "Epoch 189/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 98.0323 - accuracy: 0.4989 - val_loss: 96.5939 - val_accuracy: 0.4999\n",
      "Epoch 190/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 95.2554 - accuracy: 0.4962 - val_loss: 93.8556 - val_accuracy: 0.4999\n",
      "Epoch 191/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 92.5385 - accuracy: 0.5011 - val_loss: 91.1629 - val_accuracy: 0.4999\n",
      "Epoch 192/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 89.8675 - accuracy: 0.4985 - val_loss: 88.5102 - val_accuracy: 0.4999\n",
      "Epoch 193/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 87.2358 - accuracy: 0.4944 - val_loss: 85.9016 - val_accuracy: 0.4999\n",
      "Epoch 194/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 84.6464 - accuracy: 0.5061 - val_loss: 83.3359 - val_accuracy: 0.4999\n",
      "Epoch 195/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 82.0985 - accuracy: 0.5035 - val_loss: 80.8088 - val_accuracy: 0.4999\n",
      "Epoch 196/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 79.5953 - accuracy: 0.4984 - val_loss: 78.3257 - val_accuracy: 0.4999\n",
      "Epoch 197/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 77.1312 - accuracy: 0.4992 - val_loss: 75.8849 - val_accuracy: 0.4999\n",
      "Epoch 198/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 74.7104 - accuracy: 0.5084 - val_loss: 73.4863 - val_accuracy: 0.4999\n",
      "Epoch 199/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 72.3340 - accuracy: 0.4988 - val_loss: 71.1294 - val_accuracy: 0.4999\n",
      "Epoch 200/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 69.9958 - accuracy: 0.4940 - val_loss: 68.8095 - val_accuracy: 0.4999\n",
      "Epoch 201/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 67.6993 - accuracy: 0.4990 - val_loss: 66.5379 - val_accuracy: 0.4999\n",
      "Epoch 202/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 65.4463 - accuracy: 0.5030 - val_loss: 64.3079 - val_accuracy: 0.4999\n",
      "Epoch 203/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 63.2338 - accuracy: 0.5021 - val_loss: 62.1130 - val_accuracy: 0.4999\n",
      "Epoch 204/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 61.0608 - accuracy: 0.5024 - val_loss: 59.9619 - val_accuracy: 0.4999\n",
      "Epoch 205/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 58.9303 - accuracy: 0.5005 - val_loss: 57.8532 - val_accuracy: 0.4999\n",
      "Epoch 206/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 56.8404 - accuracy: 0.4994 - val_loss: 55.7831 - val_accuracy: 0.4999\n",
      "Epoch 207/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 54.7921 - accuracy: 0.5035 - val_loss: 53.7571 - val_accuracy: 0.4999\n",
      "Epoch 208/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 52.7841 - accuracy: 0.5015 - val_loss: 51.7711 - val_accuracy: 0.4999\n",
      "Epoch 209/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 50.8172 - accuracy: 0.5033 - val_loss: 49.8237 - val_accuracy: 0.4999\n",
      "Epoch 210/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 48.8902 - accuracy: 0.5035 - val_loss: 47.9204 - val_accuracy: 0.4999\n",
      "Epoch 211/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 47.0117 - accuracy: 0.4969 - val_loss: 46.0641 - val_accuracy: 0.4999\n",
      "Epoch 212/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 45.1740 - accuracy: 0.5039 - val_loss: 44.2467 - val_accuracy: 0.4999\n",
      "Epoch 213/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 43.3752 - accuracy: 0.4956 - val_loss: 42.4636 - val_accuracy: 0.4999\n",
      "Epoch 214/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 41.6078 - accuracy: 0.4968 - val_loss: 40.7126 - val_accuracy: 0.4999\n",
      "Epoch 215/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 39.8724 - accuracy: 0.5018 - val_loss: 38.9958 - val_accuracy: 0.4999\n",
      "Epoch 216/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 38.1752 - accuracy: 0.4993 - val_loss: 37.3196 - val_accuracy: 0.4999\n",
      "Epoch 217/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 36.5183 - accuracy: 0.4975 - val_loss: 35.6824 - val_accuracy: 0.4999\n",
      "Epoch 218/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 34.8959 - accuracy: 0.5011 - val_loss: 34.0772 - val_accuracy: 0.4999\n",
      "Epoch 219/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 33.3104 - accuracy: 0.5013 - val_loss: 32.5113 - val_accuracy: 0.4999\n",
      "Epoch 220/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 31.7608 - accuracy: 0.5033 - val_loss: 30.9797 - val_accuracy: 0.4999\n",
      "Epoch 221/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 30.2498 - accuracy: 0.4994 - val_loss: 29.4883 - val_accuracy: 0.4999\n",
      "Epoch 222/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 28.7770 - accuracy: 0.4963 - val_loss: 28.0337 - val_accuracy: 0.4999\n",
      "Epoch 223/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 27.3435 - accuracy: 0.4951 - val_loss: 26.6236 - val_accuracy: 0.4999\n",
      "Epoch 224/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 25.9568 - accuracy: 0.4967 - val_loss: 25.2628 - val_accuracy: 0.4999\n",
      "Epoch 225/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 24.6153 - accuracy: 0.5029 - val_loss: 23.9408 - val_accuracy: 0.4999\n",
      "Epoch 226/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 23.3096 - accuracy: 0.4973 - val_loss: 22.6525 - val_accuracy: 0.4999\n",
      "Epoch 227/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 22.0385 - accuracy: 0.5034 - val_loss: 21.4012 - val_accuracy: 0.4999\n",
      "Epoch 228/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 20.8062 - accuracy: 0.5036 - val_loss: 20.1882 - val_accuracy: 0.4999\n",
      "Epoch 229/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 19.6152 - accuracy: 0.5015 - val_loss: 19.0197 - val_accuracy: 0.4999\n",
      "Epoch 230/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 18.4652 - accuracy: 0.5047 - val_loss: 17.8891 - val_accuracy: 0.4999\n",
      "Epoch 231/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 17.3509 - accuracy: 0.5007 - val_loss: 16.7911 - val_accuracy: 0.4999\n",
      "Epoch 232/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 16.2686 - accuracy: 0.5040 - val_loss: 15.7282 - val_accuracy: 0.4999\n",
      "Epoch 233/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 15.2281 - accuracy: 0.5067 - val_loss: 14.7116 - val_accuracy: 0.4999\n",
      "Epoch 234/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 14.2393 - accuracy: 0.4867 - val_loss: 13.7454 - val_accuracy: 0.4999\n",
      "Epoch 235/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 13.2937 - accuracy: 0.5035 - val_loss: 12.8247 - val_accuracy: 0.4999\n",
      "Epoch 236/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 12.3931 - accuracy: 0.4966 - val_loss: 11.9479 - val_accuracy: 0.4999\n",
      "Epoch 237/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 11.5400 - accuracy: 0.5021 - val_loss: 11.1179 - val_accuracy: 0.4999\n",
      "Epoch 238/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 10.7308 - accuracy: 0.5042 - val_loss: 10.3301 - val_accuracy: 0.4999\n",
      "Epoch 239/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 9.9572 - accuracy: 0.5051 - val_loss: 9.5733 - val_accuracy: 0.4999\n",
      "Epoch 240/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 9.2204 - accuracy: 0.4945 - val_loss: 8.8539 - val_accuracy: 0.4999\n",
      "Epoch 241/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 8.5228 - accuracy: 0.4976 - val_loss: 8.1794 - val_accuracy: 0.4999\n",
      "Epoch 242/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 7.8689 - accuracy: 0.5031 - val_loss: 7.5465 - val_accuracy: 0.4999\n",
      "Epoch 243/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 7.2537 - accuracy: 0.4970 - val_loss: 6.9517 - val_accuracy: 0.4999\n",
      "Epoch 244/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 6.6806 - accuracy: 0.4977 - val_loss: 6.4001 - val_accuracy: 0.4999\n",
      "Epoch 245/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 6.1484 - accuracy: 0.4970 - val_loss: 5.8863 - val_accuracy: 0.4999\n",
      "Epoch 246/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 5.6522 - accuracy: 0.5019 - val_loss: 5.4091 - val_accuracy: 0.4999\n",
      "Epoch 247/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 5.1917 - accuracy: 0.5084 - val_loss: 4.9702 - val_accuracy: 0.4999\n",
      "Epoch 248/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 4.7729 - accuracy: 0.4970 - val_loss: 4.5685 - val_accuracy: 0.4999\n",
      "Epoch 249/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 4.3884 - accuracy: 0.5036 - val_loss: 4.2047 - val_accuracy: 0.4999\n",
      "Epoch 250/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 4.0482 - accuracy: 0.4969 - val_loss: 3.8865 - val_accuracy: 0.4999\n",
      "Epoch 251/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 3.7493 - accuracy: 0.5007 - val_loss: 3.6068 - val_accuracy: 0.4999\n",
      "Epoch 252/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 3.4856 - accuracy: 0.4975 - val_loss: 3.3607 - val_accuracy: 0.4999\n",
      "Epoch 253/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 3.2549 - accuracy: 0.4933 - val_loss: 3.1428 - val_accuracy: 0.4999\n",
      "Epoch 254/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 3.0519 - accuracy: 0.4974 - val_loss: 2.9585 - val_accuracy: 0.4999\n",
      "Epoch 255/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.8846 - accuracy: 0.4988 - val_loss: 2.8096 - val_accuracy: 0.4999\n",
      "Epoch 256/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.7565 - accuracy: 0.4982 - val_loss: 2.7016 - val_accuracy: 0.4999\n",
      "Epoch 257/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.6647 - accuracy: 0.5032 - val_loss: 2.6274 - val_accuracy: 0.4999\n",
      "Epoch 258/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.6075 - accuracy: 0.4996 - val_loss: 2.5863 - val_accuracy: 0.4999\n",
      "Epoch 259/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 2.5716 - accuracy: 0.4986 - val_loss: 2.5518 - val_accuracy: 0.4999\n",
      "Epoch 260/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.5370 - accuracy: 0.4990 - val_loss: 2.5174 - val_accuracy: 0.4999\n",
      "Epoch 261/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.5023 - accuracy: 0.4989 - val_loss: 2.4829 - val_accuracy: 0.4999\n",
      "Epoch 262/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 2.4677 - accuracy: 0.5018 - val_loss: 2.4485 - val_accuracy: 0.4999\n",
      "Epoch 263/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.4339 - accuracy: 0.5011 - val_loss: 2.4151 - val_accuracy: 0.4999\n",
      "Epoch 264/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.4016 - accuracy: 0.4918 - val_loss: 2.3824 - val_accuracy: 0.4999\n",
      "Epoch 265/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.3679 - accuracy: 0.5008 - val_loss: 2.3498 - val_accuracy: 0.4999\n",
      "Epoch 266/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 2.3358 - accuracy: 0.4989 - val_loss: 2.3178 - val_accuracy: 0.4999\n",
      "Epoch 267/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.3038 - accuracy: 0.4996 - val_loss: 2.2859 - val_accuracy: 0.4999\n",
      "Epoch 268/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.2715 - accuracy: 0.4988 - val_loss: 2.2540 - val_accuracy: 0.4999\n",
      "Epoch 269/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.2398 - accuracy: 0.5003 - val_loss: 2.2221 - val_accuracy: 0.4999\n",
      "Epoch 270/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.2078 - accuracy: 0.5006 - val_loss: 2.1901 - val_accuracy: 0.4999\n",
      "Epoch 271/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 2.1760 - accuracy: 0.4980 - val_loss: 2.1582 - val_accuracy: 0.4999\n",
      "Epoch 272/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.1434 - accuracy: 0.5068 - val_loss: 2.1271 - val_accuracy: 0.4999\n",
      "Epoch 273/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.1131 - accuracy: 0.4971 - val_loss: 2.0960 - val_accuracy: 0.4999\n",
      "Epoch 274/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 2.0826 - accuracy: 0.4963 - val_loss: 2.0657 - val_accuracy: 0.4999\n",
      "Epoch 275/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.0519 - accuracy: 0.4973 - val_loss: 2.0354 - val_accuracy: 0.4999\n",
      "Epoch 276/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 2.0215 - accuracy: 0.4997 - val_loss: 2.0051 - val_accuracy: 0.4999\n",
      "Epoch 277/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.9915 - accuracy: 0.4960 - val_loss: 1.9749 - val_accuracy: 0.4999\n",
      "Epoch 278/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.9609 - accuracy: 0.4986 - val_loss: 1.9446 - val_accuracy: 0.4999\n",
      "Epoch 279/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.9307 - accuracy: 0.4994 - val_loss: 1.9144 - val_accuracy: 0.4999\n",
      "Epoch 280/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 1.9004 - accuracy: 0.4964 - val_loss: 1.8842 - val_accuracy: 0.4999\n",
      "Epoch 281/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.8702 - accuracy: 0.4983 - val_loss: 1.8539 - val_accuracy: 0.4999\n",
      "Epoch 282/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.8401 - accuracy: 0.5028 - val_loss: 1.8251 - val_accuracy: 0.4999\n",
      "Epoch 283/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.8119 - accuracy: 0.4964 - val_loss: 1.7967 - val_accuracy: 0.4999\n",
      "Epoch 284/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.7839 - accuracy: 0.4983 - val_loss: 1.7702 - val_accuracy: 0.4999\n",
      "Epoch 285/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.7577 - accuracy: 0.4995 - val_loss: 1.7441 - val_accuracy: 0.4999\n",
      "Epoch 286/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.7320 - accuracy: 0.5026 - val_loss: 1.7189 - val_accuracy: 0.4999\n",
      "Epoch 287/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.7071 - accuracy: 0.5025 - val_loss: 1.6941 - val_accuracy: 0.4999\n",
      "Epoch 288/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.6819 - accuracy: 0.5021 - val_loss: 1.6698 - val_accuracy: 0.4999\n",
      "Epoch 289/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.6579 - accuracy: 0.5068 - val_loss: 1.6455 - val_accuracy: 0.4999\n",
      "Epoch 290/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.6336 - accuracy: 0.5060 - val_loss: 1.6211 - val_accuracy: 0.4999\n",
      "Epoch 291/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.6092 - accuracy: 0.4996 - val_loss: 1.5968 - val_accuracy: 0.4999\n",
      "Epoch 292/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.5860 - accuracy: 0.4980 - val_loss: 1.5739 - val_accuracy: 0.4999\n",
      "Epoch 293/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.5630 - accuracy: 0.4978 - val_loss: 1.5513 - val_accuracy: 0.4999\n",
      "Epoch 294/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.5402 - accuracy: 0.5001 - val_loss: 1.5286 - val_accuracy: 0.4999\n",
      "Epoch 295/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.5179 - accuracy: 0.5010 - val_loss: 1.5059 - val_accuracy: 0.4999\n",
      "Epoch 296/300\n",
      "84/84 [==============================] - 1s 16ms/step - loss: 1.4945 - accuracy: 0.5029 - val_loss: 1.4832 - val_accuracy: 0.4999\n",
      "Epoch 297/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.4722 - accuracy: 0.5025 - val_loss: 1.4608 - val_accuracy: 0.4999\n",
      "Epoch 298/300\n",
      "84/84 [==============================] - 1s 15ms/step - loss: 1.4506 - accuracy: 0.4973 - val_loss: 1.4396 - val_accuracy: 0.4999\n",
      "Epoch 299/300\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1.4292 - accuracy: 0.4985 - val_loss: 1.4186 - val_accuracy: 0.4999\n",
      "Epoch 300/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1.4083 - accuracy: 0.5040 - val_loss: 1.3983 - val_accuracy: 0.4999\n",
      "78/78 [==============================] - 0s 5ms/step - loss: 1.3983 - accuracy: 0.4999\n",
      "{'loss': 1.3982722759246826, 'accuracy': 0.49987393617630005} \n",
      " 299 \n",
      "\n",
      "Model time: 5.945892233401537 minutes\n",
      "\n",
      "Total time: 122.82774391770363 minutes\n",
      "\n",
      "\n",
      "Model  77  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                    16\n",
      "Activation function           relu\n",
      "Dropout                        0.4\n",
      "L1                             1.0\n",
      "L2                           0.001\n",
      "Batch size                      64\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 3477481, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 5s 8ms/step - loss: 311.4927 - accuracy: 0.4893 - val_loss: 261.8663 - val_accuracy: 0.4652\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 219.2748 - accuracy: 0.4992 - val_loss: 179.6010 - val_accuracy: 0.4929\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 146.7386 - accuracy: 0.4938 - val_loss: 116.8461 - val_accuracy: 0.5060\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 93.4206 - accuracy: 0.5020 - val_loss: 72.6854 - val_accuracy: 0.5009\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 57.9067 - accuracy: 0.5004 - val_loss: 46.1279 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 39.9124 - accuracy: 0.5003 - val_loss: 34.6125 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 29.9778 - accuracy: 0.5003 - val_loss: 25.6009 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 21.7986 - accuracy: 0.5003 - val_loss: 18.2108 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.1166 - accuracy: 0.5003 - val_loss: 12.2131 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 9.7386 - accuracy: 0.5003 - val_loss: 7.4514 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.6351 - accuracy: 0.5003 - val_loss: 4.0273 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2.8933 - accuracy: 0.5003 - val_loss: 1.9677 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.4345 - accuracy: 0.5003 - val_loss: 1.1379 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0477 - accuracy: 0.5003 - val_loss: 0.9630 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8950 - accuracy: 0.5003 - val_loss: 0.8309 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7855 - accuracy: 0.4981 - val_loss: 0.7524 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7389 - accuracy: 0.4970 - val_loss: 0.7339 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "324/335 [============================>.] - ETA: 0s - loss: 0.7335 - accuracy: 0.4991Restoring model weights from the end of the best epoch: 17.\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7334 - accuracy: 0.5003 - val_loss: 0.7343 - val_accuracy: 0.5001\n",
      "Epoch 18: early stopping\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.7339 - accuracy: 0.5001\n",
      "{'loss': 0.7338593602180481, 'accuracy': 0.5001260638237} \n",
      " 17 \n",
      "\n",
      "Model time: 0.6612547039985657 minutes\n",
      "\n",
      "Total time: 123.4890652783215 minutes\n",
      "\n",
      "\n",
      "Model  78  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     4\n",
      "Activation function         linear\n",
      "Dropout                        0.1\n",
      "L1                             1.0\n",
      "L2                          0.0001\n",
      "Batch size                      16\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 394331, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 8s 5ms/step - loss: 4.7027 - accuracy: 0.5030 - val_loss: 0.7752 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "1323/1339 [============================>.] - ETA: 0s - loss: 0.7720 - accuracy: 0.4998Restoring model weights from the end of the best epoch: 1.\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7720 - accuracy: 0.4998 - val_loss: 0.7754 - val_accuracy: 0.4999\n",
      "Epoch 2: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 0.7752 - accuracy: 0.5001\n",
      "{'loss': 0.7752219438552856, 'accuracy': 0.5001260638237} \n",
      " 1 \n",
      "\n",
      "Model time: 0.3123355060815811 minutes\n",
      "\n",
      "Total time: 123.80148417130113 minutes\n",
      "\n",
      "\n",
      "Model  79  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                    16\n",
      "Activation function           relu\n",
      "Dropout                        0.9\n",
      "L1                          0.0001\n",
      "L2                             0.0\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 3498369, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 4s 13ms/step - loss: 1.9043 - accuracy: 0.4996 - val_loss: 0.7502 - val_accuracy: 0.5005\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.7666 - accuracy: 0.4995 - val_loss: 0.7415 - val_accuracy: 0.5038\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6160 - accuracy: 0.5019 - val_loss: 0.7358 - val_accuracy: 0.5058\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.5665 - accuracy: 0.4992 - val_loss: 0.7318 - val_accuracy: 0.5048\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.4017 - accuracy: 0.5011 - val_loss: 0.7292 - val_accuracy: 0.5039\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.2988 - accuracy: 0.5012 - val_loss: 0.7275 - val_accuracy: 0.5050\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1626 - accuracy: 0.5018 - val_loss: 0.7265 - val_accuracy: 0.5031\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2297 - accuracy: 0.4983 - val_loss: 0.7256 - val_accuracy: 0.5010\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.0873 - accuracy: 0.5018 - val_loss: 0.7249 - val_accuracy: 0.4996\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0651 - accuracy: 0.5027 - val_loss: 0.7244 - val_accuracy: 0.5007\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.0827 - accuracy: 0.4996 - val_loss: 0.7241 - val_accuracy: 0.5015\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9989 - accuracy: 0.5014 - val_loss: 0.7238 - val_accuracy: 0.5024\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9987 - accuracy: 0.5036 - val_loss: 0.7236 - val_accuracy: 0.5018\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9609 - accuracy: 0.5029 - val_loss: 0.7235 - val_accuracy: 0.5015\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.9517 - accuracy: 0.4993 - val_loss: 0.7233 - val_accuracy: 0.5007\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8794 - accuracy: 0.5029 - val_loss: 0.7232 - val_accuracy: 0.5013\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8971 - accuracy: 0.5039 - val_loss: 0.7230 - val_accuracy: 0.5020\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.8974 - accuracy: 0.5032 - val_loss: 0.7229 - val_accuracy: 0.5018\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8809 - accuracy: 0.5004 - val_loss: 0.7228 - val_accuracy: 0.5006\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8495 - accuracy: 0.5018 - val_loss: 0.7227 - val_accuracy: 0.5006\n",
      "Epoch 21/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8273 - accuracy: 0.5010 - val_loss: 0.7226 - val_accuracy: 0.5003\n",
      "Epoch 22/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8243 - accuracy: 0.5022 - val_loss: 0.7225 - val_accuracy: 0.5003\n",
      "Epoch 23/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8535 - accuracy: 0.4996 - val_loss: 0.7224 - val_accuracy: 0.5002\n",
      "Epoch 24/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.8202 - accuracy: 0.5013 - val_loss: 0.7222 - val_accuracy: 0.5007\n",
      "Epoch 25/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8120 - accuracy: 0.4997 - val_loss: 0.7221 - val_accuracy: 0.5002\n",
      "Epoch 26/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.8042 - accuracy: 0.4987 - val_loss: 0.7220 - val_accuracy: 0.5007\n",
      "Epoch 27/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7962 - accuracy: 0.5026 - val_loss: 0.7219 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7998 - accuracy: 0.5017 - val_loss: 0.7218 - val_accuracy: 0.5000\n",
      "Epoch 29/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7749 - accuracy: 0.5037 - val_loss: 0.7217 - val_accuracy: 0.4997\n",
      "Epoch 30/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7878 - accuracy: 0.5020 - val_loss: 0.7216 - val_accuracy: 0.4999\n",
      "Epoch 31/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7618 - accuracy: 0.5034 - val_loss: 0.7215 - val_accuracy: 0.4998\n",
      "Epoch 32/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7569 - accuracy: 0.5025 - val_loss: 0.7214 - val_accuracy: 0.4999\n",
      "Epoch 33/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7612 - accuracy: 0.5026 - val_loss: 0.7213 - val_accuracy: 0.4999\n",
      "Epoch 34/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7610 - accuracy: 0.5021 - val_loss: 0.7212 - val_accuracy: 0.4998\n",
      "Epoch 35/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7455 - accuracy: 0.5024 - val_loss: 0.7211 - val_accuracy: 0.4999\n",
      "Epoch 36/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7447 - accuracy: 0.5014 - val_loss: 0.7210 - val_accuracy: 0.4998\n",
      "Epoch 37/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7519 - accuracy: 0.5047 - val_loss: 0.7208 - val_accuracy: 0.4998\n",
      "Epoch 38/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7473 - accuracy: 0.5040 - val_loss: 0.7207 - val_accuracy: 0.4998\n",
      "Epoch 39/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7526 - accuracy: 0.5025 - val_loss: 0.7206 - val_accuracy: 0.4998\n",
      "Epoch 40/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7562 - accuracy: 0.5001 - val_loss: 0.7205 - val_accuracy: 0.4998\n",
      "Epoch 41/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7373 - accuracy: 0.5032 - val_loss: 0.7204 - val_accuracy: 0.4998\n",
      "Epoch 42/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7359 - accuracy: 0.5005 - val_loss: 0.7202 - val_accuracy: 0.4998\n",
      "Epoch 43/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7466 - accuracy: 0.5005 - val_loss: 0.7201 - val_accuracy: 0.4998\n",
      "Epoch 44/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7368 - accuracy: 0.5006 - val_loss: 0.7200 - val_accuracy: 0.4999\n",
      "Epoch 45/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7344 - accuracy: 0.5007 - val_loss: 0.7198 - val_accuracy: 0.5000\n",
      "Epoch 46/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7380 - accuracy: 0.5002 - val_loss: 0.7197 - val_accuracy: 0.5000\n",
      "Epoch 47/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7280 - accuracy: 0.5025 - val_loss: 0.7196 - val_accuracy: 0.5000\n",
      "Epoch 48/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7310 - accuracy: 0.5014 - val_loss: 0.7194 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7382 - accuracy: 0.5012 - val_loss: 0.7193 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7371 - accuracy: 0.5003 - val_loss: 0.7191 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7289 - accuracy: 0.5006 - val_loss: 0.7190 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7299 - accuracy: 0.5015 - val_loss: 0.7188 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7226 - accuracy: 0.5024 - val_loss: 0.7186 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7268 - accuracy: 0.5018 - val_loss: 0.7185 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7265 - accuracy: 0.4992 - val_loss: 0.7183 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7247 - accuracy: 0.5030 - val_loss: 0.7181 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7231 - accuracy: 0.5030 - val_loss: 0.7179 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7276 - accuracy: 0.5018 - val_loss: 0.7178 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7231 - accuracy: 0.5016 - val_loss: 0.7176 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7236 - accuracy: 0.5004 - val_loss: 0.7174 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7231 - accuracy: 0.5033 - val_loss: 0.7172 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7293 - accuracy: 0.5021 - val_loss: 0.7170 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7245 - accuracy: 0.4998 - val_loss: 0.7168 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7203 - accuracy: 0.5011 - val_loss: 0.7166 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7195 - accuracy: 0.5027 - val_loss: 0.7164 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7193 - accuracy: 0.5013 - val_loss: 0.7161 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7185 - accuracy: 0.5007 - val_loss: 0.7159 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7198 - accuracy: 0.5006 - val_loss: 0.7157 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7204 - accuracy: 0.5007 - val_loss: 0.7155 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7185 - accuracy: 0.5018 - val_loss: 0.7153 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 0.7215 - accuracy: 0.5016 - val_loss: 0.7151 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7174 - accuracy: 0.5010 - val_loss: 0.7148 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7173 - accuracy: 0.5011 - val_loss: 0.7146 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7162 - accuracy: 0.5020 - val_loss: 0.7144 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7157 - accuracy: 0.5025 - val_loss: 0.7141 - val_accuracy: 0.5002\n",
      "Epoch 76/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7165 - accuracy: 0.5002 - val_loss: 0.7139 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7177 - accuracy: 0.5024 - val_loss: 0.7137 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7138 - accuracy: 0.5019 - val_loss: 0.7134 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7144 - accuracy: 0.5018 - val_loss: 0.7132 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7151 - accuracy: 0.5023 - val_loss: 0.7129 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7154 - accuracy: 0.5016 - val_loss: 0.7127 - val_accuracy: 0.5002\n",
      "Epoch 82/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7145 - accuracy: 0.5007 - val_loss: 0.7124 - val_accuracy: 0.5002\n",
      "Epoch 83/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7132 - accuracy: 0.5018 - val_loss: 0.7122 - val_accuracy: 0.5002\n",
      "Epoch 84/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7129 - accuracy: 0.5015 - val_loss: 0.7119 - val_accuracy: 0.5002\n",
      "Epoch 85/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7127 - accuracy: 0.5029 - val_loss: 0.7116 - val_accuracy: 0.5003\n",
      "Epoch 86/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7139 - accuracy: 0.5017 - val_loss: 0.7114 - val_accuracy: 0.5002\n",
      "Epoch 87/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7121 - accuracy: 0.5031 - val_loss: 0.7112 - val_accuracy: 0.5002\n",
      "Epoch 88/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7121 - accuracy: 0.5008 - val_loss: 0.7109 - val_accuracy: 0.5002\n",
      "Epoch 89/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7130 - accuracy: 0.5032 - val_loss: 0.7107 - val_accuracy: 0.5002\n",
      "Epoch 90/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7117 - accuracy: 0.5010 - val_loss: 0.7104 - val_accuracy: 0.5002\n",
      "Epoch 91/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7111 - accuracy: 0.5021 - val_loss: 0.7102 - val_accuracy: 0.5002\n",
      "Epoch 92/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7104 - accuracy: 0.5019 - val_loss: 0.7099 - val_accuracy: 0.5002\n",
      "Epoch 93/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7104 - accuracy: 0.5018 - val_loss: 0.7097 - val_accuracy: 0.5002\n",
      "Epoch 94/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7114 - accuracy: 0.5007 - val_loss: 0.7094 - val_accuracy: 0.5003\n",
      "Epoch 95/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7096 - accuracy: 0.5019 - val_loss: 0.7092 - val_accuracy: 0.5003\n",
      "Epoch 96/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7095 - accuracy: 0.5009 - val_loss: 0.7090 - val_accuracy: 0.5003\n",
      "Epoch 97/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7087 - accuracy: 0.5026 - val_loss: 0.7087 - val_accuracy: 0.5004\n",
      "Epoch 98/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7093 - accuracy: 0.4999 - val_loss: 0.7085 - val_accuracy: 0.5003\n",
      "Epoch 99/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7092 - accuracy: 0.5018 - val_loss: 0.7082 - val_accuracy: 0.5002\n",
      "Epoch 100/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7095 - accuracy: 0.5009 - val_loss: 0.7080 - val_accuracy: 0.5002\n",
      "Epoch 101/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7095 - accuracy: 0.5018 - val_loss: 0.7078 - val_accuracy: 0.5002\n",
      "Epoch 102/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7081 - accuracy: 0.5029 - val_loss: 0.7076 - val_accuracy: 0.5002\n",
      "Epoch 103/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7075 - accuracy: 0.5006 - val_loss: 0.7074 - val_accuracy: 0.5002\n",
      "Epoch 104/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7083 - accuracy: 0.5020 - val_loss: 0.7071 - val_accuracy: 0.5003\n",
      "Epoch 105/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7077 - accuracy: 0.5026 - val_loss: 0.7069 - val_accuracy: 0.5002\n",
      "Epoch 106/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7086 - accuracy: 0.5013 - val_loss: 0.7067 - val_accuracy: 0.5004\n",
      "Epoch 107/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7070 - accuracy: 0.5027 - val_loss: 0.7065 - val_accuracy: 0.5004\n",
      "Epoch 108/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.7065 - accuracy: 0.5018 - val_loss: 0.7063 - val_accuracy: 0.5002\n",
      "Epoch 109/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7067 - accuracy: 0.5024 - val_loss: 0.7061 - val_accuracy: 0.5002\n",
      "Epoch 110/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7066 - accuracy: 0.5026 - val_loss: 0.7060 - val_accuracy: 0.5002\n",
      "Epoch 111/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7067 - accuracy: 0.5017 - val_loss: 0.7058 - val_accuracy: 0.5002\n",
      "Epoch 112/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7061 - accuracy: 0.5018 - val_loss: 0.7056 - val_accuracy: 0.5002\n",
      "Epoch 113/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7065 - accuracy: 0.5006 - val_loss: 0.7054 - val_accuracy: 0.5004\n",
      "Epoch 114/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7053 - accuracy: 0.5021 - val_loss: 0.7053 - val_accuracy: 0.5002\n",
      "Epoch 115/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7054 - accuracy: 0.5021 - val_loss: 0.7051 - val_accuracy: 0.5003\n",
      "Epoch 116/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7051 - accuracy: 0.5015 - val_loss: 0.7050 - val_accuracy: 0.5004\n",
      "Epoch 117/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7056 - accuracy: 0.5017 - val_loss: 0.7048 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7048 - accuracy: 0.5020 - val_loss: 0.7046 - val_accuracy: 0.5002\n",
      "Epoch 119/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7046 - accuracy: 0.5014 - val_loss: 0.7045 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7050 - accuracy: 0.5016 - val_loss: 0.7043 - val_accuracy: 0.5002\n",
      "Epoch 121/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7043 - accuracy: 0.5017 - val_loss: 0.7042 - val_accuracy: 0.5002\n",
      "Epoch 122/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7042 - accuracy: 0.5020 - val_loss: 0.7040 - val_accuracy: 0.5002\n",
      "Epoch 123/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7046 - accuracy: 0.5006 - val_loss: 0.7039 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7039 - accuracy: 0.5021 - val_loss: 0.7037 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7035 - accuracy: 0.5015 - val_loss: 0.7035 - val_accuracy: 0.5001\n",
      "Epoch 126/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7037 - accuracy: 0.5011 - val_loss: 0.7034 - val_accuracy: 0.5001\n",
      "Epoch 127/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7037 - accuracy: 0.5017 - val_loss: 0.7032 - val_accuracy: 0.5004\n",
      "Epoch 128/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7035 - accuracy: 0.5023 - val_loss: 0.7031 - val_accuracy: 0.5004\n",
      "Epoch 129/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7033 - accuracy: 0.5028 - val_loss: 0.7029 - val_accuracy: 0.5002\n",
      "Epoch 130/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7035 - accuracy: 0.5014 - val_loss: 0.7028 - val_accuracy: 0.5003\n",
      "Epoch 131/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7025 - accuracy: 0.5009 - val_loss: 0.7026 - val_accuracy: 0.5004\n",
      "Epoch 132/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7024 - accuracy: 0.4974 - val_loss: 0.7025 - val_accuracy: 0.5008\n",
      "Epoch 133/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7026 - accuracy: 0.5014 - val_loss: 0.7023 - val_accuracy: 0.5006\n",
      "Epoch 134/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7022 - accuracy: 0.5030 - val_loss: 0.7022 - val_accuracy: 0.5008\n",
      "Epoch 135/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7026 - accuracy: 0.5018 - val_loss: 0.7020 - val_accuracy: 0.5007\n",
      "Epoch 136/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7019 - accuracy: 0.5033 - val_loss: 0.7019 - val_accuracy: 0.5005\n",
      "Epoch 137/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7020 - accuracy: 0.4989 - val_loss: 0.7018 - val_accuracy: 0.5003\n",
      "Epoch 138/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7019 - accuracy: 0.5007 - val_loss: 0.7016 - val_accuracy: 0.5002\n",
      "Epoch 139/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7017 - accuracy: 0.4991 - val_loss: 0.7015 - val_accuracy: 0.5002\n",
      "Epoch 140/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7015 - accuracy: 0.4998 - val_loss: 0.7014 - val_accuracy: 0.5002\n",
      "Epoch 141/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7015 - accuracy: 0.5014 - val_loss: 0.7012 - val_accuracy: 0.5010\n",
      "Epoch 142/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7011 - accuracy: 0.4969 - val_loss: 0.7011 - val_accuracy: 0.5005\n",
      "Epoch 143/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7009 - accuracy: 0.5008 - val_loss: 0.7009 - val_accuracy: 0.5010\n",
      "Epoch 144/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7012 - accuracy: 0.5005 - val_loss: 0.7008 - val_accuracy: 0.5007\n",
      "Epoch 145/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7007 - accuracy: 0.5015 - val_loss: 0.7007 - val_accuracy: 0.5013\n",
      "Epoch 146/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7007 - accuracy: 0.5010 - val_loss: 0.7005 - val_accuracy: 0.5008\n",
      "Epoch 147/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7004 - accuracy: 0.5031 - val_loss: 0.7004 - val_accuracy: 0.5017\n",
      "Epoch 148/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7005 - accuracy: 0.5008 - val_loss: 0.7003 - val_accuracy: 0.5008\n",
      "Epoch 149/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7001 - accuracy: 0.4990 - val_loss: 0.7002 - val_accuracy: 0.5007\n",
      "Epoch 150/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7001 - accuracy: 0.4998 - val_loss: 0.7000 - val_accuracy: 0.5020\n",
      "Epoch 151/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7003 - accuracy: 0.5017 - val_loss: 0.6999 - val_accuracy: 0.5024\n",
      "Epoch 152/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6998 - accuracy: 0.4983 - val_loss: 0.6998 - val_accuracy: 0.5018\n",
      "Epoch 153/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6998 - accuracy: 0.4999 - val_loss: 0.6997 - val_accuracy: 0.5019\n",
      "Epoch 154/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6994 - accuracy: 0.4964 - val_loss: 0.6996 - val_accuracy: 0.5014\n",
      "Epoch 155/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6995 - accuracy: 0.4979 - val_loss: 0.6994 - val_accuracy: 0.5014\n",
      "Epoch 156/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6992 - accuracy: 0.5008 - val_loss: 0.6993 - val_accuracy: 0.5008\n",
      "Epoch 157/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.5016 - val_loss: 0.6992 - val_accuracy: 0.5012\n",
      "Epoch 158/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6989 - accuracy: 0.5020 - val_loss: 0.6991 - val_accuracy: 0.5018\n",
      "Epoch 159/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6990 - accuracy: 0.5001 - val_loss: 0.6990 - val_accuracy: 0.5010\n",
      "Epoch 160/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6989 - accuracy: 0.5020 - val_loss: 0.6989 - val_accuracy: 0.5010\n",
      "Epoch 161/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6987 - accuracy: 0.5011 - val_loss: 0.6988 - val_accuracy: 0.5013\n",
      "Epoch 162/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6991 - accuracy: 0.5011 - val_loss: 0.6987 - val_accuracy: 0.5016\n",
      "Epoch 163/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6986 - accuracy: 0.5014 - val_loss: 0.6986 - val_accuracy: 0.5033\n",
      "Epoch 164/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6986 - accuracy: 0.5007 - val_loss: 0.6985 - val_accuracy: 0.5013\n",
      "Epoch 165/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6984 - accuracy: 0.5001 - val_loss: 0.6984 - val_accuracy: 0.5060\n",
      "Epoch 166/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6983 - accuracy: 0.4981 - val_loss: 0.6984 - val_accuracy: 0.5023\n",
      "Epoch 167/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6983 - accuracy: 0.4971 - val_loss: 0.6983 - val_accuracy: 0.5013\n",
      "Epoch 168/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6982 - accuracy: 0.5020 - val_loss: 0.6982 - val_accuracy: 0.5010\n",
      "Epoch 169/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6980 - accuracy: 0.5024 - val_loss: 0.6981 - val_accuracy: 0.5010\n",
      "Epoch 170/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6979 - accuracy: 0.5014 - val_loss: 0.6980 - val_accuracy: 0.5012\n",
      "Epoch 171/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6982 - accuracy: 0.4994 - val_loss: 0.6979 - val_accuracy: 0.5017\n",
      "Epoch 172/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6983 - accuracy: 0.5020 - val_loss: 0.6979 - val_accuracy: 0.5014\n",
      "Epoch 173/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6976 - accuracy: 0.5014 - val_loss: 0.6978 - val_accuracy: 0.5018\n",
      "Epoch 174/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6980 - accuracy: 0.5003 - val_loss: 0.6977 - val_accuracy: 0.5027\n",
      "Epoch 175/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6975 - accuracy: 0.4997 - val_loss: 0.6976 - val_accuracy: 0.5019\n",
      "Epoch 176/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6975 - accuracy: 0.4982 - val_loss: 0.6975 - val_accuracy: 0.5030\n",
      "Epoch 177/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6975 - accuracy: 0.5004 - val_loss: 0.6975 - val_accuracy: 0.5032\n",
      "Epoch 178/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6973 - accuracy: 0.4988 - val_loss: 0.6974 - val_accuracy: 0.5057\n",
      "Epoch 179/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6973 - accuracy: 0.4975 - val_loss: 0.6973 - val_accuracy: 0.5048\n",
      "Epoch 180/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6972 - accuracy: 0.5040 - val_loss: 0.6972 - val_accuracy: 0.5069\n",
      "Epoch 181/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6971 - accuracy: 0.5040 - val_loss: 0.6971 - val_accuracy: 0.5096\n",
      "Epoch 182/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6970 - accuracy: 0.5017 - val_loss: 0.6970 - val_accuracy: 0.5118\n",
      "Epoch 183/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6970 - accuracy: 0.5041 - val_loss: 0.6970 - val_accuracy: 0.5089\n",
      "Epoch 184/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6968 - accuracy: 0.4993 - val_loss: 0.6969 - val_accuracy: 0.5139\n",
      "Epoch 185/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.4988 - val_loss: 0.6968 - val_accuracy: 0.5109\n",
      "Epoch 186/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6967 - accuracy: 0.5037 - val_loss: 0.6967 - val_accuracy: 0.5104\n",
      "Epoch 187/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.6966 - accuracy: 0.5022 - val_loss: 0.6967 - val_accuracy: 0.5120\n",
      "Epoch 188/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6964 - accuracy: 0.5016 - val_loss: 0.6966 - val_accuracy: 0.5113\n",
      "Epoch 189/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6966 - accuracy: 0.5038 - val_loss: 0.6965 - val_accuracy: 0.5286\n",
      "Epoch 190/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6963 - accuracy: 0.5010 - val_loss: 0.6965 - val_accuracy: 0.5171\n",
      "Epoch 191/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6964 - accuracy: 0.4978 - val_loss: 0.6964 - val_accuracy: 0.5140\n",
      "Epoch 192/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6963 - accuracy: 0.5031 - val_loss: 0.6963 - val_accuracy: 0.5088\n",
      "Epoch 193/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6962 - accuracy: 0.5026 - val_loss: 0.6963 - val_accuracy: 0.5140\n",
      "Epoch 194/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6961 - accuracy: 0.4991 - val_loss: 0.6962 - val_accuracy: 0.5093\n",
      "Epoch 195/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6961 - accuracy: 0.5035 - val_loss: 0.6961 - val_accuracy: 0.5109\n",
      "Epoch 196/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6961 - accuracy: 0.5033 - val_loss: 0.6961 - val_accuracy: 0.5099\n",
      "Epoch 197/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6962 - accuracy: 0.5032 - val_loss: 0.6960 - val_accuracy: 0.5080\n",
      "Epoch 198/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6958 - accuracy: 0.5029 - val_loss: 0.6959 - val_accuracy: 0.5119\n",
      "Epoch 199/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6958 - accuracy: 0.5028 - val_loss: 0.6959 - val_accuracy: 0.5157\n",
      "Epoch 200/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6958 - accuracy: 0.4996 - val_loss: 0.6958 - val_accuracy: 0.5191\n",
      "Epoch 201/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6957 - accuracy: 0.5045 - val_loss: 0.6958 - val_accuracy: 0.5114\n",
      "Epoch 202/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6956 - accuracy: 0.4987 - val_loss: 0.6957 - val_accuracy: 0.5156\n",
      "Epoch 203/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6957 - accuracy: 0.5034 - val_loss: 0.6956 - val_accuracy: 0.5096\n",
      "Epoch 204/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.6954 - accuracy: 0.4992 - val_loss: 0.6956 - val_accuracy: 0.5107\n",
      "Epoch 205/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6955 - accuracy: 0.4998 - val_loss: 0.6955 - val_accuracy: 0.5117\n",
      "Epoch 206/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.6954 - accuracy: 0.4976 - val_loss: 0.6955 - val_accuracy: 0.5107\n",
      "Epoch 207/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6955 - accuracy: 0.5000 - val_loss: 0.6954 - val_accuracy: 0.5079\n",
      "Epoch 208/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6953 - accuracy: 0.5012 - val_loss: 0.6953 - val_accuracy: 0.5117\n",
      "Epoch 209/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6953 - accuracy: 0.5022 - val_loss: 0.6953 - val_accuracy: 0.5121\n",
      "Epoch 210/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6949 - accuracy: 0.5068 - val_loss: 0.6952 - val_accuracy: 0.5129\n",
      "Epoch 211/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6950 - accuracy: 0.4994 - val_loss: 0.6952 - val_accuracy: 0.5148\n",
      "Epoch 212/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6951 - accuracy: 0.5010 - val_loss: 0.6951 - val_accuracy: 0.5156\n",
      "Epoch 213/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6950 - accuracy: 0.5037 - val_loss: 0.6951 - val_accuracy: 0.5189\n",
      "Epoch 214/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6949 - accuracy: 0.5027 - val_loss: 0.6951 - val_accuracy: 0.5167\n",
      "Epoch 215/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6951 - accuracy: 0.5011 - val_loss: 0.6950 - val_accuracy: 0.5204\n",
      "Epoch 216/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.6949 - accuracy: 0.4974 - val_loss: 0.6950 - val_accuracy: 0.5156\n",
      "Epoch 217/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6950 - accuracy: 0.4969 - val_loss: 0.6950 - val_accuracy: 0.5113\n",
      "Epoch 218/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6949 - accuracy: 0.4980 - val_loss: 0.6949 - val_accuracy: 0.5095\n",
      "Epoch 219/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6948 - accuracy: 0.5010 - val_loss: 0.6949 - val_accuracy: 0.5084\n",
      "Epoch 220/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6948 - accuracy: 0.5025 - val_loss: 0.6949 - val_accuracy: 0.5079\n",
      "Epoch 221/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6949 - accuracy: 0.5045 - val_loss: 0.6949 - val_accuracy: 0.5094\n",
      "Epoch 222/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6945 - accuracy: 0.5022 - val_loss: 0.6948 - val_accuracy: 0.5119\n",
      "Epoch 223/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6946 - accuracy: 0.4966 - val_loss: 0.6948 - val_accuracy: 0.5127\n",
      "Epoch 224/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6945 - accuracy: 0.5022 - val_loss: 0.6948 - val_accuracy: 0.5140\n",
      "Epoch 225/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6946 - accuracy: 0.5006 - val_loss: 0.6947 - val_accuracy: 0.5108\n",
      "Epoch 226/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6945 - accuracy: 0.5024 - val_loss: 0.6947 - val_accuracy: 0.5136\n",
      "Epoch 227/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6945 - accuracy: 0.5033 - val_loss: 0.6947 - val_accuracy: 0.5165\n",
      "Epoch 228/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6943 - accuracy: 0.5010 - val_loss: 0.6946 - val_accuracy: 0.5235\n",
      "Epoch 229/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6944 - accuracy: 0.4983 - val_loss: 0.6946 - val_accuracy: 0.5192\n",
      "Epoch 230/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6947 - accuracy: 0.5019 - val_loss: 0.6946 - val_accuracy: 0.5131\n",
      "Epoch 231/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6943 - accuracy: 0.5030 - val_loss: 0.6946 - val_accuracy: 0.5127\n",
      "Epoch 232/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 0.6943 - accuracy: 0.5016 - val_loss: 0.6945 - val_accuracy: 0.5177\n",
      "Epoch 233/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6943 - accuracy: 0.5023 - val_loss: 0.6945 - val_accuracy: 0.5204\n",
      "Epoch 234/300\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.6947 - accuracy: 0.4971Restoring model weights from the end of the best epoch: 233.\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6946 - accuracy: 0.4982 - val_loss: 0.6945 - val_accuracy: 0.5154\n",
      "Epoch 234: early stopping\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.5204\n",
      "{'loss': 0.6945178508758545, 'accuracy': 0.520445704460144} \n",
      " 233 \n",
      "\n",
      "Model time: 5.4164830930531025 minutes\n",
      "\n",
      "Total time: 129.2180505990982 minutes\n",
      "\n",
      "\n",
      "Model  80  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                    16\n",
      "Activation function           relu\n",
      "Dropout                        0.5\n",
      "L1                         0.00001\n",
      "L2                             0.0\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 2083549, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 9s 6ms/step - loss: 0.8665 - accuracy: 0.5028 - val_loss: 0.6938 - val_accuracy: 0.5339\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7478 - accuracy: 0.5071 - val_loss: 0.6896 - val_accuracy: 0.5374\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7184 - accuracy: 0.5190 - val_loss: 0.6876 - val_accuracy: 0.5495\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6999 - accuracy: 0.5321 - val_loss: 0.6845 - val_accuracy: 0.5685\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6963 - accuracy: 0.5375 - val_loss: 0.6823 - val_accuracy: 0.5816\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6898 - accuracy: 0.5429 - val_loss: 0.6793 - val_accuracy: 0.5895\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6871 - accuracy: 0.5510 - val_loss: 0.6775 - val_accuracy: 0.5999\n",
      "Epoch 8/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6831 - accuracy: 0.5656 - val_loss: 0.6756 - val_accuracy: 0.6029\n",
      "Epoch 9/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6845 - accuracy: 0.5592 - val_loss: 0.6744 - val_accuracy: 0.6060\n",
      "Epoch 10/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6831 - accuracy: 0.5680 - val_loss: 0.6725 - val_accuracy: 0.6082\n",
      "Epoch 11/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6798 - accuracy: 0.5732 - val_loss: 0.6706 - val_accuracy: 0.6129\n",
      "Epoch 12/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6776 - accuracy: 0.5801 - val_loss: 0.6693 - val_accuracy: 0.6138\n",
      "Epoch 13/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6734 - accuracy: 0.5868 - val_loss: 0.6672 - val_accuracy: 0.6134\n",
      "Epoch 14/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6749 - accuracy: 0.5848 - val_loss: 0.6660 - val_accuracy: 0.6185\n",
      "Epoch 15/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6717 - accuracy: 0.5886 - val_loss: 0.6645 - val_accuracy: 0.6211\n",
      "Epoch 16/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6703 - accuracy: 0.5942 - val_loss: 0.6629 - val_accuracy: 0.6236\n",
      "Epoch 17/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6709 - accuracy: 0.5940 - val_loss: 0.6623 - val_accuracy: 0.6247\n",
      "Epoch 18/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6693 - accuracy: 0.5965 - val_loss: 0.6609 - val_accuracy: 0.6253\n",
      "Epoch 19/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6675 - accuracy: 0.6002 - val_loss: 0.6606 - val_accuracy: 0.6245\n",
      "Epoch 20/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6660 - accuracy: 0.6049 - val_loss: 0.6592 - val_accuracy: 0.6246\n",
      "Epoch 21/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6649 - accuracy: 0.6022 - val_loss: 0.6586 - val_accuracy: 0.6253\n",
      "Epoch 22/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6661 - accuracy: 0.6058 - val_loss: 0.6571 - val_accuracy: 0.6272\n",
      "Epoch 23/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6659 - accuracy: 0.6103 - val_loss: 0.6561 - val_accuracy: 0.6283\n",
      "Epoch 24/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6618 - accuracy: 0.6049 - val_loss: 0.6555 - val_accuracy: 0.6290\n",
      "Epoch 25/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6623 - accuracy: 0.6131 - val_loss: 0.6547 - val_accuracy: 0.6289\n",
      "Epoch 26/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6629 - accuracy: 0.6108 - val_loss: 0.6545 - val_accuracy: 0.6317\n",
      "Epoch 27/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6619 - accuracy: 0.6145 - val_loss: 0.6536 - val_accuracy: 0.6282\n",
      "Epoch 28/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6610 - accuracy: 0.6158 - val_loss: 0.6525 - val_accuracy: 0.6312\n",
      "Epoch 29/300\n",
      "1321/1339 [============================>.] - ETA: 0s - loss: 0.6617 - accuracy: 0.6098Restoring model weights from the end of the best epoch: 28.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6617 - accuracy: 0.6096 - val_loss: 0.6528 - val_accuracy: 0.6303\n",
      "Epoch 29: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 0.6525 - accuracy: 0.6312\n",
      "{'loss': 0.6524646282196045, 'accuracy': 0.6311702728271484} \n",
      " 28 \n",
      "\n",
      "Model time: 3.2466397434473038 minutes\n",
      "\n",
      "Total time: 132.4650069884956 minutes\n",
      "\n",
      "\n",
      "Model  81  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                    16\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.1\n",
      "L1                           100.0\n",
      "L2                             1.0\n",
      "Batch size                       8\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 2142870, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 16s 5ms/step - loss: 1582.2129 - accuracy: 0.5024 - val_loss: 1564.6017 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 1528.7849 - accuracy: 0.4971 - val_loss: 1507.4293 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "2671/2677 [============================>.] - ETA: 0s - loss: 1528.7676 - accuracy: 0.4947Restoring model weights from the end of the best epoch: 2.\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1528.7720 - accuracy: 0.4947 - val_loss: 1541.7111 - val_accuracy: 0.4999\n",
      "Epoch 3: early stopping\n",
      "2480/2480 [==============================] - 6s 3ms/step - loss: 1507.4293 - accuracy: 0.5001\n",
      "{'loss': 1507.4293212890625, 'accuracy': 0.5001260638237} \n",
      " 2 \n",
      "\n",
      "Model time: 0.827267337590456 minutes\n",
      "\n",
      "Total time: 133.29237432405353 minutes\n",
      "\n",
      "\n",
      "Model  82  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     4\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.5\n",
      "L1                          0.0001\n",
      "L2                         0.00001\n",
      "Batch size                      64\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 1850234, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 8ms/step - loss: 0.6962 - accuracy: 0.5262 - val_loss: 0.6839 - val_accuracy: 0.5807\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6897 - accuracy: 0.5593 - val_loss: 0.6713 - val_accuracy: 0.6149\n",
      "Epoch 3/300\n",
      "325/335 [============================>.] - ETA: 0s - loss: 0.6873 - accuracy: 0.5749Restoring model weights from the end of the best epoch: 2.\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6872 - accuracy: 0.5759 - val_loss: 0.6766 - val_accuracy: 0.6284\n",
      "Epoch 3: early stopping\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.6713 - accuracy: 0.6149\n",
      "{'loss': 0.6712653636932373, 'accuracy': 0.6149346828460693} \n",
      " 2 \n",
      "\n",
      "Model time: 0.16231783479452133 minutes\n",
      "\n",
      "Total time: 133.4550588093698 minutes\n",
      "\n",
      "\n",
      "Model  83  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                     4\n",
      "Activation function           tanh\n",
      "Dropout                        0.6\n",
      "L1                             0.1\n",
      "L2                         0.00001\n",
      "Batch size                      16\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 3135849, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 9s 6ms/step - loss: 5.2820 - accuracy: 0.5028 - val_loss: 2.6544 - val_accuracy: 0.5255\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.8637 - accuracy: 0.5016 - val_loss: 1.5159 - val_accuracy: 0.5037\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.3492 - accuracy: 0.4996 - val_loss: 1.1905 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.0561 - accuracy: 0.4944 - val_loss: 0.9391 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8551 - accuracy: 0.4943 - val_loss: 0.7906 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7544 - accuracy: 0.4970 - val_loss: 0.7250 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7109 - accuracy: 0.4991 - val_loss: 0.7017 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6962 - accuracy: 0.4963 - val_loss: 0.6939 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "1325/1339 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.4943Restoring model weights from the end of the best epoch: 8.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6939 - accuracy: 0.4942 - val_loss: 0.6939 - val_accuracy: 0.5001\n",
      "Epoch 9: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 0.6939 - accuracy: 0.4999\n",
      "{'loss': 0.6939111948013306, 'accuracy': 0.49987393617630005} \n",
      " 8 \n",
      "\n",
      "Model time: 1.454834669828415 minutes\n",
      "\n",
      "Total time: 134.90997682139277 minutes\n",
      "\n",
      "\n",
      "Model  84  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     4\n",
      "Activation function           tanh\n",
      "Dropout                        0.3\n",
      "L1                           0.001\n",
      "L2                           100.0\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 1725057, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 3s 10ms/step - loss: 1490.6521 - accuracy: 0.4905 - val_loss: 1377.6063 - val_accuracy: 0.5011\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1281.7424 - accuracy: 0.4928 - val_loss: 1190.3414 - val_accuracy: 0.5065\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1112.3561 - accuracy: 0.4918 - val_loss: 1037.8483 - val_accuracy: 0.5089\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 974.1041 - accuracy: 0.4954 - val_loss: 913.1292 - val_accuracy: 0.5133\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 860.8453 - accuracy: 0.4949 - val_loss: 810.7730 - val_accuracy: 0.5162\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 767.7228 - accuracy: 0.4933 - val_loss: 726.4222 - val_accuracy: 0.5189\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 690.7850 - accuracy: 0.4951 - val_loss: 656.5292 - val_accuracy: 0.5219\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 626.8237 - accuracy: 0.4980 - val_loss: 598.1953 - val_accuracy: 0.5237\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 573.2134 - accuracy: 0.5038 - val_loss: 549.0579 - val_accuracy: 0.5241\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 527.8187 - accuracy: 0.4984 - val_loss: 507.2000 - val_accuracy: 0.5245\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 488.9111 - accuracy: 0.5015 - val_loss: 471.0772 - val_accuracy: 0.5255\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 455.1028 - accuracy: 0.5046 - val_loss: 439.4536 - val_accuracy: 0.5256\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 425.2917 - accuracy: 0.5027 - val_loss: 411.3511 - val_accuracy: 0.5265\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 398.6086 - accuracy: 0.5060 - val_loss: 386.0053 - val_accuracy: 0.5251\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 374.3777 - accuracy: 0.5075 - val_loss: 362.8284 - val_accuracy: 0.5244\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 352.0861 - accuracy: 0.5060 - val_loss: 341.3772 - val_accuracy: 0.5242\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 331.3503 - accuracy: 0.5038 - val_loss: 321.3257 - val_accuracy: 0.5231\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 311.8913 - accuracy: 0.5067 - val_loss: 302.4393 - val_accuracy: 0.5189\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 293.5113 - accuracy: 0.5088 - val_loss: 284.5538 - val_accuracy: 0.5105\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 276.0722 - accuracy: 0.5067 - val_loss: 267.5549 - val_accuracy: 0.5048\n",
      "Epoch 21/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 259.4789 - accuracy: 0.5060 - val_loss: 251.3650 - val_accuracy: 0.5037\n",
      "Epoch 22/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 243.6659 - accuracy: 0.5077 - val_loss: 235.9292 - val_accuracy: 0.5007\n",
      "Epoch 23/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 228.5859 - accuracy: 0.5113 - val_loss: 221.2069 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 214.2038 - accuracy: 0.5049 - val_loss: 207.1674 - val_accuracy: 0.5006\n",
      "Epoch 25/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 200.4913 - accuracy: 0.5041 - val_loss: 193.7847 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 187.4242 - accuracy: 0.5039 - val_loss: 181.0359 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 174.9809 - accuracy: 0.5032 - val_loss: 168.9008 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 163.1415 - accuracy: 0.5050 - val_loss: 157.3601 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 151.8871 - accuracy: 0.5044 - val_loss: 146.3950 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 141.1996 - accuracy: 0.5025 - val_loss: 135.9880 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 131.0611 - accuracy: 0.5005 - val_loss: 126.1210 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 121.4544 - accuracy: 0.4955 - val_loss: 116.7771 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 112.3623 - accuracy: 0.5019 - val_loss: 107.9392 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 103.7678 - accuracy: 0.5034 - val_loss: 99.5905 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 95.6543 - accuracy: 0.5027 - val_loss: 91.7140 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 88.0050 - accuracy: 0.5027 - val_loss: 84.2939 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 80.8035 - accuracy: 0.5026 - val_loss: 77.3133 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 74.0339 - accuracy: 0.4981 - val_loss: 70.7561 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 67.6799 - accuracy: 0.5039 - val_loss: 64.6069 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 61.7261 - accuracy: 0.4967 - val_loss: 58.8500 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 56.1570 - accuracy: 0.4958 - val_loss: 53.4702 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 50.9577 - accuracy: 0.5016 - val_loss: 48.4527 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 46.1136 - accuracy: 0.5001 - val_loss: 43.7831 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 41.6103 - accuracy: 0.5008 - val_loss: 39.4473 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 37.4339 - accuracy: 0.4987 - val_loss: 35.4313 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 33.5707 - accuracy: 0.4984 - val_loss: 31.7218 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 30.0072 - accuracy: 0.4987 - val_loss: 28.3052 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 26.7303 - accuracy: 0.4933 - val_loss: 25.1686 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 23.7268 - accuracy: 0.4998 - val_loss: 22.2988 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 20.9836 - accuracy: 0.5038 - val_loss: 19.6827 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 18.4877 - accuracy: 0.4974 - val_loss: 17.3073 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 16.2261 - accuracy: 0.5004 - val_loss: 15.1596 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 14.1856 - accuracy: 0.4996 - val_loss: 13.2264 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 12.3532 - accuracy: 0.4993 - val_loss: 11.4946 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.7156 - accuracy: 0.4968 - val_loss: 9.9511 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 9.2598 - accuracy: 0.4976 - val_loss: 8.5826 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 7.9725 - accuracy: 0.5003 - val_loss: 7.3761 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 6.8409 - accuracy: 0.4997 - val_loss: 6.3186 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.8519 - accuracy: 0.5002 - val_loss: 5.3974 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.9931 - accuracy: 0.4961 - val_loss: 4.6001 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.2520 - accuracy: 0.5003 - val_loss: 3.9145 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.6170 - accuracy: 0.4985 - val_loss: 3.3291 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.0765 - accuracy: 0.5003 - val_loss: 2.8328 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.6199 - accuracy: 0.5003 - val_loss: 2.4150 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.2370 - accuracy: 0.5003 - val_loss: 2.0662 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.9185 - accuracy: 0.5003 - val_loss: 1.7771 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6556 - accuracy: 0.4994 - val_loss: 1.5396 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.4405 - accuracy: 0.5003 - val_loss: 1.3462 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2662 - accuracy: 0.5003 - val_loss: 1.1903 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1264 - accuracy: 0.5003 - val_loss: 1.0660 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.0156 - accuracy: 0.5015 - val_loss: 0.9682 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9289 - accuracy: 0.5003 - val_loss: 0.8922 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.8622 - accuracy: 0.5003 - val_loss: 0.8343 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.8117 - accuracy: 0.5003 - val_loss: 0.7909 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7743 - accuracy: 0.5003 - val_loss: 0.7591 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7472 - accuracy: 0.5003 - val_loss: 0.7364 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7281 - accuracy: 0.5003 - val_loss: 0.7206 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7150 - accuracy: 0.4987 - val_loss: 0.7100 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7063 - accuracy: 0.4990 - val_loss: 0.7031 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.7008 - accuracy: 0.5003 - val_loss: 0.6988 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6974 - accuracy: 0.5003 - val_loss: 0.6962 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6954 - accuracy: 0.4981 - val_loss: 0.6947 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6943 - accuracy: 0.4980 - val_loss: 0.6939 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6937 - accuracy: 0.5003 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6934 - accuracy: 0.4980 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.6932 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "155/168 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.4994Restoring model weights from the end of the best epoch: 90.\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 91: early stopping\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "{'loss': 0.6931520104408264, 'accuracy': 0.5001260638237} \n",
      " 90 \n",
      "\n",
      "Model time: 1.6118114478886127 minutes\n",
      "\n",
      "Total time: 136.52185493335128 minutes\n",
      "\n",
      "\n",
      "Model  85  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     4\n",
      "Activation function         linear\n",
      "Dropout                        0.3\n",
      "L1                           100.0\n",
      "L2                           0.001\n",
      "Batch size                      32\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 4600241, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 7s 7ms/step - loss: 6653.4771 - accuracy: 0.4958 - val_loss: 4726.7964 - val_accuracy: 0.5058\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3415.0781 - accuracy: 0.5054 - val_loss: 2381.0684 - val_accuracy: 0.5134\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 1864.0073 - accuracy: 0.5031 - val_loss: 1590.8911 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 1452.4906 - accuracy: 0.5039 - val_loss: 1316.2073 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1187.5330 - accuracy: 0.4977 - val_loss: 1062.4608 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 945.7752 - accuracy: 0.4927 - val_loss: 831.5313 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 723.2359 - accuracy: 0.5046 - val_loss: 617.3118 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 525.2180 - accuracy: 0.4982 - val_loss: 444.2354 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 371.8030 - accuracy: 0.5013 - val_loss: 302.6396 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 241.5085 - accuracy: 0.5001 - val_loss: 185.3909 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 137.8653 - accuracy: 0.4964 - val_loss: 94.5079 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 67.9494 - accuracy: 0.4978 - val_loss: 45.4688 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 30.0194 - accuracy: 0.4958 - val_loss: 19.5553 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 12.9210 - accuracy: 0.4978 - val_loss: 6.1796 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 2.4694 - accuracy: 0.4995 - val_loss: 1.5819 - val_accuracy: 0.4999\n",
      "Epoch 16/300\n",
      "662/670 [============================>.] - ETA: 0s - loss: 1.5971 - accuracy: 0.5012Restoring model weights from the end of the best epoch: 15.\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 1.5973 - accuracy: 0.5011 - val_loss: 1.6074 - val_accuracy: 0.5001\n",
      "Epoch 16: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 1.5819 - accuracy: 0.4999\n",
      "{'loss': 1.5819025039672852, 'accuracy': 0.49987393617630005} \n",
      " 15 \n",
      "\n",
      "Model time: 1.4441394321620464 minutes\n",
      "\n",
      "Total time: 137.96607768908143 minutes\n",
      "\n",
      "\n",
      "Model  86  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                   128\n",
      "Activation function           tanh\n",
      "Dropout                        0.7\n",
      "L1                          0.0001\n",
      "L2                            10.0\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 2518687, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 6s 12ms/step - loss: 276.2503 - accuracy: 0.4930 - val_loss: 0.7921 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 3s 9ms/step - loss: 0.7921 - accuracy: 0.4914 - val_loss: 0.7921 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "327/335 [============================>.] - ETA: 0s - loss: 0.7921 - accuracy: 0.4943Restoring model weights from the end of the best epoch: 2.\n",
      "335/335 [==============================] - 3s 10ms/step - loss: 0.7921 - accuracy: 0.4943 - val_loss: 0.7922 - val_accuracy: 0.5001\n",
      "Epoch 3: early stopping\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.7921 - accuracy: 0.5001\n",
      "{'loss': 0.7921064496040344, 'accuracy': 0.5001260638237} \n",
      " 2 \n",
      "\n",
      "Model time: 0.4015371538698673 minutes\n",
      "\n",
      "Total time: 138.36768152937293 minutes\n",
      "\n",
      "\n",
      "Model  87  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     2\n",
      "Activation function         linear\n",
      "Dropout                        0.5\n",
      "L1                             0.1\n",
      "L2                            0.01\n",
      "Batch size                     128\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 1654404, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 3s 10ms/step - loss: 5.1586 - accuracy: 0.5028 - val_loss: 4.8759 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 5.0777 - accuracy: 0.5075 - val_loss: 4.8142 - val_accuracy: 0.5012\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.9840 - accuracy: 0.5120 - val_loss: 4.7535 - val_accuracy: 0.5021\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.9468 - accuracy: 0.5063 - val_loss: 4.6944 - val_accuracy: 0.5042\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.8765 - accuracy: 0.5035 - val_loss: 4.6366 - val_accuracy: 0.5048\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 4.8037 - accuracy: 0.5091 - val_loss: 4.5798 - val_accuracy: 0.5064\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.7488 - accuracy: 0.5099 - val_loss: 4.5241 - val_accuracy: 0.5080\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 4.6747 - accuracy: 0.5110 - val_loss: 4.4692 - val_accuracy: 0.5092\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.6328 - accuracy: 0.5090 - val_loss: 4.4152 - val_accuracy: 0.5087\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.5472 - accuracy: 0.5107 - val_loss: 4.3614 - val_accuracy: 0.5082\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 4.5016 - accuracy: 0.5103 - val_loss: 4.3083 - val_accuracy: 0.5082\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4.4452 - accuracy: 0.5097 - val_loss: 4.2561 - val_accuracy: 0.5080\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 4.3793 - accuracy: 0.5147 - val_loss: 4.2052 - val_accuracy: 0.5088\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4.3263 - accuracy: 0.5108 - val_loss: 4.1540 - val_accuracy: 0.5091\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.2783 - accuracy: 0.5131 - val_loss: 4.1038 - val_accuracy: 0.5093\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4.2145 - accuracy: 0.5124 - val_loss: 4.0537 - val_accuracy: 0.5114\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.1768 - accuracy: 0.5165 - val_loss: 4.0043 - val_accuracy: 0.5110\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.1188 - accuracy: 0.5145 - val_loss: 3.9557 - val_accuracy: 0.5115\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4.0634 - accuracy: 0.5140 - val_loss: 3.9079 - val_accuracy: 0.5116\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 4.0099 - accuracy: 0.5159 - val_loss: 3.8609 - val_accuracy: 0.5124\n",
      "Epoch 21/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.9565 - accuracy: 0.5138 - val_loss: 3.8148 - val_accuracy: 0.5129\n",
      "Epoch 22/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.9084 - accuracy: 0.5159 - val_loss: 3.7687 - val_accuracy: 0.5130\n",
      "Epoch 23/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.8715 - accuracy: 0.5124 - val_loss: 3.7232 - val_accuracy: 0.5128\n",
      "Epoch 24/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.8155 - accuracy: 0.5133 - val_loss: 3.6784 - val_accuracy: 0.5129\n",
      "Epoch 25/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.7803 - accuracy: 0.5114 - val_loss: 3.6337 - val_accuracy: 0.5140\n",
      "Epoch 26/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.7367 - accuracy: 0.5106 - val_loss: 3.5894 - val_accuracy: 0.5147\n",
      "Epoch 27/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.6791 - accuracy: 0.5165 - val_loss: 3.5453 - val_accuracy: 0.5151\n",
      "Epoch 28/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 3.6412 - accuracy: 0.5117 - val_loss: 3.5016 - val_accuracy: 0.5157\n",
      "Epoch 29/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.6015 - accuracy: 0.5174 - val_loss: 3.4585 - val_accuracy: 0.5156\n",
      "Epoch 30/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.5476 - accuracy: 0.5183 - val_loss: 3.4159 - val_accuracy: 0.5162\n",
      "Epoch 31/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.4865 - accuracy: 0.5208 - val_loss: 3.3733 - val_accuracy: 0.5172\n",
      "Epoch 32/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 3.4489 - accuracy: 0.5120 - val_loss: 3.3309 - val_accuracy: 0.5180\n",
      "Epoch 33/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.4032 - accuracy: 0.5209 - val_loss: 3.2886 - val_accuracy: 0.5185\n",
      "Epoch 34/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.3611 - accuracy: 0.5175 - val_loss: 3.2469 - val_accuracy: 0.5183\n",
      "Epoch 35/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.3131 - accuracy: 0.5135 - val_loss: 3.2058 - val_accuracy: 0.5192\n",
      "Epoch 36/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.2775 - accuracy: 0.5097 - val_loss: 3.1651 - val_accuracy: 0.5199\n",
      "Epoch 37/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.2324 - accuracy: 0.5134 - val_loss: 3.1246 - val_accuracy: 0.5202\n",
      "Epoch 38/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.1914 - accuracy: 0.5124 - val_loss: 3.0844 - val_accuracy: 0.5206\n",
      "Epoch 39/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.1493 - accuracy: 0.5163 - val_loss: 3.0448 - val_accuracy: 0.5208\n",
      "Epoch 40/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.1077 - accuracy: 0.5199 - val_loss: 3.0059 - val_accuracy: 0.5211\n",
      "Epoch 41/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 3.0698 - accuracy: 0.5140 - val_loss: 2.9678 - val_accuracy: 0.5218\n",
      "Epoch 42/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.0297 - accuracy: 0.5151 - val_loss: 2.9306 - val_accuracy: 0.5219\n",
      "Epoch 43/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.9866 - accuracy: 0.5138 - val_loss: 2.8937 - val_accuracy: 0.5226\n",
      "Epoch 44/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.9466 - accuracy: 0.5105 - val_loss: 2.8571 - val_accuracy: 0.5234\n",
      "Epoch 45/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.9022 - accuracy: 0.5197 - val_loss: 2.8210 - val_accuracy: 0.5241\n",
      "Epoch 46/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.8807 - accuracy: 0.5141 - val_loss: 2.7852 - val_accuracy: 0.5243\n",
      "Epoch 47/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.8288 - accuracy: 0.5238 - val_loss: 2.7496 - val_accuracy: 0.5241\n",
      "Epoch 48/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.8023 - accuracy: 0.5199 - val_loss: 2.7150 - val_accuracy: 0.5245\n",
      "Epoch 49/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.7627 - accuracy: 0.5164 - val_loss: 2.6805 - val_accuracy: 0.5248\n",
      "Epoch 50/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.7246 - accuracy: 0.5134 - val_loss: 2.6464 - val_accuracy: 0.5247\n",
      "Epoch 51/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.6904 - accuracy: 0.5199 - val_loss: 2.6126 - val_accuracy: 0.5249\n",
      "Epoch 52/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.6462 - accuracy: 0.5238 - val_loss: 2.5787 - val_accuracy: 0.5249\n",
      "Epoch 53/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.6159 - accuracy: 0.5176 - val_loss: 2.5450 - val_accuracy: 0.5254\n",
      "Epoch 54/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.5828 - accuracy: 0.5164 - val_loss: 2.5118 - val_accuracy: 0.5254\n",
      "Epoch 55/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.5485 - accuracy: 0.5193 - val_loss: 2.4787 - val_accuracy: 0.5258\n",
      "Epoch 56/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2.5163 - accuracy: 0.5248 - val_loss: 2.4463 - val_accuracy: 0.5255\n",
      "Epoch 57/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.4794 - accuracy: 0.5162 - val_loss: 2.4143 - val_accuracy: 0.5257\n",
      "Epoch 58/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.4524 - accuracy: 0.5219 - val_loss: 2.3829 - val_accuracy: 0.5256\n",
      "Epoch 59/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.4153 - accuracy: 0.5223 - val_loss: 2.3516 - val_accuracy: 0.5251\n",
      "Epoch 60/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.3809 - accuracy: 0.5183 - val_loss: 2.3209 - val_accuracy: 0.5252\n",
      "Epoch 61/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.3522 - accuracy: 0.5197 - val_loss: 2.2905 - val_accuracy: 0.5250\n",
      "Epoch 62/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.3224 - accuracy: 0.5181 - val_loss: 2.2601 - val_accuracy: 0.5248\n",
      "Epoch 63/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.2861 - accuracy: 0.5170 - val_loss: 2.2302 - val_accuracy: 0.5249\n",
      "Epoch 64/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.2646 - accuracy: 0.5167 - val_loss: 2.2007 - val_accuracy: 0.5246\n",
      "Epoch 65/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.2226 - accuracy: 0.5188 - val_loss: 2.1714 - val_accuracy: 0.5254\n",
      "Epoch 66/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.1978 - accuracy: 0.5170 - val_loss: 2.1427 - val_accuracy: 0.5248\n",
      "Epoch 67/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.1675 - accuracy: 0.5212 - val_loss: 2.1146 - val_accuracy: 0.5248\n",
      "Epoch 68/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.1372 - accuracy: 0.5182 - val_loss: 2.0866 - val_accuracy: 0.5258\n",
      "Epoch 69/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.1063 - accuracy: 0.5196 - val_loss: 2.0592 - val_accuracy: 0.5261\n",
      "Epoch 70/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.0814 - accuracy: 0.5193 - val_loss: 2.0322 - val_accuracy: 0.5270\n",
      "Epoch 71/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2.0585 - accuracy: 0.5202 - val_loss: 2.0057 - val_accuracy: 0.5261\n",
      "Epoch 72/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.0266 - accuracy: 0.5188 - val_loss: 1.9795 - val_accuracy: 0.5264\n",
      "Epoch 73/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.9944 - accuracy: 0.5200 - val_loss: 1.9542 - val_accuracy: 0.5272\n",
      "Epoch 74/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.9697 - accuracy: 0.5273 - val_loss: 1.9293 - val_accuracy: 0.5270\n",
      "Epoch 75/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.9440 - accuracy: 0.5254 - val_loss: 1.9043 - val_accuracy: 0.5274\n",
      "Epoch 76/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.9203 - accuracy: 0.5199 - val_loss: 1.8801 - val_accuracy: 0.5279\n",
      "Epoch 77/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.8935 - accuracy: 0.5241 - val_loss: 1.8565 - val_accuracy: 0.5283\n",
      "Epoch 78/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.8681 - accuracy: 0.5224 - val_loss: 1.8332 - val_accuracy: 0.5277\n",
      "Epoch 79/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.8450 - accuracy: 0.5229 - val_loss: 1.8101 - val_accuracy: 0.5278\n",
      "Epoch 80/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.8170 - accuracy: 0.5217 - val_loss: 1.7869 - val_accuracy: 0.5277\n",
      "Epoch 81/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 1.7997 - accuracy: 0.5200 - val_loss: 1.7645 - val_accuracy: 0.5272\n",
      "Epoch 82/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.7749 - accuracy: 0.5275 - val_loss: 1.7430 - val_accuracy: 0.5275\n",
      "Epoch 83/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.7538 - accuracy: 0.5236 - val_loss: 1.7218 - val_accuracy: 0.5274\n",
      "Epoch 84/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.7349 - accuracy: 0.5176 - val_loss: 1.7010 - val_accuracy: 0.5275\n",
      "Epoch 85/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.7113 - accuracy: 0.5224 - val_loss: 1.6805 - val_accuracy: 0.5280\n",
      "Epoch 86/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6877 - accuracy: 0.5219 - val_loss: 1.6608 - val_accuracy: 0.5278\n",
      "Epoch 87/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6720 - accuracy: 0.5226 - val_loss: 1.6414 - val_accuracy: 0.5273\n",
      "Epoch 88/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6482 - accuracy: 0.5236 - val_loss: 1.6224 - val_accuracy: 0.5270\n",
      "Epoch 89/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6282 - accuracy: 0.5212 - val_loss: 1.6031 - val_accuracy: 0.5269\n",
      "Epoch 90/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6060 - accuracy: 0.5306 - val_loss: 1.5842 - val_accuracy: 0.5276\n",
      "Epoch 91/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.5910 - accuracy: 0.5218 - val_loss: 1.5656 - val_accuracy: 0.5275\n",
      "Epoch 92/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.5725 - accuracy: 0.5272 - val_loss: 1.5475 - val_accuracy: 0.5271\n",
      "Epoch 93/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.5527 - accuracy: 0.5227 - val_loss: 1.5300 - val_accuracy: 0.5266\n",
      "Epoch 94/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.5362 - accuracy: 0.5223 - val_loss: 1.5133 - val_accuracy: 0.5252\n",
      "Epoch 95/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.5152 - accuracy: 0.5238 - val_loss: 1.4969 - val_accuracy: 0.5254\n",
      "Epoch 96/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.5007 - accuracy: 0.5209 - val_loss: 1.4813 - val_accuracy: 0.5257\n",
      "Epoch 97/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 1.4871 - accuracy: 0.5234 - val_loss: 1.4669 - val_accuracy: 0.5256\n",
      "Epoch 98/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.4685 - accuracy: 0.5250 - val_loss: 1.4531 - val_accuracy: 0.5242\n",
      "Epoch 99/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.4585 - accuracy: 0.5220 - val_loss: 1.4399 - val_accuracy: 0.5241\n",
      "Epoch 100/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.4410 - accuracy: 0.5229 - val_loss: 1.4271 - val_accuracy: 0.5246\n",
      "Epoch 101/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.4280 - accuracy: 0.5236 - val_loss: 1.4145 - val_accuracy: 0.5253\n",
      "Epoch 102/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.4170 - accuracy: 0.5213 - val_loss: 1.4024 - val_accuracy: 0.5256\n",
      "Epoch 103/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.4070 - accuracy: 0.5238 - val_loss: 1.3910 - val_accuracy: 0.5257\n",
      "Epoch 104/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.3922 - accuracy: 0.5216 - val_loss: 1.3793 - val_accuracy: 0.5256\n",
      "Epoch 105/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.3802 - accuracy: 0.5248 - val_loss: 1.3678 - val_accuracy: 0.5271\n",
      "Epoch 106/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.3699 - accuracy: 0.5231 - val_loss: 1.3570 - val_accuracy: 0.5294\n",
      "Epoch 107/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.3587 - accuracy: 0.5263 - val_loss: 1.3471 - val_accuracy: 0.5298\n",
      "Epoch 108/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.3484 - accuracy: 0.5209 - val_loss: 1.3374 - val_accuracy: 0.5316\n",
      "Epoch 109/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.3392 - accuracy: 0.5232 - val_loss: 1.3283 - val_accuracy: 0.5337\n",
      "Epoch 110/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.3291 - accuracy: 0.5211 - val_loss: 1.3199 - val_accuracy: 0.5357\n",
      "Epoch 111/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.3195 - accuracy: 0.5275 - val_loss: 1.3119 - val_accuracy: 0.5361\n",
      "Epoch 112/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.3119 - accuracy: 0.5220 - val_loss: 1.3043 - val_accuracy: 0.5365\n",
      "Epoch 113/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.3058 - accuracy: 0.5252 - val_loss: 1.2969 - val_accuracy: 0.5357\n",
      "Epoch 114/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2983 - accuracy: 0.5240 - val_loss: 1.2900 - val_accuracy: 0.5368\n",
      "Epoch 115/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.2912 - accuracy: 0.5274 - val_loss: 1.2833 - val_accuracy: 0.5366\n",
      "Epoch 116/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2848 - accuracy: 0.5236 - val_loss: 1.2769 - val_accuracy: 0.5360\n",
      "Epoch 117/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2765 - accuracy: 0.5250 - val_loss: 1.2706 - val_accuracy: 0.5343\n",
      "Epoch 118/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2700 - accuracy: 0.5277 - val_loss: 1.2645 - val_accuracy: 0.5331\n",
      "Epoch 119/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2646 - accuracy: 0.5225 - val_loss: 1.2584 - val_accuracy: 0.5320\n",
      "Epoch 120/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.2566 - accuracy: 0.5246 - val_loss: 1.2523 - val_accuracy: 0.5315\n",
      "Epoch 121/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.2519 - accuracy: 0.5237 - val_loss: 1.2464 - val_accuracy: 0.5295\n",
      "Epoch 122/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2457 - accuracy: 0.5286 - val_loss: 1.2405 - val_accuracy: 0.5277\n",
      "Epoch 123/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2411 - accuracy: 0.5217 - val_loss: 1.2347 - val_accuracy: 0.5273\n",
      "Epoch 124/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.2334 - accuracy: 0.5231 - val_loss: 1.2292 - val_accuracy: 0.5262\n",
      "Epoch 125/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2282 - accuracy: 0.5221 - val_loss: 1.2240 - val_accuracy: 0.5259\n",
      "Epoch 126/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.2213 - accuracy: 0.5254 - val_loss: 1.2189 - val_accuracy: 0.5246\n",
      "Epoch 127/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2173 - accuracy: 0.5249 - val_loss: 1.2138 - val_accuracy: 0.5224\n",
      "Epoch 128/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2131 - accuracy: 0.5193 - val_loss: 1.2090 - val_accuracy: 0.5213\n",
      "Epoch 129/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.2084 - accuracy: 0.5210 - val_loss: 1.2041 - val_accuracy: 0.5194\n",
      "Epoch 130/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.2023 - accuracy: 0.5242 - val_loss: 1.1994 - val_accuracy: 0.5166\n",
      "Epoch 131/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1978 - accuracy: 0.5238 - val_loss: 1.1949 - val_accuracy: 0.5144\n",
      "Epoch 132/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1930 - accuracy: 0.5223 - val_loss: 1.1905 - val_accuracy: 0.5141\n",
      "Epoch 133/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1892 - accuracy: 0.5205 - val_loss: 1.1861 - val_accuracy: 0.5127\n",
      "Epoch 134/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1842 - accuracy: 0.5188 - val_loss: 1.1818 - val_accuracy: 0.5096\n",
      "Epoch 135/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.1796 - accuracy: 0.5135 - val_loss: 1.1776 - val_accuracy: 0.5073\n",
      "Epoch 136/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1752 - accuracy: 0.5106 - val_loss: 1.1735 - val_accuracy: 0.5052\n",
      "Epoch 137/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.1713 - accuracy: 0.5096 - val_loss: 1.1695 - val_accuracy: 0.5029\n",
      "Epoch 138/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.1669 - accuracy: 0.5108 - val_loss: 1.1653 - val_accuracy: 0.5014\n",
      "Epoch 139/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1638 - accuracy: 0.5076 - val_loss: 1.1614 - val_accuracy: 0.4991\n",
      "Epoch 140/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1594 - accuracy: 0.5057 - val_loss: 1.1576 - val_accuracy: 0.4968\n",
      "Epoch 141/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1553 - accuracy: 0.5075 - val_loss: 1.1539 - val_accuracy: 0.4948\n",
      "Epoch 142/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1519 - accuracy: 0.5075 - val_loss: 1.1502 - val_accuracy: 0.4932\n",
      "Epoch 143/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.1484 - accuracy: 0.5014 - val_loss: 1.1467 - val_accuracy: 0.4925\n",
      "Epoch 144/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1449 - accuracy: 0.5037 - val_loss: 1.1434 - val_accuracy: 0.4916\n",
      "Epoch 145/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1413 - accuracy: 0.5050 - val_loss: 1.1400 - val_accuracy: 0.4884\n",
      "Epoch 146/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1378 - accuracy: 0.5013 - val_loss: 1.1366 - val_accuracy: 0.4869\n",
      "Epoch 147/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.1348 - accuracy: 0.5032 - val_loss: 1.1333 - val_accuracy: 0.4874\n",
      "Epoch 148/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1315 - accuracy: 0.5016 - val_loss: 1.1299 - val_accuracy: 0.4882\n",
      "Epoch 149/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1283 - accuracy: 0.4991 - val_loss: 1.1267 - val_accuracy: 0.4862\n",
      "Epoch 150/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1245 - accuracy: 0.5003 - val_loss: 1.1234 - val_accuracy: 0.4856\n",
      "Epoch 151/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1217 - accuracy: 0.4972 - val_loss: 1.1201 - val_accuracy: 0.4848\n",
      "Epoch 152/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1182 - accuracy: 0.5003 - val_loss: 1.1169 - val_accuracy: 0.4854\n",
      "Epoch 153/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1152 - accuracy: 0.4989 - val_loss: 1.1138 - val_accuracy: 0.4872\n",
      "Epoch 154/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1118 - accuracy: 0.5004 - val_loss: 1.1107 - val_accuracy: 0.4908\n",
      "Epoch 155/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1092 - accuracy: 0.5003 - val_loss: 1.1077 - val_accuracy: 0.4902\n",
      "Epoch 156/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1062 - accuracy: 0.4998 - val_loss: 1.1048 - val_accuracy: 0.4919\n",
      "Epoch 157/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.1032 - accuracy: 0.5004 - val_loss: 1.1020 - val_accuracy: 0.4928\n",
      "Epoch 158/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.1004 - accuracy: 0.5019 - val_loss: 1.0994 - val_accuracy: 0.4932\n",
      "Epoch 159/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0980 - accuracy: 0.4989 - val_loss: 1.0967 - val_accuracy: 0.4918\n",
      "Epoch 160/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0951 - accuracy: 0.4994 - val_loss: 1.0940 - val_accuracy: 0.4898\n",
      "Epoch 161/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0925 - accuracy: 0.4992 - val_loss: 1.0913 - val_accuracy: 0.4905\n",
      "Epoch 162/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0901 - accuracy: 0.4954 - val_loss: 1.0887 - val_accuracy: 0.4922\n",
      "Epoch 163/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0872 - accuracy: 0.4989 - val_loss: 1.0861 - val_accuracy: 0.4915\n",
      "Epoch 164/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0847 - accuracy: 0.4968 - val_loss: 1.0836 - val_accuracy: 0.4918\n",
      "Epoch 165/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0824 - accuracy: 0.4957 - val_loss: 1.0815 - val_accuracy: 0.4932\n",
      "Epoch 166/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0803 - accuracy: 0.5003 - val_loss: 1.0795 - val_accuracy: 0.4915\n",
      "Epoch 167/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0783 - accuracy: 0.5007 - val_loss: 1.0776 - val_accuracy: 0.4900\n",
      "Epoch 168/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0766 - accuracy: 0.5013 - val_loss: 1.0757 - val_accuracy: 0.4903\n",
      "Epoch 169/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0746 - accuracy: 0.4918 - val_loss: 1.0738 - val_accuracy: 0.4924\n",
      "Epoch 170/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0728 - accuracy: 0.4972 - val_loss: 1.0719 - val_accuracy: 0.4921\n",
      "Epoch 171/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0710 - accuracy: 0.5012 - val_loss: 1.0702 - val_accuracy: 0.4913\n",
      "Epoch 172/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0692 - accuracy: 0.4970 - val_loss: 1.0684 - val_accuracy: 0.4928\n",
      "Epoch 173/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.0675 - accuracy: 0.5003 - val_loss: 1.0667 - val_accuracy: 0.4931\n",
      "Epoch 174/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0657 - accuracy: 0.4969 - val_loss: 1.0649 - val_accuracy: 0.4964\n",
      "Epoch 175/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0640 - accuracy: 0.4958 - val_loss: 1.0632 - val_accuracy: 0.4960\n",
      "Epoch 176/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0623 - accuracy: 0.5018 - val_loss: 1.0614 - val_accuracy: 0.4977\n",
      "Epoch 177/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0605 - accuracy: 0.5007 - val_loss: 1.0597 - val_accuracy: 0.4991\n",
      "Epoch 178/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0589 - accuracy: 0.5004 - val_loss: 1.0581 - val_accuracy: 0.4999\n",
      "Epoch 179/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0574 - accuracy: 0.5055 - val_loss: 1.0566 - val_accuracy: 0.4999\n",
      "Epoch 180/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0559 - accuracy: 0.4981 - val_loss: 1.0552 - val_accuracy: 0.4999\n",
      "Epoch 181/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0544 - accuracy: 0.5090 - val_loss: 1.0537 - val_accuracy: 0.4999\n",
      "Epoch 182/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0530 - accuracy: 0.5018 - val_loss: 1.0523 - val_accuracy: 0.4999\n",
      "Epoch 183/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0515 - accuracy: 0.4979 - val_loss: 1.0508 - val_accuracy: 0.4999\n",
      "Epoch 184/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0501 - accuracy: 0.5046 - val_loss: 1.0494 - val_accuracy: 0.4999\n",
      "Epoch 185/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0486 - accuracy: 0.5017 - val_loss: 1.0479 - val_accuracy: 0.5009\n",
      "Epoch 186/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0472 - accuracy: 0.4986 - val_loss: 1.0464 - val_accuracy: 0.4999\n",
      "Epoch 187/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0457 - accuracy: 0.4969 - val_loss: 1.0450 - val_accuracy: 0.4999\n",
      "Epoch 188/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0443 - accuracy: 0.4986 - val_loss: 1.0435 - val_accuracy: 0.4999\n",
      "Epoch 189/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0428 - accuracy: 0.4961 - val_loss: 1.0421 - val_accuracy: 0.4999\n",
      "Epoch 190/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0413 - accuracy: 0.5049 - val_loss: 1.0406 - val_accuracy: 0.4999\n",
      "Epoch 191/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0399 - accuracy: 0.5035 - val_loss: 1.0392 - val_accuracy: 0.4999\n",
      "Epoch 192/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0385 - accuracy: 0.4902 - val_loss: 1.0377 - val_accuracy: 0.4999\n",
      "Epoch 193/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0370 - accuracy: 0.5009 - val_loss: 1.0362 - val_accuracy: 0.4999\n",
      "Epoch 194/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0355 - accuracy: 0.5032 - val_loss: 1.0348 - val_accuracy: 0.4999\n",
      "Epoch 195/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0341 - accuracy: 0.4996 - val_loss: 1.0333 - val_accuracy: 0.4998\n",
      "Epoch 196/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.0326 - accuracy: 0.5043 - val_loss: 1.0319 - val_accuracy: 0.4999\n",
      "Epoch 197/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0312 - accuracy: 0.5024 - val_loss: 1.0305 - val_accuracy: 0.4988\n",
      "Epoch 198/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0297 - accuracy: 0.4981 - val_loss: 1.0290 - val_accuracy: 0.4999\n",
      "Epoch 199/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0283 - accuracy: 0.4975 - val_loss: 1.0275 - val_accuracy: 0.4995\n",
      "Epoch 200/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 1.0268 - accuracy: 0.5005 - val_loss: 1.0261 - val_accuracy: 0.4999\n",
      "Epoch 201/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.0254 - accuracy: 0.4993 - val_loss: 1.0246 - val_accuracy: 0.4999\n",
      "Epoch 202/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0239 - accuracy: 0.5018 - val_loss: 1.0232 - val_accuracy: 0.4999\n",
      "Epoch 203/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0224 - accuracy: 0.5028 - val_loss: 1.0217 - val_accuracy: 0.4999\n",
      "Epoch 204/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0210 - accuracy: 0.5016 - val_loss: 1.0203 - val_accuracy: 0.5006\n",
      "Epoch 205/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.0196 - accuracy: 0.4986 - val_loss: 1.0189 - val_accuracy: 0.4999\n",
      "Epoch 206/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0181 - accuracy: 0.4896 - val_loss: 1.0174 - val_accuracy: 0.4999\n",
      "Epoch 207/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0167 - accuracy: 0.5017 - val_loss: 1.0160 - val_accuracy: 0.4999\n",
      "Epoch 208/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0152 - accuracy: 0.4991 - val_loss: 1.0145 - val_accuracy: 0.4999\n",
      "Epoch 209/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0138 - accuracy: 0.5020 - val_loss: 1.0131 - val_accuracy: 0.4999\n",
      "Epoch 210/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0123 - accuracy: 0.4949 - val_loss: 1.0116 - val_accuracy: 0.4999\n",
      "Epoch 211/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0109 - accuracy: 0.5038 - val_loss: 1.0102 - val_accuracy: 0.5001\n",
      "Epoch 212/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0094 - accuracy: 0.5019 - val_loss: 1.0087 - val_accuracy: 0.4999\n",
      "Epoch 213/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 1.0080 - accuracy: 0.4954 - val_loss: 1.0073 - val_accuracy: 0.4999\n",
      "Epoch 214/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0065 - accuracy: 0.5020 - val_loss: 1.0058 - val_accuracy: 0.4999\n",
      "Epoch 215/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0051 - accuracy: 0.5011 - val_loss: 1.0044 - val_accuracy: 0.4999\n",
      "Epoch 216/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0037 - accuracy: 0.4995 - val_loss: 1.0029 - val_accuracy: 0.4999\n",
      "Epoch 217/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.0022 - accuracy: 0.5003 - val_loss: 1.0015 - val_accuracy: 0.4999\n",
      "Epoch 218/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1.0008 - accuracy: 0.4983 - val_loss: 1.0001 - val_accuracy: 0.4999\n",
      "Epoch 219/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9993 - accuracy: 0.4986 - val_loss: 0.9986 - val_accuracy: 0.4999\n",
      "Epoch 220/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9979 - accuracy: 0.5036 - val_loss: 0.9972 - val_accuracy: 0.4999\n",
      "Epoch 221/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9964 - accuracy: 0.4997 - val_loss: 0.9957 - val_accuracy: 0.4999\n",
      "Epoch 222/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9950 - accuracy: 0.4996 - val_loss: 0.9943 - val_accuracy: 0.4999\n",
      "Epoch 223/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.9936 - accuracy: 0.5030 - val_loss: 0.9929 - val_accuracy: 0.4997\n",
      "Epoch 224/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9921 - accuracy: 0.5023 - val_loss: 0.9914 - val_accuracy: 0.4999\n",
      "Epoch 225/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9907 - accuracy: 0.5023 - val_loss: 0.9900 - val_accuracy: 0.4999\n",
      "Epoch 226/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9892 - accuracy: 0.5010 - val_loss: 0.9886 - val_accuracy: 0.4988\n",
      "Epoch 227/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.9878 - accuracy: 0.4989 - val_loss: 0.9871 - val_accuracy: 0.4999\n",
      "Epoch 228/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9864 - accuracy: 0.4995 - val_loss: 0.9856 - val_accuracy: 0.4999\n",
      "Epoch 229/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9849 - accuracy: 0.5043 - val_loss: 0.9842 - val_accuracy: 0.4995\n",
      "Epoch 230/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9835 - accuracy: 0.4986 - val_loss: 0.9828 - val_accuracy: 0.4996\n",
      "Epoch 231/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9821 - accuracy: 0.5045 - val_loss: 0.9813 - val_accuracy: 0.4999\n",
      "Epoch 232/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9806 - accuracy: 0.5037 - val_loss: 0.9799 - val_accuracy: 0.4999\n",
      "Epoch 233/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9792 - accuracy: 0.4985 - val_loss: 0.9785 - val_accuracy: 0.4999\n",
      "Epoch 234/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9777 - accuracy: 0.4986 - val_loss: 0.9770 - val_accuracy: 0.4999\n",
      "Epoch 235/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9763 - accuracy: 0.5009 - val_loss: 0.9756 - val_accuracy: 0.4999\n",
      "Epoch 236/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9749 - accuracy: 0.4995 - val_loss: 0.9742 - val_accuracy: 0.4999\n",
      "Epoch 237/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9736 - accuracy: 0.4983 - val_loss: 0.9730 - val_accuracy: 0.4999\n",
      "Epoch 238/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9723 - accuracy: 0.4971 - val_loss: 0.9717 - val_accuracy: 0.4999\n",
      "Epoch 239/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9711 - accuracy: 0.4984 - val_loss: 0.9704 - val_accuracy: 0.4999\n",
      "Epoch 240/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9698 - accuracy: 0.5031 - val_loss: 0.9692 - val_accuracy: 0.4999\n",
      "Epoch 241/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9685 - accuracy: 0.5056 - val_loss: 0.9679 - val_accuracy: 0.4999\n",
      "Epoch 242/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9673 - accuracy: 0.5025 - val_loss: 0.9667 - val_accuracy: 0.4999\n",
      "Epoch 243/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9660 - accuracy: 0.5008 - val_loss: 0.9654 - val_accuracy: 0.4999\n",
      "Epoch 244/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9648 - accuracy: 0.4979 - val_loss: 0.9641 - val_accuracy: 0.4999\n",
      "Epoch 245/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9635 - accuracy: 0.5006 - val_loss: 0.9629 - val_accuracy: 0.4999\n",
      "Epoch 246/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9622 - accuracy: 0.4991 - val_loss: 0.9616 - val_accuracy: 0.4996\n",
      "Epoch 247/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9610 - accuracy: 0.4990 - val_loss: 0.9603 - val_accuracy: 0.4999\n",
      "Epoch 248/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9597 - accuracy: 0.5010 - val_loss: 0.9591 - val_accuracy: 0.4999\n",
      "Epoch 249/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9584 - accuracy: 0.4989 - val_loss: 0.9578 - val_accuracy: 0.4999\n",
      "Epoch 250/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.9572 - accuracy: 0.5025 - val_loss: 0.9565 - val_accuracy: 0.5000\n",
      "Epoch 251/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9559 - accuracy: 0.4996 - val_loss: 0.9553 - val_accuracy: 0.4999\n",
      "Epoch 252/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9547 - accuracy: 0.4990 - val_loss: 0.9540 - val_accuracy: 0.5011\n",
      "Epoch 253/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9534 - accuracy: 0.5039 - val_loss: 0.9528 - val_accuracy: 0.5000\n",
      "Epoch 254/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.9521 - accuracy: 0.4941 - val_loss: 0.9515 - val_accuracy: 0.5000\n",
      "Epoch 255/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9509 - accuracy: 0.5030 - val_loss: 0.9502 - val_accuracy: 0.4986\n",
      "Epoch 256/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9496 - accuracy: 0.4996 - val_loss: 0.9490 - val_accuracy: 0.4995\n",
      "Epoch 257/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9484 - accuracy: 0.5006 - val_loss: 0.9477 - val_accuracy: 0.4997\n",
      "Epoch 258/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9471 - accuracy: 0.5030 - val_loss: 0.9465 - val_accuracy: 0.5185\n",
      "Epoch 259/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9458 - accuracy: 0.4985 - val_loss: 0.9452 - val_accuracy: 0.5390\n",
      "Epoch 260/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9446 - accuracy: 0.5003 - val_loss: 0.9440 - val_accuracy: 0.5154\n",
      "Epoch 261/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9434 - accuracy: 0.4978 - val_loss: 0.9429 - val_accuracy: 0.5004\n",
      "Epoch 262/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9423 - accuracy: 0.5052 - val_loss: 0.9418 - val_accuracy: 0.4971\n",
      "Epoch 263/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9412 - accuracy: 0.5035 - val_loss: 0.9407 - val_accuracy: 0.5002\n",
      "Epoch 264/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9401 - accuracy: 0.4998 - val_loss: 0.9396 - val_accuracy: 0.4999\n",
      "Epoch 265/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9390 - accuracy: 0.5034 - val_loss: 0.9385 - val_accuracy: 0.4803\n",
      "Epoch 266/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9380 - accuracy: 0.5004 - val_loss: 0.9374 - val_accuracy: 0.5147\n",
      "Epoch 267/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9369 - accuracy: 0.4969 - val_loss: 0.9363 - val_accuracy: 0.5011\n",
      "Epoch 268/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9358 - accuracy: 0.5034 - val_loss: 0.9353 - val_accuracy: 0.5007\n",
      "Epoch 269/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9347 - accuracy: 0.4989 - val_loss: 0.9342 - val_accuracy: 0.5116\n",
      "Epoch 270/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9336 - accuracy: 0.5030 - val_loss: 0.9331 - val_accuracy: 0.5024\n",
      "Epoch 271/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9325 - accuracy: 0.5080 - val_loss: 0.9320 - val_accuracy: 0.5001\n",
      "Epoch 272/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9314 - accuracy: 0.5024 - val_loss: 0.9309 - val_accuracy: 0.5001\n",
      "Epoch 273/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9303 - accuracy: 0.5037 - val_loss: 0.9298 - val_accuracy: 0.5017\n",
      "Epoch 274/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9293 - accuracy: 0.5018 - val_loss: 0.9287 - val_accuracy: 0.5001\n",
      "Epoch 275/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9282 - accuracy: 0.5046 - val_loss: 0.9277 - val_accuracy: 0.5025\n",
      "Epoch 276/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9271 - accuracy: 0.4999 - val_loss: 0.9266 - val_accuracy: 0.5027\n",
      "Epoch 277/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.9260 - accuracy: 0.5011 - val_loss: 0.9255 - val_accuracy: 0.5001\n",
      "Epoch 278/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9249 - accuracy: 0.5008 - val_loss: 0.9244 - val_accuracy: 0.5001\n",
      "Epoch 279/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9239 - accuracy: 0.4987 - val_loss: 0.9233 - val_accuracy: 0.5001\n",
      "Epoch 280/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9228 - accuracy: 0.4957 - val_loss: 0.9222 - val_accuracy: 0.5003\n",
      "Epoch 281/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9217 - accuracy: 0.5043 - val_loss: 0.9212 - val_accuracy: 0.5031\n",
      "Epoch 282/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9206 - accuracy: 0.4986 - val_loss: 0.9201 - val_accuracy: 0.5022\n",
      "Epoch 283/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9195 - accuracy: 0.4991 - val_loss: 0.9190 - val_accuracy: 0.4998\n",
      "Epoch 284/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9184 - accuracy: 0.5043 - val_loss: 0.9179 - val_accuracy: 0.4992\n",
      "Epoch 285/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9174 - accuracy: 0.4983 - val_loss: 0.9168 - val_accuracy: 0.5018\n",
      "Epoch 286/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 0.9163 - accuracy: 0.4967 - val_loss: 0.9157 - val_accuracy: 0.5001\n",
      "Epoch 287/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9152 - accuracy: 0.4983 - val_loss: 0.9147 - val_accuracy: 0.5001\n",
      "Epoch 288/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9141 - accuracy: 0.5005 - val_loss: 0.9136 - val_accuracy: 0.5010\n",
      "Epoch 289/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9131 - accuracy: 0.4955 - val_loss: 0.9125 - val_accuracy: 0.5001\n",
      "Epoch 290/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9120 - accuracy: 0.5010 - val_loss: 0.9115 - val_accuracy: 0.5006\n",
      "Epoch 291/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9109 - accuracy: 0.4943 - val_loss: 0.9104 - val_accuracy: 0.5001\n",
      "Epoch 292/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9098 - accuracy: 0.4993 - val_loss: 0.9093 - val_accuracy: 0.5001\n",
      "Epoch 293/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9087 - accuracy: 0.5025 - val_loss: 0.9082 - val_accuracy: 0.5001\n",
      "Epoch 294/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9077 - accuracy: 0.4982 - val_loss: 0.9071 - val_accuracy: 0.5001\n",
      "Epoch 295/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9066 - accuracy: 0.5013 - val_loss: 0.9060 - val_accuracy: 0.5001\n",
      "Epoch 296/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9055 - accuracy: 0.4978 - val_loss: 0.9050 - val_accuracy: 0.5001\n",
      "Epoch 297/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9044 - accuracy: 0.5046 - val_loss: 0.9039 - val_accuracy: 0.5001\n",
      "Epoch 298/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9033 - accuracy: 0.5055 - val_loss: 0.9028 - val_accuracy: 0.5001\n",
      "Epoch 299/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9023 - accuracy: 0.5051 - val_loss: 0.9017 - val_accuracy: 0.5002\n",
      "Epoch 300/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.9012 - accuracy: 0.5031 - val_loss: 0.9007 - val_accuracy: 0.5001\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9007 - accuracy: 0.5001\n",
      "{'loss': 0.9006587862968445, 'accuracy': 0.5001260638237} \n",
      " 299 \n",
      "\n",
      "Model time: 4.961528234183788 minutes\n",
      "\n",
      "Total time: 143.32929310947657 minutes\n",
      "\n",
      "\n",
      "Model  88  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                     8\n",
      "Activation function         linear\n",
      "Dropout                        0.2\n",
      "L1                         0.00001\n",
      "L2                             0.0\n",
      "Batch size                      32\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 3354929, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 6ms/step - loss: 0.8302 - accuracy: 0.4941 - val_loss: 0.6996 - val_accuracy: 0.5314\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7409 - accuracy: 0.5199 - val_loss: 0.6850 - val_accuracy: 0.5639\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7188 - accuracy: 0.5227 - val_loss: 0.6823 - val_accuracy: 0.5701\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7078 - accuracy: 0.5302 - val_loss: 0.6795 - val_accuracy: 0.5831\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6992 - accuracy: 0.5366 - val_loss: 0.6771 - val_accuracy: 0.5920\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6935 - accuracy: 0.5467 - val_loss: 0.6739 - val_accuracy: 0.5990\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6893 - accuracy: 0.5539 - val_loss: 0.6713 - val_accuracy: 0.6025\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6833 - accuracy: 0.5611 - val_loss: 0.6675 - val_accuracy: 0.6109\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6790 - accuracy: 0.5757 - val_loss: 0.6652 - val_accuracy: 0.6114\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6768 - accuracy: 0.5804 - val_loss: 0.6627 - val_accuracy: 0.6161\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6718 - accuracy: 0.5824 - val_loss: 0.6609 - val_accuracy: 0.6182\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6711 - accuracy: 0.5939 - val_loss: 0.6599 - val_accuracy: 0.6178\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6687 - accuracy: 0.6017 - val_loss: 0.6592 - val_accuracy: 0.6233\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6654 - accuracy: 0.6006 - val_loss: 0.6583 - val_accuracy: 0.6205\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6641 - accuracy: 0.6085 - val_loss: 0.6573 - val_accuracy: 0.6217\n",
      "Epoch 16/300\n",
      "666/670 [============================>.] - ETA: 0s - loss: 0.6656 - accuracy: 0.6084Restoring model weights from the end of the best epoch: 15.\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.6653 - accuracy: 0.6089 - val_loss: 0.6576 - val_accuracy: 0.6211\n",
      "Epoch 16: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.6573 - accuracy: 0.6217\n",
      "{'loss': 0.6573114991188049, 'accuracy': 0.621691107749939} \n",
      " 15 \n",
      "\n",
      "Model time: 1.4399648606777191 minutes\n",
      "\n",
      "Total time: 144.7693412862718 minutes\n",
      "\n",
      "\n",
      "Model  89  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                    64\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.4\n",
      "L1                             0.1\n",
      "L2                            0.01\n",
      "Batch size                     128\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 6666037, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 6s 17ms/step - loss: 246.7856 - accuracy: 0.5012 - val_loss: 224.2894 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 203.8540 - accuracy: 0.4975 - val_loss: 183.6389 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 165.3586 - accuracy: 0.5016 - val_loss: 147.3355 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 131.1665 - accuracy: 0.4993 - val_loss: 115.3276 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 101.2248 - accuracy: 0.5003 - val_loss: 87.4804 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 75.4549 - accuracy: 0.5003 - val_loss: 63.8387 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 53.8456 - accuracy: 0.4962 - val_loss: 44.2952 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 36.3165 - accuracy: 0.5000 - val_loss: 28.8480 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 22.9198 - accuracy: 0.5037 - val_loss: 17.5624 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 13.6184 - accuracy: 0.5053 - val_loss: 10.0577 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 7.2909 - accuracy: 0.5032 - val_loss: 4.8464 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 3.1792 - accuracy: 0.4950 - val_loss: 1.8438 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.2569 - accuracy: 0.4995 - val_loss: 0.9971 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.9678 - accuracy: 0.5010 - val_loss: 0.9383 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 0.9160 - accuracy: 0.5012 - val_loss: 0.8934 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8773 - accuracy: 0.5021 - val_loss: 0.8623 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 0.8515 - accuracy: 0.5010 - val_loss: 0.8423 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8374 - accuracy: 0.5003 - val_loss: 0.8334 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 0.8318 - accuracy: 0.5003 - val_loss: 0.8311 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.8313 - accuracy: 0.5003 - val_loss: 0.8311 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "163/168 [============================>.] - ETA: 0s - loss: 0.8313 - accuracy: 0.4997Restoring model weights from the end of the best epoch: 20.\n",
      "168/168 [==============================] - 2s 11ms/step - loss: 0.8313 - accuracy: 0.5003 - val_loss: 0.8312 - val_accuracy: 0.5001\n",
      "Epoch 21: early stopping\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.8311 - accuracy: 0.5001\n",
      "{'loss': 0.83112633228302, 'accuracy': 0.5001260638237} \n",
      " 20 \n",
      "\n",
      "Model time: 0.8001723401248455 minutes\n",
      "\n",
      "Total time: 145.56958030164242 minutes\n",
      "\n",
      "\n",
      "Model  90  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                   256\n",
      "Activation function           relu\n",
      "Dropout                        0.7\n",
      "L1                           0.001\n",
      "L2                            10.0\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 2712637, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 14s 9ms/step - loss: 976.9661 - accuracy: 0.5003 - val_loss: 0.7991 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 11s 8ms/step - loss: 0.7055 - accuracy: 0.4997 - val_loss: 0.7014 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "1337/1339 [============================>.] - ETA: 0s - loss: 0.7014 - accuracy: 0.4997Restoring model weights from the end of the best epoch: 2.\n",
      "1339/1339 [==============================] - 11s 8ms/step - loss: 0.7014 - accuracy: 0.4997 - val_loss: 0.7014 - val_accuracy: 0.4999\n",
      "Epoch 3: early stopping\n",
      "1240/1240 [==============================] - 4s 3ms/step - loss: 0.7014 - accuracy: 0.4999\n",
      "{'loss': 0.7014338374137878, 'accuracy': 0.49987393617630005} \n",
      " 2 \n",
      "\n",
      "Model time: 0.6773214563727379 minutes\n",
      "\n",
      "Total time: 146.24700176343322 minutes\n",
      "\n",
      "\n",
      "Model  91  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     4\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.7\n",
      "L1                            10.0\n",
      "L2                            10.0\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 1855556, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 6ms/step - loss: 856.4596 - accuracy: 0.4933 - val_loss: 828.0162 - val_accuracy: 0.5514\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 801.0270 - accuracy: 0.4991 - val_loss: 774.0844 - val_accuracy: 0.5505\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 748.5245 - accuracy: 0.5014 - val_loss: 722.9634 - val_accuracy: 0.5511\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 698.7712 - accuracy: 0.5012 - val_loss: 674.5002 - val_accuracy: 0.5484\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 651.2379 - accuracy: 0.4975 - val_loss: 627.8481 - val_accuracy: 0.5459\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 605.6667 - accuracy: 0.5023 - val_loss: 583.3998 - val_accuracy: 0.5447\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 562.2927 - accuracy: 0.5029 - val_loss: 541.3268 - val_accuracy: 0.5419\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 521.5120 - accuracy: 0.5023 - val_loss: 501.6158 - val_accuracy: 0.5388\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 482.6972 - accuracy: 0.4984 - val_loss: 463.7751 - val_accuracy: 0.5345\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 445.9061 - accuracy: 0.5008 - val_loss: 427.9383 - val_accuracy: 0.5323\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 410.9530 - accuracy: 0.5027 - val_loss: 393.9014 - val_accuracy: 0.5250\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 377.7408 - accuracy: 0.5060 - val_loss: 361.5378 - val_accuracy: 0.5205\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 346.3425 - accuracy: 0.4993 - val_loss: 331.1574 - val_accuracy: 0.5146\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 316.9291 - accuracy: 0.5014 - val_loss: 302.7867 - val_accuracy: 0.5077\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 289.7895 - accuracy: 0.4951 - val_loss: 276.7821 - val_accuracy: 0.5066\n",
      "Epoch 16/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 264.5717 - accuracy: 0.5016 - val_loss: 252.3855 - val_accuracy: 0.5042\n",
      "Epoch 17/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 241.1910 - accuracy: 0.4991 - val_loss: 230.1600 - val_accuracy: 0.5031\n",
      "Epoch 18/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 219.9967 - accuracy: 0.4953 - val_loss: 209.8264 - val_accuracy: 0.5021\n",
      "Epoch 19/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 200.4729 - accuracy: 0.5006 - val_loss: 191.2010 - val_accuracy: 0.5000\n",
      "Epoch 20/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 182.7326 - accuracy: 0.5020 - val_loss: 174.4210 - val_accuracy: 0.4998\n",
      "Epoch 21/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 167.1807 - accuracy: 0.5028 - val_loss: 160.1571 - val_accuracy: 0.5000\n",
      "Epoch 22/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 154.0288 - accuracy: 0.4970 - val_loss: 148.0907 - val_accuracy: 0.4999\n",
      "Epoch 23/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 142.9186 - accuracy: 0.4943 - val_loss: 137.7334 - val_accuracy: 0.4999\n",
      "Epoch 24/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 133.1903 - accuracy: 0.4956 - val_loss: 128.7180 - val_accuracy: 0.4999\n",
      "Epoch 25/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 125.1574 - accuracy: 0.5003 - val_loss: 121.7409 - val_accuracy: 0.4999\n",
      "Epoch 26/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 119.1370 - accuracy: 0.5002 - val_loss: 116.5964 - val_accuracy: 0.4999\n",
      "Epoch 27/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 114.6061 - accuracy: 0.5052 - val_loss: 112.7406 - val_accuracy: 0.4999\n",
      "Epoch 28/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 111.5487 - accuracy: 0.5008 - val_loss: 110.2883 - val_accuracy: 0.4999\n",
      "Epoch 29/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 109.1942 - accuracy: 0.5014 - val_loss: 107.9606 - val_accuracy: 0.4999\n",
      "Epoch 30/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 106.8691 - accuracy: 0.5062 - val_loss: 105.6509 - val_accuracy: 0.4999\n",
      "Epoch 31/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 104.5736 - accuracy: 0.4980 - val_loss: 103.3626 - val_accuracy: 0.4999\n",
      "Epoch 32/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 102.3203 - accuracy: 0.5027 - val_loss: 101.1554 - val_accuracy: 0.4999\n",
      "Epoch 33/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 100.1216 - accuracy: 0.5002 - val_loss: 98.9655 - val_accuracy: 0.4999\n",
      "Epoch 34/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 97.9385 - accuracy: 0.5023 - val_loss: 96.7927 - val_accuracy: 0.4999\n",
      "Epoch 35/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 95.7731 - accuracy: 0.5004 - val_loss: 94.6368 - val_accuracy: 0.4999\n",
      "Epoch 36/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 93.6185 - accuracy: 0.5043 - val_loss: 92.4984 - val_accuracy: 0.4999\n",
      "Epoch 37/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 91.4903 - accuracy: 0.5030 - val_loss: 90.3765 - val_accuracy: 0.4999\n",
      "Epoch 38/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 89.3736 - accuracy: 0.5069 - val_loss: 88.2721 - val_accuracy: 0.4999\n",
      "Epoch 39/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 87.2793 - accuracy: 0.5004 - val_loss: 86.1845 - val_accuracy: 0.4999\n",
      "Epoch 40/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 85.2071 - accuracy: 0.4970 - val_loss: 84.1434 - val_accuracy: 0.4999\n",
      "Epoch 41/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 83.1968 - accuracy: 0.5007 - val_loss: 82.1563 - val_accuracy: 0.4999\n",
      "Epoch 42/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 81.2154 - accuracy: 0.5008 - val_loss: 80.1858 - val_accuracy: 0.4999\n",
      "Epoch 43/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 79.2516 - accuracy: 0.5033 - val_loss: 78.2389 - val_accuracy: 0.4999\n",
      "Epoch 44/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 77.3504 - accuracy: 0.4923 - val_loss: 76.3669 - val_accuracy: 0.4999\n",
      "Epoch 45/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 75.4826 - accuracy: 0.4981 - val_loss: 74.5102 - val_accuracy: 0.4999\n",
      "Epoch 46/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 73.6331 - accuracy: 0.4957 - val_loss: 72.6685 - val_accuracy: 0.4999\n",
      "Epoch 47/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 71.7938 - accuracy: 0.5020 - val_loss: 70.8425 - val_accuracy: 0.4999\n",
      "Epoch 48/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 69.9743 - accuracy: 0.5009 - val_loss: 69.0313 - val_accuracy: 0.4999\n",
      "Epoch 49/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 68.1673 - accuracy: 0.5005 - val_loss: 67.2357 - val_accuracy: 0.4999\n",
      "Epoch 50/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 66.3797 - accuracy: 0.5005 - val_loss: 65.4554 - val_accuracy: 0.4999\n",
      "Epoch 51/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 64.6070 - accuracy: 0.5042 - val_loss: 63.6903 - val_accuracy: 0.4999\n",
      "Epoch 52/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 62.8480 - accuracy: 0.5005 - val_loss: 61.9405 - val_accuracy: 0.4999\n",
      "Epoch 53/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 61.1058 - accuracy: 0.4961 - val_loss: 60.2115 - val_accuracy: 0.4999\n",
      "Epoch 54/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 59.4175 - accuracy: 0.4942 - val_loss: 58.5587 - val_accuracy: 0.4999\n",
      "Epoch 55/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 57.7707 - accuracy: 0.4999 - val_loss: 56.9202 - val_accuracy: 0.4999\n",
      "Epoch 56/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 56.1359 - accuracy: 0.5042 - val_loss: 55.2962 - val_accuracy: 0.4999\n",
      "Epoch 57/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 54.5216 - accuracy: 0.4932 - val_loss: 53.6863 - val_accuracy: 0.4999\n",
      "Epoch 58/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 52.9180 - accuracy: 0.5023 - val_loss: 52.1099 - val_accuracy: 0.4999\n",
      "Epoch 59/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 51.3775 - accuracy: 0.5000 - val_loss: 50.5950 - val_accuracy: 0.4999\n",
      "Epoch 60/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 49.8698 - accuracy: 0.4984 - val_loss: 49.0937 - val_accuracy: 0.4999\n",
      "Epoch 61/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 48.3728 - accuracy: 0.5050 - val_loss: 47.6099 - val_accuracy: 0.4999\n",
      "Epoch 62/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 46.9304 - accuracy: 0.5029 - val_loss: 46.2018 - val_accuracy: 0.4999\n",
      "Epoch 63/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 45.5260 - accuracy: 0.5025 - val_loss: 44.8064 - val_accuracy: 0.4999\n",
      "Epoch 64/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 44.1379 - accuracy: 0.5018 - val_loss: 43.4237 - val_accuracy: 0.4999\n",
      "Epoch 65/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 42.7594 - accuracy: 0.5058 - val_loss: 42.0536 - val_accuracy: 0.4999\n",
      "Epoch 66/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 41.3981 - accuracy: 0.4998 - val_loss: 40.7032 - val_accuracy: 0.4999\n",
      "Epoch 67/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 40.0855 - accuracy: 0.4976 - val_loss: 39.4243 - val_accuracy: 0.4999\n",
      "Epoch 68/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 38.8112 - accuracy: 0.5014 - val_loss: 38.1576 - val_accuracy: 0.4999\n",
      "Epoch 69/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 37.5496 - accuracy: 0.5038 - val_loss: 36.9020 - val_accuracy: 0.4999\n",
      "Epoch 70/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 36.3014 - accuracy: 0.4935 - val_loss: 35.6583 - val_accuracy: 0.4999\n",
      "Epoch 71/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 35.0598 - accuracy: 0.5000 - val_loss: 34.4263 - val_accuracy: 0.4999\n",
      "Epoch 72/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 33.8351 - accuracy: 0.4989 - val_loss: 33.2061 - val_accuracy: 0.4999\n",
      "Epoch 73/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 32.6186 - accuracy: 0.4999 - val_loss: 31.9974 - val_accuracy: 0.4999\n",
      "Epoch 74/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 31.4355 - accuracy: 0.5036 - val_loss: 30.8527 - val_accuracy: 0.4999\n",
      "Epoch 75/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 30.3099 - accuracy: 0.5003 - val_loss: 29.7335 - val_accuracy: 0.4999\n",
      "Epoch 76/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 29.1945 - accuracy: 0.5030 - val_loss: 28.6248 - val_accuracy: 0.4999\n",
      "Epoch 77/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 28.0921 - accuracy: 0.4999 - val_loss: 27.5270 - val_accuracy: 0.4999\n",
      "Epoch 78/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 26.9972 - accuracy: 0.5022 - val_loss: 26.4398 - val_accuracy: 0.4999\n",
      "Epoch 79/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 25.9167 - accuracy: 0.4968 - val_loss: 25.3635 - val_accuracy: 0.4999\n",
      "Epoch 80/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 24.8474 - accuracy: 0.4954 - val_loss: 24.2979 - val_accuracy: 0.4999\n",
      "Epoch 81/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 23.7820 - accuracy: 0.5053 - val_loss: 23.2430 - val_accuracy: 0.4999\n",
      "Epoch 82/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 22.7436 - accuracy: 0.5004 - val_loss: 22.2309 - val_accuracy: 0.4999\n",
      "Epoch 83/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 21.7617 - accuracy: 0.4991 - val_loss: 21.2637 - val_accuracy: 0.4999\n",
      "Epoch 84/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 20.7968 - accuracy: 0.5029 - val_loss: 20.3066 - val_accuracy: 0.4999\n",
      "Epoch 85/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 19.8475 - accuracy: 0.4986 - val_loss: 19.3764 - val_accuracy: 0.4999\n",
      "Epoch 86/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 18.9808 - accuracy: 0.4975 - val_loss: 18.5657 - val_accuracy: 0.4999\n",
      "Epoch 87/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 18.1798 - accuracy: 0.4990 - val_loss: 17.7692 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 17.3858 - accuracy: 0.5032 - val_loss: 16.9808 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 16.6023 - accuracy: 0.4968 - val_loss: 16.2004 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 15.8243 - accuracy: 0.5010 - val_loss: 15.4281 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 15.0565 - accuracy: 0.4965 - val_loss: 14.6640 - val_accuracy: 0.5001\n",
      "Epoch 92/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 14.2954 - accuracy: 0.4993 - val_loss: 13.9080 - val_accuracy: 0.5001\n",
      "Epoch 93/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 13.5444 - accuracy: 0.4925 - val_loss: 13.1601 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 12.7979 - accuracy: 0.5012 - val_loss: 12.4202 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 12.0677 - accuracy: 0.4976 - val_loss: 11.7254 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 11.4371 - accuracy: 0.4968 - val_loss: 11.1342 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 10.8484 - accuracy: 0.4989 - val_loss: 10.5493 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 10.2664 - accuracy: 0.5004 - val_loss: 9.9706 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 9.6901 - accuracy: 0.5025 - val_loss: 9.3982 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 9.1220 - accuracy: 0.5002 - val_loss: 8.8321 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 8.5584 - accuracy: 0.4978 - val_loss: 8.2724 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 8.0004 - accuracy: 0.5018 - val_loss: 7.7190 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 7.4494 - accuracy: 0.5020 - val_loss: 7.1718 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 6.9063 - accuracy: 0.4988 - val_loss: 6.6309 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 6.3667 - accuracy: 0.5078 - val_loss: 6.0979 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.8697 - accuracy: 0.5075 - val_loss: 5.6360 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.4128 - accuracy: 0.4996 - val_loss: 5.1941 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 5.0080 - accuracy: 0.5022 - val_loss: 4.8299 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.6761 - accuracy: 0.4999 - val_loss: 4.5161 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.3640 - accuracy: 0.4999 - val_loss: 4.2057 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 4.0550 - accuracy: 0.5003 - val_loss: 3.8991 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.7498 - accuracy: 0.5011 - val_loss: 3.5960 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.4478 - accuracy: 0.5055 - val_loss: 3.2963 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 3.1518 - accuracy: 0.5005 - val_loss: 3.0137 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.9028 - accuracy: 0.4991 - val_loss: 2.7877 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.6884 - accuracy: 0.5016 - val_loss: 2.6125 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.5706 - accuracy: 0.4949 - val_loss: 2.5242 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.4818 - accuracy: 0.5034 - val_loss: 2.4369 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.3951 - accuracy: 0.5009 - val_loss: 2.3504 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.3088 - accuracy: 0.5029 - val_loss: 2.2649 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.2236 - accuracy: 0.5025 - val_loss: 2.1802 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 2.1398 - accuracy: 0.4966 - val_loss: 2.0964 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 2.0558 - accuracy: 0.5044 - val_loss: 2.0136 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.9735 - accuracy: 0.5025 - val_loss: 1.9317 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.8921 - accuracy: 0.4999 - val_loss: 1.8507 - val_accuracy: 0.5001\n",
      "Epoch 126/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.8111 - accuracy: 0.5032 - val_loss: 1.7704 - val_accuracy: 0.5001\n",
      "Epoch 127/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.7314 - accuracy: 0.5020 - val_loss: 1.6912 - val_accuracy: 0.5001\n",
      "Epoch 128/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.6526 - accuracy: 0.5022 - val_loss: 1.6128 - val_accuracy: 0.5001\n",
      "Epoch 129/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5747 - accuracy: 0.4992 - val_loss: 1.5353 - val_accuracy: 0.5001\n",
      "Epoch 130/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4976 - accuracy: 0.5003 - val_loss: 1.4586 - val_accuracy: 0.5001\n",
      "Epoch 131/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4216 - accuracy: 0.5003 - val_loss: 1.3830 - val_accuracy: 0.5001\n",
      "Epoch 132/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.3462 - accuracy: 0.5003 - val_loss: 1.3083 - val_accuracy: 0.5001\n",
      "Epoch 133/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.2718 - accuracy: 0.5003 - val_loss: 1.2344 - val_accuracy: 0.5001\n",
      "Epoch 134/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1985 - accuracy: 0.5003 - val_loss: 1.1613 - val_accuracy: 0.5001\n",
      "Epoch 135/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1258 - accuracy: 0.5003 - val_loss: 1.0892 - val_accuracy: 0.5001\n",
      "Epoch 136/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0541 - accuracy: 0.5003 - val_loss: 1.0181 - val_accuracy: 0.5001\n",
      "Epoch 137/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9833 - accuracy: 0.5003 - val_loss: 0.9478 - val_accuracy: 0.5001\n",
      "Epoch 138/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9134 - accuracy: 0.5003 - val_loss: 0.8784 - val_accuracy: 0.5001\n",
      "Epoch 139/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8445 - accuracy: 0.5003 - val_loss: 0.8099 - val_accuracy: 0.5001\n",
      "Epoch 140/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7764 - accuracy: 0.5003 - val_loss: 0.7423 - val_accuracy: 0.5001\n",
      "Epoch 141/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7309 - accuracy: 0.5003 - val_loss: 0.7294 - val_accuracy: 0.5001\n",
      "Epoch 142/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7296 - accuracy: 0.5003 - val_loss: 0.7293 - val_accuracy: 0.5001\n",
      "Epoch 143/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7296 - accuracy: 0.5003 - val_loss: 0.7293 - val_accuracy: 0.5001\n",
      "Epoch 144/300\n",
      "661/670 [============================>.] - ETA: 0s - loss: 0.7296 - accuracy: 0.4997Restoring model weights from the end of the best epoch: 143.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7295 - accuracy: 0.5003 - val_loss: 0.7293 - val_accuracy: 0.5001\n",
      "Epoch 144: early stopping\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.7293 - accuracy: 0.5001\n",
      "{'loss': 0.7292898893356323, 'accuracy': 0.5001260638237} \n",
      " 143 \n",
      "\n",
      "Model time: 7.9704232811927795 minutes\n",
      "\n",
      "Total time: 154.2175083681941 minutes\n",
      "\n",
      "\n",
      "Model  92  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                   128\n",
      "Activation function           relu\n",
      "Dropout                        0.2\n",
      "L1                         0.00001\n",
      "L2                           100.0\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 2538495, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 11s 7ms/step - loss: 693.2946 - accuracy: 0.4947 - val_loss: 1.6631 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 1.6630 - accuracy: 0.5009 - val_loss: 1.6629 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "1328/1339 [============================>.] - ETA: 0s - loss: 1.6630 - accuracy: 0.4957Restoring model weights from the end of the best epoch: 2.\n",
      "1339/1339 [==============================] - 8s 6ms/step - loss: 1.6630 - accuracy: 0.4957 - val_loss: 1.6630 - val_accuracy: 0.4999\n",
      "Epoch 3: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 1.6629 - accuracy: 0.5001\n",
      "{'loss': 1.662935733795166, 'accuracy': 0.5001260638237} \n",
      " 2 \n",
      "\n",
      "Model time: 0.5276206620037556 minutes\n",
      "\n",
      "Total time: 154.74519569426775 minutes\n",
      "\n",
      "\n",
      "Model  93  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     1\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.1\n",
      "L1                             0.1\n",
      "L2                             1.0\n",
      "Batch size                       8\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 122400, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 15s 5ms/step - loss: 3.8607 - accuracy: 0.5003 - val_loss: 3.3024 - val_accuracy: 0.4985\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 2.8372 - accuracy: 0.4989 - val_loss: 2.4111 - val_accuracy: 0.4989\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 2.0596 - accuracy: 0.4998 - val_loss: 1.7399 - val_accuracy: 0.4994\n",
      "Epoch 4/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 1.4901 - accuracy: 0.5019 - val_loss: 1.2740 - val_accuracy: 0.4993\n",
      "Epoch 5/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 1.1170 - accuracy: 0.5010 - val_loss: 0.9861 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.8987 - accuracy: 0.5006 - val_loss: 0.8286 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.7858 - accuracy: 0.4989 - val_loss: 0.7541 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.7421 - accuracy: 0.5025 - val_loss: 0.7355 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.7304 - accuracy: 0.5019 - val_loss: 0.7255 - val_accuracy: 0.4999\n",
      "Epoch 10/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.7212 - accuracy: 0.4990 - val_loss: 0.7169 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.7132 - accuracy: 0.4982 - val_loss: 0.7097 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.7066 - accuracy: 0.5003 - val_loss: 0.7038 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.7014 - accuracy: 0.5003 - val_loss: 0.6992 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6974 - accuracy: 0.5003 - val_loss: 0.6958 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6946 - accuracy: 0.5003 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "2677/2677 [==============================] - 12s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "2668/2677 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5003Restoring model weights from the end of the best epoch: 28.\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 29: early stopping\n",
      "2480/2480 [==============================] - 6s 2ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "{'loss': 0.6931992769241333, 'accuracy': 0.5001260638237} \n",
      " 28 \n",
      "\n",
      "Model time: 6.091059938073158 minutes\n",
      "\n",
      "Total time: 160.8366387076676 minutes\n",
      "\n",
      "\n",
      "Model  94  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     4\n",
      "Activation function           tanh\n",
      "Dropout                        0.5\n",
      "L1                            10.0\n",
      "L2                             1.0\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 331519, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 7ms/step - loss: 122.5037 - accuracy: 0.5015 - val_loss: 18.4230 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.0276 - accuracy: 0.5006 - val_loss: 7.6829 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 5.0255 - accuracy: 0.4991 - val_loss: 4.2571 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.1935 - accuracy: 0.4997 - val_loss: 4.1337 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - ETA: 0s - loss: 4.1933 - accuracy: 0.4952Restoring model weights from the end of the best epoch: 4.\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.1933 - accuracy: 0.4952 - val_loss: 4.2494 - val_accuracy: 0.4999\n",
      "Epoch 5: early stopping\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 4.1337 - accuracy: 0.4999\n",
      "{'loss': 4.133657932281494, 'accuracy': 0.49987393617630005} \n",
      " 4 \n",
      "\n",
      "Model time: 0.22328491881489754 minutes\n",
      "\n",
      "Total time: 161.0600236169994 minutes\n",
      "\n",
      "\n",
      "Model  95  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     1\n",
      "Activation function           relu\n",
      "Dropout                        0.7\n",
      "L1                            0.01\n",
      "L2                           0.001\n",
      "Batch size                      64\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 68568, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 8ms/step - loss: 1.2711 - accuracy: 0.4956 - val_loss: 1.0527 - val_accuracy: 0.4983\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.2588 - accuracy: 0.5013 - val_loss: 1.0427 - val_accuracy: 0.4977\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.2205 - accuracy: 0.5049 - val_loss: 1.0331 - val_accuracy: 0.4976\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.2243 - accuracy: 0.5019 - val_loss: 1.0233 - val_accuracy: 0.4984\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1866 - accuracy: 0.4968 - val_loss: 1.0142 - val_accuracy: 0.4987\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1815 - accuracy: 0.4968 - val_loss: 1.0051 - val_accuracy: 0.4988\n",
      "Epoch 7/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1811 - accuracy: 0.4977 - val_loss: 0.9964 - val_accuracy: 0.4992\n",
      "Epoch 8/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1386 - accuracy: 0.5053 - val_loss: 0.9883 - val_accuracy: 0.4996\n",
      "Epoch 9/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1243 - accuracy: 0.5034 - val_loss: 0.9805 - val_accuracy: 0.5003\n",
      "Epoch 10/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1153 - accuracy: 0.5024 - val_loss: 0.9727 - val_accuracy: 0.5005\n",
      "Epoch 11/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.1087 - accuracy: 0.5011 - val_loss: 0.9650 - val_accuracy: 0.5008\n",
      "Epoch 12/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0960 - accuracy: 0.5000 - val_loss: 0.9577 - val_accuracy: 0.5010\n",
      "Epoch 13/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0847 - accuracy: 0.5041 - val_loss: 0.9506 - val_accuracy: 0.5013\n",
      "Epoch 14/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0592 - accuracy: 0.5043 - val_loss: 0.9437 - val_accuracy: 0.5020\n",
      "Epoch 15/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0585 - accuracy: 0.5009 - val_loss: 0.9370 - val_accuracy: 0.5027\n",
      "Epoch 16/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0477 - accuracy: 0.4990 - val_loss: 0.9307 - val_accuracy: 0.5033\n",
      "Epoch 17/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.0246 - accuracy: 0.5066 - val_loss: 0.9246 - val_accuracy: 0.5035\n",
      "Epoch 18/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0277 - accuracy: 0.5013 - val_loss: 0.9187 - val_accuracy: 0.5031\n",
      "Epoch 19/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0110 - accuracy: 0.5012 - val_loss: 0.9129 - val_accuracy: 0.5033\n",
      "Epoch 20/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.9941 - accuracy: 0.5066 - val_loss: 0.9073 - val_accuracy: 0.5036\n",
      "Epoch 21/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.0020 - accuracy: 0.5018 - val_loss: 0.9018 - val_accuracy: 0.5040\n",
      "Epoch 22/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9867 - accuracy: 0.5022 - val_loss: 0.8965 - val_accuracy: 0.5037\n",
      "Epoch 23/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9715 - accuracy: 0.5025 - val_loss: 0.8916 - val_accuracy: 0.5043\n",
      "Epoch 24/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.9548 - accuracy: 0.5063 - val_loss: 0.8870 - val_accuracy: 0.5042\n",
      "Epoch 25/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9665 - accuracy: 0.5049 - val_loss: 0.8821 - val_accuracy: 0.5047\n",
      "Epoch 26/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9581 - accuracy: 0.5040 - val_loss: 0.8776 - val_accuracy: 0.5042\n",
      "Epoch 27/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9429 - accuracy: 0.5034 - val_loss: 0.8734 - val_accuracy: 0.5042\n",
      "Epoch 28/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9349 - accuracy: 0.5060 - val_loss: 0.8692 - val_accuracy: 0.5039\n",
      "Epoch 29/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9275 - accuracy: 0.5054 - val_loss: 0.8653 - val_accuracy: 0.5034\n",
      "Epoch 30/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9151 - accuracy: 0.5051 - val_loss: 0.8616 - val_accuracy: 0.5038\n",
      "Epoch 31/300\n",
      "335/335 [==============================] - 2s 4ms/step - loss: 0.9217 - accuracy: 0.5035 - val_loss: 0.8579 - val_accuracy: 0.5041\n",
      "Epoch 32/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9115 - accuracy: 0.5031 - val_loss: 0.8544 - val_accuracy: 0.5042\n",
      "Epoch 33/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9024 - accuracy: 0.5024 - val_loss: 0.8511 - val_accuracy: 0.5043\n",
      "Epoch 34/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8971 - accuracy: 0.5045 - val_loss: 0.8479 - val_accuracy: 0.5047\n",
      "Epoch 35/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8958 - accuracy: 0.5020 - val_loss: 0.8447 - val_accuracy: 0.5052\n",
      "Epoch 36/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8870 - accuracy: 0.5053 - val_loss: 0.8418 - val_accuracy: 0.5055\n",
      "Epoch 37/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8813 - accuracy: 0.5080 - val_loss: 0.8390 - val_accuracy: 0.5057\n",
      "Epoch 38/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8798 - accuracy: 0.5051 - val_loss: 0.8361 - val_accuracy: 0.5057\n",
      "Epoch 39/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8764 - accuracy: 0.5031 - val_loss: 0.8333 - val_accuracy: 0.5056\n",
      "Epoch 40/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8639 - accuracy: 0.5045 - val_loss: 0.8307 - val_accuracy: 0.5058\n",
      "Epoch 41/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.8650 - accuracy: 0.5035 - val_loss: 0.8282 - val_accuracy: 0.5059\n",
      "Epoch 42/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8561 - accuracy: 0.5070 - val_loss: 0.8258 - val_accuracy: 0.5058\n",
      "Epoch 43/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8533 - accuracy: 0.5053 - val_loss: 0.8235 - val_accuracy: 0.5059\n",
      "Epoch 44/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.8522 - accuracy: 0.5038 - val_loss: 0.8213 - val_accuracy: 0.5068\n",
      "Epoch 45/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8510 - accuracy: 0.5034 - val_loss: 0.8192 - val_accuracy: 0.5070\n",
      "Epoch 46/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8402 - accuracy: 0.5048 - val_loss: 0.8171 - val_accuracy: 0.5078\n",
      "Epoch 47/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8391 - accuracy: 0.5038 - val_loss: 0.8150 - val_accuracy: 0.5082\n",
      "Epoch 48/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8382 - accuracy: 0.5058 - val_loss: 0.8130 - val_accuracy: 0.5087\n",
      "Epoch 49/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.8309 - accuracy: 0.5055 - val_loss: 0.8111 - val_accuracy: 0.5091\n",
      "Epoch 50/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8311 - accuracy: 0.5051 - val_loss: 0.8092 - val_accuracy: 0.5085\n",
      "Epoch 51/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8285 - accuracy: 0.5038 - val_loss: 0.8074 - val_accuracy: 0.5088\n",
      "Epoch 52/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8233 - accuracy: 0.5061 - val_loss: 0.8058 - val_accuracy: 0.5089\n",
      "Epoch 53/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8239 - accuracy: 0.5035 - val_loss: 0.8042 - val_accuracy: 0.5089\n",
      "Epoch 54/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8198 - accuracy: 0.5036 - val_loss: 0.8027 - val_accuracy: 0.5083\n",
      "Epoch 55/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8151 - accuracy: 0.5062 - val_loss: 0.8014 - val_accuracy: 0.5087\n",
      "Epoch 56/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8150 - accuracy: 0.5049 - val_loss: 0.8001 - val_accuracy: 0.5090\n",
      "Epoch 57/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8137 - accuracy: 0.5049 - val_loss: 0.7988 - val_accuracy: 0.5093\n",
      "Epoch 58/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8112 - accuracy: 0.5034 - val_loss: 0.7976 - val_accuracy: 0.5105\n",
      "Epoch 59/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8092 - accuracy: 0.5058 - val_loss: 0.7964 - val_accuracy: 0.5118\n",
      "Epoch 60/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8080 - accuracy: 0.5051 - val_loss: 0.7952 - val_accuracy: 0.5113\n",
      "Epoch 61/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8075 - accuracy: 0.5056 - val_loss: 0.7940 - val_accuracy: 0.5113\n",
      "Epoch 62/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.8067 - accuracy: 0.5036 - val_loss: 0.7928 - val_accuracy: 0.5113\n",
      "Epoch 63/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.8022 - accuracy: 0.5048 - val_loss: 0.7916 - val_accuracy: 0.5113\n",
      "Epoch 64/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.8010 - accuracy: 0.5068 - val_loss: 0.7905 - val_accuracy: 0.5111\n",
      "Epoch 65/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8012 - accuracy: 0.5051 - val_loss: 0.7895 - val_accuracy: 0.5112\n",
      "Epoch 66/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7971 - accuracy: 0.5049 - val_loss: 0.7885 - val_accuracy: 0.5117\n",
      "Epoch 67/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7957 - accuracy: 0.5051 - val_loss: 0.7875 - val_accuracy: 0.5120\n",
      "Epoch 68/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7960 - accuracy: 0.5039 - val_loss: 0.7865 - val_accuracy: 0.5125\n",
      "Epoch 69/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7915 - accuracy: 0.5053 - val_loss: 0.7855 - val_accuracy: 0.5133\n",
      "Epoch 70/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7928 - accuracy: 0.5053 - val_loss: 0.7846 - val_accuracy: 0.5137\n",
      "Epoch 71/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7894 - accuracy: 0.5060 - val_loss: 0.7837 - val_accuracy: 0.5135\n",
      "Epoch 72/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7896 - accuracy: 0.5065 - val_loss: 0.7828 - val_accuracy: 0.5139\n",
      "Epoch 73/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7876 - accuracy: 0.5059 - val_loss: 0.7819 - val_accuracy: 0.5142\n",
      "Epoch 74/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7879 - accuracy: 0.5048 - val_loss: 0.7810 - val_accuracy: 0.5137\n",
      "Epoch 75/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7863 - accuracy: 0.5051 - val_loss: 0.7802 - val_accuracy: 0.5135\n",
      "Epoch 76/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7850 - accuracy: 0.5060 - val_loss: 0.7794 - val_accuracy: 0.5133\n",
      "Epoch 77/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7834 - accuracy: 0.5051 - val_loss: 0.7785 - val_accuracy: 0.5132\n",
      "Epoch 78/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7828 - accuracy: 0.5045 - val_loss: 0.7777 - val_accuracy: 0.5136\n",
      "Epoch 79/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7819 - accuracy: 0.5060 - val_loss: 0.7769 - val_accuracy: 0.5138\n",
      "Epoch 80/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7805 - accuracy: 0.5052 - val_loss: 0.7762 - val_accuracy: 0.5138\n",
      "Epoch 81/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.7798 - accuracy: 0.5057 - val_loss: 0.7754 - val_accuracy: 0.5130\n",
      "Epoch 82/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7770 - accuracy: 0.5068 - val_loss: 0.7746 - val_accuracy: 0.5130\n",
      "Epoch 83/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7784 - accuracy: 0.5044 - val_loss: 0.7738 - val_accuracy: 0.5135\n",
      "Epoch 84/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7762 - accuracy: 0.5063 - val_loss: 0.7730 - val_accuracy: 0.5139\n",
      "Epoch 85/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7750 - accuracy: 0.5053 - val_loss: 0.7722 - val_accuracy: 0.5139\n",
      "Epoch 86/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7747 - accuracy: 0.5054 - val_loss: 0.7714 - val_accuracy: 0.5138\n",
      "Epoch 87/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7732 - accuracy: 0.5072 - val_loss: 0.7707 - val_accuracy: 0.5136\n",
      "Epoch 88/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7725 - accuracy: 0.5064 - val_loss: 0.7699 - val_accuracy: 0.5135\n",
      "Epoch 89/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7727 - accuracy: 0.5050 - val_loss: 0.7690 - val_accuracy: 0.5137\n",
      "Epoch 90/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7724 - accuracy: 0.5059 - val_loss: 0.7682 - val_accuracy: 0.5139\n",
      "Epoch 91/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7702 - accuracy: 0.5062 - val_loss: 0.7675 - val_accuracy: 0.5140\n",
      "Epoch 92/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7691 - accuracy: 0.5065 - val_loss: 0.7667 - val_accuracy: 0.5141\n",
      "Epoch 93/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7692 - accuracy: 0.5050 - val_loss: 0.7660 - val_accuracy: 0.5145\n",
      "Epoch 94/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7676 - accuracy: 0.5055 - val_loss: 0.7652 - val_accuracy: 0.5146\n",
      "Epoch 95/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7673 - accuracy: 0.5073 - val_loss: 0.7645 - val_accuracy: 0.5150\n",
      "Epoch 96/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7654 - accuracy: 0.5056 - val_loss: 0.7637 - val_accuracy: 0.5153\n",
      "Epoch 97/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7657 - accuracy: 0.5045 - val_loss: 0.7630 - val_accuracy: 0.5159\n",
      "Epoch 98/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7633 - accuracy: 0.5058 - val_loss: 0.7622 - val_accuracy: 0.5164\n",
      "Epoch 99/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7654 - accuracy: 0.5032 - val_loss: 0.7615 - val_accuracy: 0.5156\n",
      "Epoch 100/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7633 - accuracy: 0.5045 - val_loss: 0.7608 - val_accuracy: 0.5155\n",
      "Epoch 101/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7616 - accuracy: 0.5048 - val_loss: 0.7601 - val_accuracy: 0.5154\n",
      "Epoch 102/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7614 - accuracy: 0.5053 - val_loss: 0.7594 - val_accuracy: 0.5158\n",
      "Epoch 103/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7608 - accuracy: 0.5049 - val_loss: 0.7587 - val_accuracy: 0.5157\n",
      "Epoch 104/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7602 - accuracy: 0.5047 - val_loss: 0.7581 - val_accuracy: 0.5160\n",
      "Epoch 105/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7594 - accuracy: 0.5046 - val_loss: 0.7574 - val_accuracy: 0.5157\n",
      "Epoch 106/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7589 - accuracy: 0.5049 - val_loss: 0.7567 - val_accuracy: 0.5160\n",
      "Epoch 107/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7573 - accuracy: 0.5055 - val_loss: 0.7561 - val_accuracy: 0.5165\n",
      "Epoch 108/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7578 - accuracy: 0.5046 - val_loss: 0.7554 - val_accuracy: 0.5165\n",
      "Epoch 109/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7571 - accuracy: 0.5050 - val_loss: 0.7548 - val_accuracy: 0.5166\n",
      "Epoch 110/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7557 - accuracy: 0.5063 - val_loss: 0.7542 - val_accuracy: 0.5169\n",
      "Epoch 111/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7543 - accuracy: 0.5070 - val_loss: 0.7536 - val_accuracy: 0.5174\n",
      "Epoch 112/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7545 - accuracy: 0.5058 - val_loss: 0.7529 - val_accuracy: 0.5173\n",
      "Epoch 113/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7535 - accuracy: 0.5058 - val_loss: 0.7523 - val_accuracy: 0.5176\n",
      "Epoch 114/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7535 - accuracy: 0.5057 - val_loss: 0.7517 - val_accuracy: 0.5179\n",
      "Epoch 115/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7525 - accuracy: 0.5053 - val_loss: 0.7511 - val_accuracy: 0.5181\n",
      "Epoch 116/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7527 - accuracy: 0.5036 - val_loss: 0.7505 - val_accuracy: 0.5182\n",
      "Epoch 117/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7519 - accuracy: 0.5042 - val_loss: 0.7499 - val_accuracy: 0.5181\n",
      "Epoch 118/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7511 - accuracy: 0.5046 - val_loss: 0.7493 - val_accuracy: 0.5187\n",
      "Epoch 119/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7502 - accuracy: 0.5058 - val_loss: 0.7487 - val_accuracy: 0.5187\n",
      "Epoch 120/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7490 - accuracy: 0.5058 - val_loss: 0.7481 - val_accuracy: 0.5190\n",
      "Epoch 121/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7485 - accuracy: 0.5061 - val_loss: 0.7475 - val_accuracy: 0.5199\n",
      "Epoch 122/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7476 - accuracy: 0.5067 - val_loss: 0.7470 - val_accuracy: 0.5199\n",
      "Epoch 123/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7476 - accuracy: 0.5063 - val_loss: 0.7464 - val_accuracy: 0.5205\n",
      "Epoch 124/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7469 - accuracy: 0.5072 - val_loss: 0.7458 - val_accuracy: 0.5206\n",
      "Epoch 125/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7468 - accuracy: 0.5061 - val_loss: 0.7453 - val_accuracy: 0.5206\n",
      "Epoch 126/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7464 - accuracy: 0.5058 - val_loss: 0.7447 - val_accuracy: 0.5211\n",
      "Epoch 127/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7453 - accuracy: 0.5067 - val_loss: 0.7442 - val_accuracy: 0.5217\n",
      "Epoch 128/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7444 - accuracy: 0.5065 - val_loss: 0.7436 - val_accuracy: 0.5221\n",
      "Epoch 129/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7445 - accuracy: 0.5065 - val_loss: 0.7431 - val_accuracy: 0.5225\n",
      "Epoch 130/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7436 - accuracy: 0.5062 - val_loss: 0.7425 - val_accuracy: 0.5231\n",
      "Epoch 131/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7434 - accuracy: 0.5066 - val_loss: 0.7420 - val_accuracy: 0.5239\n",
      "Epoch 132/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7433 - accuracy: 0.5060 - val_loss: 0.7414 - val_accuracy: 0.5242\n",
      "Epoch 133/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7422 - accuracy: 0.5059 - val_loss: 0.7408 - val_accuracy: 0.5245\n",
      "Epoch 134/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7415 - accuracy: 0.5071 - val_loss: 0.7402 - val_accuracy: 0.5249\n",
      "Epoch 135/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7410 - accuracy: 0.5063 - val_loss: 0.7397 - val_accuracy: 0.5254\n",
      "Epoch 136/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7403 - accuracy: 0.5069 - val_loss: 0.7392 - val_accuracy: 0.5255\n",
      "Epoch 137/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7399 - accuracy: 0.5057 - val_loss: 0.7387 - val_accuracy: 0.5261\n",
      "Epoch 138/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7393 - accuracy: 0.5061 - val_loss: 0.7381 - val_accuracy: 0.5263\n",
      "Epoch 139/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7388 - accuracy: 0.5075 - val_loss: 0.7376 - val_accuracy: 0.5262\n",
      "Epoch 140/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7385 - accuracy: 0.5051 - val_loss: 0.7371 - val_accuracy: 0.5265\n",
      "Epoch 141/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7378 - accuracy: 0.5074 - val_loss: 0.7366 - val_accuracy: 0.5267\n",
      "Epoch 142/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7378 - accuracy: 0.5059 - val_loss: 0.7361 - val_accuracy: 0.5268\n",
      "Epoch 143/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7371 - accuracy: 0.5051 - val_loss: 0.7356 - val_accuracy: 0.5270\n",
      "Epoch 144/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7364 - accuracy: 0.5056 - val_loss: 0.7351 - val_accuracy: 0.5269\n",
      "Epoch 145/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7361 - accuracy: 0.5072 - val_loss: 0.7346 - val_accuracy: 0.5276\n",
      "Epoch 146/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7353 - accuracy: 0.5072 - val_loss: 0.7341 - val_accuracy: 0.5279\n",
      "Epoch 147/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7353 - accuracy: 0.5049 - val_loss: 0.7336 - val_accuracy: 0.5281\n",
      "Epoch 148/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7346 - accuracy: 0.5059 - val_loss: 0.7331 - val_accuracy: 0.5281\n",
      "Epoch 149/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7339 - accuracy: 0.5056 - val_loss: 0.7326 - val_accuracy: 0.5286\n",
      "Epoch 150/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7336 - accuracy: 0.5065 - val_loss: 0.7320 - val_accuracy: 0.5291\n",
      "Epoch 151/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 0.7334 - accuracy: 0.5048 - val_loss: 0.7315 - val_accuracy: 0.5296\n",
      "Epoch 152/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7323 - accuracy: 0.5065 - val_loss: 0.7310 - val_accuracy: 0.5298\n",
      "Epoch 153/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7316 - accuracy: 0.5074 - val_loss: 0.7305 - val_accuracy: 0.5302\n",
      "Epoch 154/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7313 - accuracy: 0.5073 - val_loss: 0.7300 - val_accuracy: 0.5307\n",
      "Epoch 155/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7310 - accuracy: 0.5067 - val_loss: 0.7295 - val_accuracy: 0.5312\n",
      "Epoch 156/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7305 - accuracy: 0.5064 - val_loss: 0.7290 - val_accuracy: 0.5321\n",
      "Epoch 157/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7301 - accuracy: 0.5059 - val_loss: 0.7285 - val_accuracy: 0.5325\n",
      "Epoch 158/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7297 - accuracy: 0.5076 - val_loss: 0.7280 - val_accuracy: 0.5330\n",
      "Epoch 159/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7290 - accuracy: 0.5070 - val_loss: 0.7275 - val_accuracy: 0.5339\n",
      "Epoch 160/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7289 - accuracy: 0.5064 - val_loss: 0.7270 - val_accuracy: 0.5341\n",
      "Epoch 161/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7283 - accuracy: 0.5075 - val_loss: 0.7265 - val_accuracy: 0.5348\n",
      "Epoch 162/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7270 - accuracy: 0.5088 - val_loss: 0.7260 - val_accuracy: 0.5353\n",
      "Epoch 163/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7272 - accuracy: 0.5079 - val_loss: 0.7256 - val_accuracy: 0.5364\n",
      "Epoch 164/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.7264 - accuracy: 0.5088 - val_loss: 0.7251 - val_accuracy: 0.5375\n",
      "Epoch 165/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7266 - accuracy: 0.5077 - val_loss: 0.7247 - val_accuracy: 0.5377\n",
      "Epoch 166/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7257 - accuracy: 0.5085 - val_loss: 0.7242 - val_accuracy: 0.5383\n",
      "Epoch 167/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7255 - accuracy: 0.5083 - val_loss: 0.7238 - val_accuracy: 0.5397\n",
      "Epoch 168/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7254 - accuracy: 0.5082 - val_loss: 0.7234 - val_accuracy: 0.5397\n",
      "Epoch 169/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7244 - accuracy: 0.5091 - val_loss: 0.7229 - val_accuracy: 0.5412\n",
      "Epoch 170/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7242 - accuracy: 0.5086 - val_loss: 0.7225 - val_accuracy: 0.5425\n",
      "Epoch 171/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7237 - accuracy: 0.5082 - val_loss: 0.7221 - val_accuracy: 0.5431\n",
      "Epoch 172/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7240 - accuracy: 0.5069 - val_loss: 0.7217 - val_accuracy: 0.5434\n",
      "Epoch 173/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7235 - accuracy: 0.5080 - val_loss: 0.7213 - val_accuracy: 0.5440\n",
      "Epoch 174/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7223 - accuracy: 0.5106 - val_loss: 0.7208 - val_accuracy: 0.5461\n",
      "Epoch 175/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7227 - accuracy: 0.5073 - val_loss: 0.7204 - val_accuracy: 0.5466\n",
      "Epoch 176/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7223 - accuracy: 0.5074 - val_loss: 0.7200 - val_accuracy: 0.5473\n",
      "Epoch 177/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7212 - accuracy: 0.5092 - val_loss: 0.7196 - val_accuracy: 0.5478\n",
      "Epoch 178/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7211 - accuracy: 0.5099 - val_loss: 0.7193 - val_accuracy: 0.5489\n",
      "Epoch 179/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7208 - accuracy: 0.5097 - val_loss: 0.7189 - val_accuracy: 0.5501\n",
      "Epoch 180/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7204 - accuracy: 0.5101 - val_loss: 0.7186 - val_accuracy: 0.5507\n",
      "Epoch 181/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7206 - accuracy: 0.5072 - val_loss: 0.7183 - val_accuracy: 0.5507\n",
      "Epoch 182/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7199 - accuracy: 0.5089 - val_loss: 0.7180 - val_accuracy: 0.5511\n",
      "Epoch 183/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7198 - accuracy: 0.5085 - val_loss: 0.7177 - val_accuracy: 0.5514\n",
      "Epoch 184/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7195 - accuracy: 0.5089 - val_loss: 0.7175 - val_accuracy: 0.5519\n",
      "Epoch 185/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7196 - accuracy: 0.5074 - val_loss: 0.7172 - val_accuracy: 0.5513\n",
      "Epoch 186/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7190 - accuracy: 0.5086 - val_loss: 0.7170 - val_accuracy: 0.5511\n",
      "Epoch 187/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7187 - accuracy: 0.5082 - val_loss: 0.7168 - val_accuracy: 0.5513\n",
      "Epoch 188/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7185 - accuracy: 0.5082 - val_loss: 0.7166 - val_accuracy: 0.5514\n",
      "Epoch 189/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7183 - accuracy: 0.5082 - val_loss: 0.7163 - val_accuracy: 0.5512\n",
      "Epoch 190/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7183 - accuracy: 0.5067 - val_loss: 0.7162 - val_accuracy: 0.5510\n",
      "Epoch 191/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7179 - accuracy: 0.5072 - val_loss: 0.7159 - val_accuracy: 0.5511\n",
      "Epoch 192/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7173 - accuracy: 0.5093 - val_loss: 0.7157 - val_accuracy: 0.5510\n",
      "Epoch 193/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7174 - accuracy: 0.5076 - val_loss: 0.7155 - val_accuracy: 0.5508\n",
      "Epoch 194/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7169 - accuracy: 0.5092 - val_loss: 0.7152 - val_accuracy: 0.5504\n",
      "Epoch 195/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7171 - accuracy: 0.5070 - val_loss: 0.7150 - val_accuracy: 0.5505\n",
      "Epoch 196/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7163 - accuracy: 0.5087 - val_loss: 0.7148 - val_accuracy: 0.5511\n",
      "Epoch 197/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7161 - accuracy: 0.5079 - val_loss: 0.7145 - val_accuracy: 0.5510\n",
      "Epoch 198/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7163 - accuracy: 0.5067 - val_loss: 0.7143 - val_accuracy: 0.5508\n",
      "Epoch 199/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7158 - accuracy: 0.5079 - val_loss: 0.7141 - val_accuracy: 0.5512\n",
      "Epoch 200/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7154 - accuracy: 0.5096 - val_loss: 0.7138 - val_accuracy: 0.5523\n",
      "Epoch 201/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7150 - accuracy: 0.5098 - val_loss: 0.7135 - val_accuracy: 0.5529\n",
      "Epoch 202/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7150 - accuracy: 0.5089 - val_loss: 0.7133 - val_accuracy: 0.5532\n",
      "Epoch 203/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7148 - accuracy: 0.5089 - val_loss: 0.7130 - val_accuracy: 0.5535\n",
      "Epoch 204/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7146 - accuracy: 0.5074 - val_loss: 0.7128 - val_accuracy: 0.5539\n",
      "Epoch 205/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7142 - accuracy: 0.5100 - val_loss: 0.7126 - val_accuracy: 0.5547\n",
      "Epoch 206/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7143 - accuracy: 0.5072 - val_loss: 0.7124 - val_accuracy: 0.5542\n",
      "Epoch 207/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7135 - accuracy: 0.5090 - val_loss: 0.7121 - val_accuracy: 0.5541\n",
      "Epoch 208/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7136 - accuracy: 0.5083 - val_loss: 0.7119 - val_accuracy: 0.5548\n",
      "Epoch 209/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7136 - accuracy: 0.5073 - val_loss: 0.7116 - val_accuracy: 0.5554\n",
      "Epoch 210/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7134 - accuracy: 0.5068 - val_loss: 0.7114 - val_accuracy: 0.5556\n",
      "Epoch 211/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7129 - accuracy: 0.5084 - val_loss: 0.7112 - val_accuracy: 0.5560\n",
      "Epoch 212/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7120 - accuracy: 0.5118 - val_loss: 0.7109 - val_accuracy: 0.5568\n",
      "Epoch 213/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7124 - accuracy: 0.5098 - val_loss: 0.7106 - val_accuracy: 0.5575\n",
      "Epoch 214/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7120 - accuracy: 0.5087 - val_loss: 0.7104 - val_accuracy: 0.5586\n",
      "Epoch 215/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7120 - accuracy: 0.5093 - val_loss: 0.7101 - val_accuracy: 0.5600\n",
      "Epoch 216/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7115 - accuracy: 0.5104 - val_loss: 0.7098 - val_accuracy: 0.5608\n",
      "Epoch 217/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7116 - accuracy: 0.5094 - val_loss: 0.7096 - val_accuracy: 0.5611\n",
      "Epoch 218/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7110 - accuracy: 0.5096 - val_loss: 0.7094 - val_accuracy: 0.5614\n",
      "Epoch 219/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7112 - accuracy: 0.5090 - val_loss: 0.7092 - val_accuracy: 0.5608\n",
      "Epoch 220/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7109 - accuracy: 0.5103 - val_loss: 0.7090 - val_accuracy: 0.5610\n",
      "Epoch 221/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7105 - accuracy: 0.5096 - val_loss: 0.7088 - val_accuracy: 0.5615\n",
      "Epoch 222/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7109 - accuracy: 0.5085 - val_loss: 0.7087 - val_accuracy: 0.5613\n",
      "Epoch 223/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7105 - accuracy: 0.5100 - val_loss: 0.7085 - val_accuracy: 0.5623\n",
      "Epoch 224/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7105 - accuracy: 0.5091 - val_loss: 0.7083 - val_accuracy: 0.5615\n",
      "Epoch 225/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7102 - accuracy: 0.5084 - val_loss: 0.7082 - val_accuracy: 0.5615\n",
      "Epoch 226/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7098 - accuracy: 0.5117 - val_loss: 0.7079 - val_accuracy: 0.5612\n",
      "Epoch 227/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7095 - accuracy: 0.5113 - val_loss: 0.7078 - val_accuracy: 0.5615\n",
      "Epoch 228/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7098 - accuracy: 0.5095 - val_loss: 0.7076 - val_accuracy: 0.5618\n",
      "Epoch 229/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7090 - accuracy: 0.5121 - val_loss: 0.7074 - val_accuracy: 0.5625\n",
      "Epoch 230/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7094 - accuracy: 0.5092 - val_loss: 0.7073 - val_accuracy: 0.5622\n",
      "Epoch 231/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7089 - accuracy: 0.5108 - val_loss: 0.7071 - val_accuracy: 0.5623\n",
      "Epoch 232/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7090 - accuracy: 0.5102 - val_loss: 0.7070 - val_accuracy: 0.5624\n",
      "Epoch 233/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7084 - accuracy: 0.5125 - val_loss: 0.7069 - val_accuracy: 0.5627\n",
      "Epoch 234/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7083 - accuracy: 0.5110 - val_loss: 0.7067 - val_accuracy: 0.5628\n",
      "Epoch 235/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7085 - accuracy: 0.5097 - val_loss: 0.7066 - val_accuracy: 0.5630\n",
      "Epoch 236/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7081 - accuracy: 0.5106 - val_loss: 0.7065 - val_accuracy: 0.5630\n",
      "Epoch 237/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7082 - accuracy: 0.5086 - val_loss: 0.7064 - val_accuracy: 0.5625\n",
      "Epoch 238/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7079 - accuracy: 0.5110 - val_loss: 0.7062 - val_accuracy: 0.5633\n",
      "Epoch 239/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7081 - accuracy: 0.5086 - val_loss: 0.7061 - val_accuracy: 0.5631\n",
      "Epoch 240/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7075 - accuracy: 0.5130 - val_loss: 0.7060 - val_accuracy: 0.5636\n",
      "Epoch 241/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7073 - accuracy: 0.5123 - val_loss: 0.7059 - val_accuracy: 0.5635\n",
      "Epoch 242/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7077 - accuracy: 0.5111 - val_loss: 0.7057 - val_accuracy: 0.5638\n",
      "Epoch 243/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7071 - accuracy: 0.5130 - val_loss: 0.7056 - val_accuracy: 0.5641\n",
      "Epoch 244/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7074 - accuracy: 0.5093 - val_loss: 0.7055 - val_accuracy: 0.5640\n",
      "Epoch 245/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7073 - accuracy: 0.5107 - val_loss: 0.7054 - val_accuracy: 0.5641\n",
      "Epoch 246/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7068 - accuracy: 0.5104 - val_loss: 0.7053 - val_accuracy: 0.5637\n",
      "Epoch 247/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7072 - accuracy: 0.5103 - val_loss: 0.7052 - val_accuracy: 0.5641\n",
      "Epoch 248/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7066 - accuracy: 0.5120 - val_loss: 0.7051 - val_accuracy: 0.5647\n",
      "Epoch 249/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7064 - accuracy: 0.5132 - val_loss: 0.7050 - val_accuracy: 0.5654\n",
      "Epoch 250/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7067 - accuracy: 0.5108 - val_loss: 0.7048 - val_accuracy: 0.5669\n",
      "Epoch 251/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7065 - accuracy: 0.5124 - val_loss: 0.7047 - val_accuracy: 0.5673\n",
      "Epoch 252/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7064 - accuracy: 0.5112 - val_loss: 0.7046 - val_accuracy: 0.5677\n",
      "Epoch 253/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7063 - accuracy: 0.5114 - val_loss: 0.7045 - val_accuracy: 0.5682\n",
      "Epoch 254/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7059 - accuracy: 0.5133 - val_loss: 0.7044 - val_accuracy: 0.5682\n",
      "Epoch 255/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7060 - accuracy: 0.5109 - val_loss: 0.7043 - val_accuracy: 0.5680\n",
      "Epoch 256/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7058 - accuracy: 0.5127 - val_loss: 0.7043 - val_accuracy: 0.5682\n",
      "Epoch 257/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7058 - accuracy: 0.5121 - val_loss: 0.7042 - val_accuracy: 0.5679\n",
      "Epoch 258/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7062 - accuracy: 0.5088 - val_loss: 0.7042 - val_accuracy: 0.5671\n",
      "Epoch 259/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.7057 - accuracy: 0.5117 - val_loss: 0.7041 - val_accuracy: 0.5672\n",
      "Epoch 260/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7051 - accuracy: 0.5143 - val_loss: 0.7040 - val_accuracy: 0.5678\n",
      "Epoch 261/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7048 - accuracy: 0.5158 - val_loss: 0.7039 - val_accuracy: 0.5682\n",
      "Epoch 262/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7051 - accuracy: 0.5149 - val_loss: 0.7038 - val_accuracy: 0.5684\n",
      "Epoch 263/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7052 - accuracy: 0.5141 - val_loss: 0.7037 - val_accuracy: 0.5687\n",
      "Epoch 264/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7051 - accuracy: 0.5142 - val_loss: 0.7036 - val_accuracy: 0.5688\n",
      "Epoch 265/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7050 - accuracy: 0.5133 - val_loss: 0.7035 - val_accuracy: 0.5689\n",
      "Epoch 266/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7049 - accuracy: 0.5123 - val_loss: 0.7035 - val_accuracy: 0.5694\n",
      "Epoch 267/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7046 - accuracy: 0.5136 - val_loss: 0.7034 - val_accuracy: 0.5693\n",
      "Epoch 268/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7046 - accuracy: 0.5150 - val_loss: 0.7033 - val_accuracy: 0.5694\n",
      "Epoch 269/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7046 - accuracy: 0.5148 - val_loss: 0.7032 - val_accuracy: 0.5700\n",
      "Epoch 270/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7043 - accuracy: 0.5153 - val_loss: 0.7031 - val_accuracy: 0.5708\n",
      "Epoch 271/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7046 - accuracy: 0.5144 - val_loss: 0.7030 - val_accuracy: 0.5712\n",
      "Epoch 272/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7049 - accuracy: 0.5121 - val_loss: 0.7030 - val_accuracy: 0.5711\n",
      "Epoch 273/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7045 - accuracy: 0.5104 - val_loss: 0.7029 - val_accuracy: 0.5706\n",
      "Epoch 274/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7038 - accuracy: 0.5158 - val_loss: 0.7028 - val_accuracy: 0.5715\n",
      "Epoch 275/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7041 - accuracy: 0.5143 - val_loss: 0.7027 - val_accuracy: 0.5716\n",
      "Epoch 276/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7039 - accuracy: 0.5149 - val_loss: 0.7027 - val_accuracy: 0.5717\n",
      "Epoch 277/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7042 - accuracy: 0.5119 - val_loss: 0.7026 - val_accuracy: 0.5726\n",
      "Epoch 278/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7037 - accuracy: 0.5145 - val_loss: 0.7025 - val_accuracy: 0.5734\n",
      "Epoch 279/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7037 - accuracy: 0.5136 - val_loss: 0.7024 - val_accuracy: 0.5735\n",
      "Epoch 280/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7037 - accuracy: 0.5154 - val_loss: 0.7023 - val_accuracy: 0.5748\n",
      "Epoch 281/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7036 - accuracy: 0.5145 - val_loss: 0.7022 - val_accuracy: 0.5748\n",
      "Epoch 282/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7034 - accuracy: 0.5144 - val_loss: 0.7022 - val_accuracy: 0.5752\n",
      "Epoch 283/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7035 - accuracy: 0.5146 - val_loss: 0.7021 - val_accuracy: 0.5768\n",
      "Epoch 284/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7034 - accuracy: 0.5157 - val_loss: 0.7020 - val_accuracy: 0.5770\n",
      "Epoch 285/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7033 - accuracy: 0.5154 - val_loss: 0.7019 - val_accuracy: 0.5778\n",
      "Epoch 286/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7029 - accuracy: 0.5170 - val_loss: 0.7018 - val_accuracy: 0.5777\n",
      "Epoch 287/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7029 - accuracy: 0.5162 - val_loss: 0.7017 - val_accuracy: 0.5789\n",
      "Epoch 288/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7032 - accuracy: 0.5136 - val_loss: 0.7017 - val_accuracy: 0.5788\n",
      "Epoch 289/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7029 - accuracy: 0.5163 - val_loss: 0.7016 - val_accuracy: 0.5793\n",
      "Epoch 290/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7027 - accuracy: 0.5171 - val_loss: 0.7015 - val_accuracy: 0.5795\n",
      "Epoch 291/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7024 - accuracy: 0.5181 - val_loss: 0.7014 - val_accuracy: 0.5800\n",
      "Epoch 292/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7027 - accuracy: 0.5181 - val_loss: 0.7013 - val_accuracy: 0.5809\n",
      "Epoch 293/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7026 - accuracy: 0.5161 - val_loss: 0.7012 - val_accuracy: 0.5818\n",
      "Epoch 294/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7027 - accuracy: 0.5145 - val_loss: 0.7012 - val_accuracy: 0.5825\n",
      "Epoch 295/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7024 - accuracy: 0.5181 - val_loss: 0.7011 - val_accuracy: 0.5831\n",
      "Epoch 296/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7026 - accuracy: 0.5157 - val_loss: 0.7010 - val_accuracy: 0.5841\n",
      "Epoch 297/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7025 - accuracy: 0.5141 - val_loss: 0.7009 - val_accuracy: 0.5843\n",
      "Epoch 298/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7023 - accuracy: 0.5167 - val_loss: 0.7008 - val_accuracy: 0.5856\n",
      "Epoch 299/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7020 - accuracy: 0.5200 - val_loss: 0.7007 - val_accuracy: 0.5851\n",
      "Epoch 300/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7020 - accuracy: 0.5181 - val_loss: 0.7006 - val_accuracy: 0.5866\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.7006 - accuracy: 0.5866\n",
      "{'loss': 0.7006456851959229, 'accuracy': 0.5866485238075256} \n",
      " 299 \n",
      "\n",
      "Model time: 8.540310624986887 minutes\n",
      "\n",
      "Total time: 169.60040092468262 minutes\n",
      "\n",
      "\n",
      "Model  96  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                   256\n",
      "Activation function           tanh\n",
      "Dropout                        0.0\n",
      "L1                         0.00001\n",
      "L2                             0.1\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 1247830, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 7s 7ms/step - loss: 0.9330 - accuracy: 0.5151 - val_loss: 2.5163 - val_accuracy: 0.5067\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 5s 8ms/step - loss: 0.8703 - accuracy: 0.5191 - val_loss: 0.7958 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "668/670 [============================>.] - ETA: 0s - loss: 0.8712 - accuracy: 0.5155Restoring model weights from the end of the best epoch: 2.\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.8714 - accuracy: 0.5155 - val_loss: 0.9445 - val_accuracy: 0.5099\n",
      "Epoch 3: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.7958 - accuracy: 0.5001\n",
      "{'loss': 0.7957994937896729, 'accuracy': 0.5001260638237} \n",
      " 2 \n",
      "\n",
      "Model time: 0.31158557161688805 minutes\n",
      "\n",
      "Total time: 169.91206981614232 minutes\n",
      "\n",
      "\n",
      "Model  97  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                    32\n",
      "Activation function           tanh\n",
      "Dropout                        0.1\n",
      "L1                             1.0\n",
      "L2                           100.0\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 3582221, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 8s 9ms/step - loss: 10563.5381 - accuracy: 0.5217 - val_loss: 8304.0479 - val_accuracy: 0.5289\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6544.6294 - accuracy: 0.5172 - val_loss: 4986.7510 - val_accuracy: 0.5087\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3823.9382 - accuracy: 0.5091 - val_loss: 2819.6313 - val_accuracy: 0.4811\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2111.9609 - accuracy: 0.4881 - val_loss: 1519.2479 - val_accuracy: 0.4630\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1123.6827 - accuracy: 0.4845 - val_loss: 798.0300 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 576.2270 - accuracy: 0.4963 - val_loss: 386.9687 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 258.0514 - accuracy: 0.4916 - val_loss: 153.0247 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 90.5124 - accuracy: 0.5009 - val_loss: 44.5897 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 24.4043 - accuracy: 0.4953 - val_loss: 12.4743 - val_accuracy: 0.4999\n",
      "Epoch 10/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 8.5976 - accuracy: 0.4962 - val_loss: 5.5707 - val_accuracy: 0.4999\n",
      "Epoch 11/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3.6421 - accuracy: 0.4982 - val_loss: 2.1661 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.5110 - accuracy: 0.4965 - val_loss: 1.1485 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.0895 - accuracy: 0.4968 - val_loss: 1.0775 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "323/335 [===========================>..] - ETA: 0s - loss: 1.0775 - accuracy: 0.4978Restoring model weights from the end of the best epoch: 13.\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.0775 - accuracy: 0.4979 - val_loss: 1.0775 - val_accuracy: 0.5001\n",
      "Epoch 14: early stopping\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 1.0775 - accuracy: 0.5001\n",
      "{'loss': 1.077457070350647, 'accuracy': 0.5001260638237} \n",
      " 13 \n",
      "\n",
      "Model time: 0.78752226755023 minutes\n",
      "\n",
      "Total time: 170.6996753923595 minutes\n",
      "\n",
      "\n",
      "Model  98  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                    64\n",
      "Activation function         linear\n",
      "Dropout                        0.9\n",
      "L1                           0.001\n",
      "L2                            10.0\n",
      "Batch size                     256\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 2448280, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 3s 19ms/step - loss: 1620.1327 - accuracy: 0.5017 - val_loss: 1604.7555 - val_accuracy: 0.5005\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1597.6368 - accuracy: 0.5037 - val_loss: 1582.5425 - val_accuracy: 0.5004\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1575.4911 - accuracy: 0.5032 - val_loss: 1560.6294 - val_accuracy: 0.5005\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1553.6519 - accuracy: 0.5038 - val_loss: 1539.0101 - val_accuracy: 0.5010\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1532.1709 - accuracy: 0.5011 - val_loss: 1517.6766 - val_accuracy: 0.5014\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1510.8815 - accuracy: 0.5045 - val_loss: 1496.6223 - val_accuracy: 0.5015\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1489.8024 - accuracy: 0.5013 - val_loss: 1475.8417 - val_accuracy: 0.5017\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1469.0028 - accuracy: 0.5037 - val_loss: 1455.3287 - val_accuracy: 0.5013\n",
      "Epoch 9/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1448.6493 - accuracy: 0.5067 - val_loss: 1435.0758 - val_accuracy: 0.5011\n",
      "Epoch 10/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1428.4412 - accuracy: 0.5036 - val_loss: 1415.0776 - val_accuracy: 0.5013\n",
      "Epoch 11/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1408.4781 - accuracy: 0.5008 - val_loss: 1395.3293 - val_accuracy: 0.5015\n",
      "Epoch 12/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1388.8635 - accuracy: 0.5045 - val_loss: 1375.8243 - val_accuracy: 0.5015\n",
      "Epoch 13/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1369.4540 - accuracy: 0.5011 - val_loss: 1356.5593 - val_accuracy: 0.5019\n",
      "Epoch 14/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1350.2528 - accuracy: 0.4957 - val_loss: 1337.5300 - val_accuracy: 0.5017\n",
      "Epoch 15/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1331.1995 - accuracy: 0.5041 - val_loss: 1318.7322 - val_accuracy: 0.5018\n",
      "Epoch 16/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1312.4319 - accuracy: 0.5024 - val_loss: 1300.1594 - val_accuracy: 0.5019\n",
      "Epoch 17/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1293.9147 - accuracy: 0.5027 - val_loss: 1281.8096 - val_accuracy: 0.5020\n",
      "Epoch 18/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1275.6184 - accuracy: 0.4940 - val_loss: 1263.6775 - val_accuracy: 0.5020\n",
      "Epoch 19/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1257.4575 - accuracy: 0.5089 - val_loss: 1245.7615 - val_accuracy: 0.5020\n",
      "Epoch 20/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1239.6305 - accuracy: 0.5032 - val_loss: 1228.0557 - val_accuracy: 0.5024\n",
      "Epoch 21/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1221.9172 - accuracy: 0.5061 - val_loss: 1210.5581 - val_accuracy: 0.5030\n",
      "Epoch 22/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1204.4413 - accuracy: 0.5015 - val_loss: 1193.2650 - val_accuracy: 0.5027\n",
      "Epoch 23/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1187.2810 - accuracy: 0.5041 - val_loss: 1176.1699 - val_accuracy: 0.5023\n",
      "Epoch 24/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1170.2147 - accuracy: 0.4963 - val_loss: 1159.2737 - val_accuracy: 0.5022\n",
      "Epoch 25/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1153.3712 - accuracy: 0.4976 - val_loss: 1142.5712 - val_accuracy: 0.5021\n",
      "Epoch 26/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1136.7758 - accuracy: 0.4988 - val_loss: 1126.0602 - val_accuracy: 0.5019\n",
      "Epoch 27/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1120.2283 - accuracy: 0.5008 - val_loss: 1109.7391 - val_accuracy: 0.5015\n",
      "Epoch 28/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1103.9978 - accuracy: 0.5003 - val_loss: 1093.6034 - val_accuracy: 0.5022\n",
      "Epoch 29/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1087.9906 - accuracy: 0.4987 - val_loss: 1077.6500 - val_accuracy: 0.5020\n",
      "Epoch 30/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1072.0419 - accuracy: 0.4979 - val_loss: 1061.8794 - val_accuracy: 0.5020\n",
      "Epoch 31/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1056.2488 - accuracy: 0.5003 - val_loss: 1046.2883 - val_accuracy: 0.5017\n",
      "Epoch 32/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1040.5920 - accuracy: 0.5041 - val_loss: 1030.8752 - val_accuracy: 0.5016\n",
      "Epoch 33/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1025.2332 - accuracy: 0.5034 - val_loss: 1015.6370 - val_accuracy: 0.5016\n",
      "Epoch 34/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 1010.1273 - accuracy: 0.5055 - val_loss: 1000.5690 - val_accuracy: 0.5013\n",
      "Epoch 35/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 995.0231 - accuracy: 0.5029 - val_loss: 985.6721 - val_accuracy: 0.5012\n",
      "Epoch 36/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 980.2070 - accuracy: 0.5023 - val_loss: 970.9427 - val_accuracy: 0.5010\n",
      "Epoch 37/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 965.5298 - accuracy: 0.5050 - val_loss: 956.3799 - val_accuracy: 0.5007\n",
      "Epoch 38/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 951.0333 - accuracy: 0.4972 - val_loss: 941.9811 - val_accuracy: 0.5014\n",
      "Epoch 39/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 936.6320 - accuracy: 0.5044 - val_loss: 927.7450 - val_accuracy: 0.5015\n",
      "Epoch 40/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 922.4944 - accuracy: 0.4968 - val_loss: 913.6700 - val_accuracy: 0.5017\n",
      "Epoch 41/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 908.3613 - accuracy: 0.5011 - val_loss: 899.7545 - val_accuracy: 0.5013\n",
      "Epoch 42/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 894.5654 - accuracy: 0.4977 - val_loss: 885.9958 - val_accuracy: 0.5021\n",
      "Epoch 43/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 880.8073 - accuracy: 0.4974 - val_loss: 872.3940 - val_accuracy: 0.5024\n",
      "Epoch 44/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 867.2258 - accuracy: 0.5069 - val_loss: 858.9466 - val_accuracy: 0.5028\n",
      "Epoch 45/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 853.8333 - accuracy: 0.5035 - val_loss: 845.6516 - val_accuracy: 0.5032\n",
      "Epoch 46/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 840.5933 - accuracy: 0.5046 - val_loss: 832.5083 - val_accuracy: 0.5026\n",
      "Epoch 47/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 827.4335 - accuracy: 0.5080 - val_loss: 819.5156 - val_accuracy: 0.5032\n",
      "Epoch 48/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 814.5062 - accuracy: 0.5030 - val_loss: 806.6714 - val_accuracy: 0.5035\n",
      "Epoch 49/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 801.6921 - accuracy: 0.5049 - val_loss: 793.9747 - val_accuracy: 0.5035\n",
      "Epoch 50/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 789.0865 - accuracy: 0.5029 - val_loss: 781.4236 - val_accuracy: 0.5036\n",
      "Epoch 51/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 776.5658 - accuracy: 0.5021 - val_loss: 769.0171 - val_accuracy: 0.5041\n",
      "Epoch 52/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 764.2104 - accuracy: 0.4942 - val_loss: 756.7545 - val_accuracy: 0.5042\n",
      "Epoch 53/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 751.9894 - accuracy: 0.4996 - val_loss: 744.6342 - val_accuracy: 0.5039\n",
      "Epoch 54/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 739.8753 - accuracy: 0.4984 - val_loss: 732.6551 - val_accuracy: 0.5045\n",
      "Epoch 55/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 727.9173 - accuracy: 0.5029 - val_loss: 720.8167 - val_accuracy: 0.5043\n",
      "Epoch 56/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 716.1489 - accuracy: 0.5046 - val_loss: 709.1164 - val_accuracy: 0.5046\n",
      "Epoch 57/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 704.4724 - accuracy: 0.5029 - val_loss: 697.5540 - val_accuracy: 0.5046\n",
      "Epoch 58/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 692.9765 - accuracy: 0.5027 - val_loss: 686.1284 - val_accuracy: 0.5048\n",
      "Epoch 59/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 681.5333 - accuracy: 0.5070 - val_loss: 674.8389 - val_accuracy: 0.5053\n",
      "Epoch 60/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 670.3484 - accuracy: 0.4982 - val_loss: 663.6830 - val_accuracy: 0.5056\n",
      "Epoch 61/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 659.1808 - accuracy: 0.5037 - val_loss: 652.6613 - val_accuracy: 0.5052\n",
      "Epoch 62/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 648.1777 - accuracy: 0.5117 - val_loss: 641.7721 - val_accuracy: 0.5055\n",
      "Epoch 63/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 637.3508 - accuracy: 0.5019 - val_loss: 631.0142 - val_accuracy: 0.5061\n",
      "Epoch 64/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 626.6257 - accuracy: 0.5058 - val_loss: 620.3867 - val_accuracy: 0.5062\n",
      "Epoch 65/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 616.0624 - accuracy: 0.5050 - val_loss: 609.8881 - val_accuracy: 0.5064\n",
      "Epoch 66/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 605.5961 - accuracy: 0.5005 - val_loss: 599.5181 - val_accuracy: 0.5064\n",
      "Epoch 67/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 595.3001 - accuracy: 0.4971 - val_loss: 589.2748 - val_accuracy: 0.5064\n",
      "Epoch 68/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 585.0678 - accuracy: 0.4978 - val_loss: 579.1586 - val_accuracy: 0.5066\n",
      "Epoch 69/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 574.9985 - accuracy: 0.4994 - val_loss: 569.1674 - val_accuracy: 0.5074\n",
      "Epoch 70/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 565.0417 - accuracy: 0.5002 - val_loss: 559.3020 - val_accuracy: 0.5076\n",
      "Epoch 71/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 555.2163 - accuracy: 0.5017 - val_loss: 549.5591 - val_accuracy: 0.5071\n",
      "Epoch 72/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 545.5112 - accuracy: 0.5048 - val_loss: 539.9395 - val_accuracy: 0.5073\n",
      "Epoch 73/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 535.9066 - accuracy: 0.5091 - val_loss: 530.4424 - val_accuracy: 0.5076\n",
      "Epoch 74/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 526.4596 - accuracy: 0.5069 - val_loss: 521.0655 - val_accuracy: 0.5075\n",
      "Epoch 75/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 517.1225 - accuracy: 0.4982 - val_loss: 511.8089 - val_accuracy: 0.5075\n",
      "Epoch 76/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 507.9010 - accuracy: 0.5015 - val_loss: 502.6712 - val_accuracy: 0.5073\n",
      "Epoch 77/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 498.8150 - accuracy: 0.5016 - val_loss: 493.6514 - val_accuracy: 0.5076\n",
      "Epoch 78/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 489.8304 - accuracy: 0.5001 - val_loss: 484.7492 - val_accuracy: 0.5076\n",
      "Epoch 79/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 480.9641 - accuracy: 0.5017 - val_loss: 475.9637 - val_accuracy: 0.5079\n",
      "Epoch 80/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 472.1974 - accuracy: 0.5030 - val_loss: 467.2939 - val_accuracy: 0.5081\n",
      "Epoch 81/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 463.5730 - accuracy: 0.5023 - val_loss: 458.7388 - val_accuracy: 0.5082\n",
      "Epoch 82/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 455.0760 - accuracy: 0.5038 - val_loss: 450.2970 - val_accuracy: 0.5081\n",
      "Epoch 83/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 446.6858 - accuracy: 0.5013 - val_loss: 441.9679 - val_accuracy: 0.5083\n",
      "Epoch 84/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 438.3799 - accuracy: 0.5016 - val_loss: 433.7512 - val_accuracy: 0.5085\n",
      "Epoch 85/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 430.2087 - accuracy: 0.5053 - val_loss: 425.6455 - val_accuracy: 0.5083\n",
      "Epoch 86/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 422.1100 - accuracy: 0.5068 - val_loss: 417.6508 - val_accuracy: 0.5085\n",
      "Epoch 87/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 414.1594 - accuracy: 0.5009 - val_loss: 409.7657 - val_accuracy: 0.5088\n",
      "Epoch 88/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 406.3452 - accuracy: 0.5035 - val_loss: 401.9883 - val_accuracy: 0.5094\n",
      "Epoch 89/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 398.5866 - accuracy: 0.5031 - val_loss: 394.3193 - val_accuracy: 0.5097\n",
      "Epoch 90/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 390.9666 - accuracy: 0.5037 - val_loss: 386.7568 - val_accuracy: 0.5097\n",
      "Epoch 91/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 383.4457 - accuracy: 0.5056 - val_loss: 379.3004 - val_accuracy: 0.5099\n",
      "Epoch 92/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 376.0104 - accuracy: 0.5010 - val_loss: 371.9496 - val_accuracy: 0.5103\n",
      "Epoch 93/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 368.7009 - accuracy: 0.5046 - val_loss: 364.7030 - val_accuracy: 0.5106\n",
      "Epoch 94/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 361.4976 - accuracy: 0.5063 - val_loss: 357.5599 - val_accuracy: 0.5116\n",
      "Epoch 95/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 354.3780 - accuracy: 0.5111 - val_loss: 350.5198 - val_accuracy: 0.5120\n",
      "Epoch 96/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 347.3912 - accuracy: 0.5020 - val_loss: 343.5816 - val_accuracy: 0.5124\n",
      "Epoch 97/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 340.4775 - accuracy: 0.5069 - val_loss: 336.7444 - val_accuracy: 0.5132\n",
      "Epoch 98/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 333.6949 - accuracy: 0.5055 - val_loss: 330.0073 - val_accuracy: 0.5134\n",
      "Epoch 99/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 327.0041 - accuracy: 0.4995 - val_loss: 323.3690 - val_accuracy: 0.5135\n",
      "Epoch 100/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 320.3928 - accuracy: 0.5057 - val_loss: 316.8297 - val_accuracy: 0.5134\n",
      "Epoch 101/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 313.9051 - accuracy: 0.4965 - val_loss: 310.3878 - val_accuracy: 0.5135\n",
      "Epoch 102/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 307.4978 - accuracy: 0.5071 - val_loss: 304.0429 - val_accuracy: 0.5136\n",
      "Epoch 103/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 301.1763 - accuracy: 0.5067 - val_loss: 297.7945 - val_accuracy: 0.5138\n",
      "Epoch 104/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 294.9683 - accuracy: 0.5027 - val_loss: 291.6414 - val_accuracy: 0.5138\n",
      "Epoch 105/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 288.8566 - accuracy: 0.5026 - val_loss: 285.5824 - val_accuracy: 0.5139\n",
      "Epoch 106/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 282.8349 - accuracy: 0.5068 - val_loss: 279.6171 - val_accuracy: 0.5145\n",
      "Epoch 107/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 276.9033 - accuracy: 0.5029 - val_loss: 273.7446 - val_accuracy: 0.5146\n",
      "Epoch 108/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 271.0763 - accuracy: 0.5051 - val_loss: 267.9640 - val_accuracy: 0.5157\n",
      "Epoch 109/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 265.3322 - accuracy: 0.4993 - val_loss: 262.2744 - val_accuracy: 0.5155\n",
      "Epoch 110/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 259.6720 - accuracy: 0.5037 - val_loss: 256.6753 - val_accuracy: 0.5162\n",
      "Epoch 111/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 254.1164 - accuracy: 0.5015 - val_loss: 251.1656 - val_accuracy: 0.5168\n",
      "Epoch 112/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 248.6461 - accuracy: 0.5048 - val_loss: 245.7447 - val_accuracy: 0.5174\n",
      "Epoch 113/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 243.2504 - accuracy: 0.5020 - val_loss: 240.4117 - val_accuracy: 0.5181\n",
      "Epoch 114/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 237.9653 - accuracy: 0.5022 - val_loss: 235.1656 - val_accuracy: 0.5178\n",
      "Epoch 115/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 232.7516 - accuracy: 0.4970 - val_loss: 230.0058 - val_accuracy: 0.5180\n",
      "Epoch 116/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 227.6242 - accuracy: 0.5000 - val_loss: 224.9317 - val_accuracy: 0.5181\n",
      "Epoch 117/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 222.5927 - accuracy: 0.4991 - val_loss: 219.9419 - val_accuracy: 0.5179\n",
      "Epoch 118/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 217.6292 - accuracy: 0.5067 - val_loss: 215.0360 - val_accuracy: 0.5182\n",
      "Epoch 119/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 212.7628 - accuracy: 0.5036 - val_loss: 210.2131 - val_accuracy: 0.5189\n",
      "Epoch 120/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 207.9724 - accuracy: 0.5053 - val_loss: 205.4725 - val_accuracy: 0.5192\n",
      "Epoch 121/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 203.2684 - accuracy: 0.5025 - val_loss: 200.8131 - val_accuracy: 0.5192\n",
      "Epoch 122/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 198.6437 - accuracy: 0.5053 - val_loss: 196.2342 - val_accuracy: 0.5191\n",
      "Epoch 123/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 194.1078 - accuracy: 0.5013 - val_loss: 191.7350 - val_accuracy: 0.5187\n",
      "Epoch 124/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 189.6317 - accuracy: 0.5078 - val_loss: 187.3148 - val_accuracy: 0.5189\n",
      "Epoch 125/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 185.2565 - accuracy: 0.5018 - val_loss: 182.9726 - val_accuracy: 0.5195\n",
      "Epoch 126/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 180.9403 - accuracy: 0.5040 - val_loss: 178.7077 - val_accuracy: 0.5195\n",
      "Epoch 127/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 176.7118 - accuracy: 0.4975 - val_loss: 174.5193 - val_accuracy: 0.5196\n",
      "Epoch 128/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 172.5583 - accuracy: 0.5068 - val_loss: 170.4066 - val_accuracy: 0.5202\n",
      "Epoch 129/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 168.4783 - accuracy: 0.5039 - val_loss: 166.3687 - val_accuracy: 0.5205\n",
      "Epoch 130/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 164.4698 - accuracy: 0.5075 - val_loss: 162.4049 - val_accuracy: 0.5208\n",
      "Epoch 131/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 160.5431 - accuracy: 0.5020 - val_loss: 158.5142 - val_accuracy: 0.5217\n",
      "Epoch 132/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 156.6811 - accuracy: 0.5044 - val_loss: 154.6962 - val_accuracy: 0.5217\n",
      "Epoch 133/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 152.8947 - accuracy: 0.5081 - val_loss: 150.9496 - val_accuracy: 0.5223\n",
      "Epoch 134/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 149.1844 - accuracy: 0.5078 - val_loss: 147.2738 - val_accuracy: 0.5226\n",
      "Epoch 135/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 145.5415 - accuracy: 0.5008 - val_loss: 143.6680 - val_accuracy: 0.5234\n",
      "Epoch 136/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 141.9630 - accuracy: 0.5048 - val_loss: 140.1314 - val_accuracy: 0.5243\n",
      "Epoch 137/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 138.4567 - accuracy: 0.5113 - val_loss: 136.6633 - val_accuracy: 0.5239\n",
      "Epoch 138/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 135.0211 - accuracy: 0.5049 - val_loss: 133.2627 - val_accuracy: 0.5246\n",
      "Epoch 139/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 131.6488 - accuracy: 0.5069 - val_loss: 129.9290 - val_accuracy: 0.5248\n",
      "Epoch 140/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 128.3450 - accuracy: 0.5054 - val_loss: 126.6612 - val_accuracy: 0.5251\n",
      "Epoch 141/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 125.1127 - accuracy: 0.5039 - val_loss: 123.4584 - val_accuracy: 0.5258\n",
      "Epoch 142/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 121.9354 - accuracy: 0.5090 - val_loss: 120.3201 - val_accuracy: 0.5256\n",
      "Epoch 143/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 118.8290 - accuracy: 0.5091 - val_loss: 117.2453 - val_accuracy: 0.5262\n",
      "Epoch 144/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 115.7833 - accuracy: 0.5028 - val_loss: 114.2332 - val_accuracy: 0.5255\n",
      "Epoch 145/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 112.8023 - accuracy: 0.5028 - val_loss: 111.2830 - val_accuracy: 0.5253\n",
      "Epoch 146/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 109.8773 - accuracy: 0.5065 - val_loss: 108.3941 - val_accuracy: 0.5255\n",
      "Epoch 147/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 107.0164 - accuracy: 0.5088 - val_loss: 105.5654 - val_accuracy: 0.5260\n",
      "Epoch 148/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 104.2154 - accuracy: 0.5078 - val_loss: 102.7964 - val_accuracy: 0.5260\n",
      "Epoch 149/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 101.4745 - accuracy: 0.5039 - val_loss: 100.0861 - val_accuracy: 0.5257\n",
      "Epoch 150/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 98.7950 - accuracy: 0.4970 - val_loss: 97.4336 - val_accuracy: 0.5261\n",
      "Epoch 151/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 96.1662 - accuracy: 0.5078 - val_loss: 94.8384 - val_accuracy: 0.5262\n",
      "Epoch 152/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 93.5988 - accuracy: 0.5008 - val_loss: 92.2995 - val_accuracy: 0.5261\n",
      "Epoch 153/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 91.0866 - accuracy: 0.5021 - val_loss: 89.8162 - val_accuracy: 0.5265\n",
      "Epoch 154/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 88.6308 - accuracy: 0.5049 - val_loss: 87.3876 - val_accuracy: 0.5264\n",
      "Epoch 155/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 86.2259 - accuracy: 0.4977 - val_loss: 85.0130 - val_accuracy: 0.5270\n",
      "Epoch 156/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 83.8791 - accuracy: 0.5056 - val_loss: 82.6916 - val_accuracy: 0.5275\n",
      "Epoch 157/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 81.5818 - accuracy: 0.4988 - val_loss: 80.4226 - val_accuracy: 0.5279\n",
      "Epoch 158/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 79.3371 - accuracy: 0.5020 - val_loss: 78.2053 - val_accuracy: 0.5284\n",
      "Epoch 159/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 77.1430 - accuracy: 0.5032 - val_loss: 76.0388 - val_accuracy: 0.5276\n",
      "Epoch 160/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 75.0028 - accuracy: 0.5008 - val_loss: 73.9223 - val_accuracy: 0.5278\n",
      "Epoch 161/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 72.9074 - accuracy: 0.5035 - val_loss: 71.8552 - val_accuracy: 0.5281\n",
      "Epoch 162/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 70.8650 - accuracy: 0.4967 - val_loss: 69.8364 - val_accuracy: 0.5280\n",
      "Epoch 163/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 68.8686 - accuracy: 0.5059 - val_loss: 67.8654 - val_accuracy: 0.5296\n",
      "Epoch 164/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 66.9200 - accuracy: 0.5045 - val_loss: 65.9414 - val_accuracy: 0.5297\n",
      "Epoch 165/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 65.0185 - accuracy: 0.5106 - val_loss: 64.0635 - val_accuracy: 0.5289\n",
      "Epoch 166/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 63.1632 - accuracy: 0.4982 - val_loss: 62.2310 - val_accuracy: 0.5295\n",
      "Epoch 167/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 61.3517 - accuracy: 0.5082 - val_loss: 60.4431 - val_accuracy: 0.5299\n",
      "Epoch 168/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 59.5853 - accuracy: 0.5003 - val_loss: 58.6991 - val_accuracy: 0.5301\n",
      "Epoch 169/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 57.8630 - accuracy: 0.5053 - val_loss: 56.9981 - val_accuracy: 0.5306\n",
      "Epoch 170/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 56.1819 - accuracy: 0.5017 - val_loss: 55.3395 - val_accuracy: 0.5293\n",
      "Epoch 171/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 54.5429 - accuracy: 0.5078 - val_loss: 53.7225 - val_accuracy: 0.5294\n",
      "Epoch 172/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 52.9463 - accuracy: 0.5062 - val_loss: 52.1463 - val_accuracy: 0.5294\n",
      "Epoch 173/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 51.3897 - accuracy: 0.5064 - val_loss: 50.6102 - val_accuracy: 0.5292\n",
      "Epoch 174/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 49.8718 - accuracy: 0.5050 - val_loss: 49.1135 - val_accuracy: 0.5294\n",
      "Epoch 175/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 48.3948 - accuracy: 0.5099 - val_loss: 47.6553 - val_accuracy: 0.5295\n",
      "Epoch 176/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 46.9548 - accuracy: 0.5073 - val_loss: 46.2350 - val_accuracy: 0.5303\n",
      "Epoch 177/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 45.5534 - accuracy: 0.5056 - val_loss: 44.8518 - val_accuracy: 0.5298\n",
      "Epoch 178/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 44.1873 - accuracy: 0.5099 - val_loss: 43.5050 - val_accuracy: 0.5300\n",
      "Epoch 179/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 42.8586 - accuracy: 0.5013 - val_loss: 42.1938 - val_accuracy: 0.5296\n",
      "Epoch 180/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 41.5647 - accuracy: 0.5062 - val_loss: 40.9176 - val_accuracy: 0.5294\n",
      "Epoch 181/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 40.3047 - accuracy: 0.5082 - val_loss: 39.6757 - val_accuracy: 0.5296\n",
      "Epoch 182/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 39.0797 - accuracy: 0.5015 - val_loss: 38.4673 - val_accuracy: 0.5296\n",
      "Epoch 183/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 37.8872 - accuracy: 0.5002 - val_loss: 37.2917 - val_accuracy: 0.5288\n",
      "Epoch 184/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 36.7275 - accuracy: 0.5046 - val_loss: 36.1483 - val_accuracy: 0.5293\n",
      "Epoch 185/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 35.5996 - accuracy: 0.5014 - val_loss: 35.0363 - val_accuracy: 0.5286\n",
      "Epoch 186/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 34.5024 - accuracy: 0.5090 - val_loss: 33.9551 - val_accuracy: 0.5286\n",
      "Epoch 187/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 33.4361 - accuracy: 0.4987 - val_loss: 32.9040 - val_accuracy: 0.5294\n",
      "Epoch 188/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 32.3996 - accuracy: 0.5017 - val_loss: 31.8823 - val_accuracy: 0.5269\n",
      "Epoch 189/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 31.3921 - accuracy: 0.4988 - val_loss: 30.8894 - val_accuracy: 0.5277\n",
      "Epoch 190/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 30.4126 - accuracy: 0.5060 - val_loss: 29.9245 - val_accuracy: 0.5267\n",
      "Epoch 191/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 29.4610 - accuracy: 0.5065 - val_loss: 28.9871 - val_accuracy: 0.5248\n",
      "Epoch 192/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 28.5372 - accuracy: 0.5080 - val_loss: 28.0765 - val_accuracy: 0.5253\n",
      "Epoch 193/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 27.6395 - accuracy: 0.5044 - val_loss: 27.1920 - val_accuracy: 0.5241\n",
      "Epoch 194/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 26.7678 - accuracy: 0.4999 - val_loss: 26.3331 - val_accuracy: 0.5237\n",
      "Epoch 195/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 25.9210 - accuracy: 0.5019 - val_loss: 25.4991 - val_accuracy: 0.5229\n",
      "Epoch 196/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 25.0990 - accuracy: 0.5044 - val_loss: 24.6894 - val_accuracy: 0.5190\n",
      "Epoch 197/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 24.3010 - accuracy: 0.5038 - val_loss: 23.9034 - val_accuracy: 0.5182\n",
      "Epoch 198/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 23.5264 - accuracy: 0.5057 - val_loss: 23.1404 - val_accuracy: 0.5168\n",
      "Epoch 199/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 22.7744 - accuracy: 0.5005 - val_loss: 22.4000 - val_accuracy: 0.5164\n",
      "Epoch 200/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 22.0451 - accuracy: 0.4980 - val_loss: 21.6815 - val_accuracy: 0.5133\n",
      "Epoch 201/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 21.3369 - accuracy: 0.5067 - val_loss: 20.9844 - val_accuracy: 0.5128\n",
      "Epoch 202/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 20.6501 - accuracy: 0.5045 - val_loss: 20.3080 - val_accuracy: 0.5117\n",
      "Epoch 203/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 19.9836 - accuracy: 0.5019 - val_loss: 19.6519 - val_accuracy: 0.5093\n",
      "Epoch 204/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 19.3371 - accuracy: 0.5100 - val_loss: 19.0154 - val_accuracy: 0.5082\n",
      "Epoch 205/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 18.7102 - accuracy: 0.5039 - val_loss: 18.3981 - val_accuracy: 0.5080\n",
      "Epoch 206/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 18.1022 - accuracy: 0.5006 - val_loss: 17.7994 - val_accuracy: 0.5054\n",
      "Epoch 207/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 17.5124 - accuracy: 0.5011 - val_loss: 17.2188 - val_accuracy: 0.5046\n",
      "Epoch 208/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 16.9406 - accuracy: 0.5006 - val_loss: 16.6559 - val_accuracy: 0.5049\n",
      "Epoch 209/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 16.3859 - accuracy: 0.5039 - val_loss: 16.1100 - val_accuracy: 0.5025\n",
      "Epoch 210/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 15.8482 - accuracy: 0.5035 - val_loss: 15.5807 - val_accuracy: 0.5019\n",
      "Epoch 211/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 15.3271 - accuracy: 0.4989 - val_loss: 15.0675 - val_accuracy: 0.5013\n",
      "Epoch 212/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 14.8215 - accuracy: 0.5030 - val_loss: 14.5701 - val_accuracy: 0.5011\n",
      "Epoch 213/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 14.3316 - accuracy: 0.4995 - val_loss: 14.0878 - val_accuracy: 0.5008\n",
      "Epoch 214/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 13.8566 - accuracy: 0.5003 - val_loss: 13.6203 - val_accuracy: 0.5004\n",
      "Epoch 215/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 13.3962 - accuracy: 0.5027 - val_loss: 13.1671 - val_accuracy: 0.5000\n",
      "Epoch 216/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 12.9500 - accuracy: 0.5021 - val_loss: 12.7279 - val_accuracy: 0.5002\n",
      "Epoch 217/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 12.5174 - accuracy: 0.4965 - val_loss: 12.3022 - val_accuracy: 0.5005\n",
      "Epoch 218/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 12.0982 - accuracy: 0.5027 - val_loss: 11.8895 - val_accuracy: 0.5003\n",
      "Epoch 219/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 11.6918 - accuracy: 0.5018 - val_loss: 11.4896 - val_accuracy: 0.5004\n",
      "Epoch 220/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 11.2980 - accuracy: 0.4982 - val_loss: 11.1021 - val_accuracy: 0.5003\n",
      "Epoch 221/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 10.9164 - accuracy: 0.4993 - val_loss: 10.7265 - val_accuracy: 0.5001\n",
      "Epoch 222/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 10.5467 - accuracy: 0.4923 - val_loss: 10.3626 - val_accuracy: 0.5001\n",
      "Epoch 223/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 10.1883 - accuracy: 0.4997 - val_loss: 10.0100 - val_accuracy: 0.5001\n",
      "Epoch 224/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 9.8411 - accuracy: 0.5032 - val_loss: 9.6684 - val_accuracy: 0.5001\n",
      "Epoch 225/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 9.5048 - accuracy: 0.4973 - val_loss: 9.3374 - val_accuracy: 0.5001\n",
      "Epoch 226/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 9.1789 - accuracy: 0.4987 - val_loss: 9.0169 - val_accuracy: 0.5001\n",
      "Epoch 227/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 8.8633 - accuracy: 0.5011 - val_loss: 8.7064 - val_accuracy: 0.5001\n",
      "Epoch 228/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 8.5576 - accuracy: 0.5044 - val_loss: 8.4057 - val_accuracy: 0.5001\n",
      "Epoch 229/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 8.2617 - accuracy: 0.5053 - val_loss: 8.1145 - val_accuracy: 0.5001\n",
      "Epoch 230/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 7.9751 - accuracy: 0.5012 - val_loss: 7.8326 - val_accuracy: 0.5001\n",
      "Epoch 231/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 7.6977 - accuracy: 0.4972 - val_loss: 7.5598 - val_accuracy: 0.5001\n",
      "Epoch 232/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 7.4293 - accuracy: 0.4973 - val_loss: 7.2958 - val_accuracy: 0.5001\n",
      "Epoch 233/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 7.1694 - accuracy: 0.4959 - val_loss: 7.0403 - val_accuracy: 0.5001\n",
      "Epoch 234/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 6.9180 - accuracy: 0.5032 - val_loss: 6.7932 - val_accuracy: 0.5001\n",
      "Epoch 235/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 6.6750 - accuracy: 0.5007 - val_loss: 6.5542 - val_accuracy: 0.5001\n",
      "Epoch 236/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 6.4399 - accuracy: 0.5052 - val_loss: 6.3232 - val_accuracy: 0.5001\n",
      "Epoch 237/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 6.2128 - accuracy: 0.4961 - val_loss: 6.0999 - val_accuracy: 0.5001\n",
      "Epoch 238/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 5.9932 - accuracy: 0.5052 - val_loss: 5.8842 - val_accuracy: 0.5001\n",
      "Epoch 239/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 5.7811 - accuracy: 0.4999 - val_loss: 5.6758 - val_accuracy: 0.5001\n",
      "Epoch 240/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 5.5763 - accuracy: 0.5012 - val_loss: 5.4747 - val_accuracy: 0.5001\n",
      "Epoch 241/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 5.3786 - accuracy: 0.4927 - val_loss: 5.2805 - val_accuracy: 0.5001\n",
      "Epoch 242/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 5.1878 - accuracy: 0.4970 - val_loss: 5.0931 - val_accuracy: 0.5001\n",
      "Epoch 243/300\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 5.0038 - accuracy: 0.4972 - val_loss: 4.9125 - val_accuracy: 0.5001\n",
      "Epoch 244/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 4.8263 - accuracy: 0.5029 - val_loss: 4.7383 - val_accuracy: 0.5001\n",
      "Epoch 245/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 4.6553 - accuracy: 0.4973 - val_loss: 4.5705 - val_accuracy: 0.5001\n",
      "Epoch 246/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 4.4905 - accuracy: 0.5054 - val_loss: 4.4088 - val_accuracy: 0.5001\n",
      "Epoch 247/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 4.3318 - accuracy: 0.5005 - val_loss: 4.2532 - val_accuracy: 0.5001\n",
      "Epoch 248/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 4.1791 - accuracy: 0.4958 - val_loss: 4.1034 - val_accuracy: 0.5001\n",
      "Epoch 249/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 4.0321 - accuracy: 0.4947 - val_loss: 3.9593 - val_accuracy: 0.5001\n",
      "Epoch 250/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 3.8908 - accuracy: 0.4980 - val_loss: 3.8208 - val_accuracy: 0.5001\n",
      "Epoch 251/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.7549 - accuracy: 0.5050 - val_loss: 3.6877 - val_accuracy: 0.5001\n",
      "Epoch 252/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 3.6244 - accuracy: 0.4938 - val_loss: 3.5598 - val_accuracy: 0.5001\n",
      "Epoch 253/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 3.4990 - accuracy: 0.4997 - val_loss: 3.4370 - val_accuracy: 0.5001\n",
      "Epoch 254/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.3786 - accuracy: 0.4985 - val_loss: 3.3192 - val_accuracy: 0.5001\n",
      "Epoch 255/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 3.2632 - accuracy: 0.4976 - val_loss: 3.2061 - val_accuracy: 0.5001\n",
      "Epoch 256/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 3.1524 - accuracy: 0.5031 - val_loss: 3.0978 - val_accuracy: 0.5001\n",
      "Epoch 257/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 3.0463 - accuracy: 0.4943 - val_loss: 2.9939 - val_accuracy: 0.5001\n",
      "Epoch 258/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.9446 - accuracy: 0.5012 - val_loss: 2.8944 - val_accuracy: 0.5001\n",
      "Epoch 259/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.8472 - accuracy: 0.4956 - val_loss: 2.7992 - val_accuracy: 0.5001\n",
      "Epoch 260/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.7540 - accuracy: 0.4956 - val_loss: 2.7080 - val_accuracy: 0.5001\n",
      "Epoch 261/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.6648 - accuracy: 0.4993 - val_loss: 2.6208 - val_accuracy: 0.5001\n",
      "Epoch 262/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.5795 - accuracy: 0.4994 - val_loss: 2.5374 - val_accuracy: 0.5001\n",
      "Epoch 263/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.4980 - accuracy: 0.4949 - val_loss: 2.4577 - val_accuracy: 0.5001\n",
      "Epoch 264/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.4200 - accuracy: 0.5036 - val_loss: 2.3816 - val_accuracy: 0.5001\n",
      "Epoch 265/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.3456 - accuracy: 0.4997 - val_loss: 2.3089 - val_accuracy: 0.5001\n",
      "Epoch 266/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.2745 - accuracy: 0.5066 - val_loss: 2.2395 - val_accuracy: 0.5001\n",
      "Epoch 267/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.2067 - accuracy: 0.5030 - val_loss: 2.1733 - val_accuracy: 0.5001\n",
      "Epoch 268/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.1420 - accuracy: 0.4946 - val_loss: 2.1101 - val_accuracy: 0.5001\n",
      "Epoch 269/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.0803 - accuracy: 0.4980 - val_loss: 2.0499 - val_accuracy: 0.5001\n",
      "Epoch 270/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.0214 - accuracy: 0.5030 - val_loss: 1.9925 - val_accuracy: 0.5001\n",
      "Epoch 271/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.9654 - accuracy: 0.4945 - val_loss: 1.9378 - val_accuracy: 0.5001\n",
      "Epoch 272/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.9119 - accuracy: 0.5027 - val_loss: 1.8857 - val_accuracy: 0.5001\n",
      "Epoch 273/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.8610 - accuracy: 0.4991 - val_loss: 1.8360 - val_accuracy: 0.5001\n",
      "Epoch 274/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.8126 - accuracy: 0.4980 - val_loss: 1.7887 - val_accuracy: 0.5001\n",
      "Epoch 275/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.7664 - accuracy: 0.5001 - val_loss: 1.7437 - val_accuracy: 0.5001\n",
      "Epoch 276/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1.7225 - accuracy: 0.4935 - val_loss: 1.7008 - val_accuracy: 0.5001\n",
      "Epoch 277/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.6806 - accuracy: 0.5018 - val_loss: 1.6600 - val_accuracy: 0.5001\n",
      "Epoch 278/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.6407 - accuracy: 0.4928 - val_loss: 1.6211 - val_accuracy: 0.5001\n",
      "Epoch 279/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.6028 - accuracy: 0.4982 - val_loss: 1.5841 - val_accuracy: 0.5001\n",
      "Epoch 280/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.5667 - accuracy: 0.5002 - val_loss: 1.5489 - val_accuracy: 0.5001\n",
      "Epoch 281/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.5322 - accuracy: 0.5016 - val_loss: 1.5153 - val_accuracy: 0.5001\n",
      "Epoch 282/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1.4995 - accuracy: 0.4993 - val_loss: 1.4833 - val_accuracy: 0.5001\n",
      "Epoch 283/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.4682 - accuracy: 0.4963 - val_loss: 1.4529 - val_accuracy: 0.5001\n",
      "Epoch 284/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.4385 - accuracy: 0.5024 - val_loss: 1.4238 - val_accuracy: 0.5001\n",
      "Epoch 285/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.4100 - accuracy: 0.5032 - val_loss: 1.3961 - val_accuracy: 0.5001\n",
      "Epoch 286/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1.3830 - accuracy: 0.5010 - val_loss: 1.3696 - val_accuracy: 0.5001\n",
      "Epoch 287/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.3571 - accuracy: 0.4945 - val_loss: 1.3443 - val_accuracy: 0.5001\n",
      "Epoch 288/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.3324 - accuracy: 0.5051 - val_loss: 1.3202 - val_accuracy: 0.5001\n",
      "Epoch 289/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1.3088 - accuracy: 0.4988 - val_loss: 1.2971 - val_accuracy: 0.5001\n",
      "Epoch 290/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.2862 - accuracy: 0.4974 - val_loss: 1.2750 - val_accuracy: 0.5001\n",
      "Epoch 291/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.2645 - accuracy: 0.4980 - val_loss: 1.2539 - val_accuracy: 0.5001\n",
      "Epoch 292/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.2438 - accuracy: 0.5047 - val_loss: 1.2336 - val_accuracy: 0.5001\n",
      "Epoch 293/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.2239 - accuracy: 0.5061 - val_loss: 1.2141 - val_accuracy: 0.5001\n",
      "Epoch 294/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.2048 - accuracy: 0.4987 - val_loss: 1.1954 - val_accuracy: 0.5001\n",
      "Epoch 295/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.1865 - accuracy: 0.5014 - val_loss: 1.1774 - val_accuracy: 0.5001\n",
      "Epoch 296/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1.1689 - accuracy: 0.5020 - val_loss: 1.1601 - val_accuracy: 0.5001\n",
      "Epoch 297/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.1519 - accuracy: 0.4938 - val_loss: 1.1435 - val_accuracy: 0.5001\n",
      "Epoch 298/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.1355 - accuracy: 0.5006 - val_loss: 1.1274 - val_accuracy: 0.5001\n",
      "Epoch 299/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.1197 - accuracy: 0.4964 - val_loss: 1.1119 - val_accuracy: 0.5001\n",
      "Epoch 300/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.1045 - accuracy: 0.5033 - val_loss: 1.0969 - val_accuracy: 0.5001\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 1.0969 - accuracy: 0.5001\n",
      "{'loss': 1.0969147682189941, 'accuracy': 0.5001260638237} \n",
      " 299 \n",
      "\n",
      "Model time: 4.164229568094015 minutes\n",
      "\n",
      "Total time: 174.86398827657104 minutes\n",
      "\n",
      "\n",
      "Model  99  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                    16\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.3\n",
      "L1                            10.0\n",
      "L2                           0.001\n",
      "Batch size                     128\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 3550932, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 4s 10ms/step - loss: 3600.5283 - accuracy: 0.5002 - val_loss: 3572.4390 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 3545.2559 - accuracy: 0.5001 - val_loss: 3517.5002 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 3490.5383 - accuracy: 0.5011 - val_loss: 3463.0327 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3436.3752 - accuracy: 0.5001 - val_loss: 3409.1709 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 3382.7412 - accuracy: 0.5008 - val_loss: 3355.7771 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 3329.5840 - accuracy: 0.5010 - val_loss: 3302.8499 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3276.9124 - accuracy: 0.4996 - val_loss: 3250.4446 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3224.7495 - accuracy: 0.4995 - val_loss: 3198.4922 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 3173.0017 - accuracy: 0.5001 - val_loss: 3147.0083 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 3121.8008 - accuracy: 0.5003 - val_loss: 3096.0938 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 3071.1167 - accuracy: 0.5006 - val_loss: 3045.6099 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3020.8342 - accuracy: 0.4997 - val_loss: 2995.5508 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2971.0037 - accuracy: 0.5005 - val_loss: 2945.9446 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 2921.6187 - accuracy: 0.4995 - val_loss: 2896.8147 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2872.7849 - accuracy: 0.5005 - val_loss: 2848.2556 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2824.4722 - accuracy: 0.5005 - val_loss: 2800.1941 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2776.6428 - accuracy: 0.5005 - val_loss: 2752.5916 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2729.2749 - accuracy: 0.5016 - val_loss: 2705.4932 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2682.4275 - accuracy: 0.5012 - val_loss: 2658.9062 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2636.1531 - accuracy: 0.5007 - val_loss: 2612.9211 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2590.4163 - accuracy: 0.5011 - val_loss: 2567.4731 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2545.2063 - accuracy: 0.5001 - val_loss: 2522.4580 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2500.3953 - accuracy: 0.5014 - val_loss: 2477.8806 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2456.0645 - accuracy: 0.5009 - val_loss: 2433.8054 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2412.2800 - accuracy: 0.5015 - val_loss: 2390.3462 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2369.0615 - accuracy: 0.5015 - val_loss: 2347.3247 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 2326.2451 - accuracy: 0.5005 - val_loss: 2304.7197 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2283.8643 - accuracy: 0.4988 - val_loss: 2262.5525 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2241.8552 - accuracy: 0.5015 - val_loss: 2220.7161 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2200.2224 - accuracy: 0.5009 - val_loss: 2179.2930 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2159.0396 - accuracy: 0.4993 - val_loss: 2138.3804 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2118.4026 - accuracy: 0.5002 - val_loss: 2098.0020 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2078.2034 - accuracy: 0.4996 - val_loss: 2058.0039 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 2038.4855 - accuracy: 0.4989 - val_loss: 2018.5596 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1999.2678 - accuracy: 0.4997 - val_loss: 1979.5884 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1960.5148 - accuracy: 0.5007 - val_loss: 1941.0399 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1922.1481 - accuracy: 0.5024 - val_loss: 1902.8698 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1884.2113 - accuracy: 0.4972 - val_loss: 1865.1627 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1846.7468 - accuracy: 0.5017 - val_loss: 1827.9585 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1809.7886 - accuracy: 0.4989 - val_loss: 1791.2334 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1773.2849 - accuracy: 0.4999 - val_loss: 1754.9629 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1737.2751 - accuracy: 0.5017 - val_loss: 1719.2435 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1701.8146 - accuracy: 0.5003 - val_loss: 1684.0253 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1666.8369 - accuracy: 0.5003 - val_loss: 1649.3104 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1632.3663 - accuracy: 0.4989 - val_loss: 1615.0706 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1598.3564 - accuracy: 0.5013 - val_loss: 1581.3258 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1564.8525 - accuracy: 0.4989 - val_loss: 1548.0287 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1531.7682 - accuracy: 0.4994 - val_loss: 1515.1971 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1499.2523 - accuracy: 0.5006 - val_loss: 1483.0156 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1467.4004 - accuracy: 0.5006 - val_loss: 1451.4655 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1436.0142 - accuracy: 0.4995 - val_loss: 1420.2147 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1404.9502 - accuracy: 0.4979 - val_loss: 1389.3813 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1374.4210 - accuracy: 0.4999 - val_loss: 1359.1571 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1344.4149 - accuracy: 0.5009 - val_loss: 1329.3478 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1314.7871 - accuracy: 0.5007 - val_loss: 1299.9139 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1285.5741 - accuracy: 0.4990 - val_loss: 1270.9395 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1256.8162 - accuracy: 0.5012 - val_loss: 1242.4218 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1228.5345 - accuracy: 0.5010 - val_loss: 1214.3558 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1200.6637 - accuracy: 0.4971 - val_loss: 1186.7172 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1173.2731 - accuracy: 0.5005 - val_loss: 1159.5404 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1146.2974 - accuracy: 0.5013 - val_loss: 1132.8055 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1119.7819 - accuracy: 0.4999 - val_loss: 1106.4933 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1093.7360 - accuracy: 0.5004 - val_loss: 1080.7517 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 1068.2626 - accuracy: 0.4996 - val_loss: 1055.4923 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 1043.2205 - accuracy: 0.5031 - val_loss: 1030.7164 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1018.7036 - accuracy: 0.5008 - val_loss: 1006.4724 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 994.7283 - accuracy: 0.5011 - val_loss: 982.7380 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 971.1570 - accuracy: 0.4983 - val_loss: 959.3302 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 947.9700 - accuracy: 0.4991 - val_loss: 936.3725 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 925.2443 - accuracy: 0.4997 - val_loss: 913.8845 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 902.9659 - accuracy: 0.4993 - val_loss: 891.8177 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 881.1191 - accuracy: 0.4974 - val_loss: 870.2477 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 859.8571 - accuracy: 0.5004 - val_loss: 849.2615 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 839.1161 - accuracy: 0.4979 - val_loss: 828.7715 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 818.8200 - accuracy: 0.5017 - val_loss: 808.6791 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 798.9504 - accuracy: 0.4986 - val_loss: 789.0401 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 779.5170 - accuracy: 0.5010 - val_loss: 769.8223 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 760.5780 - accuracy: 0.5032 - val_loss: 751.1707 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 742.1989 - accuracy: 0.4983 - val_loss: 733.0435 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 724.2962 - accuracy: 0.5014 - val_loss: 715.3682 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 706.7971 - accuracy: 0.4993 - val_loss: 698.0206 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 689.6674 - accuracy: 0.5000 - val_loss: 681.1758 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 673.1155 - accuracy: 0.5019 - val_loss: 664.8763 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 656.9753 - accuracy: 0.4994 - val_loss: 648.9199 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 641.2254 - accuracy: 0.5027 - val_loss: 633.3710 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 625.9016 - accuracy: 0.5001 - val_loss: 618.3108 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 611.1451 - accuracy: 0.5007 - val_loss: 603.8896 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 597.0316 - accuracy: 0.5033 - val_loss: 590.0365 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 583.3624 - accuracy: 0.4986 - val_loss: 576.5468 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 570.0898 - accuracy: 0.4998 - val_loss: 563.5184 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 557.3271 - accuracy: 0.5003 - val_loss: 551.0532 - val_accuracy: 0.5001\n",
      "Epoch 92/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 545.1500 - accuracy: 0.5027 - val_loss: 539.1721 - val_accuracy: 0.5001\n",
      "Epoch 93/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 533.5245 - accuracy: 0.4995 - val_loss: 527.7537 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 522.2911 - accuracy: 0.4995 - val_loss: 516.7178 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 511.4036 - accuracy: 0.5027 - val_loss: 506.0122 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 500.9385 - accuracy: 0.5017 - val_loss: 495.7733 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 490.8849 - accuracy: 0.5011 - val_loss: 485.9020 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 481.2022 - accuracy: 0.4958 - val_loss: 476.4339 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 471.9918 - accuracy: 0.4987 - val_loss: 467.4702 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 463.2616 - accuracy: 0.4985 - val_loss: 458.9879 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 455.0335 - accuracy: 0.5008 - val_loss: 451.0568 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 447.3494 - accuracy: 0.5013 - val_loss: 443.5927 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 440.1211 - accuracy: 0.5007 - val_loss: 436.5985 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 433.3755 - accuracy: 0.4971 - val_loss: 430.1297 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 427.1491 - accuracy: 0.4976 - val_loss: 424.1252 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 421.3442 - accuracy: 0.5008 - val_loss: 418.5351 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 415.9329 - accuracy: 0.5083 - val_loss: 413.2400 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 410.6527 - accuracy: 0.5018 - val_loss: 407.9643 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 405.3917 - accuracy: 0.5006 - val_loss: 402.7268 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 400.1775 - accuracy: 0.4952 - val_loss: 397.5178 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 394.9665 - accuracy: 0.4996 - val_loss: 392.3200 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 389.7798 - accuracy: 0.5008 - val_loss: 387.1425 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 384.6138 - accuracy: 0.5029 - val_loss: 381.9841 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 379.4553 - accuracy: 0.5021 - val_loss: 376.8262 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 374.3117 - accuracy: 0.5003 - val_loss: 371.7059 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 369.2107 - accuracy: 0.4949 - val_loss: 366.6214 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 364.1528 - accuracy: 0.5040 - val_loss: 361.6010 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 359.1545 - accuracy: 0.5008 - val_loss: 356.6111 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 354.1744 - accuracy: 0.5008 - val_loss: 351.6520 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 349.2343 - accuracy: 0.4982 - val_loss: 346.7231 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 344.3230 - accuracy: 0.4905 - val_loss: 341.8316 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 339.4494 - accuracy: 0.5021 - val_loss: 336.9739 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 334.5938 - accuracy: 0.4973 - val_loss: 332.1185 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 329.7426 - accuracy: 0.5059 - val_loss: 327.2799 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 324.9185 - accuracy: 0.4995 - val_loss: 322.4761 - val_accuracy: 0.5001\n",
      "Epoch 126/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 320.1434 - accuracy: 0.4995 - val_loss: 317.7260 - val_accuracy: 0.5001\n",
      "Epoch 127/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 315.4051 - accuracy: 0.4941 - val_loss: 312.9951 - val_accuracy: 0.5001\n",
      "Epoch 128/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 310.7003 - accuracy: 0.4992 - val_loss: 308.3246 - val_accuracy: 0.5001\n",
      "Epoch 129/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 306.0539 - accuracy: 0.4937 - val_loss: 303.7029 - val_accuracy: 0.5001\n",
      "Epoch 130/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 301.4503 - accuracy: 0.5053 - val_loss: 299.1294 - val_accuracy: 0.5001\n",
      "Epoch 131/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 296.9200 - accuracy: 0.4955 - val_loss: 294.6331 - val_accuracy: 0.5001\n",
      "Epoch 132/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 292.4357 - accuracy: 0.5014 - val_loss: 290.1690 - val_accuracy: 0.5001\n",
      "Epoch 133/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 288.0191 - accuracy: 0.4998 - val_loss: 285.7971 - val_accuracy: 0.5001\n",
      "Epoch 134/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 283.6731 - accuracy: 0.5057 - val_loss: 281.4813 - val_accuracy: 0.5001\n",
      "Epoch 135/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 279.3875 - accuracy: 0.5001 - val_loss: 277.2175 - val_accuracy: 0.5001\n",
      "Epoch 136/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 275.1503 - accuracy: 0.4966 - val_loss: 273.0135 - val_accuracy: 0.5001\n",
      "Epoch 137/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 270.9748 - accuracy: 0.4951 - val_loss: 268.8598 - val_accuracy: 0.5001\n",
      "Epoch 138/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 266.8364 - accuracy: 0.5024 - val_loss: 264.7478 - val_accuracy: 0.5001\n",
      "Epoch 139/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 262.7567 - accuracy: 0.4981 - val_loss: 260.6953 - val_accuracy: 0.5001\n",
      "Epoch 140/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 258.7199 - accuracy: 0.5012 - val_loss: 256.6757 - val_accuracy: 0.5001\n",
      "Epoch 141/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 254.7243 - accuracy: 0.5033 - val_loss: 252.7196 - val_accuracy: 0.5001\n",
      "Epoch 142/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 250.7991 - accuracy: 0.5010 - val_loss: 248.8053 - val_accuracy: 0.5001\n",
      "Epoch 143/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 246.8857 - accuracy: 0.4996 - val_loss: 244.8928 - val_accuracy: 0.5001\n",
      "Epoch 144/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 242.9844 - accuracy: 0.5037 - val_loss: 241.0076 - val_accuracy: 0.5001\n",
      "Epoch 145/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 239.1044 - accuracy: 0.5015 - val_loss: 237.1270 - val_accuracy: 0.5001\n",
      "Epoch 146/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 235.2331 - accuracy: 0.4955 - val_loss: 233.2760 - val_accuracy: 0.5001\n",
      "Epoch 147/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 231.4030 - accuracy: 0.5057 - val_loss: 229.4709 - val_accuracy: 0.5001\n",
      "Epoch 148/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 227.6327 - accuracy: 0.4987 - val_loss: 225.7281 - val_accuracy: 0.5001\n",
      "Epoch 149/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 223.8996 - accuracy: 0.4992 - val_loss: 222.0084 - val_accuracy: 0.5001\n",
      "Epoch 150/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 220.2040 - accuracy: 0.5048 - val_loss: 218.3421 - val_accuracy: 0.5001\n",
      "Epoch 151/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 216.5614 - accuracy: 0.5038 - val_loss: 214.7189 - val_accuracy: 0.4999\n",
      "Epoch 152/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 212.9563 - accuracy: 0.5000 - val_loss: 211.1322 - val_accuracy: 0.4999\n",
      "Epoch 153/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 209.3837 - accuracy: 0.5018 - val_loss: 207.5720 - val_accuracy: 0.4999\n",
      "Epoch 154/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 205.8396 - accuracy: 0.5028 - val_loss: 204.0542 - val_accuracy: 0.4999\n",
      "Epoch 155/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 202.3399 - accuracy: 0.5011 - val_loss: 200.5599 - val_accuracy: 0.4999\n",
      "Epoch 156/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 198.8488 - accuracy: 0.4980 - val_loss: 197.0848 - val_accuracy: 0.4999\n",
      "Epoch 157/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 195.4115 - accuracy: 0.5010 - val_loss: 193.6852 - val_accuracy: 0.4999\n",
      "Epoch 158/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 192.0323 - accuracy: 0.4988 - val_loss: 190.3214 - val_accuracy: 0.4999\n",
      "Epoch 159/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 188.6878 - accuracy: 0.5029 - val_loss: 186.9978 - val_accuracy: 0.4999\n",
      "Epoch 160/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 185.3824 - accuracy: 0.4963 - val_loss: 183.7037 - val_accuracy: 0.4999\n",
      "Epoch 161/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 182.1035 - accuracy: 0.5017 - val_loss: 180.4502 - val_accuracy: 0.4999\n",
      "Epoch 162/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 178.8610 - accuracy: 0.4995 - val_loss: 177.2169 - val_accuracy: 0.4999\n",
      "Epoch 163/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 175.6458 - accuracy: 0.4972 - val_loss: 174.0197 - val_accuracy: 0.4999\n",
      "Epoch 164/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 172.4579 - accuracy: 0.4996 - val_loss: 170.8464 - val_accuracy: 0.4999\n",
      "Epoch 165/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 169.2952 - accuracy: 0.4996 - val_loss: 167.6920 - val_accuracy: 0.4999\n",
      "Epoch 166/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 166.1539 - accuracy: 0.4982 - val_loss: 164.5676 - val_accuracy: 0.4999\n",
      "Epoch 167/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 163.0430 - accuracy: 0.5015 - val_loss: 161.4684 - val_accuracy: 0.4999\n",
      "Epoch 168/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 159.9553 - accuracy: 0.5029 - val_loss: 158.3927 - val_accuracy: 0.4999\n",
      "Epoch 169/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 156.9062 - accuracy: 0.4911 - val_loss: 155.3706 - val_accuracy: 0.4999\n",
      "Epoch 170/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 153.8941 - accuracy: 0.5009 - val_loss: 152.3688 - val_accuracy: 0.4999\n",
      "Epoch 171/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 150.9093 - accuracy: 0.5009 - val_loss: 149.4039 - val_accuracy: 0.4999\n",
      "Epoch 172/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 147.9597 - accuracy: 0.5006 - val_loss: 146.4647 - val_accuracy: 0.4999\n",
      "Epoch 173/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 145.0413 - accuracy: 0.4993 - val_loss: 143.5704 - val_accuracy: 0.4999\n",
      "Epoch 174/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 142.1679 - accuracy: 0.4956 - val_loss: 140.7237 - val_accuracy: 0.4999\n",
      "Epoch 175/300\n",
      "168/168 [==============================] - 1s 9ms/step - loss: 139.3469 - accuracy: 0.4980 - val_loss: 137.9183 - val_accuracy: 0.4999\n",
      "Epoch 176/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 136.5410 - accuracy: 0.4959 - val_loss: 135.1128 - val_accuracy: 0.4999\n",
      "Epoch 177/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 133.7347 - accuracy: 0.5042 - val_loss: 132.3074 - val_accuracy: 0.4999\n",
      "Epoch 178/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 130.9349 - accuracy: 0.5036 - val_loss: 129.5166 - val_accuracy: 0.4999\n",
      "Epoch 179/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 128.1480 - accuracy: 0.4914 - val_loss: 126.7280 - val_accuracy: 0.4999\n",
      "Epoch 180/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 125.3632 - accuracy: 0.4976 - val_loss: 123.9561 - val_accuracy: 0.4999\n",
      "Epoch 181/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 122.6177 - accuracy: 0.4998 - val_loss: 121.2396 - val_accuracy: 0.4999\n",
      "Epoch 182/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 119.9145 - accuracy: 0.5061 - val_loss: 118.5536 - val_accuracy: 0.4999\n",
      "Epoch 183/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 117.2534 - accuracy: 0.5017 - val_loss: 115.9225 - val_accuracy: 0.4999\n",
      "Epoch 184/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 114.6567 - accuracy: 0.4988 - val_loss: 113.3514 - val_accuracy: 0.4999\n",
      "Epoch 185/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 112.1083 - accuracy: 0.5026 - val_loss: 110.8401 - val_accuracy: 0.4999\n",
      "Epoch 186/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 109.6292 - accuracy: 0.4962 - val_loss: 108.3706 - val_accuracy: 0.4999\n",
      "Epoch 187/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 107.1667 - accuracy: 0.4947 - val_loss: 105.9275 - val_accuracy: 0.4999\n",
      "Epoch 188/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 104.7461 - accuracy: 0.4952 - val_loss: 103.5228 - val_accuracy: 0.4999\n",
      "Epoch 189/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 102.3428 - accuracy: 0.4976 - val_loss: 101.1252 - val_accuracy: 0.4999\n",
      "Epoch 190/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 99.9630 - accuracy: 0.5055 - val_loss: 98.7672 - val_accuracy: 0.4999\n",
      "Epoch 191/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 97.6286 - accuracy: 0.4939 - val_loss: 96.4479 - val_accuracy: 0.4999\n",
      "Epoch 192/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 95.3197 - accuracy: 0.4975 - val_loss: 94.1559 - val_accuracy: 0.4999\n",
      "Epoch 193/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 93.0350 - accuracy: 0.5006 - val_loss: 91.8801 - val_accuracy: 0.4999\n",
      "Epoch 194/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 90.7715 - accuracy: 0.5023 - val_loss: 89.6278 - val_accuracy: 0.4999\n",
      "Epoch 195/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 88.5294 - accuracy: 0.4926 - val_loss: 87.4017 - val_accuracy: 0.4999\n",
      "Epoch 196/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 86.3322 - accuracy: 0.5014 - val_loss: 85.2360 - val_accuracy: 0.4999\n",
      "Epoch 197/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 84.1882 - accuracy: 0.5005 - val_loss: 83.1037 - val_accuracy: 0.4999\n",
      "Epoch 198/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 82.0659 - accuracy: 0.4980 - val_loss: 80.9985 - val_accuracy: 0.4999\n",
      "Epoch 199/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 79.9822 - accuracy: 0.5006 - val_loss: 78.9317 - val_accuracy: 0.4999\n",
      "Epoch 200/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 77.9304 - accuracy: 0.5050 - val_loss: 76.9101 - val_accuracy: 0.4999\n",
      "Epoch 201/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 75.9284 - accuracy: 0.5016 - val_loss: 74.9152 - val_accuracy: 0.4999\n",
      "Epoch 202/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 73.9496 - accuracy: 0.4976 - val_loss: 72.9496 - val_accuracy: 0.4999\n",
      "Epoch 203/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 71.9938 - accuracy: 0.5011 - val_loss: 71.0131 - val_accuracy: 0.4999\n",
      "Epoch 204/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 70.0790 - accuracy: 0.5051 - val_loss: 69.1194 - val_accuracy: 0.4999\n",
      "Epoch 205/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 68.1979 - accuracy: 0.4961 - val_loss: 67.2463 - val_accuracy: 0.4999\n",
      "Epoch 206/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 66.3362 - accuracy: 0.5018 - val_loss: 65.3964 - val_accuracy: 0.4999\n",
      "Epoch 207/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 64.4923 - accuracy: 0.5051 - val_loss: 63.5665 - val_accuracy: 0.4999\n",
      "Epoch 208/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 62.6919 - accuracy: 0.5062 - val_loss: 61.7981 - val_accuracy: 0.4999\n",
      "Epoch 209/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 60.9482 - accuracy: 0.5052 - val_loss: 60.0871 - val_accuracy: 0.4999\n",
      "Epoch 210/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 59.2720 - accuracy: 0.4989 - val_loss: 58.4331 - val_accuracy: 0.4999\n",
      "Epoch 211/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 57.6234 - accuracy: 0.5037 - val_loss: 56.7867 - val_accuracy: 0.4999\n",
      "Epoch 212/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 55.9840 - accuracy: 0.4954 - val_loss: 55.1543 - val_accuracy: 0.4999\n",
      "Epoch 213/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 54.3576 - accuracy: 0.4976 - val_loss: 53.5362 - val_accuracy: 0.4999\n",
      "Epoch 214/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 52.7477 - accuracy: 0.5016 - val_loss: 51.9367 - val_accuracy: 0.4999\n",
      "Epoch 215/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 51.1577 - accuracy: 0.5026 - val_loss: 50.3545 - val_accuracy: 0.4999\n",
      "Epoch 216/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 49.5869 - accuracy: 0.4978 - val_loss: 48.8028 - val_accuracy: 0.4999\n",
      "Epoch 217/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 48.0604 - accuracy: 0.5042 - val_loss: 47.2991 - val_accuracy: 0.4999\n",
      "Epoch 218/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 46.5683 - accuracy: 0.5034 - val_loss: 45.8152 - val_accuracy: 0.4999\n",
      "Epoch 219/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 45.0934 - accuracy: 0.5039 - val_loss: 44.3502 - val_accuracy: 0.4999\n",
      "Epoch 220/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 43.6346 - accuracy: 0.4975 - val_loss: 42.8971 - val_accuracy: 0.4999\n",
      "Epoch 221/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 42.1952 - accuracy: 0.4968 - val_loss: 41.4690 - val_accuracy: 0.4999\n",
      "Epoch 222/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 40.7704 - accuracy: 0.5012 - val_loss: 40.0527 - val_accuracy: 0.4999\n",
      "Epoch 223/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 39.3691 - accuracy: 0.4998 - val_loss: 38.6741 - val_accuracy: 0.4999\n",
      "Epoch 224/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 38.0146 - accuracy: 0.5044 - val_loss: 37.3376 - val_accuracy: 0.4999\n",
      "Epoch 225/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 36.7114 - accuracy: 0.4980 - val_loss: 36.0688 - val_accuracy: 0.4999\n",
      "Epoch 226/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 35.4597 - accuracy: 0.5017 - val_loss: 34.8361 - val_accuracy: 0.4999\n",
      "Epoch 227/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 34.2426 - accuracy: 0.4916 - val_loss: 33.6265 - val_accuracy: 0.4999\n",
      "Epoch 228/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 33.0345 - accuracy: 0.4973 - val_loss: 32.4254 - val_accuracy: 0.4999\n",
      "Epoch 229/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 31.8483 - accuracy: 0.4969 - val_loss: 31.2601 - val_accuracy: 0.4999\n",
      "Epoch 230/300\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 30.6986 - accuracy: 0.4996 - val_loss: 30.1177 - val_accuracy: 0.4999\n",
      "Epoch 231/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 29.5626 - accuracy: 0.5059 - val_loss: 28.9982 - val_accuracy: 0.4999\n",
      "Epoch 232/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 28.4671 - accuracy: 0.5004 - val_loss: 27.9251 - val_accuracy: 0.4999\n",
      "Epoch 233/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 27.4199 - accuracy: 0.4933 - val_loss: 26.9048 - val_accuracy: 0.4999\n",
      "Epoch 234/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 26.4194 - accuracy: 0.5000 - val_loss: 25.9237 - val_accuracy: 0.4999\n",
      "Epoch 235/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 25.4522 - accuracy: 0.5044 - val_loss: 24.9661 - val_accuracy: 0.4999\n",
      "Epoch 236/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 24.5002 - accuracy: 0.4981 - val_loss: 24.0293 - val_accuracy: 0.4999\n",
      "Epoch 237/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 23.5988 - accuracy: 0.4941 - val_loss: 23.1593 - val_accuracy: 0.4999\n",
      "Epoch 238/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 22.7411 - accuracy: 0.4958 - val_loss: 22.3148 - val_accuracy: 0.4999\n",
      "Epoch 239/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 21.9109 - accuracy: 0.4980 - val_loss: 21.4916 - val_accuracy: 0.4999\n",
      "Epoch 240/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 21.0910 - accuracy: 0.4964 - val_loss: 20.6823 - val_accuracy: 0.4999\n",
      "Epoch 241/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 20.3171 - accuracy: 0.4971 - val_loss: 19.9405 - val_accuracy: 0.4999\n",
      "Epoch 242/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 19.5887 - accuracy: 0.4971 - val_loss: 19.2287 - val_accuracy: 0.4999\n",
      "Epoch 243/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 18.8826 - accuracy: 0.5004 - val_loss: 18.5232 - val_accuracy: 0.4999\n",
      "Epoch 244/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 18.1991 - accuracy: 0.4962 - val_loss: 17.8776 - val_accuracy: 0.4999\n",
      "Epoch 245/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 17.5751 - accuracy: 0.5015 - val_loss: 17.2663 - val_accuracy: 0.4999\n",
      "Epoch 246/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 16.9787 - accuracy: 0.5008 - val_loss: 16.6864 - val_accuracy: 0.4999\n",
      "Epoch 247/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 16.4138 - accuracy: 0.5017 - val_loss: 16.1395 - val_accuracy: 0.4999\n",
      "Epoch 248/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 15.8752 - accuracy: 0.5013 - val_loss: 15.6019 - val_accuracy: 0.4999\n",
      "Epoch 249/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 15.3424 - accuracy: 0.4984 - val_loss: 15.0762 - val_accuracy: 0.4999\n",
      "Epoch 250/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 14.8269 - accuracy: 0.4998 - val_loss: 14.5734 - val_accuracy: 0.4999\n",
      "Epoch 251/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 14.3525 - accuracy: 0.4995 - val_loss: 14.1370 - val_accuracy: 0.4999\n",
      "Epoch 252/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 13.9391 - accuracy: 0.5028 - val_loss: 13.7338 - val_accuracy: 0.4999\n",
      "Epoch 253/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 13.5469 - accuracy: 0.5024 - val_loss: 13.3568 - val_accuracy: 0.4999\n",
      "Epoch 254/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 13.1825 - accuracy: 0.4986 - val_loss: 13.0143 - val_accuracy: 0.4999\n",
      "Epoch 255/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 12.8676 - accuracy: 0.4987 - val_loss: 12.7177 - val_accuracy: 0.4999\n",
      "Epoch 256/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 12.5799 - accuracy: 0.5031 - val_loss: 12.4419 - val_accuracy: 0.4999\n",
      "Epoch 257/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 12.3135 - accuracy: 0.4987 - val_loss: 12.1878 - val_accuracy: 0.4999\n",
      "Epoch 258/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 12.0744 - accuracy: 0.4981 - val_loss: 11.9600 - val_accuracy: 0.4999\n",
      "Epoch 259/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 11.8526 - accuracy: 0.5036 - val_loss: 11.7416 - val_accuracy: 0.4999\n",
      "Epoch 260/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 11.6348 - accuracy: 0.4999 - val_loss: 11.5231 - val_accuracy: 0.4999\n",
      "Epoch 261/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 11.4198 - accuracy: 0.4966 - val_loss: 11.3157 - val_accuracy: 0.4999\n",
      "Epoch 262/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 11.2173 - accuracy: 0.4986 - val_loss: 11.1140 - val_accuracy: 0.4999\n",
      "Epoch 263/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 11.0154 - accuracy: 0.5015 - val_loss: 10.9125 - val_accuracy: 0.4999\n",
      "Epoch 264/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.8140 - accuracy: 0.5017 - val_loss: 10.7109 - val_accuracy: 0.4999\n",
      "Epoch 265/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.6126 - accuracy: 0.5011 - val_loss: 10.5095 - val_accuracy: 0.4999\n",
      "Epoch 266/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.4108 - accuracy: 0.5003 - val_loss: 10.3081 - val_accuracy: 0.4999\n",
      "Epoch 267/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 10.2121 - accuracy: 0.4991 - val_loss: 10.1169 - val_accuracy: 0.4999\n",
      "Epoch 268/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 10.0265 - accuracy: 0.5009 - val_loss: 9.9321 - val_accuracy: 0.4999\n",
      "Epoch 269/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 9.8412 - accuracy: 0.4982 - val_loss: 9.7473 - val_accuracy: 0.4999\n",
      "Epoch 270/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.6573 - accuracy: 0.4943 - val_loss: 9.5624 - val_accuracy: 0.4999\n",
      "Epoch 271/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 9.4720 - accuracy: 0.4983 - val_loss: 9.3776 - val_accuracy: 0.4999\n",
      "Epoch 272/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 9.2872 - accuracy: 0.5005 - val_loss: 9.1929 - val_accuracy: 0.4999\n",
      "Epoch 273/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 9.1022 - accuracy: 0.5002 - val_loss: 9.0081 - val_accuracy: 0.4999\n",
      "Epoch 274/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.9171 - accuracy: 0.5041 - val_loss: 8.8234 - val_accuracy: 0.4999\n",
      "Epoch 275/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.7327 - accuracy: 0.4964 - val_loss: 8.6387 - val_accuracy: 0.4999\n",
      "Epoch 276/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.5505 - accuracy: 0.5011 - val_loss: 8.4637 - val_accuracy: 0.4999\n",
      "Epoch 277/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 8.3812 - accuracy: 0.4984 - val_loss: 8.2958 - val_accuracy: 0.4999\n",
      "Epoch 278/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 8.2129 - accuracy: 0.4997 - val_loss: 8.1279 - val_accuracy: 0.4999\n",
      "Epoch 279/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 8.0452 - accuracy: 0.4994 - val_loss: 7.9599 - val_accuracy: 0.4999\n",
      "Epoch 280/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 7.8770 - accuracy: 0.4994 - val_loss: 7.7919 - val_accuracy: 0.4999\n",
      "Epoch 281/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 7.7095 - accuracy: 0.4997 - val_loss: 7.6239 - val_accuracy: 0.4999\n",
      "Epoch 282/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 7.5419 - accuracy: 0.4997 - val_loss: 7.4559 - val_accuracy: 0.4999\n",
      "Epoch 283/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 7.3735 - accuracy: 0.4997 - val_loss: 7.2880 - val_accuracy: 0.4999\n",
      "Epoch 284/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 7.2055 - accuracy: 0.4997 - val_loss: 7.1202 - val_accuracy: 0.4999\n",
      "Epoch 285/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 7.0377 - accuracy: 0.4997 - val_loss: 6.9524 - val_accuracy: 0.4999\n",
      "Epoch 286/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 6.8722 - accuracy: 0.4997 - val_loss: 6.7933 - val_accuracy: 0.4999\n",
      "Epoch 287/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 6.7192 - accuracy: 0.4997 - val_loss: 6.6421 - val_accuracy: 0.4999\n",
      "Epoch 288/300\n",
      "168/168 [==============================] - 1s 8ms/step - loss: 6.5678 - accuracy: 0.4997 - val_loss: 6.4908 - val_accuracy: 0.4999\n",
      "Epoch 289/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 6.4169 - accuracy: 0.4997 - val_loss: 6.3396 - val_accuracy: 0.4999\n",
      "Epoch 290/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 6.2654 - accuracy: 0.4997 - val_loss: 6.1884 - val_accuracy: 0.4999\n",
      "Epoch 291/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 6.1142 - accuracy: 0.4997 - val_loss: 6.0374 - val_accuracy: 0.4999\n",
      "Epoch 292/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 5.9630 - accuracy: 0.4997 - val_loss: 5.8863 - val_accuracy: 0.4999\n",
      "Epoch 293/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 5.8119 - accuracy: 0.4997 - val_loss: 5.7352 - val_accuracy: 0.4999\n",
      "Epoch 294/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.6609 - accuracy: 0.4997 - val_loss: 5.5840 - val_accuracy: 0.4999\n",
      "Epoch 295/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 5.5096 - accuracy: 0.4997 - val_loss: 5.4327 - val_accuracy: 0.4999\n",
      "Epoch 296/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 5.3583 - accuracy: 0.4997 - val_loss: 5.2815 - val_accuracy: 0.4999\n",
      "Epoch 297/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.2070 - accuracy: 0.4997 - val_loss: 5.1303 - val_accuracy: 0.4999\n",
      "Epoch 298/300\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 5.0561 - accuracy: 0.4997 - val_loss: 4.9793 - val_accuracy: 0.4999\n",
      "Epoch 299/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 4.9051 - accuracy: 0.4997 - val_loss: 4.8314 - val_accuracy: 0.4999\n",
      "Epoch 300/300\n",
      "168/168 [==============================] - 1s 7ms/step - loss: 4.7653 - accuracy: 0.4997 - val_loss: 4.6970 - val_accuracy: 0.4999\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 4.6970 - accuracy: 0.4999\n",
      "{'loss': 4.697038650512695, 'accuracy': 0.49987393617630005} \n",
      " 299 \n",
      "\n",
      "Model time: 5.669656902551651 minutes\n",
      "\n",
      "Total time: 180.53374519571662 minutes\n",
      "\n",
      "\n",
      "Model  100  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                    16\n",
      "Activation function           tanh\n",
      "Dropout                        0.3\n",
      "L1                             0.0\n",
      "L2                            10.0\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 3433222, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 6ms/step - loss: 7.0869 - accuracy: 0.4967 - val_loss: 1.5508 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 1.5217 - accuracy: 0.4998 - val_loss: 1.5451 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - ETA: 0s - loss: 1.5217 - accuracy: 0.5045Restoring model weights from the end of the best epoch: 2.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5217 - accuracy: 0.5045 - val_loss: 1.5549 - val_accuracy: 0.4999\n",
      "Epoch 3: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 1.5451 - accuracy: 0.5001\n",
      "{'loss': 1.545130729675293, 'accuracy': 0.5001260638237} \n",
      " 2 \n",
      "\n",
      "Model time: 0.265901904553175 minutes\n",
      "\n",
      "Total time: 180.7997137606144 minutes\n",
      "\n",
      "\n",
      "Model  101  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    3\n",
      "Hidden units                     1\n",
      "Activation function           tanh\n",
      "Dropout                        0.7\n",
      "L1                            0.01\n",
      "L2                         0.00001\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 2829140, dtype: object\n",
      "NN3Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 7s 6ms/step - loss: 0.9604 - accuracy: 0.4958 - val_loss: 1.0061 - val_accuracy: 0.5211\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9498 - accuracy: 0.4996 - val_loss: 0.9974 - val_accuracy: 0.5210\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9484 - accuracy: 0.4934 - val_loss: 0.9883 - val_accuracy: 0.5206\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9336 - accuracy: 0.4997 - val_loss: 0.9798 - val_accuracy: 0.5204\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.9409 - accuracy: 0.4992 - val_loss: 0.9717 - val_accuracy: 0.5200\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9311 - accuracy: 0.4987 - val_loss: 0.9632 - val_accuracy: 0.5199\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9179 - accuracy: 0.4990 - val_loss: 0.9549 - val_accuracy: 0.5207\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9084 - accuracy: 0.4957 - val_loss: 0.9476 - val_accuracy: 0.5202\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.9100 - accuracy: 0.5016 - val_loss: 0.9403 - val_accuracy: 0.5207\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9060 - accuracy: 0.4992 - val_loss: 0.9330 - val_accuracy: 0.5205\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8972 - accuracy: 0.4957 - val_loss: 0.9264 - val_accuracy: 0.5202\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8908 - accuracy: 0.5043 - val_loss: 0.9201 - val_accuracy: 0.5204\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8916 - accuracy: 0.4994 - val_loss: 0.9147 - val_accuracy: 0.5203\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8819 - accuracy: 0.4931 - val_loss: 0.9086 - val_accuracy: 0.5197\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8857 - accuracy: 0.4989 - val_loss: 0.9031 - val_accuracy: 0.5197\n",
      "Epoch 16/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8771 - accuracy: 0.4981 - val_loss: 0.8970 - val_accuracy: 0.5198\n",
      "Epoch 17/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.8734 - accuracy: 0.5001 - val_loss: 0.8920 - val_accuracy: 0.5199\n",
      "Epoch 18/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8665 - accuracy: 0.5017 - val_loss: 0.8871 - val_accuracy: 0.5203\n",
      "Epoch 19/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8653 - accuracy: 0.4979 - val_loss: 0.8822 - val_accuracy: 0.5205\n",
      "Epoch 20/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8573 - accuracy: 0.5008 - val_loss: 0.8777 - val_accuracy: 0.5203\n",
      "Epoch 21/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8585 - accuracy: 0.5009 - val_loss: 0.8734 - val_accuracy: 0.5201\n",
      "Epoch 22/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8548 - accuracy: 0.4935 - val_loss: 0.8693 - val_accuracy: 0.5201\n",
      "Epoch 23/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8535 - accuracy: 0.5012 - val_loss: 0.8655 - val_accuracy: 0.5211\n",
      "Epoch 24/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8492 - accuracy: 0.5022 - val_loss: 0.8619 - val_accuracy: 0.5213\n",
      "Epoch 25/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8471 - accuracy: 0.4996 - val_loss: 0.8586 - val_accuracy: 0.5217\n",
      "Epoch 26/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8455 - accuracy: 0.4999 - val_loss: 0.8557 - val_accuracy: 0.5212\n",
      "Epoch 27/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8496 - accuracy: 0.4990 - val_loss: 0.8530 - val_accuracy: 0.5216\n",
      "Epoch 28/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8475 - accuracy: 0.4984 - val_loss: 0.8506 - val_accuracy: 0.5219\n",
      "Epoch 29/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.8470 - accuracy: 0.4962 - val_loss: 0.8482 - val_accuracy: 0.5227\n",
      "Epoch 30/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.8418 - accuracy: 0.5079 - val_loss: 0.8457 - val_accuracy: 0.5228\n",
      "Epoch 31/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8431 - accuracy: 0.4980 - val_loss: 0.8436 - val_accuracy: 0.5233\n",
      "Epoch 32/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8443 - accuracy: 0.5005 - val_loss: 0.8414 - val_accuracy: 0.5236\n",
      "Epoch 33/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8430 - accuracy: 0.4959 - val_loss: 0.8392 - val_accuracy: 0.5234\n",
      "Epoch 34/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8355 - accuracy: 0.5045 - val_loss: 0.8372 - val_accuracy: 0.5237\n",
      "Epoch 35/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8336 - accuracy: 0.5012 - val_loss: 0.8349 - val_accuracy: 0.5229\n",
      "Epoch 36/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8364 - accuracy: 0.5011 - val_loss: 0.8331 - val_accuracy: 0.5228\n",
      "Epoch 37/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8363 - accuracy: 0.5067 - val_loss: 0.8311 - val_accuracy: 0.5232\n",
      "Epoch 38/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8366 - accuracy: 0.4981 - val_loss: 0.8292 - val_accuracy: 0.5231\n",
      "Epoch 39/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.8302 - accuracy: 0.5038 - val_loss: 0.8271 - val_accuracy: 0.5228\n",
      "Epoch 40/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8324 - accuracy: 0.5019 - val_loss: 0.8253 - val_accuracy: 0.5225\n",
      "Epoch 41/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8290 - accuracy: 0.5036 - val_loss: 0.8237 - val_accuracy: 0.5225\n",
      "Epoch 42/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8258 - accuracy: 0.5046 - val_loss: 0.8218 - val_accuracy: 0.5223\n",
      "Epoch 43/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8288 - accuracy: 0.4990 - val_loss: 0.8200 - val_accuracy: 0.5221\n",
      "Epoch 44/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8305 - accuracy: 0.5013 - val_loss: 0.8182 - val_accuracy: 0.5223\n",
      "Epoch 45/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8283 - accuracy: 0.5048 - val_loss: 0.8165 - val_accuracy: 0.5225\n",
      "Epoch 46/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8276 - accuracy: 0.5057 - val_loss: 0.8150 - val_accuracy: 0.5223\n",
      "Epoch 47/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8261 - accuracy: 0.5012 - val_loss: 0.8133 - val_accuracy: 0.5215\n",
      "Epoch 48/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8174 - accuracy: 0.5020 - val_loss: 0.8116 - val_accuracy: 0.5213\n",
      "Epoch 49/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8269 - accuracy: 0.5023 - val_loss: 0.8099 - val_accuracy: 0.5212\n",
      "Epoch 50/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8160 - accuracy: 0.5019 - val_loss: 0.8082 - val_accuracy: 0.5215\n",
      "Epoch 51/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8250 - accuracy: 0.5052 - val_loss: 0.8067 - val_accuracy: 0.5215\n",
      "Epoch 52/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8167 - accuracy: 0.4995 - val_loss: 0.8052 - val_accuracy: 0.5220\n",
      "Epoch 53/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8240 - accuracy: 0.4988 - val_loss: 0.8037 - val_accuracy: 0.5220\n",
      "Epoch 54/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8172 - accuracy: 0.5041 - val_loss: 0.8024 - val_accuracy: 0.5226\n",
      "Epoch 55/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.8169 - accuracy: 0.5040 - val_loss: 0.8010 - val_accuracy: 0.5232\n",
      "Epoch 56/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8148 - accuracy: 0.5004 - val_loss: 0.7995 - val_accuracy: 0.5231\n",
      "Epoch 57/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8150 - accuracy: 0.5004 - val_loss: 0.7982 - val_accuracy: 0.5233\n",
      "Epoch 58/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8143 - accuracy: 0.5015 - val_loss: 0.7970 - val_accuracy: 0.5233\n",
      "Epoch 59/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8122 - accuracy: 0.5016 - val_loss: 0.7958 - val_accuracy: 0.5234\n",
      "Epoch 60/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8111 - accuracy: 0.4964 - val_loss: 0.7943 - val_accuracy: 0.5236\n",
      "Epoch 61/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8080 - accuracy: 0.5023 - val_loss: 0.7932 - val_accuracy: 0.5234\n",
      "Epoch 62/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8106 - accuracy: 0.5073 - val_loss: 0.7918 - val_accuracy: 0.5234\n",
      "Epoch 63/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8101 - accuracy: 0.5006 - val_loss: 0.7906 - val_accuracy: 0.5241\n",
      "Epoch 64/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8036 - accuracy: 0.5031 - val_loss: 0.7894 - val_accuracy: 0.5241\n",
      "Epoch 65/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8083 - accuracy: 0.4983 - val_loss: 0.7882 - val_accuracy: 0.5237\n",
      "Epoch 66/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8016 - accuracy: 0.5060 - val_loss: 0.7869 - val_accuracy: 0.5234\n",
      "Epoch 67/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8073 - accuracy: 0.4968 - val_loss: 0.7858 - val_accuracy: 0.5240\n",
      "Epoch 68/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8030 - accuracy: 0.4954 - val_loss: 0.7847 - val_accuracy: 0.5242\n",
      "Epoch 69/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8000 - accuracy: 0.5030 - val_loss: 0.7836 - val_accuracy: 0.5239\n",
      "Epoch 70/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8024 - accuracy: 0.5013 - val_loss: 0.7826 - val_accuracy: 0.5242\n",
      "Epoch 71/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.8031 - accuracy: 0.5000 - val_loss: 0.7814 - val_accuracy: 0.5245\n",
      "Epoch 72/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8003 - accuracy: 0.5072 - val_loss: 0.7804 - val_accuracy: 0.5247\n",
      "Epoch 73/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7993 - accuracy: 0.5004 - val_loss: 0.7793 - val_accuracy: 0.5242\n",
      "Epoch 74/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7947 - accuracy: 0.5005 - val_loss: 0.7782 - val_accuracy: 0.5250\n",
      "Epoch 75/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7930 - accuracy: 0.5025 - val_loss: 0.7773 - val_accuracy: 0.5251\n",
      "Epoch 76/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7959 - accuracy: 0.5007 - val_loss: 0.7763 - val_accuracy: 0.5258\n",
      "Epoch 77/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7984 - accuracy: 0.4990 - val_loss: 0.7755 - val_accuracy: 0.5257\n",
      "Epoch 78/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7921 - accuracy: 0.5012 - val_loss: 0.7746 - val_accuracy: 0.5254\n",
      "Epoch 79/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7905 - accuracy: 0.5016 - val_loss: 0.7737 - val_accuracy: 0.5257\n",
      "Epoch 80/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7924 - accuracy: 0.5010 - val_loss: 0.7727 - val_accuracy: 0.5267\n",
      "Epoch 81/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7906 - accuracy: 0.5009 - val_loss: 0.7718 - val_accuracy: 0.5260\n",
      "Epoch 82/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7901 - accuracy: 0.4950 - val_loss: 0.7709 - val_accuracy: 0.5259\n",
      "Epoch 83/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7904 - accuracy: 0.5013 - val_loss: 0.7701 - val_accuracy: 0.5263\n",
      "Epoch 84/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7904 - accuracy: 0.5011 - val_loss: 0.7692 - val_accuracy: 0.5266\n",
      "Epoch 85/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7907 - accuracy: 0.5031 - val_loss: 0.7683 - val_accuracy: 0.5266\n",
      "Epoch 86/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7854 - accuracy: 0.5005 - val_loss: 0.7675 - val_accuracy: 0.5275\n",
      "Epoch 87/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7886 - accuracy: 0.5002 - val_loss: 0.7665 - val_accuracy: 0.5270\n",
      "Epoch 88/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7878 - accuracy: 0.5009 - val_loss: 0.7656 - val_accuracy: 0.5278\n",
      "Epoch 89/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7828 - accuracy: 0.4997 - val_loss: 0.7648 - val_accuracy: 0.5277\n",
      "Epoch 90/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7820 - accuracy: 0.5025 - val_loss: 0.7641 - val_accuracy: 0.5281\n",
      "Epoch 91/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7842 - accuracy: 0.5004 - val_loss: 0.7634 - val_accuracy: 0.5273\n",
      "Epoch 92/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7800 - accuracy: 0.5019 - val_loss: 0.7625 - val_accuracy: 0.5283\n",
      "Epoch 93/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7813 - accuracy: 0.5031 - val_loss: 0.7617 - val_accuracy: 0.5283\n",
      "Epoch 94/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7806 - accuracy: 0.5008 - val_loss: 0.7610 - val_accuracy: 0.5280\n",
      "Epoch 95/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7833 - accuracy: 0.5007 - val_loss: 0.7603 - val_accuracy: 0.5282\n",
      "Epoch 96/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7780 - accuracy: 0.5013 - val_loss: 0.7596 - val_accuracy: 0.5288\n",
      "Epoch 97/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7799 - accuracy: 0.5012 - val_loss: 0.7589 - val_accuracy: 0.5281\n",
      "Epoch 98/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7765 - accuracy: 0.5015 - val_loss: 0.7582 - val_accuracy: 0.5278\n",
      "Epoch 99/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7772 - accuracy: 0.5028 - val_loss: 0.7575 - val_accuracy: 0.5287\n",
      "Epoch 100/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7745 - accuracy: 0.5040 - val_loss: 0.7570 - val_accuracy: 0.5287\n",
      "Epoch 101/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7715 - accuracy: 0.5035 - val_loss: 0.7563 - val_accuracy: 0.5285\n",
      "Epoch 102/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7717 - accuracy: 0.5022 - val_loss: 0.7556 - val_accuracy: 0.5283\n",
      "Epoch 103/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7737 - accuracy: 0.4979 - val_loss: 0.7550 - val_accuracy: 0.5279\n",
      "Epoch 104/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7724 - accuracy: 0.4998 - val_loss: 0.7543 - val_accuracy: 0.5284\n",
      "Epoch 105/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7683 - accuracy: 0.5001 - val_loss: 0.7537 - val_accuracy: 0.5284\n",
      "Epoch 106/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7692 - accuracy: 0.5025 - val_loss: 0.7531 - val_accuracy: 0.5286\n",
      "Epoch 107/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7697 - accuracy: 0.5011 - val_loss: 0.7525 - val_accuracy: 0.5290\n",
      "Epoch 108/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7693 - accuracy: 0.5019 - val_loss: 0.7518 - val_accuracy: 0.5294\n",
      "Epoch 109/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7698 - accuracy: 0.4999 - val_loss: 0.7512 - val_accuracy: 0.5293\n",
      "Epoch 110/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7657 - accuracy: 0.5015 - val_loss: 0.7506 - val_accuracy: 0.5294\n",
      "Epoch 111/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7669 - accuracy: 0.5004 - val_loss: 0.7499 - val_accuracy: 0.5296\n",
      "Epoch 112/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7637 - accuracy: 0.5010 - val_loss: 0.7493 - val_accuracy: 0.5302\n",
      "Epoch 113/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7610 - accuracy: 0.5060 - val_loss: 0.7487 - val_accuracy: 0.5298\n",
      "Epoch 114/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7639 - accuracy: 0.5021 - val_loss: 0.7481 - val_accuracy: 0.5299\n",
      "Epoch 115/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7614 - accuracy: 0.4981 - val_loss: 0.7474 - val_accuracy: 0.5296\n",
      "Epoch 116/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7637 - accuracy: 0.4983 - val_loss: 0.7469 - val_accuracy: 0.5303\n",
      "Epoch 117/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7603 - accuracy: 0.5026 - val_loss: 0.7462 - val_accuracy: 0.5308\n",
      "Epoch 118/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7617 - accuracy: 0.5000 - val_loss: 0.7456 - val_accuracy: 0.5315\n",
      "Epoch 119/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7581 - accuracy: 0.5019 - val_loss: 0.7450 - val_accuracy: 0.5312\n",
      "Epoch 120/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7592 - accuracy: 0.5018 - val_loss: 0.7445 - val_accuracy: 0.5317\n",
      "Epoch 121/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7554 - accuracy: 0.5002 - val_loss: 0.7439 - val_accuracy: 0.5325\n",
      "Epoch 122/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7543 - accuracy: 0.5016 - val_loss: 0.7433 - val_accuracy: 0.5330\n",
      "Epoch 123/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7538 - accuracy: 0.5012 - val_loss: 0.7428 - val_accuracy: 0.5340\n",
      "Epoch 124/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7557 - accuracy: 0.5022 - val_loss: 0.7422 - val_accuracy: 0.5342\n",
      "Epoch 125/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7547 - accuracy: 0.5006 - val_loss: 0.7417 - val_accuracy: 0.5343\n",
      "Epoch 126/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7542 - accuracy: 0.5004 - val_loss: 0.7413 - val_accuracy: 0.5342\n",
      "Epoch 127/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7522 - accuracy: 0.5003 - val_loss: 0.7407 - val_accuracy: 0.5346\n",
      "Epoch 128/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7521 - accuracy: 0.5010 - val_loss: 0.7401 - val_accuracy: 0.5345\n",
      "Epoch 129/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7504 - accuracy: 0.5029 - val_loss: 0.7396 - val_accuracy: 0.5354\n",
      "Epoch 130/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7487 - accuracy: 0.5047 - val_loss: 0.7391 - val_accuracy: 0.5351\n",
      "Epoch 131/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7476 - accuracy: 0.5018 - val_loss: 0.7386 - val_accuracy: 0.5361\n",
      "Epoch 132/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7486 - accuracy: 0.5013 - val_loss: 0.7381 - val_accuracy: 0.5366\n",
      "Epoch 133/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7498 - accuracy: 0.4994 - val_loss: 0.7376 - val_accuracy: 0.5364\n",
      "Epoch 134/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7471 - accuracy: 0.5034 - val_loss: 0.7371 - val_accuracy: 0.5367\n",
      "Epoch 135/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7455 - accuracy: 0.5043 - val_loss: 0.7366 - val_accuracy: 0.5365\n",
      "Epoch 136/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7462 - accuracy: 0.5011 - val_loss: 0.7361 - val_accuracy: 0.5358\n",
      "Epoch 137/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7432 - accuracy: 0.5029 - val_loss: 0.7356 - val_accuracy: 0.5364\n",
      "Epoch 138/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7429 - accuracy: 0.5036 - val_loss: 0.7351 - val_accuracy: 0.5377\n",
      "Epoch 139/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7421 - accuracy: 0.5013 - val_loss: 0.7346 - val_accuracy: 0.5383\n",
      "Epoch 140/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7410 - accuracy: 0.5023 - val_loss: 0.7341 - val_accuracy: 0.5385\n",
      "Epoch 141/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7398 - accuracy: 0.5030 - val_loss: 0.7336 - val_accuracy: 0.5393\n",
      "Epoch 142/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7405 - accuracy: 0.4990 - val_loss: 0.7331 - val_accuracy: 0.5401\n",
      "Epoch 143/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7408 - accuracy: 0.5023 - val_loss: 0.7327 - val_accuracy: 0.5408\n",
      "Epoch 144/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7403 - accuracy: 0.4988 - val_loss: 0.7322 - val_accuracy: 0.5408\n",
      "Epoch 145/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7378 - accuracy: 0.5031 - val_loss: 0.7318 - val_accuracy: 0.5406\n",
      "Epoch 146/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7377 - accuracy: 0.5020 - val_loss: 0.7313 - val_accuracy: 0.5410\n",
      "Epoch 147/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7367 - accuracy: 0.5015 - val_loss: 0.7308 - val_accuracy: 0.5429\n",
      "Epoch 148/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7379 - accuracy: 0.5018 - val_loss: 0.7304 - val_accuracy: 0.5437\n",
      "Epoch 149/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7349 - accuracy: 0.5021 - val_loss: 0.7299 - val_accuracy: 0.5457\n",
      "Epoch 150/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7346 - accuracy: 0.5022 - val_loss: 0.7294 - val_accuracy: 0.5474\n",
      "Epoch 151/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7344 - accuracy: 0.5018 - val_loss: 0.7289 - val_accuracy: 0.5484\n",
      "Epoch 152/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7342 - accuracy: 0.5020 - val_loss: 0.7285 - val_accuracy: 0.5475\n",
      "Epoch 153/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7342 - accuracy: 0.5010 - val_loss: 0.7281 - val_accuracy: 0.5471\n",
      "Epoch 154/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7322 - accuracy: 0.5027 - val_loss: 0.7276 - val_accuracy: 0.5481\n",
      "Epoch 155/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7311 - accuracy: 0.5035 - val_loss: 0.7272 - val_accuracy: 0.5485\n",
      "Epoch 156/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7309 - accuracy: 0.5018 - val_loss: 0.7267 - val_accuracy: 0.5491\n",
      "Epoch 157/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7308 - accuracy: 0.5024 - val_loss: 0.7263 - val_accuracy: 0.5511\n",
      "Epoch 158/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7299 - accuracy: 0.5025 - val_loss: 0.7259 - val_accuracy: 0.5514\n",
      "Epoch 159/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7301 - accuracy: 0.5012 - val_loss: 0.7255 - val_accuracy: 0.5509\n",
      "Epoch 160/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7285 - accuracy: 0.5028 - val_loss: 0.7251 - val_accuracy: 0.5505\n",
      "Epoch 161/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7282 - accuracy: 0.5019 - val_loss: 0.7247 - val_accuracy: 0.5508\n",
      "Epoch 162/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7275 - accuracy: 0.5023 - val_loss: 0.7243 - val_accuracy: 0.5512\n",
      "Epoch 163/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7267 - accuracy: 0.5024 - val_loss: 0.7239 - val_accuracy: 0.5509\n",
      "Epoch 164/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7263 - accuracy: 0.5027 - val_loss: 0.7235 - val_accuracy: 0.5512\n",
      "Epoch 165/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7257 - accuracy: 0.5026 - val_loss: 0.7231 - val_accuracy: 0.5525\n",
      "Epoch 166/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7252 - accuracy: 0.5036 - val_loss: 0.7227 - val_accuracy: 0.5524\n",
      "Epoch 167/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7250 - accuracy: 0.5019 - val_loss: 0.7223 - val_accuracy: 0.5525\n",
      "Epoch 168/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7252 - accuracy: 0.5030 - val_loss: 0.7218 - val_accuracy: 0.5540\n",
      "Epoch 169/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7241 - accuracy: 0.5018 - val_loss: 0.7214 - val_accuracy: 0.5540\n",
      "Epoch 170/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7240 - accuracy: 0.5013 - val_loss: 0.7210 - val_accuracy: 0.5554\n",
      "Epoch 171/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7229 - accuracy: 0.5013 - val_loss: 0.7206 - val_accuracy: 0.5537\n",
      "Epoch 172/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7227 - accuracy: 0.5017 - val_loss: 0.7202 - val_accuracy: 0.5549\n",
      "Epoch 173/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7218 - accuracy: 0.5021 - val_loss: 0.7198 - val_accuracy: 0.5563\n",
      "Epoch 174/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7210 - accuracy: 0.5017 - val_loss: 0.7194 - val_accuracy: 0.5561\n",
      "Epoch 175/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7211 - accuracy: 0.5020 - val_loss: 0.7190 - val_accuracy: 0.5565\n",
      "Epoch 176/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7202 - accuracy: 0.5020 - val_loss: 0.7186 - val_accuracy: 0.5563\n",
      "Epoch 177/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7192 - accuracy: 0.5041 - val_loss: 0.7182 - val_accuracy: 0.5545\n",
      "Epoch 178/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7188 - accuracy: 0.5033 - val_loss: 0.7178 - val_accuracy: 0.5568\n",
      "Epoch 179/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7186 - accuracy: 0.5031 - val_loss: 0.7174 - val_accuracy: 0.5580\n",
      "Epoch 180/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7180 - accuracy: 0.5023 - val_loss: 0.7169 - val_accuracy: 0.5561\n",
      "Epoch 181/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7180 - accuracy: 0.5020 - val_loss: 0.7165 - val_accuracy: 0.5570\n",
      "Epoch 182/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7168 - accuracy: 0.5035 - val_loss: 0.7161 - val_accuracy: 0.5578\n",
      "Epoch 183/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7165 - accuracy: 0.5026 - val_loss: 0.7157 - val_accuracy: 0.5603\n",
      "Epoch 184/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7165 - accuracy: 0.5033 - val_loss: 0.7154 - val_accuracy: 0.5627\n",
      "Epoch 185/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7154 - accuracy: 0.5021 - val_loss: 0.7150 - val_accuracy: 0.5606\n",
      "Epoch 186/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7158 - accuracy: 0.5015 - val_loss: 0.7146 - val_accuracy: 0.5622\n",
      "Epoch 187/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7148 - accuracy: 0.5032 - val_loss: 0.7142 - val_accuracy: 0.5609\n",
      "Epoch 188/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7143 - accuracy: 0.5033 - val_loss: 0.7138 - val_accuracy: 0.5637\n",
      "Epoch 189/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7139 - accuracy: 0.5027 - val_loss: 0.7135 - val_accuracy: 0.5625\n",
      "Epoch 190/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7135 - accuracy: 0.5033 - val_loss: 0.7131 - val_accuracy: 0.5657\n",
      "Epoch 191/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7132 - accuracy: 0.5024 - val_loss: 0.7127 - val_accuracy: 0.5663\n",
      "Epoch 192/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7130 - accuracy: 0.5025 - val_loss: 0.7124 - val_accuracy: 0.5625\n",
      "Epoch 193/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7128 - accuracy: 0.5029 - val_loss: 0.7120 - val_accuracy: 0.5637\n",
      "Epoch 194/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7123 - accuracy: 0.5015 - val_loss: 0.7117 - val_accuracy: 0.5638\n",
      "Epoch 195/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7116 - accuracy: 0.5029 - val_loss: 0.7113 - val_accuracy: 0.5645\n",
      "Epoch 196/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7110 - accuracy: 0.5047 - val_loss: 0.7110 - val_accuracy: 0.5679\n",
      "Epoch 197/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7110 - accuracy: 0.5038 - val_loss: 0.7106 - val_accuracy: 0.5658\n",
      "Epoch 198/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7108 - accuracy: 0.5029 - val_loss: 0.7103 - val_accuracy: 0.5681\n",
      "Epoch 199/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7103 - accuracy: 0.5034 - val_loss: 0.7100 - val_accuracy: 0.5604\n",
      "Epoch 200/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7100 - accuracy: 0.5032 - val_loss: 0.7097 - val_accuracy: 0.5608\n",
      "Epoch 201/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7095 - accuracy: 0.5037 - val_loss: 0.7094 - val_accuracy: 0.5627\n",
      "Epoch 202/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7095 - accuracy: 0.5033 - val_loss: 0.7091 - val_accuracy: 0.5654\n",
      "Epoch 203/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7091 - accuracy: 0.5028 - val_loss: 0.7088 - val_accuracy: 0.5628\n",
      "Epoch 204/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7087 - accuracy: 0.5039 - val_loss: 0.7086 - val_accuracy: 0.5688\n",
      "Epoch 205/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7087 - accuracy: 0.5021 - val_loss: 0.7083 - val_accuracy: 0.5649\n",
      "Epoch 206/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7084 - accuracy: 0.5022 - val_loss: 0.7081 - val_accuracy: 0.5628\n",
      "Epoch 207/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7081 - accuracy: 0.5020 - val_loss: 0.7078 - val_accuracy: 0.5553\n",
      "Epoch 208/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7078 - accuracy: 0.5027 - val_loss: 0.7076 - val_accuracy: 0.5503\n",
      "Epoch 209/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7077 - accuracy: 0.5029 - val_loss: 0.7074 - val_accuracy: 0.5498\n",
      "Epoch 210/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7073 - accuracy: 0.5033 - val_loss: 0.7071 - val_accuracy: 0.5451\n",
      "Epoch 211/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7070 - accuracy: 0.5040 - val_loss: 0.7069 - val_accuracy: 0.5469\n",
      "Epoch 212/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7069 - accuracy: 0.5029 - val_loss: 0.7066 - val_accuracy: 0.5442\n",
      "Epoch 213/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7065 - accuracy: 0.5027 - val_loss: 0.7063 - val_accuracy: 0.5356\n",
      "Epoch 214/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7062 - accuracy: 0.5040 - val_loss: 0.7061 - val_accuracy: 0.5336\n",
      "Epoch 215/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7060 - accuracy: 0.5027 - val_loss: 0.7058 - val_accuracy: 0.5342\n",
      "Epoch 216/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7058 - accuracy: 0.5031 - val_loss: 0.7056 - val_accuracy: 0.5317\n",
      "Epoch 217/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7056 - accuracy: 0.5020 - val_loss: 0.7054 - val_accuracy: 0.5265\n",
      "Epoch 218/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7053 - accuracy: 0.5032 - val_loss: 0.7051 - val_accuracy: 0.5298\n",
      "Epoch 219/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7050 - accuracy: 0.5055 - val_loss: 0.7049 - val_accuracy: 0.5270\n",
      "Epoch 220/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7049 - accuracy: 0.5024 - val_loss: 0.7047 - val_accuracy: 0.5247\n",
      "Epoch 221/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7046 - accuracy: 0.5020 - val_loss: 0.7045 - val_accuracy: 0.5238\n",
      "Epoch 222/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7044 - accuracy: 0.5023 - val_loss: 0.7042 - val_accuracy: 0.5193\n",
      "Epoch 223/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7042 - accuracy: 0.5019 - val_loss: 0.7040 - val_accuracy: 0.5178\n",
      "Epoch 224/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7039 - accuracy: 0.5019 - val_loss: 0.7038 - val_accuracy: 0.5123\n",
      "Epoch 225/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7037 - accuracy: 0.5024 - val_loss: 0.7036 - val_accuracy: 0.5109\n",
      "Epoch 226/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7035 - accuracy: 0.5022 - val_loss: 0.7034 - val_accuracy: 0.5091\n",
      "Epoch 227/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7033 - accuracy: 0.5020 - val_loss: 0.7031 - val_accuracy: 0.5075\n",
      "Epoch 228/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7030 - accuracy: 0.5026 - val_loss: 0.7029 - val_accuracy: 0.5054\n",
      "Epoch 229/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7028 - accuracy: 0.5014 - val_loss: 0.7027 - val_accuracy: 0.5036\n",
      "Epoch 230/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7026 - accuracy: 0.5016 - val_loss: 0.7025 - val_accuracy: 0.5017\n",
      "Epoch 231/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7024 - accuracy: 0.5016 - val_loss: 0.7023 - val_accuracy: 0.5001\n",
      "Epoch 232/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7022 - accuracy: 0.5013 - val_loss: 0.7020 - val_accuracy: 0.5001\n",
      "Epoch 233/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7019 - accuracy: 0.5020 - val_loss: 0.7018 - val_accuracy: 0.5001\n",
      "Epoch 234/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7017 - accuracy: 0.5011 - val_loss: 0.7016 - val_accuracy: 0.5001\n",
      "Epoch 235/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7014 - accuracy: 0.5011 - val_loss: 0.7013 - val_accuracy: 0.5001\n",
      "Epoch 236/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7012 - accuracy: 0.5003 - val_loss: 0.7011 - val_accuracy: 0.5001\n",
      "Epoch 237/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7010 - accuracy: 0.5003 - val_loss: 0.7009 - val_accuracy: 0.5001\n",
      "Epoch 238/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7008 - accuracy: 0.5003 - val_loss: 0.7007 - val_accuracy: 0.5001\n",
      "Epoch 239/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7006 - accuracy: 0.5003 - val_loss: 0.7005 - val_accuracy: 0.5001\n",
      "Epoch 240/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7004 - accuracy: 0.5003 - val_loss: 0.7003 - val_accuracy: 0.5001\n",
      "Epoch 241/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7002 - accuracy: 0.5003 - val_loss: 0.7001 - val_accuracy: 0.5001\n",
      "Epoch 242/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7000 - accuracy: 0.5003 - val_loss: 0.6999 - val_accuracy: 0.5001\n",
      "Epoch 243/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6998 - accuracy: 0.5003 - val_loss: 0.6997 - val_accuracy: 0.5001\n",
      "Epoch 244/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6996 - accuracy: 0.5003 - val_loss: 0.6995 - val_accuracy: 0.5001\n",
      "Epoch 245/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6994 - accuracy: 0.5003 - val_loss: 0.6993 - val_accuracy: 0.5001\n",
      "Epoch 246/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6992 - accuracy: 0.5003 - val_loss: 0.6991 - val_accuracy: 0.5001\n",
      "Epoch 247/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6990 - accuracy: 0.5003 - val_loss: 0.6989 - val_accuracy: 0.5001\n",
      "Epoch 248/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6988 - accuracy: 0.5003 - val_loss: 0.6987 - val_accuracy: 0.5001\n",
      "Epoch 249/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6986 - accuracy: 0.5003 - val_loss: 0.6985 - val_accuracy: 0.5001\n",
      "Epoch 250/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.6984 - accuracy: 0.5003 - val_loss: 0.6983 - val_accuracy: 0.5001\n",
      "Epoch 251/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6982 - accuracy: 0.5003 - val_loss: 0.6981 - val_accuracy: 0.5001\n",
      "Epoch 252/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6980 - accuracy: 0.5003 - val_loss: 0.6979 - val_accuracy: 0.5001\n",
      "Epoch 253/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6978 - accuracy: 0.5003 - val_loss: 0.6977 - val_accuracy: 0.5001\n",
      "Epoch 254/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6976 - accuracy: 0.5003 - val_loss: 0.6975 - val_accuracy: 0.5001\n",
      "Epoch 255/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6974 - accuracy: 0.5003 - val_loss: 0.6973 - val_accuracy: 0.5001\n",
      "Epoch 256/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6972 - accuracy: 0.5003 - val_loss: 0.6971 - val_accuracy: 0.5001\n",
      "Epoch 257/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6970 - accuracy: 0.5003 - val_loss: 0.6969 - val_accuracy: 0.5001\n",
      "Epoch 258/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6968 - accuracy: 0.5003 - val_loss: 0.6967 - val_accuracy: 0.5001\n",
      "Epoch 259/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6966 - accuracy: 0.5003 - val_loss: 0.6965 - val_accuracy: 0.5001\n",
      "Epoch 260/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6964 - accuracy: 0.5003 - val_loss: 0.6963 - val_accuracy: 0.5001\n",
      "Epoch 261/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6962 - accuracy: 0.5003 - val_loss: 0.6961 - val_accuracy: 0.5001\n",
      "Epoch 262/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6960 - accuracy: 0.5003 - val_loss: 0.6959 - val_accuracy: 0.5001\n",
      "Epoch 263/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6959 - accuracy: 0.5003 - val_loss: 0.6958 - val_accuracy: 0.5001\n",
      "Epoch 264/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6957 - accuracy: 0.5003 - val_loss: 0.6957 - val_accuracy: 0.5001\n",
      "Epoch 265/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6956 - accuracy: 0.5003 - val_loss: 0.6955 - val_accuracy: 0.5001\n",
      "Epoch 266/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6955 - accuracy: 0.5003 - val_loss: 0.6954 - val_accuracy: 0.5001\n",
      "Epoch 267/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6953 - accuracy: 0.5003 - val_loss: 0.6953 - val_accuracy: 0.5001\n",
      "Epoch 268/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6952 - accuracy: 0.5003 - val_loss: 0.6951 - val_accuracy: 0.5001\n",
      "Epoch 269/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6951 - accuracy: 0.5003 - val_loss: 0.6950 - val_accuracy: 0.5001\n",
      "Epoch 270/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6949 - accuracy: 0.5003 - val_loss: 0.6949 - val_accuracy: 0.5001\n",
      "Epoch 271/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6948 - accuracy: 0.5003 - val_loss: 0.6947 - val_accuracy: 0.5001\n",
      "Epoch 272/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6947 - accuracy: 0.5003 - val_loss: 0.6946 - val_accuracy: 0.5001\n",
      "Epoch 273/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6945 - accuracy: 0.5003 - val_loss: 0.6945 - val_accuracy: 0.5001\n",
      "Epoch 274/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6944 - accuracy: 0.5003 - val_loss: 0.6943 - val_accuracy: 0.5001\n",
      "Epoch 275/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6943 - accuracy: 0.5003 - val_loss: 0.6942 - val_accuracy: 0.5001\n",
      "Epoch 276/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6941 - accuracy: 0.5003 - val_loss: 0.6941 - val_accuracy: 0.5001\n",
      "Epoch 277/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6940 - accuracy: 0.5003 - val_loss: 0.6939 - val_accuracy: 0.5001\n",
      "Epoch 278/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6939 - accuracy: 0.5003 - val_loss: 0.6938 - val_accuracy: 0.5001\n",
      "Epoch 279/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6938 - accuracy: 0.5003 - val_loss: 0.6938 - val_accuracy: 0.5001\n",
      "Epoch 280/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6937 - accuracy: 0.5003 - val_loss: 0.6937 - val_accuracy: 0.5001\n",
      "Epoch 281/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.6937 - accuracy: 0.5003 - val_loss: 0.6936 - val_accuracy: 0.5001\n",
      "Epoch 282/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6936 - accuracy: 0.5003 - val_loss: 0.6936 - val_accuracy: 0.5001\n",
      "Epoch 283/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6935 - accuracy: 0.5003 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 284/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6935 - accuracy: 0.5003 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
      "Epoch 285/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
      "Epoch 286/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 287/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 288/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 289/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 290/300\n",
      "666/670 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5001Restoring model weights from the end of the best epoch: 289.\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.5001\n",
      "Epoch 290: early stopping\n",
      "620/620 [==============================] - 2s 3ms/step - loss: 0.6932 - accuracy: 0.5001\n",
      "{'loss': 0.6931552886962891, 'accuracy': 0.5001260638237} \n",
      " 289 \n",
      "\n",
      "Model time: 16.26344880834222 minutes\n",
      "\n",
      "Total time: 197.06326257437468 minutes\n",
      "\n",
      "\n",
      "Model  102  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                   256\n",
      "Activation function           relu\n",
      "Dropout                        0.9\n",
      "L1                           100.0\n",
      "L2                             0.1\n",
      "Batch size                       8\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 2718339, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 21s 7ms/step - loss: 10354.3105 - accuracy: 0.4977 - val_loss: 1385.7504 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "2674/2677 [============================>.] - ETA: 0s - loss: 1391.8397 - accuracy: 0.4968Restoring model weights from the end of the best epoch: 1.\n",
      "2677/2677 [==============================] - 19s 7ms/step - loss: 1391.8422 - accuracy: 0.4968 - val_loss: 1390.8242 - val_accuracy: 0.5001\n",
      "Epoch 2: early stopping\n",
      "2480/2480 [==============================] - 7s 3ms/step - loss: 1385.7504 - accuracy: 0.4999\n",
      "{'loss': 1385.7503662109375, 'accuracy': 0.49987393617630005} \n",
      " 1 \n",
      "\n",
      "Model time: 0.7915889881551266 minutes\n",
      "\n",
      "Total time: 197.85493487864733 minutes\n",
      "\n",
      "\n",
      "Model  103  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     8\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.4\n",
      "L1                            10.0\n",
      "L2                           100.0\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 1999356, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 9s 5ms/step - loss: 3864.1353 - accuracy: 0.4996 - val_loss: 3587.5464 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 3333.2900 - accuracy: 0.4974 - val_loss: 3088.6328 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2864.0283 - accuracy: 0.4930 - val_loss: 2648.0593 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2450.6655 - accuracy: 0.4978 - val_loss: 2261.5334 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2090.7686 - accuracy: 0.4957 - val_loss: 1927.3988 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1779.8768 - accuracy: 0.5024 - val_loss: 1639.4796 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1513.5305 - accuracy: 0.5059 - val_loss: 1393.8463 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "1339/1339 [==============================] - 9s 7ms/step - loss: 1287.9518 - accuracy: 0.4972 - val_loss: 1187.7999 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1100.0403 - accuracy: 0.4994 - val_loss: 1017.5816 - val_accuracy: 0.4999\n",
      "Epoch 10/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 945.6348 - accuracy: 0.4974 - val_loss: 878.0917 - val_accuracy: 0.4999\n",
      "Epoch 11/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 819.7322 - accuracy: 0.5023 - val_loss: 765.4044 - val_accuracy: 0.4999\n",
      "Epoch 12/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 720.0716 - accuracy: 0.4977 - val_loss: 678.7296 - val_accuracy: 0.4999\n",
      "Epoch 13/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 645.0970 - accuracy: 0.5011 - val_loss: 614.3626 - val_accuracy: 0.4999\n",
      "Epoch 14/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 589.2988 - accuracy: 0.4995 - val_loss: 566.2947 - val_accuracy: 0.4999\n",
      "Epoch 15/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 544.7396 - accuracy: 0.4957 - val_loss: 523.4329 - val_accuracy: 0.4999\n",
      "Epoch 16/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 502.9137 - accuracy: 0.4971 - val_loss: 482.6230 - val_accuracy: 0.4999\n",
      "Epoch 17/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 463.1313 - accuracy: 0.4995 - val_loss: 443.9379 - val_accuracy: 0.4999\n",
      "Epoch 18/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 425.5692 - accuracy: 0.4973 - val_loss: 407.4437 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 390.1730 - accuracy: 0.4995 - val_loss: 373.2133 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 356.9987 - accuracy: 0.5012 - val_loss: 341.0003 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 325.6566 - accuracy: 0.4995 - val_loss: 310.5606 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 296.1816 - accuracy: 0.4991 - val_loss: 282.0262 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 268.5812 - accuracy: 0.5064 - val_loss: 255.3489 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 242.7519 - accuracy: 0.4999 - val_loss: 230.3627 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 218.5921 - accuracy: 0.5036 - val_loss: 207.0210 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 196.0721 - accuracy: 0.4974 - val_loss: 185.3894 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 175.3307 - accuracy: 0.4979 - val_loss: 165.4743 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 156.1786 - accuracy: 0.4996 - val_loss: 147.0901 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 138.6534 - accuracy: 0.4998 - val_loss: 130.4799 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 122.8182 - accuracy: 0.4988 - val_loss: 115.3513 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 108.3291 - accuracy: 0.4966 - val_loss: 101.4592 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 95.0104 - accuracy: 0.5025 - val_loss: 88.7253 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 82.8689 - accuracy: 0.4996 - val_loss: 77.1892 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 71.8404 - accuracy: 0.5010 - val_loss: 66.6410 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 61.7701 - accuracy: 0.4983 - val_loss: 57.0153 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 52.6217 - accuracy: 0.5017 - val_loss: 48.3866 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 44.4957 - accuracy: 0.4973 - val_loss: 40.7057 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 37.1720 - accuracy: 0.5044 - val_loss: 33.7662 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 30.7410 - accuracy: 0.4947 - val_loss: 27.8312 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 25.1945 - accuracy: 0.5011 - val_loss: 22.6509 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 20.3100 - accuracy: 0.5046 - val_loss: 18.0746 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 16.2593 - accuracy: 0.4986 - val_loss: 14.5540 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 13.0550 - accuracy: 0.5038 - val_loss: 11.6685 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 10.4174 - accuracy: 0.5049 - val_loss: 9.2155 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 8.1876 - accuracy: 0.5021 - val_loss: 7.2919 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 6.6235 - accuracy: 0.4975 - val_loss: 6.0198 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 5.4953 - accuracy: 0.4928 - val_loss: 4.9859 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 4.5143 - accuracy: 0.5031 - val_loss: 4.0594 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 3.6501 - accuracy: 0.5003 - val_loss: 3.2860 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2.9762 - accuracy: 0.5003 - val_loss: 2.6775 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.4034 - accuracy: 0.5003 - val_loss: 2.1405 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.9022 - accuracy: 0.5003 - val_loss: 1.6751 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.4924 - accuracy: 0.5003 - val_loss: 1.3500 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.2343 - accuracy: 0.5003 - val_loss: 1.1239 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.0260 - accuracy: 0.5003 - val_loss: 0.9338 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.8534 - accuracy: 0.5003 - val_loss: 0.7792 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7679 - accuracy: 0.5003 - val_loss: 0.7674 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7673 - accuracy: 0.5003 - val_loss: 0.7673 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7672 - accuracy: 0.5003 - val_loss: 0.7672 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7672 - accuracy: 0.5003 - val_loss: 0.7672 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7671 - accuracy: 0.5003 - val_loss: 0.7670 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7670 - accuracy: 0.5003 - val_loss: 0.7670 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7670 - accuracy: 0.5003 - val_loss: 0.7669 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7669 - accuracy: 0.5003 - val_loss: 0.7668 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7668 - accuracy: 0.5003 - val_loss: 0.7668 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7668 - accuracy: 0.5003 - val_loss: 0.7667 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "1328/1339 [============================>.] - ETA: 0s - loss: 0.7668 - accuracy: 0.5002Restoring model weights from the end of the best epoch: 66.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7668 - accuracy: 0.5003 - val_loss: 0.7667 - val_accuracy: 0.5001\n",
      "Epoch 67: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 0.7667 - accuracy: 0.5001\n",
      "{'loss': 0.7666903138160706, 'accuracy': 0.5001260638237} \n",
      " 66 \n",
      "\n",
      "Model time: 7.306585215032101 minutes\n",
      "\n",
      "Total time: 205.16162006929517 minutes\n",
      "\n",
      "\n",
      "Model  104  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                     4\n",
      "Activation function           relu\n",
      "Dropout                        0.7\n",
      "L1                          0.0001\n",
      "L2                             0.1\n",
      "Batch size                     256\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 5979116, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 5s 18ms/step - loss: 3.6883 - accuracy: 0.4972 - val_loss: 3.3527 - val_accuracy: 0.4963\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.6232 - accuracy: 0.4994 - val_loss: 3.3411 - val_accuracy: 0.4956\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.7239 - accuracy: 0.5004 - val_loss: 3.3294 - val_accuracy: 0.4953\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.6746 - accuracy: 0.5000 - val_loss: 3.3178 - val_accuracy: 0.4952\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 3.6069 - accuracy: 0.4996 - val_loss: 3.3066 - val_accuracy: 0.4951\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.5813 - accuracy: 0.5002 - val_loss: 3.2948 - val_accuracy: 0.4950\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.6308 - accuracy: 0.4982 - val_loss: 3.2830 - val_accuracy: 0.4957\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.5659 - accuracy: 0.4997 - val_loss: 3.2717 - val_accuracy: 0.4951\n",
      "Epoch 9/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 3.5886 - accuracy: 0.4990 - val_loss: 3.2605 - val_accuracy: 0.4943\n",
      "Epoch 10/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.5277 - accuracy: 0.5013 - val_loss: 3.2491 - val_accuracy: 0.4933\n",
      "Epoch 11/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.5474 - accuracy: 0.5007 - val_loss: 3.2380 - val_accuracy: 0.4928\n",
      "Epoch 12/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 3.5177 - accuracy: 0.5015 - val_loss: 3.2270 - val_accuracy: 0.4926\n",
      "Epoch 13/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.6078 - accuracy: 0.4988 - val_loss: 3.2163 - val_accuracy: 0.4921\n",
      "Epoch 14/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.4870 - accuracy: 0.5000 - val_loss: 3.2053 - val_accuracy: 0.4905\n",
      "Epoch 15/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.5487 - accuracy: 0.4996 - val_loss: 3.1945 - val_accuracy: 0.4899\n",
      "Epoch 16/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 3.4710 - accuracy: 0.5007 - val_loss: 3.1838 - val_accuracy: 0.4894\n",
      "Epoch 17/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 3.4084 - accuracy: 0.5016 - val_loss: 3.1730 - val_accuracy: 0.4881\n",
      "Epoch 18/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.4386 - accuracy: 0.4997 - val_loss: 3.1623 - val_accuracy: 0.4880\n",
      "Epoch 19/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.4123 - accuracy: 0.5014 - val_loss: 3.1516 - val_accuracy: 0.4881\n",
      "Epoch 20/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.3972 - accuracy: 0.5011 - val_loss: 3.1410 - val_accuracy: 0.4876\n",
      "Epoch 21/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.3783 - accuracy: 0.5010 - val_loss: 3.1304 - val_accuracy: 0.4884\n",
      "Epoch 22/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.3900 - accuracy: 0.5004 - val_loss: 3.1200 - val_accuracy: 0.4876\n",
      "Epoch 23/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.3741 - accuracy: 0.5001 - val_loss: 3.1096 - val_accuracy: 0.4870\n",
      "Epoch 24/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.3323 - accuracy: 0.5000 - val_loss: 3.0988 - val_accuracy: 0.4868\n",
      "Epoch 25/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 3.3271 - accuracy: 0.5011 - val_loss: 3.0884 - val_accuracy: 0.4864\n",
      "Epoch 26/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 3.2668 - accuracy: 0.5016 - val_loss: 3.0777 - val_accuracy: 0.4861\n",
      "Epoch 27/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.2439 - accuracy: 0.5013 - val_loss: 3.0675 - val_accuracy: 0.4849\n",
      "Epoch 28/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 3.3157 - accuracy: 0.4992 - val_loss: 3.0573 - val_accuracy: 0.4842\n",
      "Epoch 29/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.2699 - accuracy: 0.5005 - val_loss: 3.0471 - val_accuracy: 0.4833\n",
      "Epoch 30/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.2582 - accuracy: 0.4999 - val_loss: 3.0370 - val_accuracy: 0.4825\n",
      "Epoch 31/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 3.2751 - accuracy: 0.5001 - val_loss: 3.0270 - val_accuracy: 0.4816\n",
      "Epoch 32/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.2778 - accuracy: 0.5010 - val_loss: 3.0170 - val_accuracy: 0.4809\n",
      "Epoch 33/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.2194 - accuracy: 0.5012 - val_loss: 3.0071 - val_accuracy: 0.4810\n",
      "Epoch 34/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.1921 - accuracy: 0.4997 - val_loss: 2.9971 - val_accuracy: 0.4802\n",
      "Epoch 35/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.1858 - accuracy: 0.5000 - val_loss: 2.9873 - val_accuracy: 0.4798\n",
      "Epoch 36/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.1475 - accuracy: 0.4994 - val_loss: 2.9775 - val_accuracy: 0.4788\n",
      "Epoch 37/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 3.2060 - accuracy: 0.5003 - val_loss: 2.9677 - val_accuracy: 0.4779\n",
      "Epoch 38/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 3.1689 - accuracy: 0.5003 - val_loss: 2.9581 - val_accuracy: 0.4782\n",
      "Epoch 39/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.1527 - accuracy: 0.4996 - val_loss: 2.9484 - val_accuracy: 0.4778\n",
      "Epoch 40/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 3.1203 - accuracy: 0.5026 - val_loss: 2.9389 - val_accuracy: 0.4764\n",
      "Epoch 41/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.1294 - accuracy: 0.5003 - val_loss: 2.9293 - val_accuracy: 0.4754\n",
      "Epoch 42/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.1007 - accuracy: 0.5017 - val_loss: 2.9196 - val_accuracy: 0.4735\n",
      "Epoch 43/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 3.1078 - accuracy: 0.4996 - val_loss: 2.9103 - val_accuracy: 0.4724\n",
      "Epoch 44/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.0946 - accuracy: 0.4991 - val_loss: 2.9007 - val_accuracy: 0.4728\n",
      "Epoch 45/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.0785 - accuracy: 0.4999 - val_loss: 2.8916 - val_accuracy: 0.4717\n",
      "Epoch 46/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.0145 - accuracy: 0.5011 - val_loss: 2.8820 - val_accuracy: 0.4696\n",
      "Epoch 47/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.0937 - accuracy: 0.5002 - val_loss: 2.8729 - val_accuracy: 0.4702\n",
      "Epoch 48/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.0472 - accuracy: 0.5017 - val_loss: 2.8639 - val_accuracy: 0.4691\n",
      "Epoch 49/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 3.0725 - accuracy: 0.5014 - val_loss: 2.8549 - val_accuracy: 0.4696\n",
      "Epoch 50/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.0073 - accuracy: 0.4996 - val_loss: 2.8457 - val_accuracy: 0.4705\n",
      "Epoch 51/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.9697 - accuracy: 0.5010 - val_loss: 2.8363 - val_accuracy: 0.4722\n",
      "Epoch 52/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.9943 - accuracy: 0.4998 - val_loss: 2.8272 - val_accuracy: 0.4722\n",
      "Epoch 53/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.9857 - accuracy: 0.5008 - val_loss: 2.8184 - val_accuracy: 0.4724\n",
      "Epoch 54/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 2.9920 - accuracy: 0.5010 - val_loss: 2.8097 - val_accuracy: 0.4730\n",
      "Epoch 55/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.9663 - accuracy: 0.4995 - val_loss: 2.8007 - val_accuracy: 0.4729\n",
      "Epoch 56/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.9310 - accuracy: 0.5015 - val_loss: 2.7920 - val_accuracy: 0.4734\n",
      "Epoch 57/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.9527 - accuracy: 0.4989 - val_loss: 2.7833 - val_accuracy: 0.4729\n",
      "Epoch 58/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.9380 - accuracy: 0.5003 - val_loss: 2.7748 - val_accuracy: 0.4733\n",
      "Epoch 59/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.9284 - accuracy: 0.4990 - val_loss: 2.7662 - val_accuracy: 0.4728\n",
      "Epoch 60/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.9364 - accuracy: 0.4995 - val_loss: 2.7577 - val_accuracy: 0.4733\n",
      "Epoch 61/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.8698 - accuracy: 0.5016 - val_loss: 2.7489 - val_accuracy: 0.4739\n",
      "Epoch 62/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.8890 - accuracy: 0.5002 - val_loss: 2.7406 - val_accuracy: 0.4733\n",
      "Epoch 63/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.8560 - accuracy: 0.4995 - val_loss: 2.7316 - val_accuracy: 0.4742\n",
      "Epoch 64/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.8716 - accuracy: 0.5002 - val_loss: 2.7234 - val_accuracy: 0.4740\n",
      "Epoch 65/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.8410 - accuracy: 0.5009 - val_loss: 2.7152 - val_accuracy: 0.4748\n",
      "Epoch 66/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.8302 - accuracy: 0.4998 - val_loss: 2.7068 - val_accuracy: 0.4745\n",
      "Epoch 67/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.8385 - accuracy: 0.4998 - val_loss: 2.6983 - val_accuracy: 0.4753\n",
      "Epoch 68/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.8312 - accuracy: 0.5002 - val_loss: 2.6899 - val_accuracy: 0.4759\n",
      "Epoch 69/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.8013 - accuracy: 0.4998 - val_loss: 2.6812 - val_accuracy: 0.4764\n",
      "Epoch 70/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.7953 - accuracy: 0.5000 - val_loss: 2.6729 - val_accuracy: 0.4775\n",
      "Epoch 71/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.8654 - accuracy: 0.4991 - val_loss: 2.6652 - val_accuracy: 0.4780\n",
      "Epoch 72/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.7647 - accuracy: 0.5004 - val_loss: 2.6571 - val_accuracy: 0.4781\n",
      "Epoch 73/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.7684 - accuracy: 0.5008 - val_loss: 2.6487 - val_accuracy: 0.4786\n",
      "Epoch 74/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 2.7277 - accuracy: 0.5016 - val_loss: 2.6405 - val_accuracy: 0.4792\n",
      "Epoch 75/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.7303 - accuracy: 0.5006 - val_loss: 2.6322 - val_accuracy: 0.4796\n",
      "Epoch 76/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.7309 - accuracy: 0.5007 - val_loss: 2.6241 - val_accuracy: 0.4780\n",
      "Epoch 77/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.7285 - accuracy: 0.5003 - val_loss: 2.6160 - val_accuracy: 0.4780\n",
      "Epoch 78/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.7273 - accuracy: 0.5000 - val_loss: 2.6081 - val_accuracy: 0.4778\n",
      "Epoch 79/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.7364 - accuracy: 0.5003 - val_loss: 2.6004 - val_accuracy: 0.4787\n",
      "Epoch 80/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.6927 - accuracy: 0.5013 - val_loss: 2.5924 - val_accuracy: 0.4798\n",
      "Epoch 81/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.6760 - accuracy: 0.5004 - val_loss: 2.5843 - val_accuracy: 0.4803\n",
      "Epoch 82/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.6816 - accuracy: 0.5004 - val_loss: 2.5765 - val_accuracy: 0.4802\n",
      "Epoch 83/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.6729 - accuracy: 0.5017 - val_loss: 2.5686 - val_accuracy: 0.4807\n",
      "Epoch 84/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.6681 - accuracy: 0.5007 - val_loss: 2.5609 - val_accuracy: 0.4813\n",
      "Epoch 85/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.6464 - accuracy: 0.5010 - val_loss: 2.5531 - val_accuracy: 0.4810\n",
      "Epoch 86/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.6242 - accuracy: 0.5016 - val_loss: 2.5452 - val_accuracy: 0.4807\n",
      "Epoch 87/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.6327 - accuracy: 0.5007 - val_loss: 2.5374 - val_accuracy: 0.4816\n",
      "Epoch 88/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.6354 - accuracy: 0.5019 - val_loss: 2.5298 - val_accuracy: 0.4818\n",
      "Epoch 89/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.5963 - accuracy: 0.5008 - val_loss: 2.5223 - val_accuracy: 0.4826\n",
      "Epoch 90/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 2.6212 - accuracy: 0.4992 - val_loss: 2.5148 - val_accuracy: 0.4825\n",
      "Epoch 91/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.6049 - accuracy: 0.5004 - val_loss: 2.5073 - val_accuracy: 0.4831\n",
      "Epoch 92/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.5825 - accuracy: 0.5006 - val_loss: 2.4997 - val_accuracy: 0.4833\n",
      "Epoch 93/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.5939 - accuracy: 0.5001 - val_loss: 2.4924 - val_accuracy: 0.4842\n",
      "Epoch 94/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.5606 - accuracy: 0.4999 - val_loss: 2.4851 - val_accuracy: 0.4843\n",
      "Epoch 95/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.5873 - accuracy: 0.5004 - val_loss: 2.4779 - val_accuracy: 0.4849\n",
      "Epoch 96/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.5735 - accuracy: 0.5005 - val_loss: 2.4708 - val_accuracy: 0.4855\n",
      "Epoch 97/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 2.5269 - accuracy: 0.5009 - val_loss: 2.4634 - val_accuracy: 0.4863\n",
      "Epoch 98/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.5252 - accuracy: 0.5011 - val_loss: 2.4560 - val_accuracy: 0.4871\n",
      "Epoch 99/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.5234 - accuracy: 0.5011 - val_loss: 2.4484 - val_accuracy: 0.4859\n",
      "Epoch 100/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 2.5421 - accuracy: 0.5008 - val_loss: 2.4412 - val_accuracy: 0.4868\n",
      "Epoch 101/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.5191 - accuracy: 0.5005 - val_loss: 2.4343 - val_accuracy: 0.4864\n",
      "Epoch 102/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.5131 - accuracy: 0.4989 - val_loss: 2.4271 - val_accuracy: 0.4868\n",
      "Epoch 103/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.4773 - accuracy: 0.5012 - val_loss: 2.4196 - val_accuracy: 0.4873\n",
      "Epoch 104/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.5077 - accuracy: 0.4991 - val_loss: 2.4124 - val_accuracy: 0.4884\n",
      "Epoch 105/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.4856 - accuracy: 0.5007 - val_loss: 2.4054 - val_accuracy: 0.4890\n",
      "Epoch 106/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 2.4598 - accuracy: 0.5013 - val_loss: 2.3983 - val_accuracy: 0.4895\n",
      "Epoch 107/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.4594 - accuracy: 0.4998 - val_loss: 2.3911 - val_accuracy: 0.4898\n",
      "Epoch 108/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.4509 - accuracy: 0.5013 - val_loss: 2.3841 - val_accuracy: 0.4905\n",
      "Epoch 109/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.4545 - accuracy: 0.4992 - val_loss: 2.3772 - val_accuracy: 0.4914\n",
      "Epoch 110/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.4352 - accuracy: 0.5004 - val_loss: 2.3704 - val_accuracy: 0.4918\n",
      "Epoch 111/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.4392 - accuracy: 0.4996 - val_loss: 2.3634 - val_accuracy: 0.4921\n",
      "Epoch 112/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.3955 - accuracy: 0.5011 - val_loss: 2.3561 - val_accuracy: 0.4925\n",
      "Epoch 113/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.4130 - accuracy: 0.5011 - val_loss: 2.3492 - val_accuracy: 0.4929\n",
      "Epoch 114/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3999 - accuracy: 0.5003 - val_loss: 2.3426 - val_accuracy: 0.4934\n",
      "Epoch 115/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3881 - accuracy: 0.4994 - val_loss: 2.3359 - val_accuracy: 0.4939\n",
      "Epoch 116/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3952 - accuracy: 0.5003 - val_loss: 2.3292 - val_accuracy: 0.4939\n",
      "Epoch 117/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.4058 - accuracy: 0.4998 - val_loss: 2.3228 - val_accuracy: 0.4942\n",
      "Epoch 118/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3654 - accuracy: 0.5009 - val_loss: 2.3157 - val_accuracy: 0.4952\n",
      "Epoch 119/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3817 - accuracy: 0.5011 - val_loss: 2.3094 - val_accuracy: 0.4955\n",
      "Epoch 120/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3579 - accuracy: 0.5008 - val_loss: 2.3028 - val_accuracy: 0.4959\n",
      "Epoch 121/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3685 - accuracy: 0.5006 - val_loss: 2.2963 - val_accuracy: 0.4957\n",
      "Epoch 122/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3389 - accuracy: 0.5001 - val_loss: 2.2898 - val_accuracy: 0.4958\n",
      "Epoch 123/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.3339 - accuracy: 0.5004 - val_loss: 2.2832 - val_accuracy: 0.4958\n",
      "Epoch 124/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.3376 - accuracy: 0.5000 - val_loss: 2.2765 - val_accuracy: 0.4957\n",
      "Epoch 125/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.3307 - accuracy: 0.5009 - val_loss: 2.2701 - val_accuracy: 0.4964\n",
      "Epoch 126/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.3294 - accuracy: 0.5007 - val_loss: 2.2637 - val_accuracy: 0.4965\n",
      "Epoch 127/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3145 - accuracy: 0.5011 - val_loss: 2.2573 - val_accuracy: 0.4969\n",
      "Epoch 128/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3214 - accuracy: 0.5005 - val_loss: 2.2510 - val_accuracy: 0.4973\n",
      "Epoch 129/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.2949 - accuracy: 0.4992 - val_loss: 2.2447 - val_accuracy: 0.4968\n",
      "Epoch 130/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2837 - accuracy: 0.5008 - val_loss: 2.2383 - val_accuracy: 0.4968\n",
      "Epoch 131/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2642 - accuracy: 0.5011 - val_loss: 2.2316 - val_accuracy: 0.4972\n",
      "Epoch 132/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.2664 - accuracy: 0.5008 - val_loss: 2.2254 - val_accuracy: 0.4977\n",
      "Epoch 133/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 2.2838 - accuracy: 0.5000 - val_loss: 2.2192 - val_accuracy: 0.4977\n",
      "Epoch 134/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2661 - accuracy: 0.5005 - val_loss: 2.2130 - val_accuracy: 0.4977\n",
      "Epoch 135/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.2460 - accuracy: 0.5016 - val_loss: 2.2067 - val_accuracy: 0.4977\n",
      "Epoch 136/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2496 - accuracy: 0.4998 - val_loss: 2.2003 - val_accuracy: 0.4979\n",
      "Epoch 137/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2344 - accuracy: 0.5004 - val_loss: 2.1939 - val_accuracy: 0.4984\n",
      "Epoch 138/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.2392 - accuracy: 0.5008 - val_loss: 2.1878 - val_accuracy: 0.4985\n",
      "Epoch 139/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2180 - accuracy: 0.5002 - val_loss: 2.1815 - val_accuracy: 0.4986\n",
      "Epoch 140/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.2053 - accuracy: 0.5010 - val_loss: 2.1753 - val_accuracy: 0.4984\n",
      "Epoch 141/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2200 - accuracy: 0.4993 - val_loss: 2.1692 - val_accuracy: 0.4984\n",
      "Epoch 142/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2092 - accuracy: 0.5002 - val_loss: 2.1632 - val_accuracy: 0.4984\n",
      "Epoch 143/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.1898 - accuracy: 0.5011 - val_loss: 2.1570 - val_accuracy: 0.4984\n",
      "Epoch 144/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.1915 - accuracy: 0.5002 - val_loss: 2.1512 - val_accuracy: 0.4984\n",
      "Epoch 145/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.1890 - accuracy: 0.5010 - val_loss: 2.1453 - val_accuracy: 0.4981\n",
      "Epoch 146/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.1780 - accuracy: 0.5001 - val_loss: 2.1393 - val_accuracy: 0.4982\n",
      "Epoch 147/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.1647 - accuracy: 0.5016 - val_loss: 2.1332 - val_accuracy: 0.4982\n",
      "Epoch 148/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.1788 - accuracy: 0.5003 - val_loss: 2.1277 - val_accuracy: 0.4984\n",
      "Epoch 149/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.1404 - accuracy: 0.5004 - val_loss: 2.1217 - val_accuracy: 0.4984\n",
      "Epoch 150/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.1538 - accuracy: 0.5011 - val_loss: 2.1158 - val_accuracy: 0.4986\n",
      "Epoch 151/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 2.1505 - accuracy: 0.4996 - val_loss: 2.1102 - val_accuracy: 0.4986\n",
      "Epoch 152/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.1447 - accuracy: 0.5000 - val_loss: 2.1044 - val_accuracy: 0.4985\n",
      "Epoch 153/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.1217 - accuracy: 0.5012 - val_loss: 2.0985 - val_accuracy: 0.4985\n",
      "Epoch 154/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.1281 - accuracy: 0.5007 - val_loss: 2.0926 - val_accuracy: 0.4988\n",
      "Epoch 155/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.1094 - accuracy: 0.5009 - val_loss: 2.0867 - val_accuracy: 0.4987\n",
      "Epoch 156/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.1272 - accuracy: 0.5005 - val_loss: 2.0809 - val_accuracy: 0.4989\n",
      "Epoch 157/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.0992 - accuracy: 0.5002 - val_loss: 2.0750 - val_accuracy: 0.4991\n",
      "Epoch 158/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.1144 - accuracy: 0.5017 - val_loss: 2.0694 - val_accuracy: 0.4991\n",
      "Epoch 159/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.0855 - accuracy: 0.5013 - val_loss: 2.0635 - val_accuracy: 0.4991\n",
      "Epoch 160/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.0755 - accuracy: 0.5007 - val_loss: 2.0576 - val_accuracy: 0.4994\n",
      "Epoch 161/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.0755 - accuracy: 0.5011 - val_loss: 2.0515 - val_accuracy: 0.4993\n",
      "Epoch 162/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.0745 - accuracy: 0.5007 - val_loss: 2.0457 - val_accuracy: 0.4993\n",
      "Epoch 163/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.0634 - accuracy: 0.5001 - val_loss: 2.0399 - val_accuracy: 0.4993\n",
      "Epoch 164/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.0745 - accuracy: 0.4998 - val_loss: 2.0346 - val_accuracy: 0.4995\n",
      "Epoch 165/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.0596 - accuracy: 0.4999 - val_loss: 2.0292 - val_accuracy: 0.4993\n",
      "Epoch 166/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.0472 - accuracy: 0.4997 - val_loss: 2.0236 - val_accuracy: 0.4994\n",
      "Epoch 167/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.0465 - accuracy: 0.5005 - val_loss: 2.0180 - val_accuracy: 0.4992\n",
      "Epoch 168/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.0332 - accuracy: 0.5009 - val_loss: 2.0124 - val_accuracy: 0.4992\n",
      "Epoch 169/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 2.0316 - accuracy: 0.5002 - val_loss: 2.0068 - val_accuracy: 0.4990\n",
      "Epoch 170/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.0281 - accuracy: 0.5013 - val_loss: 2.0016 - val_accuracy: 0.4988\n",
      "Epoch 171/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.0171 - accuracy: 0.5012 - val_loss: 1.9961 - val_accuracy: 0.4989\n",
      "Epoch 172/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.0095 - accuracy: 0.5006 - val_loss: 1.9905 - val_accuracy: 0.4989\n",
      "Epoch 173/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 2.0111 - accuracy: 0.5001 - val_loss: 1.9852 - val_accuracy: 0.4991\n",
      "Epoch 174/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.0055 - accuracy: 0.5004 - val_loss: 1.9801 - val_accuracy: 0.4992\n",
      "Epoch 175/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9924 - accuracy: 0.5011 - val_loss: 1.9749 - val_accuracy: 0.4993\n",
      "Epoch 176/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9950 - accuracy: 0.5004 - val_loss: 1.9696 - val_accuracy: 0.4996\n",
      "Epoch 177/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9872 - accuracy: 0.5007 - val_loss: 1.9644 - val_accuracy: 0.4997\n",
      "Epoch 178/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9766 - accuracy: 0.5004 - val_loss: 1.9588 - val_accuracy: 0.4996\n",
      "Epoch 179/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.9721 - accuracy: 0.5008 - val_loss: 1.9534 - val_accuracy: 0.4998\n",
      "Epoch 180/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.9648 - accuracy: 0.5001 - val_loss: 1.9480 - val_accuracy: 0.4999\n",
      "Epoch 181/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.9595 - accuracy: 0.5002 - val_loss: 1.9426 - val_accuracy: 0.4998\n",
      "Epoch 182/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 1.9519 - accuracy: 0.4999 - val_loss: 1.9373 - val_accuracy: 0.4998\n",
      "Epoch 183/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.9445 - accuracy: 0.5010 - val_loss: 1.9318 - val_accuracy: 0.4998\n",
      "Epoch 184/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.9434 - accuracy: 0.5006 - val_loss: 1.9264 - val_accuracy: 0.4999\n",
      "Epoch 185/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9335 - accuracy: 0.5007 - val_loss: 1.9210 - val_accuracy: 0.4999\n",
      "Epoch 186/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9320 - accuracy: 0.5011 - val_loss: 1.9161 - val_accuracy: 0.4999\n",
      "Epoch 187/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9267 - accuracy: 0.5003 - val_loss: 1.9110 - val_accuracy: 0.4999\n",
      "Epoch 188/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.9140 - accuracy: 0.5011 - val_loss: 1.9055 - val_accuracy: 0.4999\n",
      "Epoch 189/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.9173 - accuracy: 0.5007 - val_loss: 1.9003 - val_accuracy: 0.4999\n",
      "Epoch 190/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9080 - accuracy: 0.5001 - val_loss: 1.8949 - val_accuracy: 0.5000\n",
      "Epoch 191/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.9029 - accuracy: 0.5009 - val_loss: 1.8896 - val_accuracy: 0.4999\n",
      "Epoch 192/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.8920 - accuracy: 0.5009 - val_loss: 1.8842 - val_accuracy: 0.4999\n",
      "Epoch 193/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.9013 - accuracy: 0.4997 - val_loss: 1.8792 - val_accuracy: 0.4998\n",
      "Epoch 194/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.8847 - accuracy: 0.5013 - val_loss: 1.8743 - val_accuracy: 0.4999\n",
      "Epoch 195/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.8810 - accuracy: 0.5005 - val_loss: 1.8693 - val_accuracy: 0.4999\n",
      "Epoch 196/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.8797 - accuracy: 0.5002 - val_loss: 1.8639 - val_accuracy: 0.4999\n",
      "Epoch 197/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.8701 - accuracy: 0.5003 - val_loss: 1.8588 - val_accuracy: 0.5000\n",
      "Epoch 198/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.8680 - accuracy: 0.5002 - val_loss: 1.8537 - val_accuracy: 0.5001\n",
      "Epoch 199/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.8638 - accuracy: 0.5009 - val_loss: 1.8486 - val_accuracy: 0.5002\n",
      "Epoch 200/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.8552 - accuracy: 0.5011 - val_loss: 1.8435 - val_accuracy: 0.5003\n",
      "Epoch 201/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.8450 - accuracy: 0.5016 - val_loss: 1.8382 - val_accuracy: 0.5004\n",
      "Epoch 202/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.8466 - accuracy: 0.5008 - val_loss: 1.8332 - val_accuracy: 0.5003\n",
      "Epoch 203/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.8367 - accuracy: 0.5006 - val_loss: 1.8281 - val_accuracy: 0.5003\n",
      "Epoch 204/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.8331 - accuracy: 0.5010 - val_loss: 1.8232 - val_accuracy: 0.5003\n",
      "Epoch 205/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.8268 - accuracy: 0.5016 - val_loss: 1.8182 - val_accuracy: 0.5003\n",
      "Epoch 206/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.8244 - accuracy: 0.5009 - val_loss: 1.8133 - val_accuracy: 0.5003\n",
      "Epoch 207/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1.8248 - accuracy: 0.4999 - val_loss: 1.8084 - val_accuracy: 0.5002\n",
      "Epoch 208/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.8143 - accuracy: 0.5003 - val_loss: 1.8037 - val_accuracy: 0.5002\n",
      "Epoch 209/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.8062 - accuracy: 0.5012 - val_loss: 1.7986 - val_accuracy: 0.5003\n",
      "Epoch 210/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.8073 - accuracy: 0.5004 - val_loss: 1.7939 - val_accuracy: 0.5003\n",
      "Epoch 211/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.8039 - accuracy: 0.5003 - val_loss: 1.7893 - val_accuracy: 0.5002\n",
      "Epoch 212/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.7921 - accuracy: 0.5006 - val_loss: 1.7844 - val_accuracy: 0.5002\n",
      "Epoch 213/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.7893 - accuracy: 0.5013 - val_loss: 1.7793 - val_accuracy: 0.5002\n",
      "Epoch 214/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.7851 - accuracy: 0.5000 - val_loss: 1.7746 - val_accuracy: 0.5002\n",
      "Epoch 215/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.7807 - accuracy: 0.5002 - val_loss: 1.7697 - val_accuracy: 0.5001\n",
      "Epoch 216/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.7720 - accuracy: 0.5011 - val_loss: 1.7647 - val_accuracy: 0.5001\n",
      "Epoch 217/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.7680 - accuracy: 0.5006 - val_loss: 1.7598 - val_accuracy: 0.5001\n",
      "Epoch 218/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.7606 - accuracy: 0.5008 - val_loss: 1.7550 - val_accuracy: 0.5002\n",
      "Epoch 219/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.7550 - accuracy: 0.5005 - val_loss: 1.7499 - val_accuracy: 0.5001\n",
      "Epoch 220/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.7537 - accuracy: 0.5008 - val_loss: 1.7454 - val_accuracy: 0.5001\n",
      "Epoch 221/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.7482 - accuracy: 0.5005 - val_loss: 1.7407 - val_accuracy: 0.5000\n",
      "Epoch 222/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.7405 - accuracy: 0.5016 - val_loss: 1.7358 - val_accuracy: 0.5001\n",
      "Epoch 223/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.7387 - accuracy: 0.5004 - val_loss: 1.7310 - val_accuracy: 0.5000\n",
      "Epoch 224/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.7315 - accuracy: 0.5005 - val_loss: 1.7260 - val_accuracy: 0.5000\n",
      "Epoch 225/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.7308 - accuracy: 0.5001 - val_loss: 1.7215 - val_accuracy: 0.5000\n",
      "Epoch 226/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.7271 - accuracy: 0.5007 - val_loss: 1.7171 - val_accuracy: 0.5001\n",
      "Epoch 227/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.7227 - accuracy: 0.5002 - val_loss: 1.7126 - val_accuracy: 0.5001\n",
      "Epoch 228/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.7149 - accuracy: 0.5005 - val_loss: 1.7081 - val_accuracy: 0.5001\n",
      "Epoch 229/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.7109 - accuracy: 0.5008 - val_loss: 1.7035 - val_accuracy: 0.5000\n",
      "Epoch 230/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.7070 - accuracy: 0.5000 - val_loss: 1.6989 - val_accuracy: 0.5000\n",
      "Epoch 231/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.6984 - accuracy: 0.5010 - val_loss: 1.6942 - val_accuracy: 0.5000\n",
      "Epoch 232/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.6960 - accuracy: 0.5009 - val_loss: 1.6898 - val_accuracy: 0.5001\n",
      "Epoch 233/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.6919 - accuracy: 0.5002 - val_loss: 1.6852 - val_accuracy: 0.5001\n",
      "Epoch 234/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.6849 - accuracy: 0.5011 - val_loss: 1.6807 - val_accuracy: 0.5001\n",
      "Epoch 235/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.6832 - accuracy: 0.5012 - val_loss: 1.6762 - val_accuracy: 0.5001\n",
      "Epoch 236/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.6765 - accuracy: 0.5006 - val_loss: 1.6718 - val_accuracy: 0.5001\n",
      "Epoch 237/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1.6718 - accuracy: 0.5004 - val_loss: 1.6673 - val_accuracy: 0.5001\n",
      "Epoch 238/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.6656 - accuracy: 0.5007 - val_loss: 1.6627 - val_accuracy: 0.5001\n",
      "Epoch 239/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.6608 - accuracy: 0.5007 - val_loss: 1.6580 - val_accuracy: 0.5001\n",
      "Epoch 240/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.6578 - accuracy: 0.5004 - val_loss: 1.6535 - val_accuracy: 0.5001\n",
      "Epoch 241/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.6563 - accuracy: 0.5006 - val_loss: 1.6492 - val_accuracy: 0.5001\n",
      "Epoch 242/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.6501 - accuracy: 0.5011 - val_loss: 1.6447 - val_accuracy: 0.5001\n",
      "Epoch 243/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.6439 - accuracy: 0.5001 - val_loss: 1.6402 - val_accuracy: 0.5001\n",
      "Epoch 244/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.6403 - accuracy: 0.5004 - val_loss: 1.6358 - val_accuracy: 0.5000\n",
      "Epoch 245/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.6365 - accuracy: 0.5003 - val_loss: 1.6314 - val_accuracy: 0.5000\n",
      "Epoch 246/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.6348 - accuracy: 0.5008 - val_loss: 1.6272 - val_accuracy: 0.5001\n",
      "Epoch 247/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.6267 - accuracy: 0.4999 - val_loss: 1.6229 - val_accuracy: 0.5001\n",
      "Epoch 248/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.6248 - accuracy: 0.5006 - val_loss: 1.6186 - val_accuracy: 0.5001\n",
      "Epoch 249/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.6181 - accuracy: 0.5003 - val_loss: 1.6142 - val_accuracy: 0.5001\n",
      "Epoch 250/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.6153 - accuracy: 0.5004 - val_loss: 1.6100 - val_accuracy: 0.5001\n",
      "Epoch 251/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.6118 - accuracy: 0.5003 - val_loss: 1.6059 - val_accuracy: 0.5001\n",
      "Epoch 252/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.6064 - accuracy: 0.5004 - val_loss: 1.6018 - val_accuracy: 0.5001\n",
      "Epoch 253/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.6011 - accuracy: 0.5004 - val_loss: 1.5976 - val_accuracy: 0.5001\n",
      "Epoch 254/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.5976 - accuracy: 0.5005 - val_loss: 1.5935 - val_accuracy: 0.5001\n",
      "Epoch 255/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.5926 - accuracy: 0.5007 - val_loss: 1.5894 - val_accuracy: 0.5001\n",
      "Epoch 256/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.5904 - accuracy: 0.5004 - val_loss: 1.5853 - val_accuracy: 0.5001\n",
      "Epoch 257/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.5838 - accuracy: 0.5005 - val_loss: 1.5810 - val_accuracy: 0.5001\n",
      "Epoch 258/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.5803 - accuracy: 0.5001 - val_loss: 1.5768 - val_accuracy: 0.5001\n",
      "Epoch 259/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5772 - accuracy: 0.5004 - val_loss: 1.5726 - val_accuracy: 0.5001\n",
      "Epoch 260/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5722 - accuracy: 0.5007 - val_loss: 1.5686 - val_accuracy: 0.5001\n",
      "Epoch 261/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.5682 - accuracy: 0.5003 - val_loss: 1.5645 - val_accuracy: 0.5001\n",
      "Epoch 262/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5633 - accuracy: 0.5005 - val_loss: 1.5604 - val_accuracy: 0.5001\n",
      "Epoch 263/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.5596 - accuracy: 0.5003 - val_loss: 1.5565 - val_accuracy: 0.5001\n",
      "Epoch 264/300\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 1.5559 - accuracy: 0.5004 - val_loss: 1.5524 - val_accuracy: 0.5001\n",
      "Epoch 265/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.5530 - accuracy: 0.5004 - val_loss: 1.5485 - val_accuracy: 0.5001\n",
      "Epoch 266/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5481 - accuracy: 0.5002 - val_loss: 1.5447 - val_accuracy: 0.5001\n",
      "Epoch 267/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.5437 - accuracy: 0.5005 - val_loss: 1.5407 - val_accuracy: 0.5001\n",
      "Epoch 268/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.5388 - accuracy: 0.5006 - val_loss: 1.5367 - val_accuracy: 0.5001\n",
      "Epoch 269/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.5350 - accuracy: 0.5008 - val_loss: 1.5328 - val_accuracy: 0.5001\n",
      "Epoch 270/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5312 - accuracy: 0.5007 - val_loss: 1.5288 - val_accuracy: 0.5001\n",
      "Epoch 271/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.5275 - accuracy: 0.5005 - val_loss: 1.5249 - val_accuracy: 0.5001\n",
      "Epoch 272/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.5240 - accuracy: 0.5005 - val_loss: 1.5210 - val_accuracy: 0.5001\n",
      "Epoch 273/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5194 - accuracy: 0.5006 - val_loss: 1.5172 - val_accuracy: 0.5001\n",
      "Epoch 274/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.5171 - accuracy: 0.5005 - val_loss: 1.5134 - val_accuracy: 0.5001\n",
      "Epoch 275/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5122 - accuracy: 0.5001 - val_loss: 1.5095 - val_accuracy: 0.5001\n",
      "Epoch 276/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5091 - accuracy: 0.5003 - val_loss: 1.5056 - val_accuracy: 0.5001\n",
      "Epoch 277/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.5037 - accuracy: 0.5005 - val_loss: 1.5020 - val_accuracy: 0.5001\n",
      "Epoch 278/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.5001 - accuracy: 0.5006 - val_loss: 1.4980 - val_accuracy: 0.5001\n",
      "Epoch 279/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.4971 - accuracy: 0.5002 - val_loss: 1.4943 - val_accuracy: 0.5001\n",
      "Epoch 280/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.4929 - accuracy: 0.5006 - val_loss: 1.4906 - val_accuracy: 0.5001\n",
      "Epoch 281/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4904 - accuracy: 0.5005 - val_loss: 1.4869 - val_accuracy: 0.5001\n",
      "Epoch 282/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.4854 - accuracy: 0.5004 - val_loss: 1.4832 - val_accuracy: 0.5001\n",
      "Epoch 283/300\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 1.4823 - accuracy: 0.5002 - val_loss: 1.4796 - val_accuracy: 0.5001\n",
      "Epoch 284/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4781 - accuracy: 0.5007 - val_loss: 1.4760 - val_accuracy: 0.5001\n",
      "Epoch 285/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.4751 - accuracy: 0.5003 - val_loss: 1.4725 - val_accuracy: 0.5001\n",
      "Epoch 286/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4721 - accuracy: 0.5005 - val_loss: 1.4691 - val_accuracy: 0.5001\n",
      "Epoch 287/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.4672 - accuracy: 0.5003 - val_loss: 1.4654 - val_accuracy: 0.5001\n",
      "Epoch 288/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4640 - accuracy: 0.5007 - val_loss: 1.4619 - val_accuracy: 0.5001\n",
      "Epoch 289/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4613 - accuracy: 0.5004 - val_loss: 1.4584 - val_accuracy: 0.5001\n",
      "Epoch 290/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 1.4577 - accuracy: 0.5000 - val_loss: 1.4550 - val_accuracy: 0.5001\n",
      "Epoch 291/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4534 - accuracy: 0.5006 - val_loss: 1.4515 - val_accuracy: 0.5001\n",
      "Epoch 292/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4507 - accuracy: 0.5003 - val_loss: 1.4480 - val_accuracy: 0.5001\n",
      "Epoch 293/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.4466 - accuracy: 0.5002 - val_loss: 1.4445 - val_accuracy: 0.5001\n",
      "Epoch 294/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4429 - accuracy: 0.5004 - val_loss: 1.4410 - val_accuracy: 0.5001\n",
      "Epoch 295/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.4394 - accuracy: 0.5004 - val_loss: 1.4375 - val_accuracy: 0.5001\n",
      "Epoch 296/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 1.4362 - accuracy: 0.5006 - val_loss: 1.4342 - val_accuracy: 0.5001\n",
      "Epoch 297/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.4326 - accuracy: 0.5004 - val_loss: 1.4307 - val_accuracy: 0.5001\n",
      "Epoch 298/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4303 - accuracy: 0.5002 - val_loss: 1.4275 - val_accuracy: 0.5001\n",
      "Epoch 299/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.4263 - accuracy: 0.5003 - val_loss: 1.4241 - val_accuracy: 0.5001\n",
      "Epoch 300/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4225 - accuracy: 0.5005 - val_loss: 1.4208 - val_accuracy: 0.5001\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 1.4208 - accuracy: 0.5001\n",
      "{'loss': 1.4207673072814941, 'accuracy': 0.5001260638237} \n",
      " 299 \n",
      "\n",
      "Model time: 3.4097545444965363 minutes\n",
      "\n",
      "Total time: 208.57147461920977 minutes\n",
      "\n",
      "\n",
      "Model  105  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                     1\n",
      "Activation function         linear\n",
      "Dropout                        0.1\n",
      "L1                             1.0\n",
      "L2                          0.0001\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                0.001\n",
      "Name: 5682015, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 11s 6ms/step - loss: 3.0355 - accuracy: 0.5004 - val_loss: 1.0084 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8020 - accuracy: 0.4974 - val_loss: 0.7839 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7827 - accuracy: 0.4985 - val_loss: 0.7817 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "1326/1339 [============================>.] - ETA: 0s - loss: 0.7827 - accuracy: 0.4960Restoring model weights from the end of the best epoch: 3.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7827 - accuracy: 0.4960 - val_loss: 0.7851 - val_accuracy: 0.4999\n",
      "Epoch 4: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 0.7817 - accuracy: 0.5001\n",
      "{'loss': 0.7816901206970215, 'accuracy': 0.5001260638237} \n",
      " 3 \n",
      "\n",
      "Model time: 0.8047825396060944 minutes\n",
      "\n",
      "Total time: 209.37632383033633 minutes\n",
      "\n",
      "\n",
      "Model  106  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     4\n",
      "Activation function           relu\n",
      "Dropout                        0.4\n",
      "L1                             1.0\n",
      "L2                             1.0\n",
      "Batch size                     128\n",
      "Optimizer                     Adam\n",
      "Learning rate                 0.01\n",
      "Name: 4565986, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 4s 11ms/step - loss: 11.7447 - accuracy: 0.5002 - val_loss: 1.5611 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "155/168 [==========================>...] - ETA: 0s - loss: 1.5988 - accuracy: 0.4981Restoring model weights from the end of the best epoch: 1.\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.5997 - accuracy: 0.4975 - val_loss: 1.6038 - val_accuracy: 0.5001\n",
      "Epoch 2: early stopping\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 1.5611 - accuracy: 0.5001\n",
      "{'loss': 1.561118245124817, 'accuracy': 0.5001260638237} \n",
      " 1 \n",
      "\n",
      "Model time: 0.113833237439394 minutes\n",
      "\n",
      "Total time: 209.49025704711676 minutes\n",
      "\n",
      "\n",
      "Model  107  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                     4\n",
      "Activation function           relu\n",
      "Dropout                        0.0\n",
      "L1                             0.0\n",
      "L2                             0.0\n",
      "Batch size                      16\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 5948649, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 9s 5ms/step - loss: 0.6928 - accuracy: 0.5109 - val_loss: 0.6925 - val_accuracy: 0.5393\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6913 - accuracy: 0.5406 - val_loss: 0.6901 - val_accuracy: 0.5590\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6886 - accuracy: 0.5594 - val_loss: 0.6866 - val_accuracy: 0.5739\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6850 - accuracy: 0.5707 - val_loss: 0.6836 - val_accuracy: 0.5817\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6811 - accuracy: 0.5817 - val_loss: 0.6823 - val_accuracy: 0.5753\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6775 - accuracy: 0.5874 - val_loss: 0.6796 - val_accuracy: 0.5802\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6742 - accuracy: 0.5918 - val_loss: 0.6785 - val_accuracy: 0.5768\n",
      "Epoch 8/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6713 - accuracy: 0.5960 - val_loss: 0.6773 - val_accuracy: 0.5774\n",
      "Epoch 9/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6689 - accuracy: 0.5989 - val_loss: 0.6750 - val_accuracy: 0.5843\n",
      "Epoch 10/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6663 - accuracy: 0.6035 - val_loss: 0.6732 - val_accuracy: 0.5882\n",
      "Epoch 11/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6641 - accuracy: 0.6067 - val_loss: 0.6727 - val_accuracy: 0.5890\n",
      "Epoch 12/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6621 - accuracy: 0.6087 - val_loss: 0.6709 - val_accuracy: 0.5916\n",
      "Epoch 13/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6600 - accuracy: 0.6116 - val_loss: 0.6695 - val_accuracy: 0.5935\n",
      "Epoch 14/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6580 - accuracy: 0.6160 - val_loss: 0.6687 - val_accuracy: 0.5935\n",
      "Epoch 15/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6559 - accuracy: 0.6198 - val_loss: 0.6650 - val_accuracy: 0.6002\n",
      "Epoch 16/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6538 - accuracy: 0.6230 - val_loss: 0.6639 - val_accuracy: 0.6022\n",
      "Epoch 17/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6520 - accuracy: 0.6256 - val_loss: 0.6630 - val_accuracy: 0.6044\n",
      "Epoch 18/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6504 - accuracy: 0.6254 - val_loss: 0.6610 - val_accuracy: 0.6079\n",
      "Epoch 19/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6488 - accuracy: 0.6284 - val_loss: 0.6603 - val_accuracy: 0.6092\n",
      "Epoch 20/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6474 - accuracy: 0.6305 - val_loss: 0.6599 - val_accuracy: 0.6080\n",
      "Epoch 21/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6463 - accuracy: 0.6301 - val_loss: 0.6590 - val_accuracy: 0.6111\n",
      "Epoch 22/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6451 - accuracy: 0.6328 - val_loss: 0.6588 - val_accuracy: 0.6118\n",
      "Epoch 23/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6441 - accuracy: 0.6353 - val_loss: 0.6578 - val_accuracy: 0.6136\n",
      "Epoch 24/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6432 - accuracy: 0.6360 - val_loss: 0.6560 - val_accuracy: 0.6149\n",
      "Epoch 25/300\n",
      "1324/1339 [============================>.] - ETA: 0s - loss: 0.6423 - accuracy: 0.6370Restoring model weights from the end of the best epoch: 24.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6422 - accuracy: 0.6370 - val_loss: 0.6561 - val_accuracy: 0.6142\n",
      "Epoch 25: early stopping\n",
      "1240/1240 [==============================] - 3s 2ms/step - loss: 0.6560 - accuracy: 0.6149\n",
      "{'loss': 0.6559594869613647, 'accuracy': 0.6149346828460693} \n",
      " 24 \n",
      "\n",
      "Model time: 2.9248470664024353 minutes\n",
      "\n",
      "Total time: 212.4151707738638 minutes\n",
      "\n",
      "\n",
      "Model  108  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     4\n",
      "Activation function         linear\n",
      "Dropout                        0.6\n",
      "L1                             0.1\n",
      "L2                             0.0\n",
      "Batch size                      16\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 4612908, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "1339/1339 [==============================] - 10s 6ms/step - loss: 10.9159 - accuracy: 0.5097 - val_loss: 9.3841 - val_accuracy: 0.5032\n",
      "Epoch 2/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 10.2982 - accuracy: 0.4988 - val_loss: 8.8031 - val_accuracy: 0.5035\n",
      "Epoch 3/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 9.5275 - accuracy: 0.4989 - val_loss: 8.2537 - val_accuracy: 0.5036\n",
      "Epoch 4/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 8.9946 - accuracy: 0.4924 - val_loss: 7.7382 - val_accuracy: 0.5042\n",
      "Epoch 5/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 8.3280 - accuracy: 0.5012 - val_loss: 7.2538 - val_accuracy: 0.5063\n",
      "Epoch 6/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 7.7837 - accuracy: 0.4980 - val_loss: 6.8005 - val_accuracy: 0.5091\n",
      "Epoch 7/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 7.2483 - accuracy: 0.4972 - val_loss: 6.3858 - val_accuracy: 0.5116\n",
      "Epoch 8/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 6.8015 - accuracy: 0.5043 - val_loss: 6.0181 - val_accuracy: 0.5147\n",
      "Epoch 9/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 6.3732 - accuracy: 0.4990 - val_loss: 5.6866 - val_accuracy: 0.5145\n",
      "Epoch 10/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 5.9528 - accuracy: 0.5003 - val_loss: 5.3890 - val_accuracy: 0.5174\n",
      "Epoch 11/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 5.6490 - accuracy: 0.5018 - val_loss: 5.1260 - val_accuracy: 0.5190\n",
      "Epoch 12/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 5.3326 - accuracy: 0.5030 - val_loss: 4.8847 - val_accuracy: 0.5216\n",
      "Epoch 13/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 5.0634 - accuracy: 0.4991 - val_loss: 4.6731 - val_accuracy: 0.5231\n",
      "Epoch 14/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 4.8209 - accuracy: 0.4989 - val_loss: 4.4865 - val_accuracy: 0.5252\n",
      "Epoch 15/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 4.5952 - accuracy: 0.5045 - val_loss: 4.3124 - val_accuracy: 0.5275\n",
      "Epoch 16/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 4.3855 - accuracy: 0.5016 - val_loss: 4.1357 - val_accuracy: 0.5293\n",
      "Epoch 17/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 4.1780 - accuracy: 0.5016 - val_loss: 3.9595 - val_accuracy: 0.5306\n",
      "Epoch 18/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 3.9745 - accuracy: 0.5060 - val_loss: 3.7830 - val_accuracy: 0.5307\n",
      "Epoch 19/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 3.7763 - accuracy: 0.4994 - val_loss: 3.6060 - val_accuracy: 0.5323\n",
      "Epoch 20/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 3.5701 - accuracy: 0.5000 - val_loss: 3.4221 - val_accuracy: 0.5330\n",
      "Epoch 21/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 3.3692 - accuracy: 0.4959 - val_loss: 3.2356 - val_accuracy: 0.5312\n",
      "Epoch 22/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 3.1749 - accuracy: 0.5017 - val_loss: 3.0544 - val_accuracy: 0.5342\n",
      "Epoch 23/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2.9871 - accuracy: 0.4999 - val_loss: 2.8791 - val_accuracy: 0.5393\n",
      "Epoch 24/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2.8051 - accuracy: 0.4996 - val_loss: 2.7040 - val_accuracy: 0.5430\n",
      "Epoch 25/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2.6255 - accuracy: 0.4933 - val_loss: 2.5341 - val_accuracy: 0.5437\n",
      "Epoch 26/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2.4579 - accuracy: 0.5070 - val_loss: 2.3755 - val_accuracy: 0.5457\n",
      "Epoch 27/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2.3049 - accuracy: 0.5028 - val_loss: 2.2360 - val_accuracy: 0.5436\n",
      "Epoch 28/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 2.1745 - accuracy: 0.5025 - val_loss: 2.1135 - val_accuracy: 0.5395\n",
      "Epoch 29/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 2.0612 - accuracy: 0.5003 - val_loss: 2.0113 - val_accuracy: 0.5290\n",
      "Epoch 30/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.9677 - accuracy: 0.5002 - val_loss: 1.9263 - val_accuracy: 0.5100\n",
      "Epoch 31/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.8921 - accuracy: 0.4990 - val_loss: 1.8601 - val_accuracy: 0.4928\n",
      "Epoch 32/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.8294 - accuracy: 0.4963 - val_loss: 1.7991 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.7697 - accuracy: 0.4959 - val_loss: 1.7407 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.7127 - accuracy: 0.5016 - val_loss: 1.6847 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.6585 - accuracy: 0.5036 - val_loss: 1.6325 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.6078 - accuracy: 0.5007 - val_loss: 1.5836 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.5608 - accuracy: 0.4988 - val_loss: 1.5380 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.5153 - accuracy: 0.4983 - val_loss: 1.4925 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.4697 - accuracy: 0.5036 - val_loss: 1.4471 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.4244 - accuracy: 0.4988 - val_loss: 1.4021 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.3802 - accuracy: 0.5007 - val_loss: 1.3585 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.3385 - accuracy: 0.5041 - val_loss: 1.3184 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.2986 - accuracy: 0.4990 - val_loss: 1.2790 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.2598 - accuracy: 0.5001 - val_loss: 1.2409 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.2223 - accuracy: 0.5020 - val_loss: 1.2038 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.1858 - accuracy: 0.4995 - val_loss: 1.1677 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.1496 - accuracy: 0.5002 - val_loss: 1.1317 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.1144 - accuracy: 0.5003 - val_loss: 1.0974 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 1.0820 - accuracy: 0.5003 - val_loss: 1.0671 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.0528 - accuracy: 0.5003 - val_loss: 1.0388 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 1.0255 - accuracy: 0.5003 - val_loss: 1.0120 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.9993 - accuracy: 0.5003 - val_loss: 0.9866 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.9742 - accuracy: 0.5003 - val_loss: 0.9621 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.9503 - accuracy: 0.5003 - val_loss: 0.9391 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.9284 - accuracy: 0.5003 - val_loss: 0.9177 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.9070 - accuracy: 0.5003 - val_loss: 0.8967 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8866 - accuracy: 0.5003 - val_loss: 0.8766 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8678 - accuracy: 0.5003 - val_loss: 0.8591 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8504 - accuracy: 0.5003 - val_loss: 0.8417 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8330 - accuracy: 0.5003 - val_loss: 0.8243 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.8156 - accuracy: 0.5003 - val_loss: 0.8068 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.7982 - accuracy: 0.5003 - val_loss: 0.7894 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7807 - accuracy: 0.4985 - val_loss: 0.7720 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7638 - accuracy: 0.5003 - val_loss: 0.7558 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7483 - accuracy: 0.5003 - val_loss: 0.7416 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7365 - accuracy: 0.5003 - val_loss: 0.7317 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7270 - accuracy: 0.5003 - val_loss: 0.7223 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7176 - accuracy: 0.5003 - val_loss: 0.7130 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7096 - accuracy: 0.5003 - val_loss: 0.7067 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.7040 - accuracy: 0.5003 - val_loss: 0.7015 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6995 - accuracy: 0.5003 - val_loss: 0.6975 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6962 - accuracy: 0.5003 - val_loss: 0.6948 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "1339/1339 [==============================] - 6s 5ms/step - loss: 0.6940 - accuracy: 0.5003 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "1320/1339 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5000Restoring model weights from the end of the best epoch: 73.\n",
      "1339/1339 [==============================] - 7s 5ms/step - loss: 0.6935 - accuracy: 0.5003 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 74: early stopping\n",
      "1240/1240 [==============================] - 3s 3ms/step - loss: 0.6935 - accuracy: 0.5001\n",
      "{'loss': 0.6935172080993652, 'accuracy': 0.5001260638237} \n",
      " 73 \n",
      "\n",
      "Model time: 8.385374926030636 minutes\n",
      "\n",
      "Total time: 220.80066237971187 minutes\n",
      "\n",
      "\n",
      "Model  109  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     4\n",
      "Activation function           relu\n",
      "Dropout                        0.0\n",
      "L1                             1.0\n",
      "L2                             0.1\n",
      "Batch size                      64\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 1751115, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 7ms/step - loss: 20.3374 - accuracy: 0.4950 - val_loss: 5.4079 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3.3697 - accuracy: 0.5013 - val_loss: 1.6966 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0142 - accuracy: 0.4979 - val_loss: 0.7870 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7865 - accuracy: 0.5022 - val_loss: 0.7821 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "319/335 [===========================>..] - ETA: 0s - loss: 0.7861 - accuracy: 0.4998Restoring model weights from the end of the best epoch: 4.\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7861 - accuracy: 0.4999 - val_loss: 0.7854 - val_accuracy: 0.4999\n",
      "Epoch 5: early stopping\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 0.7821 - accuracy: 0.5001\n",
      "{'loss': 0.7821478247642517, 'accuracy': 0.5001260638237} \n",
      " 4 \n",
      "\n",
      "Model time: 0.2158331423997879 minutes\n",
      "\n",
      "Total time: 221.01657883822918 minutes\n",
      "\n",
      "\n",
      "Model  110  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     4\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.0\n",
      "L1                            0.01\n",
      "L2                           0.001\n",
      "Batch size                      32\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 1829828, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "670/670 [==============================] - 6s 6ms/step - loss: 1.6124 - accuracy: 0.4997 - val_loss: 1.5822 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.5545 - accuracy: 0.4997 - val_loss: 1.5252 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4990 - accuracy: 0.4997 - val_loss: 1.4709 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.4457 - accuracy: 0.4997 - val_loss: 1.4185 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.3943 - accuracy: 0.4997 - val_loss: 1.3680 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.3451 - accuracy: 0.4997 - val_loss: 1.3197 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.2979 - accuracy: 0.4997 - val_loss: 1.2737 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 1.2531 - accuracy: 0.4997 - val_loss: 1.2299 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.2104 - accuracy: 0.4997 - val_loss: 1.1886 - val_accuracy: 0.4999\n",
      "Epoch 10/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1705 - accuracy: 0.4997 - val_loss: 1.1501 - val_accuracy: 0.4999\n",
      "Epoch 11/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.1328 - accuracy: 0.4997 - val_loss: 1.1136 - val_accuracy: 0.4999\n",
      "Epoch 12/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0976 - accuracy: 0.4997 - val_loss: 1.0797 - val_accuracy: 0.4999\n",
      "Epoch 13/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0646 - accuracy: 0.4997 - val_loss: 1.0479 - val_accuracy: 0.4999\n",
      "Epoch 14/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0338 - accuracy: 0.4997 - val_loss: 1.0181 - val_accuracy: 0.4999\n",
      "Epoch 15/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 1.0047 - accuracy: 0.4997 - val_loss: 0.9900 - val_accuracy: 0.4999\n",
      "Epoch 16/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9776 - accuracy: 0.4997 - val_loss: 0.9644 - val_accuracy: 0.4999\n",
      "Epoch 17/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9531 - accuracy: 0.4997 - val_loss: 0.9409 - val_accuracy: 0.4999\n",
      "Epoch 18/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9305 - accuracy: 0.4997 - val_loss: 0.9194 - val_accuracy: 0.4999\n",
      "Epoch 19/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.9097 - accuracy: 0.4997 - val_loss: 0.8997 - val_accuracy: 0.4999\n",
      "Epoch 20/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8908 - accuracy: 0.4997 - val_loss: 0.8818 - val_accuracy: 0.4999\n",
      "Epoch 21/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8740 - accuracy: 0.4997 - val_loss: 0.8663 - val_accuracy: 0.4999\n",
      "Epoch 22/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8596 - accuracy: 0.4997 - val_loss: 0.8529 - val_accuracy: 0.4999\n",
      "Epoch 23/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8470 - accuracy: 0.4997 - val_loss: 0.8410 - val_accuracy: 0.4999\n",
      "Epoch 24/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8357 - accuracy: 0.4997 - val_loss: 0.8304 - val_accuracy: 0.4999\n",
      "Epoch 25/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8260 - accuracy: 0.4997 - val_loss: 0.8219 - val_accuracy: 0.4999\n",
      "Epoch 26/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8185 - accuracy: 0.4997 - val_loss: 0.8153 - val_accuracy: 0.4999\n",
      "Epoch 27/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8127 - accuracy: 0.4997 - val_loss: 0.8103 - val_accuracy: 0.4999\n",
      "Epoch 28/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8088 - accuracy: 0.4997 - val_loss: 0.8074 - val_accuracy: 0.4999\n",
      "Epoch 29/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8063 - accuracy: 0.4997 - val_loss: 0.8051 - val_accuracy: 0.4999\n",
      "Epoch 30/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8042 - accuracy: 0.4997 - val_loss: 0.8033 - val_accuracy: 0.4999\n",
      "Epoch 31/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8025 - accuracy: 0.4997 - val_loss: 0.8016 - val_accuracy: 0.4999\n",
      "Epoch 32/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.8008 - accuracy: 0.4997 - val_loss: 0.8000 - val_accuracy: 0.4999\n",
      "Epoch 33/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7992 - accuracy: 0.4997 - val_loss: 0.7984 - val_accuracy: 0.4999\n",
      "Epoch 34/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7977 - accuracy: 0.4997 - val_loss: 0.7970 - val_accuracy: 0.4999\n",
      "Epoch 35/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7963 - accuracy: 0.4997 - val_loss: 0.7957 - val_accuracy: 0.4999\n",
      "Epoch 36/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7950 - accuracy: 0.4997 - val_loss: 0.7944 - val_accuracy: 0.4999\n",
      "Epoch 37/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7938 - accuracy: 0.4997 - val_loss: 0.7931 - val_accuracy: 0.4999\n",
      "Epoch 38/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7925 - accuracy: 0.4997 - val_loss: 0.7919 - val_accuracy: 0.4999\n",
      "Epoch 39/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7913 - accuracy: 0.4997 - val_loss: 0.7907 - val_accuracy: 0.4999\n",
      "Epoch 40/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7900 - accuracy: 0.4997 - val_loss: 0.7894 - val_accuracy: 0.4999\n",
      "Epoch 41/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7888 - accuracy: 0.4997 - val_loss: 0.7882 - val_accuracy: 0.4999\n",
      "Epoch 42/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7876 - accuracy: 0.4997 - val_loss: 0.7870 - val_accuracy: 0.4999\n",
      "Epoch 43/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7865 - accuracy: 0.4997 - val_loss: 0.7859 - val_accuracy: 0.4999\n",
      "Epoch 44/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7853 - accuracy: 0.4997 - val_loss: 0.7848 - val_accuracy: 0.4999\n",
      "Epoch 45/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7842 - accuracy: 0.4997 - val_loss: 0.7836 - val_accuracy: 0.4999\n",
      "Epoch 46/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7831 - accuracy: 0.4997 - val_loss: 0.7825 - val_accuracy: 0.4999\n",
      "Epoch 47/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7819 - accuracy: 0.4997 - val_loss: 0.7814 - val_accuracy: 0.4999\n",
      "Epoch 48/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7808 - accuracy: 0.4997 - val_loss: 0.7803 - val_accuracy: 0.4999\n",
      "Epoch 49/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7797 - accuracy: 0.4997 - val_loss: 0.7791 - val_accuracy: 0.4999\n",
      "Epoch 50/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7786 - accuracy: 0.4997 - val_loss: 0.7780 - val_accuracy: 0.4999\n",
      "Epoch 51/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7775 - accuracy: 0.4997 - val_loss: 0.7769 - val_accuracy: 0.4999\n",
      "Epoch 52/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7764 - accuracy: 0.4997 - val_loss: 0.7758 - val_accuracy: 0.4999\n",
      "Epoch 53/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7753 - accuracy: 0.4997 - val_loss: 0.7748 - val_accuracy: 0.4999\n",
      "Epoch 54/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7743 - accuracy: 0.4997 - val_loss: 0.7738 - val_accuracy: 0.4999\n",
      "Epoch 55/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7733 - accuracy: 0.4997 - val_loss: 0.7727 - val_accuracy: 0.4999\n",
      "Epoch 56/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7722 - accuracy: 0.4997 - val_loss: 0.7717 - val_accuracy: 0.4999\n",
      "Epoch 57/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7712 - accuracy: 0.4997 - val_loss: 0.7707 - val_accuracy: 0.4999\n",
      "Epoch 58/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7702 - accuracy: 0.4997 - val_loss: 0.7697 - val_accuracy: 0.4999\n",
      "Epoch 59/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7691 - accuracy: 0.4945 - val_loss: 0.7686 - val_accuracy: 0.4999\n",
      "Epoch 60/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7681 - accuracy: 0.4989 - val_loss: 0.7676 - val_accuracy: 0.4999\n",
      "Epoch 61/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7671 - accuracy: 0.4988 - val_loss: 0.7666 - val_accuracy: 0.4999\n",
      "Epoch 62/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7661 - accuracy: 0.4977 - val_loss: 0.7656 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7651 - accuracy: 0.4984 - val_loss: 0.7646 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7641 - accuracy: 0.5003 - val_loss: 0.7636 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7631 - accuracy: 0.5003 - val_loss: 0.7626 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7621 - accuracy: 0.4941 - val_loss: 0.7616 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7611 - accuracy: 0.5003 - val_loss: 0.7606 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7602 - accuracy: 0.5003 - val_loss: 0.7597 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 0.7592 - accuracy: 0.5003 - val_loss: 0.7587 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7583 - accuracy: 0.5003 - val_loss: 0.7578 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7574 - accuracy: 0.4962 - val_loss: 0.7570 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7565 - accuracy: 0.5003 - val_loss: 0.7561 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7557 - accuracy: 0.5003 - val_loss: 0.7552 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7548 - accuracy: 0.5003 - val_loss: 0.7544 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7540 - accuracy: 0.5003 - val_loss: 0.7535 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7531 - accuracy: 0.5003 - val_loss: 0.7527 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7522 - accuracy: 0.4974 - val_loss: 0.7518 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7514 - accuracy: 0.4961 - val_loss: 0.7510 - val_accuracy: 0.4999\n",
      "Epoch 79/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7506 - accuracy: 0.4971 - val_loss: 0.7501 - val_accuracy: 0.4999\n",
      "Epoch 80/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7497 - accuracy: 0.4980 - val_loss: 0.7493 - val_accuracy: 0.4999\n",
      "Epoch 81/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7489 - accuracy: 0.4997 - val_loss: 0.7485 - val_accuracy: 0.4999\n",
      "Epoch 82/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7481 - accuracy: 0.4946 - val_loss: 0.7478 - val_accuracy: 0.4999\n",
      "Epoch 83/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7474 - accuracy: 0.4997 - val_loss: 0.7470 - val_accuracy: 0.4999\n",
      "Epoch 84/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7466 - accuracy: 0.4984 - val_loss: 0.7462 - val_accuracy: 0.4999\n",
      "Epoch 85/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7458 - accuracy: 0.4997 - val_loss: 0.7454 - val_accuracy: 0.4999\n",
      "Epoch 86/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7450 - accuracy: 0.4997 - val_loss: 0.7446 - val_accuracy: 0.4999\n",
      "Epoch 87/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7442 - accuracy: 0.4994 - val_loss: 0.7438 - val_accuracy: 0.4999\n",
      "Epoch 88/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7434 - accuracy: 0.4960 - val_loss: 0.7430 - val_accuracy: 0.4999\n",
      "Epoch 89/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7426 - accuracy: 0.4967 - val_loss: 0.7422 - val_accuracy: 0.4999\n",
      "Epoch 90/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7418 - accuracy: 0.4929 - val_loss: 0.7414 - val_accuracy: 0.4999\n",
      "Epoch 91/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7410 - accuracy: 0.4939 - val_loss: 0.7406 - val_accuracy: 0.4999\n",
      "Epoch 92/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7402 - accuracy: 0.4997 - val_loss: 0.7398 - val_accuracy: 0.4999\n",
      "Epoch 93/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7394 - accuracy: 0.4947 - val_loss: 0.7391 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7387 - accuracy: 0.4967 - val_loss: 0.7384 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7380 - accuracy: 0.5003 - val_loss: 0.7376 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7373 - accuracy: 0.4948 - val_loss: 0.7369 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7365 - accuracy: 0.5003 - val_loss: 0.7362 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7359 - accuracy: 0.5003 - val_loss: 0.7355 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7352 - accuracy: 0.5003 - val_loss: 0.7349 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7346 - accuracy: 0.5003 - val_loss: 0.7342 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7339 - accuracy: 0.5003 - val_loss: 0.7336 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7332 - accuracy: 0.5003 - val_loss: 0.7329 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7326 - accuracy: 0.5003 - val_loss: 0.7322 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7319 - accuracy: 0.5003 - val_loss: 0.7316 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7313 - accuracy: 0.5003 - val_loss: 0.7310 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7307 - accuracy: 0.5003 - val_loss: 0.7304 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7301 - accuracy: 0.5003 - val_loss: 0.7298 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7295 - accuracy: 0.5003 - val_loss: 0.7293 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7290 - accuracy: 0.5003 - val_loss: 0.7288 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7286 - accuracy: 0.5003 - val_loss: 0.7283 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7281 - accuracy: 0.5003 - val_loss: 0.7279 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7276 - accuracy: 0.5003 - val_loss: 0.7274 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7272 - accuracy: 0.5003 - val_loss: 0.7270 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7267 - accuracy: 0.5003 - val_loss: 0.7265 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7263 - accuracy: 0.5003 - val_loss: 0.7260 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7258 - accuracy: 0.5003 - val_loss: 0.7256 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7254 - accuracy: 0.5003 - val_loss: 0.7252 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7250 - accuracy: 0.5003 - val_loss: 0.7249 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7247 - accuracy: 0.5003 - val_loss: 0.7245 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7244 - accuracy: 0.5003 - val_loss: 0.7242 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7240 - accuracy: 0.5003 - val_loss: 0.7239 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7237 - accuracy: 0.5003 - val_loss: 0.7235 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7234 - accuracy: 0.5003 - val_loss: 0.7232 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7230 - accuracy: 0.5003 - val_loss: 0.7229 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7227 - accuracy: 0.5003 - val_loss: 0.7225 - val_accuracy: 0.5001\n",
      "Epoch 126/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7224 - accuracy: 0.5003 - val_loss: 0.7222 - val_accuracy: 0.5001\n",
      "Epoch 127/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7221 - accuracy: 0.5003 - val_loss: 0.7219 - val_accuracy: 0.5001\n",
      "Epoch 128/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7218 - accuracy: 0.5003 - val_loss: 0.7217 - val_accuracy: 0.5001\n",
      "Epoch 129/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7215 - accuracy: 0.5003 - val_loss: 0.7214 - val_accuracy: 0.5001\n",
      "Epoch 130/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7213 - accuracy: 0.5003 - val_loss: 0.7212 - val_accuracy: 0.5001\n",
      "Epoch 131/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7211 - accuracy: 0.5003 - val_loss: 0.7210 - val_accuracy: 0.5001\n",
      "Epoch 132/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7209 - accuracy: 0.5003 - val_loss: 0.7208 - val_accuracy: 0.5001\n",
      "Epoch 133/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7207 - accuracy: 0.5003 - val_loss: 0.7206 - val_accuracy: 0.5001\n",
      "Epoch 134/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7205 - accuracy: 0.5003 - val_loss: 0.7204 - val_accuracy: 0.5001\n",
      "Epoch 135/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7203 - accuracy: 0.5003 - val_loss: 0.7202 - val_accuracy: 0.5001\n",
      "Epoch 136/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7201 - accuracy: 0.5003 - val_loss: 0.7200 - val_accuracy: 0.5001\n",
      "Epoch 137/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7199 - accuracy: 0.5003 - val_loss: 0.7198 - val_accuracy: 0.5001\n",
      "Epoch 138/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7197 - accuracy: 0.5003 - val_loss: 0.7196 - val_accuracy: 0.5001\n",
      "Epoch 139/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7195 - accuracy: 0.5003 - val_loss: 0.7194 - val_accuracy: 0.5001\n",
      "Epoch 140/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7193 - accuracy: 0.5003 - val_loss: 0.7192 - val_accuracy: 0.5001\n",
      "Epoch 141/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7191 - accuracy: 0.5003 - val_loss: 0.7190 - val_accuracy: 0.5001\n",
      "Epoch 142/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7189 - accuracy: 0.5003 - val_loss: 0.7188 - val_accuracy: 0.5001\n",
      "Epoch 143/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7187 - accuracy: 0.5003 - val_loss: 0.7186 - val_accuracy: 0.5001\n",
      "Epoch 144/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7185 - accuracy: 0.5003 - val_loss: 0.7184 - val_accuracy: 0.5001\n",
      "Epoch 145/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7183 - accuracy: 0.5003 - val_loss: 0.7182 - val_accuracy: 0.5001\n",
      "Epoch 146/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7181 - accuracy: 0.5003 - val_loss: 0.7181 - val_accuracy: 0.5001\n",
      "Epoch 147/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7180 - accuracy: 0.5003 - val_loss: 0.7179 - val_accuracy: 0.5001\n",
      "Epoch 148/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7179 - accuracy: 0.5003 - val_loss: 0.7178 - val_accuracy: 0.5001\n",
      "Epoch 149/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7177 - accuracy: 0.5003 - val_loss: 0.7176 - val_accuracy: 0.5001\n",
      "Epoch 150/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7176 - accuracy: 0.5003 - val_loss: 0.7175 - val_accuracy: 0.5001\n",
      "Epoch 151/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7174 - accuracy: 0.5003 - val_loss: 0.7174 - val_accuracy: 0.5001\n",
      "Epoch 152/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7173 - accuracy: 0.5003 - val_loss: 0.7172 - val_accuracy: 0.5001\n",
      "Epoch 153/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7171 - accuracy: 0.5003 - val_loss: 0.7171 - val_accuracy: 0.5001\n",
      "Epoch 154/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7170 - accuracy: 0.5003 - val_loss: 0.7169 - val_accuracy: 0.5001\n",
      "Epoch 155/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7169 - accuracy: 0.5003 - val_loss: 0.7168 - val_accuracy: 0.5001\n",
      "Epoch 156/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7167 - accuracy: 0.5003 - val_loss: 0.7166 - val_accuracy: 0.5001\n",
      "Epoch 157/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7166 - accuracy: 0.5003 - val_loss: 0.7165 - val_accuracy: 0.5001\n",
      "Epoch 158/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7164 - accuracy: 0.5003 - val_loss: 0.7164 - val_accuracy: 0.5001\n",
      "Epoch 159/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7163 - accuracy: 0.5003 - val_loss: 0.7162 - val_accuracy: 0.5001\n",
      "Epoch 160/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7162 - accuracy: 0.5003 - val_loss: 0.7161 - val_accuracy: 0.5001\n",
      "Epoch 161/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7160 - accuracy: 0.5003 - val_loss: 0.7159 - val_accuracy: 0.5001\n",
      "Epoch 162/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7159 - accuracy: 0.5003 - val_loss: 0.7158 - val_accuracy: 0.5001\n",
      "Epoch 163/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7157 - accuracy: 0.5003 - val_loss: 0.7157 - val_accuracy: 0.5001\n",
      "Epoch 164/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7156 - accuracy: 0.5003 - val_loss: 0.7155 - val_accuracy: 0.5001\n",
      "Epoch 165/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7154 - accuracy: 0.5003 - val_loss: 0.7154 - val_accuracy: 0.5001\n",
      "Epoch 166/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7153 - accuracy: 0.5003 - val_loss: 0.7152 - val_accuracy: 0.5001\n",
      "Epoch 167/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7152 - accuracy: 0.5003 - val_loss: 0.7151 - val_accuracy: 0.5001\n",
      "Epoch 168/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7150 - accuracy: 0.5003 - val_loss: 0.7149 - val_accuracy: 0.5001\n",
      "Epoch 169/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7149 - accuracy: 0.5003 - val_loss: 0.7148 - val_accuracy: 0.5001\n",
      "Epoch 170/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7148 - accuracy: 0.5003 - val_loss: 0.7147 - val_accuracy: 0.5001\n",
      "Epoch 171/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7147 - accuracy: 0.5003 - val_loss: 0.7147 - val_accuracy: 0.5001\n",
      "Epoch 172/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7146 - accuracy: 0.5003 - val_loss: 0.7146 - val_accuracy: 0.5001\n",
      "Epoch 173/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7145 - accuracy: 0.5003 - val_loss: 0.7145 - val_accuracy: 0.5001\n",
      "Epoch 174/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7145 - accuracy: 0.5003 - val_loss: 0.7144 - val_accuracy: 0.5001\n",
      "Epoch 175/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7144 - accuracy: 0.5003 - val_loss: 0.7143 - val_accuracy: 0.5001\n",
      "Epoch 176/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7143 - accuracy: 0.5003 - val_loss: 0.7143 - val_accuracy: 0.5001\n",
      "Epoch 177/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7142 - accuracy: 0.5003 - val_loss: 0.7142 - val_accuracy: 0.5001\n",
      "Epoch 178/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7141 - accuracy: 0.5003 - val_loss: 0.7141 - val_accuracy: 0.5001\n",
      "Epoch 179/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7140 - accuracy: 0.5003 - val_loss: 0.7140 - val_accuracy: 0.5001\n",
      "Epoch 180/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7140 - accuracy: 0.5003 - val_loss: 0.7139 - val_accuracy: 0.5001\n",
      "Epoch 181/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7139 - accuracy: 0.5003 - val_loss: 0.7138 - val_accuracy: 0.5001\n",
      "Epoch 182/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7138 - accuracy: 0.5003 - val_loss: 0.7137 - val_accuracy: 0.5001\n",
      "Epoch 183/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7137 - accuracy: 0.5003 - val_loss: 0.7137 - val_accuracy: 0.5001\n",
      "Epoch 184/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7136 - accuracy: 0.5003 - val_loss: 0.7136 - val_accuracy: 0.5001\n",
      "Epoch 185/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7135 - accuracy: 0.5003 - val_loss: 0.7135 - val_accuracy: 0.5001\n",
      "Epoch 186/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7135 - accuracy: 0.5003 - val_loss: 0.7134 - val_accuracy: 0.5001\n",
      "Epoch 187/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7134 - accuracy: 0.5003 - val_loss: 0.7133 - val_accuracy: 0.5001\n",
      "Epoch 188/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7133 - accuracy: 0.5003 - val_loss: 0.7133 - val_accuracy: 0.5001\n",
      "Epoch 189/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7132 - accuracy: 0.5003 - val_loss: 0.7132 - val_accuracy: 0.5001\n",
      "Epoch 190/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7131 - accuracy: 0.5003 - val_loss: 0.7131 - val_accuracy: 0.5001\n",
      "Epoch 191/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7130 - accuracy: 0.5003 - val_loss: 0.7130 - val_accuracy: 0.5001\n",
      "Epoch 192/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7130 - accuracy: 0.5003 - val_loss: 0.7129 - val_accuracy: 0.5001\n",
      "Epoch 193/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7129 - accuracy: 0.5003 - val_loss: 0.7128 - val_accuracy: 0.5001\n",
      "Epoch 194/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7128 - accuracy: 0.5003 - val_loss: 0.7128 - val_accuracy: 0.5001\n",
      "Epoch 195/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7127 - accuracy: 0.5003 - val_loss: 0.7127 - val_accuracy: 0.5001\n",
      "Epoch 196/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7126 - accuracy: 0.5003 - val_loss: 0.7126 - val_accuracy: 0.5001\n",
      "Epoch 197/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7125 - accuracy: 0.5003 - val_loss: 0.7125 - val_accuracy: 0.5001\n",
      "Epoch 198/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7125 - accuracy: 0.5003 - val_loss: 0.7124 - val_accuracy: 0.5001\n",
      "Epoch 199/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7124 - accuracy: 0.5003 - val_loss: 0.7123 - val_accuracy: 0.5001\n",
      "Epoch 200/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7123 - accuracy: 0.5003 - val_loss: 0.7123 - val_accuracy: 0.5001\n",
      "Epoch 201/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7122 - accuracy: 0.5003 - val_loss: 0.7122 - val_accuracy: 0.5001\n",
      "Epoch 202/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7121 - accuracy: 0.5003 - val_loss: 0.7121 - val_accuracy: 0.5001\n",
      "Epoch 203/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7121 - accuracy: 0.5003 - val_loss: 0.7120 - val_accuracy: 0.5001\n",
      "Epoch 204/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7120 - accuracy: 0.5003 - val_loss: 0.7119 - val_accuracy: 0.5001\n",
      "Epoch 205/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7119 - accuracy: 0.5003 - val_loss: 0.7118 - val_accuracy: 0.5001\n",
      "Epoch 206/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7118 - accuracy: 0.5003 - val_loss: 0.7118 - val_accuracy: 0.5001\n",
      "Epoch 207/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7117 - accuracy: 0.5003 - val_loss: 0.7117 - val_accuracy: 0.5001\n",
      "Epoch 208/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7116 - accuracy: 0.5003 - val_loss: 0.7116 - val_accuracy: 0.5001\n",
      "Epoch 209/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7116 - accuracy: 0.5003 - val_loss: 0.7115 - val_accuracy: 0.5001\n",
      "Epoch 210/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7115 - accuracy: 0.5003 - val_loss: 0.7115 - val_accuracy: 0.5001\n",
      "Epoch 211/300\n",
      "670/670 [==============================] - 4s 5ms/step - loss: 0.7114 - accuracy: 0.5003 - val_loss: 0.7114 - val_accuracy: 0.5001\n",
      "Epoch 212/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7113 - accuracy: 0.5003 - val_loss: 0.7113 - val_accuracy: 0.5001\n",
      "Epoch 213/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7112 - accuracy: 0.5003 - val_loss: 0.7112 - val_accuracy: 0.5001\n",
      "Epoch 214/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7112 - accuracy: 0.5003 - val_loss: 0.7111 - val_accuracy: 0.5001\n",
      "Epoch 215/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7111 - accuracy: 0.5003 - val_loss: 0.7110 - val_accuracy: 0.5001\n",
      "Epoch 216/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7110 - accuracy: 0.5003 - val_loss: 0.7110 - val_accuracy: 0.5001\n",
      "Epoch 217/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7109 - accuracy: 0.5003 - val_loss: 0.7109 - val_accuracy: 0.5001\n",
      "Epoch 218/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7108 - accuracy: 0.5003 - val_loss: 0.7108 - val_accuracy: 0.5001\n",
      "Epoch 219/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7108 - accuracy: 0.5003 - val_loss: 0.7107 - val_accuracy: 0.5001\n",
      "Epoch 220/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7107 - accuracy: 0.5003 - val_loss: 0.7106 - val_accuracy: 0.5001\n",
      "Epoch 221/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7106 - accuracy: 0.5003 - val_loss: 0.7106 - val_accuracy: 0.5001\n",
      "Epoch 222/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7105 - accuracy: 0.5003 - val_loss: 0.7105 - val_accuracy: 0.5001\n",
      "Epoch 223/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7104 - accuracy: 0.5003 - val_loss: 0.7104 - val_accuracy: 0.5001\n",
      "Epoch 224/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7104 - accuracy: 0.5003 - val_loss: 0.7103 - val_accuracy: 0.5001\n",
      "Epoch 225/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7103 - accuracy: 0.5003 - val_loss: 0.7102 - val_accuracy: 0.5001\n",
      "Epoch 226/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7102 - accuracy: 0.5003 - val_loss: 0.7101 - val_accuracy: 0.5001\n",
      "Epoch 227/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7101 - accuracy: 0.5003 - val_loss: 0.7101 - val_accuracy: 0.5001\n",
      "Epoch 228/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7100 - accuracy: 0.5003 - val_loss: 0.7100 - val_accuracy: 0.5001\n",
      "Epoch 229/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7099 - accuracy: 0.5003 - val_loss: 0.7099 - val_accuracy: 0.5001\n",
      "Epoch 230/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7099 - accuracy: 0.5003 - val_loss: 0.7098 - val_accuracy: 0.5001\n",
      "Epoch 231/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7098 - accuracy: 0.5003 - val_loss: 0.7098 - val_accuracy: 0.5001\n",
      "Epoch 232/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7097 - accuracy: 0.5003 - val_loss: 0.7097 - val_accuracy: 0.5001\n",
      "Epoch 233/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7097 - accuracy: 0.5003 - val_loss: 0.7096 - val_accuracy: 0.5001\n",
      "Epoch 234/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7096 - accuracy: 0.5003 - val_loss: 0.7096 - val_accuracy: 0.5001\n",
      "Epoch 235/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7095 - accuracy: 0.5003 - val_loss: 0.7095 - val_accuracy: 0.5001\n",
      "Epoch 236/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7095 - accuracy: 0.5003 - val_loss: 0.7094 - val_accuracy: 0.5001\n",
      "Epoch 237/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7094 - accuracy: 0.5003 - val_loss: 0.7094 - val_accuracy: 0.5001\n",
      "Epoch 238/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7093 - accuracy: 0.5003 - val_loss: 0.7093 - val_accuracy: 0.5001\n",
      "Epoch 239/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7093 - accuracy: 0.5003 - val_loss: 0.7093 - val_accuracy: 0.5001\n",
      "Epoch 240/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7092 - accuracy: 0.5003 - val_loss: 0.7092 - val_accuracy: 0.5001\n",
      "Epoch 241/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7092 - accuracy: 0.5003 - val_loss: 0.7091 - val_accuracy: 0.5001\n",
      "Epoch 242/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7091 - accuracy: 0.5003 - val_loss: 0.7091 - val_accuracy: 0.5001\n",
      "Epoch 243/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7090 - accuracy: 0.5003 - val_loss: 0.7090 - val_accuracy: 0.5001\n",
      "Epoch 244/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7090 - accuracy: 0.5003 - val_loss: 0.7090 - val_accuracy: 0.5001\n",
      "Epoch 245/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7089 - accuracy: 0.5003 - val_loss: 0.7089 - val_accuracy: 0.5001\n",
      "Epoch 246/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7089 - accuracy: 0.5003 - val_loss: 0.7088 - val_accuracy: 0.5001\n",
      "Epoch 247/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7088 - accuracy: 0.5003 - val_loss: 0.7088 - val_accuracy: 0.5001\n",
      "Epoch 248/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7087 - accuracy: 0.5003 - val_loss: 0.7087 - val_accuracy: 0.5001\n",
      "Epoch 249/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7087 - accuracy: 0.5003 - val_loss: 0.7086 - val_accuracy: 0.5001\n",
      "Epoch 250/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7086 - accuracy: 0.5003 - val_loss: 0.7086 - val_accuracy: 0.5001\n",
      "Epoch 251/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7086 - accuracy: 0.5003 - val_loss: 0.7085 - val_accuracy: 0.5001\n",
      "Epoch 252/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7085 - accuracy: 0.5003 - val_loss: 0.7085 - val_accuracy: 0.5001\n",
      "Epoch 253/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7084 - accuracy: 0.5003 - val_loss: 0.7084 - val_accuracy: 0.5001\n",
      "Epoch 254/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7084 - accuracy: 0.5003 - val_loss: 0.7083 - val_accuracy: 0.5001\n",
      "Epoch 255/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7083 - accuracy: 0.5003 - val_loss: 0.7083 - val_accuracy: 0.5001\n",
      "Epoch 256/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7082 - accuracy: 0.5003 - val_loss: 0.7082 - val_accuracy: 0.5001\n",
      "Epoch 257/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7082 - accuracy: 0.5003 - val_loss: 0.7082 - val_accuracy: 0.5001\n",
      "Epoch 258/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7081 - accuracy: 0.5003 - val_loss: 0.7081 - val_accuracy: 0.5001\n",
      "Epoch 259/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7081 - accuracy: 0.5003 - val_loss: 0.7080 - val_accuracy: 0.5001\n",
      "Epoch 260/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 0.7080 - accuracy: 0.5003 - val_loss: 0.7080 - val_accuracy: 0.5001\n",
      "Epoch 261/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7079 - accuracy: 0.5003 - val_loss: 0.7079 - val_accuracy: 0.5001\n",
      "Epoch 262/300\n",
      "670/670 [==============================] - 5s 7ms/step - loss: 0.7079 - accuracy: 0.5003 - val_loss: 0.7078 - val_accuracy: 0.5001\n",
      "Epoch 263/300\n",
      "670/670 [==============================] - 4s 6ms/step - loss: 0.7078 - accuracy: 0.5003 - val_loss: 0.7078 - val_accuracy: 0.5001\n",
      "Epoch 264/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7078 - accuracy: 0.5003 - val_loss: 0.7077 - val_accuracy: 0.5001\n",
      "Epoch 265/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7077 - accuracy: 0.5003 - val_loss: 0.7077 - val_accuracy: 0.5001\n",
      "Epoch 266/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7076 - accuracy: 0.5003 - val_loss: 0.7076 - val_accuracy: 0.5001\n",
      "Epoch 267/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7076 - accuracy: 0.5003 - val_loss: 0.7075 - val_accuracy: 0.5001\n",
      "Epoch 268/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7075 - accuracy: 0.5003 - val_loss: 0.7075 - val_accuracy: 0.5001\n",
      "Epoch 269/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7075 - accuracy: 0.5003 - val_loss: 0.7074 - val_accuracy: 0.5001\n",
      "Epoch 270/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7074 - accuracy: 0.5003 - val_loss: 0.7074 - val_accuracy: 0.5001\n",
      "Epoch 271/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7073 - accuracy: 0.5003 - val_loss: 0.7073 - val_accuracy: 0.5001\n",
      "Epoch 272/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7073 - accuracy: 0.5003 - val_loss: 0.7072 - val_accuracy: 0.5001\n",
      "Epoch 273/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7072 - accuracy: 0.5003 - val_loss: 0.7072 - val_accuracy: 0.5001\n",
      "Epoch 274/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7072 - accuracy: 0.5003 - val_loss: 0.7071 - val_accuracy: 0.5001\n",
      "Epoch 275/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7071 - accuracy: 0.5003 - val_loss: 0.7071 - val_accuracy: 0.5001\n",
      "Epoch 276/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7070 - accuracy: 0.5003 - val_loss: 0.7070 - val_accuracy: 0.5001\n",
      "Epoch 277/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7070 - accuracy: 0.5003 - val_loss: 0.7070 - val_accuracy: 0.5001\n",
      "Epoch 278/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7069 - accuracy: 0.5003 - val_loss: 0.7069 - val_accuracy: 0.5001\n",
      "Epoch 279/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7069 - accuracy: 0.5003 - val_loss: 0.7068 - val_accuracy: 0.5001\n",
      "Epoch 280/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7068 - accuracy: 0.5003 - val_loss: 0.7068 - val_accuracy: 0.5001\n",
      "Epoch 281/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7067 - accuracy: 0.5003 - val_loss: 0.7067 - val_accuracy: 0.5001\n",
      "Epoch 282/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7067 - accuracy: 0.5003 - val_loss: 0.7067 - val_accuracy: 0.5001\n",
      "Epoch 283/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7066 - accuracy: 0.5003 - val_loss: 0.7066 - val_accuracy: 0.5001\n",
      "Epoch 284/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7066 - accuracy: 0.5003 - val_loss: 0.7065 - val_accuracy: 0.5001\n",
      "Epoch 285/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7065 - accuracy: 0.5003 - val_loss: 0.7065 - val_accuracy: 0.5001\n",
      "Epoch 286/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7064 - accuracy: 0.5003 - val_loss: 0.7064 - val_accuracy: 0.5001\n",
      "Epoch 287/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7064 - accuracy: 0.5003 - val_loss: 0.7064 - val_accuracy: 0.5001\n",
      "Epoch 288/300\n",
      "670/670 [==============================] - 3s 4ms/step - loss: 0.7063 - accuracy: 0.5003 - val_loss: 0.7063 - val_accuracy: 0.5001\n",
      "Epoch 289/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7063 - accuracy: 0.5003 - val_loss: 0.7062 - val_accuracy: 0.5001\n",
      "Epoch 290/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7062 - accuracy: 0.5003 - val_loss: 0.7062 - val_accuracy: 0.5001\n",
      "Epoch 291/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7061 - accuracy: 0.5003 - val_loss: 0.7061 - val_accuracy: 0.5001\n",
      "Epoch 292/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7061 - accuracy: 0.5003 - val_loss: 0.7061 - val_accuracy: 0.5001\n",
      "Epoch 293/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7060 - accuracy: 0.5003 - val_loss: 0.7060 - val_accuracy: 0.5001\n",
      "Epoch 294/300\n",
      "670/670 [==============================] - 4s 7ms/step - loss: 0.7060 - accuracy: 0.5003 - val_loss: 0.7059 - val_accuracy: 0.5001\n",
      "Epoch 295/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7059 - accuracy: 0.5003 - val_loss: 0.7059 - val_accuracy: 0.5001\n",
      "Epoch 296/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7058 - accuracy: 0.5003 - val_loss: 0.7058 - val_accuracy: 0.5001\n",
      "Epoch 297/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7058 - accuracy: 0.5003 - val_loss: 0.7058 - val_accuracy: 0.5001\n",
      "Epoch 298/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7057 - accuracy: 0.5003 - val_loss: 0.7057 - val_accuracy: 0.5001\n",
      "Epoch 299/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7057 - accuracy: 0.5003 - val_loss: 0.7056 - val_accuracy: 0.5001\n",
      "Epoch 300/300\n",
      "670/670 [==============================] - 3s 5ms/step - loss: 0.7056 - accuracy: 0.5003 - val_loss: 0.7056 - val_accuracy: 0.5001\n",
      "620/620 [==============================] - 2s 2ms/step - loss: 0.7056 - accuracy: 0.5001\n",
      "{'loss': 0.7055757641792297, 'accuracy': 0.5001260638237} \n",
      " 299 \n",
      "\n",
      "Model time: 16.292033709585667 minutes\n",
      "\n",
      "Total time: 237.30867923423648 minutes\n",
      "\n",
      "\n",
      "Model  111  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                   256\n",
      "Activation function           tanh\n",
      "Dropout                        0.7\n",
      "L1                             0.0\n",
      "L2                             1.0\n",
      "Batch size                     256\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 2671246, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 4s 28ms/step - loss: 12.4052 - accuracy: 0.4988 - val_loss: 3.4755 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 3.4514 - accuracy: 0.4936 - val_loss: 3.4542 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 3.4522 - accuracy: 0.5028 - val_loss: 3.4503 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 3.4520 - accuracy: 0.4985 - val_loss: 3.4463 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "82/84 [============================>.] - ETA: 0s - loss: 3.4515 - accuracy: 0.4953Restoring model weights from the end of the best epoch: 4.\n",
      "84/84 [==============================] - 2s 20ms/step - loss: 3.4515 - accuracy: 0.4965 - val_loss: 3.4541 - val_accuracy: 0.5001\n",
      "Epoch 5: early stopping\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 3.4463 - accuracy: 0.4999\n",
      "{'loss': 3.4462904930114746, 'accuracy': 0.49987393617630005} \n",
      " 4 \n",
      "\n",
      "Model time: 0.21219979599118233 minutes\n",
      "\n",
      "Total time: 237.52097901701927 minutes\n",
      "\n",
      "\n",
      "Model  112  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                    32\n",
      "Activation function         linear\n",
      "Dropout                        0.0\n",
      "L1                           0.001\n",
      "L2                           0.001\n",
      "Batch size                       8\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 6456963, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 17s 6ms/step - loss: 1.1378 - accuracy: 0.6077 - val_loss: 0.7600 - val_accuracy: 0.6060\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7025 - accuracy: 0.6222 - val_loss: 0.6830 - val_accuracy: 0.6235\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.6785 - accuracy: 0.6269 - val_loss: 0.6798 - val_accuracy: 0.6290\n",
      "Epoch 4/300\n",
      "2674/2677 [============================>.] - ETA: 0s - loss: 0.6746 - accuracy: 0.6279Restoring model weights from the end of the best epoch: 3.\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.6746 - accuracy: 0.6280 - val_loss: 0.6800 - val_accuracy: 0.6233\n",
      "Epoch 4: early stopping\n",
      "2480/2480 [==============================] - 6s 2ms/step - loss: 0.6798 - accuracy: 0.6290\n",
      "{'loss': 0.6797550320625305, 'accuracy': 0.6289517283439636} \n",
      " 3 \n",
      "\n",
      "Model time: 1.1222988814115524 minutes\n",
      "\n",
      "Total time: 238.64337789267302 minutes\n",
      "\n",
      "\n",
      "Model  113  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                    32\n",
      "Activation function           relu\n",
      "Dropout                        0.4\n",
      "L1                           100.0\n",
      "L2                            10.0\n",
      "Batch size                      64\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 2232268, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 7ms/step - loss: 64688.6250 - accuracy: 0.5015 - val_loss: 63566.0352 - val_accuracy: 0.5107\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 62469.0586 - accuracy: 0.5047 - val_loss: 61368.8477 - val_accuracy: 0.5132\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 60290.6289 - accuracy: 0.5050 - val_loss: 59209.8516 - val_accuracy: 0.5117\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 58152.4297 - accuracy: 0.5070 - val_loss: 57092.6836 - val_accuracy: 0.5121\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 56055.3984 - accuracy: 0.5048 - val_loss: 55015.0703 - val_accuracy: 0.5124\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 53995.7734 - accuracy: 0.4993 - val_loss: 52974.0000 - val_accuracy: 0.5119\n",
      "Epoch 7/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 51975.6719 - accuracy: 0.5029 - val_loss: 50976.0039 - val_accuracy: 0.5127\n",
      "Epoch 8/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 49999.5781 - accuracy: 0.5073 - val_loss: 49022.0430 - val_accuracy: 0.5142\n",
      "Epoch 9/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 48066.9609 - accuracy: 0.5063 - val_loss: 47110.1016 - val_accuracy: 0.5162\n",
      "Epoch 10/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 46175.0664 - accuracy: 0.5085 - val_loss: 45237.1055 - val_accuracy: 0.5185\n",
      "Epoch 11/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 44319.5273 - accuracy: 0.5055 - val_loss: 43401.0039 - val_accuracy: 0.5198\n",
      "Epoch 12/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 42503.9844 - accuracy: 0.5129 - val_loss: 41605.2617 - val_accuracy: 0.5203\n",
      "Epoch 13/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 40729.2109 - accuracy: 0.5069 - val_loss: 39852.9727 - val_accuracy: 0.5219\n",
      "Epoch 14/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 38998.7617 - accuracy: 0.5092 - val_loss: 38142.3398 - val_accuracy: 0.5211\n",
      "Epoch 15/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 37306.1914 - accuracy: 0.5061 - val_loss: 36470.6367 - val_accuracy: 0.5238\n",
      "Epoch 16/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 35657.9453 - accuracy: 0.5023 - val_loss: 34846.0000 - val_accuracy: 0.5255\n",
      "Epoch 17/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 34055.2422 - accuracy: 0.5048 - val_loss: 33264.3867 - val_accuracy: 0.5263\n",
      "Epoch 18/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 32492.7148 - accuracy: 0.5096 - val_loss: 31720.3730 - val_accuracy: 0.5286\n",
      "Epoch 19/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 30968.6250 - accuracy: 0.5079 - val_loss: 30217.5586 - val_accuracy: 0.5296\n",
      "Epoch 20/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29487.2949 - accuracy: 0.5112 - val_loss: 28756.6387 - val_accuracy: 0.5298\n",
      "Epoch 21/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 28045.9941 - accuracy: 0.5118 - val_loss: 27335.5449 - val_accuracy: 0.5285\n",
      "Epoch 22/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 26644.1934 - accuracy: 0.5144 - val_loss: 25953.0117 - val_accuracy: 0.5279\n",
      "Epoch 23/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 25283.1895 - accuracy: 0.5039 - val_loss: 24615.0312 - val_accuracy: 0.5253\n",
      "Epoch 24/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 23966.7930 - accuracy: 0.5118 - val_loss: 23319.9570 - val_accuracy: 0.5230\n",
      "Epoch 25/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 22693.8984 - accuracy: 0.5068 - val_loss: 22069.1523 - val_accuracy: 0.5192\n",
      "Epoch 26/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 21461.8203 - accuracy: 0.5076 - val_loss: 20854.8711 - val_accuracy: 0.5168\n",
      "Epoch 27/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 20266.9355 - accuracy: 0.5107 - val_loss: 19680.9609 - val_accuracy: 0.5133\n",
      "Epoch 28/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 19113.7598 - accuracy: 0.5082 - val_loss: 18548.8301 - val_accuracy: 0.5102\n",
      "Epoch 29/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 18002.3066 - accuracy: 0.5066 - val_loss: 17457.5078 - val_accuracy: 0.5087\n",
      "Epoch 30/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 16930.0547 - accuracy: 0.5039 - val_loss: 16403.8496 - val_accuracy: 0.5055\n",
      "Epoch 31/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 15895.0410 - accuracy: 0.5023 - val_loss: 15389.1768 - val_accuracy: 0.5035\n",
      "Epoch 32/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 14901.8438 - accuracy: 0.5042 - val_loss: 14416.0576 - val_accuracy: 0.5022\n",
      "Epoch 33/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13947.2842 - accuracy: 0.5029 - val_loss: 13481.0420 - val_accuracy: 0.5014\n",
      "Epoch 34/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 13033.8818 - accuracy: 0.5025 - val_loss: 12588.8047 - val_accuracy: 0.5002\n",
      "Epoch 35/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12161.7871 - accuracy: 0.4970 - val_loss: 11738.3213 - val_accuracy: 0.4989\n",
      "Epoch 36/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 11332.8018 - accuracy: 0.4987 - val_loss: 10930.2227 - val_accuracy: 0.4995\n",
      "Epoch 37/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 10543.9893 - accuracy: 0.4982 - val_loss: 10161.3213 - val_accuracy: 0.4998\n",
      "Epoch 38/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 9795.4561 - accuracy: 0.4993 - val_loss: 9433.0703 - val_accuracy: 0.5000\n",
      "Epoch 39/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 9085.0312 - accuracy: 0.5001 - val_loss: 8741.6709 - val_accuracy: 0.4998\n",
      "Epoch 40/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 8418.2246 - accuracy: 0.5005 - val_loss: 8099.7148 - val_accuracy: 0.5000\n",
      "Epoch 41/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 7798.0508 - accuracy: 0.5005 - val_loss: 7500.5010 - val_accuracy: 0.5002\n",
      "Epoch 42/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 7218.2524 - accuracy: 0.5000 - val_loss: 6939.8447 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6676.2007 - accuracy: 0.4999 - val_loss: 6417.2461 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 6173.5542 - accuracy: 0.5004 - val_loss: 5934.1572 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5710.7168 - accuracy: 0.5004 - val_loss: 5491.0088 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5284.3799 - accuracy: 0.5003 - val_loss: 5082.2153 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4897.5986 - accuracy: 0.5003 - val_loss: 4719.6211 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4558.3755 - accuracy: 0.5003 - val_loss: 4402.2808 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4260.1367 - accuracy: 0.5003 - val_loss: 4123.5942 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4003.3611 - accuracy: 0.5003 - val_loss: 3889.4465 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3790.8379 - accuracy: 0.5003 - val_loss: 3698.4175 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3615.0444 - accuracy: 0.5003 - val_loss: 3531.5598 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3450.1321 - accuracy: 0.5003 - val_loss: 3368.3137 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 3288.5220 - accuracy: 0.5003 - val_loss: 3208.6880 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 3130.3655 - accuracy: 0.5003 - val_loss: 3051.9402 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2975.4387 - accuracy: 0.5003 - val_loss: 2898.8433 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2824.0591 - accuracy: 0.5003 - val_loss: 2749.0142 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2676.0996 - accuracy: 0.5003 - val_loss: 2603.4417 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2533.1055 - accuracy: 0.5003 - val_loss: 2462.9595 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2394.9153 - accuracy: 0.5003 - val_loss: 2327.1238 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2261.4961 - accuracy: 0.5003 - val_loss: 2195.8567 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2131.3525 - accuracy: 0.5003 - val_loss: 2066.7512 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2004.2849 - accuracy: 0.5003 - val_loss: 1941.8756 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1880.7423 - accuracy: 0.5003 - val_loss: 1819.4047 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1759.6583 - accuracy: 0.5003 - val_loss: 1700.4126 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1643.8240 - accuracy: 0.5003 - val_loss: 1587.5107 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 1533.6404 - accuracy: 0.5003 - val_loss: 1480.2235 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1428.6339 - accuracy: 0.5003 - val_loss: 1377.1180 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1327.9158 - accuracy: 0.5003 - val_loss: 1279.0953 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1231.7661 - accuracy: 0.5003 - val_loss: 1184.3445 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 1138.6852 - accuracy: 0.5003 - val_loss: 1093.1456 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1049.0226 - accuracy: 0.5003 - val_loss: 1005.3878 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 963.2819 - accuracy: 0.5003 - val_loss: 921.4907 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 881.4291 - accuracy: 0.5003 - val_loss: 841.3444 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 802.6184 - accuracy: 0.5003 - val_loss: 764.0740 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 727.0522 - accuracy: 0.5003 - val_loss: 690.5659 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 656.3154 - accuracy: 0.5003 - val_loss: 622.4520 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 589.8578 - accuracy: 0.5003 - val_loss: 557.5948 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 527.0103 - accuracy: 0.5003 - val_loss: 496.7498 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 468.1992 - accuracy: 0.5003 - val_loss: 440.3443 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 414.1855 - accuracy: 0.5003 - val_loss: 389.1484 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 366.3095 - accuracy: 0.5003 - val_loss: 343.8600 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 322.9153 - accuracy: 0.5003 - val_loss: 302.9048 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 284.7069 - accuracy: 0.5003 - val_loss: 266.8136 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 250.3875 - accuracy: 0.5003 - val_loss: 234.3075 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 219.3752 - accuracy: 0.5003 - val_loss: 205.1540 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 192.2404 - accuracy: 0.5003 - val_loss: 179.7290 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 168.4526 - accuracy: 0.5003 - val_loss: 157.4298 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 148.0812 - accuracy: 0.5003 - val_loss: 139.2165 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 131.8283 - accuracy: 0.5003 - val_loss: 125.3022 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 120.6314 - accuracy: 0.5003 - val_loss: 116.5706 - val_accuracy: 0.5001\n",
      "Epoch 92/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 113.2361 - accuracy: 0.5003 - val_loss: 109.9785 - val_accuracy: 0.5001\n",
      "Epoch 93/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 106.7835 - accuracy: 0.5003 - val_loss: 103.5608 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 100.4449 - accuracy: 0.5003 - val_loss: 97.3664 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 94.3421 - accuracy: 0.5003 - val_loss: 91.2916 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 88.2546 - accuracy: 0.5003 - val_loss: 85.1913 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 82.1710 - accuracy: 0.5003 - val_loss: 79.1244 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 76.2505 - accuracy: 0.5003 - val_loss: 73.4757 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 70.7927 - accuracy: 0.5003 - val_loss: 68.0864 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 65.3905 - accuracy: 0.5003 - val_loss: 62.6835 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 60.3241 - accuracy: 0.5003 - val_loss: 57.9577 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 55.5981 - accuracy: 0.5003 - val_loss: 53.2182 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 50.8955 - accuracy: 0.5003 - val_loss: 48.6287 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 46.4392 - accuracy: 0.5003 - val_loss: 44.2308 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 42.0803 - accuracy: 0.5003 - val_loss: 40.0509 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 38.3639 - accuracy: 0.5003 - val_loss: 36.6624 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 35.0427 - accuracy: 0.5003 - val_loss: 33.4919 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 32.0219 - accuracy: 0.5003 - val_loss: 30.6235 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 29.2880 - accuracy: 0.5003 - val_loss: 27.9408 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 26.7239 - accuracy: 0.5003 - val_loss: 25.5299 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 24.3625 - accuracy: 0.5003 - val_loss: 23.1849 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 22.0048 - accuracy: 0.5003 - val_loss: 20.8144 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 19.7049 - accuracy: 0.5003 - val_loss: 18.6678 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 17.6557 - accuracy: 0.5003 - val_loss: 16.6348 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 15.6372 - accuracy: 0.5003 - val_loss: 14.6308 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "335/335 [==============================] - 3s 8ms/step - loss: 13.6200 - accuracy: 0.5003 - val_loss: 12.6006 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 11.6043 - accuracy: 0.5003 - val_loss: 10.5993 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 9.6342 - accuracy: 0.5003 - val_loss: 8.7452 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 7.9167 - accuracy: 0.5003 - val_loss: 7.0810 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 6.3230 - accuracy: 0.5003 - val_loss: 5.6937 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 5.3667 - accuracy: 0.5003 - val_loss: 5.0368 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 4.6983 - accuracy: 0.5003 - val_loss: 4.3923 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.2327 - accuracy: 0.5003 - val_loss: 4.0717 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.0105 - accuracy: 0.5003 - val_loss: 3.9982 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "334/335 [============================>.] - ETA: 0s - loss: 4.0052 - accuracy: 0.5002Restoring model weights from the end of the best epoch: 124.\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 4.0051 - accuracy: 0.5003 - val_loss: 4.0121 - val_accuracy: 0.5001\n",
      "Epoch 125: early stopping\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 3.9982 - accuracy: 0.5001\n",
      "{'loss': 3.9982030391693115, 'accuracy': 0.5001260638237} \n",
      " 124 \n",
      "\n",
      "Model time: 4.163479167968035 minutes\n",
      "\n",
      "Total time: 242.80692372471094 minutes\n",
      "\n",
      "\n",
      "Model  114  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    4\n",
      "Hidden units                     1\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.8\n",
      "L1                             0.1\n",
      "L2                           100.0\n",
      "Batch size                      64\n",
      "Optimizer                     Adam\n",
      "Learning rate              0.00001\n",
      "Name: 4348584, dtype: object\n",
      "NN4Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 5s 7ms/step - loss: 522.6724 - accuracy: 0.4947 - val_loss: 516.1216 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 510.2731 - accuracy: 0.4976 - val_loss: 503.9803 - val_accuracy: 0.5001\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 498.3648 - accuracy: 0.4951 - val_loss: 492.3126 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 486.9104 - accuracy: 0.4955 - val_loss: 481.0816 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 475.8913 - accuracy: 0.4990 - val_loss: 470.2574 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 465.2392 - accuracy: 0.5062 - val_loss: 459.8188 - val_accuracy: 0.5001\n",
      "Epoch 7/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 454.9976 - accuracy: 0.4931 - val_loss: 449.7318 - val_accuracy: 0.5001\n",
      "Epoch 8/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 445.0669 - accuracy: 0.5016 - val_loss: 439.9762 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 435.4731 - accuracy: 0.4992 - val_loss: 430.5368 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 426.1974 - accuracy: 0.4951 - val_loss: 421.3986 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 417.1987 - accuracy: 0.4975 - val_loss: 412.5517 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 408.4729 - accuracy: 0.4996 - val_loss: 403.9811 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 400.0396 - accuracy: 0.5005 - val_loss: 395.6787 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 391.8744 - accuracy: 0.4970 - val_loss: 387.6372 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 383.9565 - accuracy: 0.4996 - val_loss: 379.8489 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 376.2908 - accuracy: 0.5019 - val_loss: 372.3071 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 368.8534 - accuracy: 0.5014 - val_loss: 365.0035 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 361.6843 - accuracy: 0.4975 - val_loss: 357.9335 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 354.7220 - accuracy: 0.5010 - val_loss: 351.0900 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 347.9939 - accuracy: 0.4972 - val_loss: 344.4683 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 341.4551 - accuracy: 0.5055 - val_loss: 338.0614 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 335.1878 - accuracy: 0.4950 - val_loss: 331.8638 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 329.0771 - accuracy: 0.5007 - val_loss: 325.8702 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 323.1707 - accuracy: 0.5053 - val_loss: 320.0734 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 317.4714 - accuracy: 0.5023 - val_loss: 314.4689 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 311.9551 - accuracy: 0.5021 - val_loss: 309.0496 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 306.6432 - accuracy: 0.4997 - val_loss: 303.8112 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 301.4859 - accuracy: 0.4983 - val_loss: 298.7477 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 296.5099 - accuracy: 0.4975 - val_loss: 293.8544 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 291.6999 - accuracy: 0.4969 - val_loss: 289.1264 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 287.0416 - accuracy: 0.4986 - val_loss: 284.5592 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 282.5625 - accuracy: 0.4997 - val_loss: 280.1478 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 278.2094 - accuracy: 0.5032 - val_loss: 275.8876 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 274.0256 - accuracy: 0.5007 - val_loss: 271.7733 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 269.9732 - accuracy: 0.5024 - val_loss: 267.8016 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 266.0872 - accuracy: 0.4975 - val_loss: 263.9667 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 262.3153 - accuracy: 0.5002 - val_loss: 260.2639 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 258.6722 - accuracy: 0.4980 - val_loss: 256.6888 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 255.1455 - accuracy: 0.5059 - val_loss: 253.2362 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 251.7614 - accuracy: 0.4973 - val_loss: 249.9022 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 248.4971 - accuracy: 0.4932 - val_loss: 246.6819 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 245.3194 - accuracy: 0.4982 - val_loss: 243.5714 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 242.2570 - accuracy: 0.4988 - val_loss: 240.5650 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 239.2994 - accuracy: 0.5013 - val_loss: 237.6588 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 236.4396 - accuracy: 0.5028 - val_loss: 234.8485 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 233.6876 - accuracy: 0.4960 - val_loss: 232.1293 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 230.9983 - accuracy: 0.4980 - val_loss: 229.4967 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 228.4082 - accuracy: 0.4998 - val_loss: 226.9474 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 225.9016 - accuracy: 0.4967 - val_loss: 224.4778 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 223.4633 - accuracy: 0.4989 - val_loss: 222.0831 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 221.1204 - accuracy: 0.4913 - val_loss: 219.7580 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 218.7978 - accuracy: 0.5057 - val_loss: 217.4986 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 216.5882 - accuracy: 0.4997 - val_loss: 215.3005 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 214.4097 - accuracy: 0.4991 - val_loss: 213.1595 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 212.2908 - accuracy: 0.5027 - val_loss: 211.0715 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 210.2287 - accuracy: 0.5002 - val_loss: 209.0316 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 208.2085 - accuracy: 0.5021 - val_loss: 207.0357 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 206.2295 - accuracy: 0.5013 - val_loss: 205.0801 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 204.2980 - accuracy: 0.4984 - val_loss: 203.1600 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 202.3886 - accuracy: 0.5010 - val_loss: 201.2724 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 200.5163 - accuracy: 0.5009 - val_loss: 199.4125 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 198.6715 - accuracy: 0.4994 - val_loss: 197.5778 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 196.8436 - accuracy: 0.5018 - val_loss: 195.7646 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 195.0480 - accuracy: 0.4954 - val_loss: 193.9695 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 193.2549 - accuracy: 0.5011 - val_loss: 192.1900 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 191.4739 - accuracy: 0.5004 - val_loss: 190.4244 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 189.7268 - accuracy: 0.4967 - val_loss: 188.6715 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 187.9697 - accuracy: 0.4991 - val_loss: 186.9303 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 186.2308 - accuracy: 0.4996 - val_loss: 185.2000 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 184.5073 - accuracy: 0.4985 - val_loss: 183.4807 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 182.7972 - accuracy: 0.4961 - val_loss: 181.7722 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 181.0824 - accuracy: 0.5037 - val_loss: 180.0754 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 179.3989 - accuracy: 0.4970 - val_loss: 178.3892 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 177.7134 - accuracy: 0.4982 - val_loss: 176.7139 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 176.0338 - accuracy: 0.5040 - val_loss: 175.0493 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 174.3810 - accuracy: 0.4983 - val_loss: 173.3958 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 172.7268 - accuracy: 0.5023 - val_loss: 171.7525 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 171.0860 - accuracy: 0.5016 - val_loss: 170.1202 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 169.4641 - accuracy: 0.4997 - val_loss: 168.4989 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 167.8427 - accuracy: 0.5004 - val_loss: 166.8890 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 166.2422 - accuracy: 0.5021 - val_loss: 165.2904 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 164.6514 - accuracy: 0.4970 - val_loss: 163.7026 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 163.0605 - accuracy: 0.5016 - val_loss: 162.1255 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 161.4826 - accuracy: 0.5042 - val_loss: 160.5593 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 159.9178 - accuracy: 0.5048 - val_loss: 159.0045 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 158.3842 - accuracy: 0.4961 - val_loss: 157.4605 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 156.8397 - accuracy: 0.4987 - val_loss: 155.9265 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 155.3108 - accuracy: 0.5000 - val_loss: 154.4036 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 153.7909 - accuracy: 0.4985 - val_loss: 152.8918 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 152.2882 - accuracy: 0.4961 - val_loss: 151.3907 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 150.7845 - accuracy: 0.4999 - val_loss: 149.9003 - val_accuracy: 0.5001\n",
      "Epoch 92/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 149.3024 - accuracy: 0.4985 - val_loss: 148.4210 - val_accuracy: 0.5001\n",
      "Epoch 93/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 147.8207 - accuracy: 0.5031 - val_loss: 146.9522 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 146.3630 - accuracy: 0.4981 - val_loss: 145.4947 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 144.9060 - accuracy: 0.5025 - val_loss: 144.0479 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 143.4680 - accuracy: 0.4989 - val_loss: 142.6117 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 142.0289 - accuracy: 0.5014 - val_loss: 141.1862 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 140.6122 - accuracy: 0.4992 - val_loss: 139.7713 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 139.2034 - accuracy: 0.4983 - val_loss: 138.3672 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 137.8010 - accuracy: 0.4999 - val_loss: 136.9735 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 136.4086 - accuracy: 0.5021 - val_loss: 135.5911 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 135.0343 - accuracy: 0.4992 - val_loss: 134.2193 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 133.6620 - accuracy: 0.5005 - val_loss: 132.8587 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 132.3066 - accuracy: 0.5012 - val_loss: 131.5086 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 130.9577 - accuracy: 0.5047 - val_loss: 130.1695 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 129.6211 - accuracy: 0.5034 - val_loss: 128.8412 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 128.3026 - accuracy: 0.5009 - val_loss: 127.5234 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 126.9843 - accuracy: 0.5055 - val_loss: 126.2162 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 125.6868 - accuracy: 0.5017 - val_loss: 124.9198 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 124.3941 - accuracy: 0.5005 - val_loss: 123.6339 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 123.1156 - accuracy: 0.5004 - val_loss: 122.3586 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 121.8429 - accuracy: 0.4985 - val_loss: 121.0935 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 120.5816 - accuracy: 0.4985 - val_loss: 119.8390 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 119.3343 - accuracy: 0.4962 - val_loss: 118.5953 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 118.0878 - accuracy: 0.5020 - val_loss: 117.3624 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 116.8627 - accuracy: 0.4998 - val_loss: 116.1401 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 115.6494 - accuracy: 0.4960 - val_loss: 114.9283 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 114.4357 - accuracy: 0.5007 - val_loss: 113.7271 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 113.2404 - accuracy: 0.4988 - val_loss: 112.5369 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 112.0651 - accuracy: 0.4913 - val_loss: 111.3565 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 110.8776 - accuracy: 0.5002 - val_loss: 110.1864 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 109.7141 - accuracy: 0.4973 - val_loss: 109.0270 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 108.5556 - accuracy: 0.4994 - val_loss: 107.8780 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 107.4042 - accuracy: 0.5055 - val_loss: 106.7391 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 106.2764 - accuracy: 0.4987 - val_loss: 105.6104 - val_accuracy: 0.5001\n",
      "Epoch 126/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 105.1564 - accuracy: 0.4949 - val_loss: 104.4918 - val_accuracy: 0.5001\n",
      "Epoch 127/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 104.0441 - accuracy: 0.4949 - val_loss: 103.3835 - val_accuracy: 0.5001\n",
      "Epoch 128/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 102.9395 - accuracy: 0.4940 - val_loss: 102.2854 - val_accuracy: 0.5001\n",
      "Epoch 129/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 101.8384 - accuracy: 0.5002 - val_loss: 101.1975 - val_accuracy: 0.5001\n",
      "Epoch 130/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 100.7515 - accuracy: 0.5011 - val_loss: 100.1195 - val_accuracy: 0.5001\n",
      "Epoch 131/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 99.6866 - accuracy: 0.4944 - val_loss: 99.0514 - val_accuracy: 0.5001\n",
      "Epoch 132/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 98.6138 - accuracy: 0.5002 - val_loss: 97.9928 - val_accuracy: 0.5001\n",
      "Epoch 133/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 97.5664 - accuracy: 0.4945 - val_loss: 96.9437 - val_accuracy: 0.5001\n",
      "Epoch 134/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 96.5135 - accuracy: 0.5004 - val_loss: 95.9043 - val_accuracy: 0.5001\n",
      "Epoch 135/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 95.4842 - accuracy: 0.4966 - val_loss: 94.8741 - val_accuracy: 0.5001\n",
      "Epoch 136/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 94.4555 - accuracy: 0.4971 - val_loss: 93.8532 - val_accuracy: 0.5001\n",
      "Epoch 137/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 93.4367 - accuracy: 0.4996 - val_loss: 92.8414 - val_accuracy: 0.5001\n",
      "Epoch 138/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 92.4323 - accuracy: 0.4954 - val_loss: 91.8389 - val_accuracy: 0.5001\n",
      "Epoch 139/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 91.4275 - accuracy: 0.5011 - val_loss: 90.8450 - val_accuracy: 0.5001\n",
      "Epoch 140/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 90.4421 - accuracy: 0.4968 - val_loss: 89.8599 - val_accuracy: 0.5001\n",
      "Epoch 141/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 89.4538 - accuracy: 0.5025 - val_loss: 88.8833 - val_accuracy: 0.5001\n",
      "Epoch 142/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 88.4823 - accuracy: 0.5006 - val_loss: 87.9153 - val_accuracy: 0.5001\n",
      "Epoch 143/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 87.5198 - accuracy: 0.4981 - val_loss: 86.9558 - val_accuracy: 0.5001\n",
      "Epoch 144/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 86.5681 - accuracy: 0.4938 - val_loss: 86.0049 - val_accuracy: 0.5001\n",
      "Epoch 145/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 85.6098 - accuracy: 0.5039 - val_loss: 85.0629 - val_accuracy: 0.5001\n",
      "Epoch 146/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 84.6752 - accuracy: 0.4998 - val_loss: 84.1295 - val_accuracy: 0.5001\n",
      "Epoch 147/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 83.7502 - accuracy: 0.4952 - val_loss: 83.2046 - val_accuracy: 0.5001\n",
      "Epoch 148/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 82.8212 - accuracy: 0.5026 - val_loss: 82.2882 - val_accuracy: 0.5001\n",
      "Epoch 149/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 81.9137 - accuracy: 0.4986 - val_loss: 81.3801 - val_accuracy: 0.5001\n",
      "Epoch 150/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 81.0065 - accuracy: 0.4996 - val_loss: 80.4809 - val_accuracy: 0.5001\n",
      "Epoch 151/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 80.1120 - accuracy: 0.4981 - val_loss: 79.5901 - val_accuracy: 0.5001\n",
      "Epoch 152/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 79.2177 - accuracy: 0.5053 - val_loss: 78.7077 - val_accuracy: 0.5001\n",
      "Epoch 153/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 78.3456 - accuracy: 0.4980 - val_loss: 77.8340 - val_accuracy: 0.5001\n",
      "Epoch 154/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 77.4738 - accuracy: 0.4986 - val_loss: 76.9688 - val_accuracy: 0.5001\n",
      "Epoch 155/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 76.6124 - accuracy: 0.4983 - val_loss: 76.1121 - val_accuracy: 0.5001\n",
      "Epoch 156/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 75.7597 - accuracy: 0.4972 - val_loss: 75.2638 - val_accuracy: 0.5001\n",
      "Epoch 157/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 74.9114 - accuracy: 0.5021 - val_loss: 74.4240 - val_accuracy: 0.5001\n",
      "Epoch 158/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 74.0732 - accuracy: 0.5025 - val_loss: 73.5929 - val_accuracy: 0.5001\n",
      "Epoch 159/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 73.2449 - accuracy: 0.5024 - val_loss: 72.7701 - val_accuracy: 0.5001\n",
      "Epoch 160/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 72.4268 - accuracy: 0.5019 - val_loss: 71.9557 - val_accuracy: 0.5001\n",
      "Epoch 161/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 71.6191 - accuracy: 0.4990 - val_loss: 71.1497 - val_accuracy: 0.5001\n",
      "Epoch 162/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 70.8212 - accuracy: 0.4941 - val_loss: 70.3523 - val_accuracy: 0.5001\n",
      "Epoch 163/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 70.0236 - accuracy: 0.4970 - val_loss: 69.5632 - val_accuracy: 0.5001\n",
      "Epoch 164/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 69.2367 - accuracy: 0.4982 - val_loss: 68.7825 - val_accuracy: 0.5001\n",
      "Epoch 165/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 68.4583 - accuracy: 0.4994 - val_loss: 68.0103 - val_accuracy: 0.5001\n",
      "Epoch 166/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 67.6904 - accuracy: 0.4982 - val_loss: 67.2464 - val_accuracy: 0.5001\n",
      "Epoch 167/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 66.9246 - accuracy: 0.5055 - val_loss: 66.4909 - val_accuracy: 0.5001\n",
      "Epoch 168/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 66.1798 - accuracy: 0.4959 - val_loss: 65.7439 - val_accuracy: 0.5001\n",
      "Epoch 169/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 65.4321 - accuracy: 0.5004 - val_loss: 65.0050 - val_accuracy: 0.4999\n",
      "Epoch 170/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 64.6966 - accuracy: 0.5009 - val_loss: 64.2744 - val_accuracy: 0.4999\n",
      "Epoch 171/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 63.9698 - accuracy: 0.5009 - val_loss: 63.5523 - val_accuracy: 0.4999\n",
      "Epoch 172/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 63.2585 - accuracy: 0.4918 - val_loss: 62.8382 - val_accuracy: 0.4999\n",
      "Epoch 173/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 62.5419 - accuracy: 0.4982 - val_loss: 62.1325 - val_accuracy: 0.4999\n",
      "Epoch 174/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 61.8353 - accuracy: 0.5042 - val_loss: 61.4350 - val_accuracy: 0.4999\n",
      "Epoch 175/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 61.1394 - accuracy: 0.5046 - val_loss: 60.7457 - val_accuracy: 0.4999\n",
      "Epoch 176/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 60.4581 - accuracy: 0.4987 - val_loss: 60.0645 - val_accuracy: 0.4999\n",
      "Epoch 177/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 59.7784 - accuracy: 0.5015 - val_loss: 59.3915 - val_accuracy: 0.4999\n",
      "Epoch 178/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 59.1119 - accuracy: 0.4979 - val_loss: 58.7265 - val_accuracy: 0.4999\n",
      "Epoch 179/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 58.4504 - accuracy: 0.4975 - val_loss: 58.0697 - val_accuracy: 0.4999\n",
      "Epoch 180/300\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 57.7974 - accuracy: 0.4970 - val_loss: 57.4208 - val_accuracy: 0.4999\n",
      "Epoch 181/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 57.1508 - accuracy: 0.4976 - val_loss: 56.7800 - val_accuracy: 0.4999\n",
      "Epoch 182/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 56.5135 - accuracy: 0.4977 - val_loss: 56.1471 - val_accuracy: 0.4999\n",
      "Epoch 183/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 55.8800 - accuracy: 0.5029 - val_loss: 55.5224 - val_accuracy: 0.4999\n",
      "Epoch 184/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 55.2622 - accuracy: 0.4977 - val_loss: 54.9060 - val_accuracy: 0.4999\n",
      "Epoch 185/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 54.6510 - accuracy: 0.4956 - val_loss: 54.2977 - val_accuracy: 0.4999\n",
      "Epoch 186/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 54.0412 - accuracy: 0.5014 - val_loss: 53.6984 - val_accuracy: 0.4999\n",
      "Epoch 187/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 53.4488 - accuracy: 0.4971 - val_loss: 53.1064 - val_accuracy: 0.4999\n",
      "Epoch 188/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 52.8599 - accuracy: 0.4979 - val_loss: 52.5222 - val_accuracy: 0.4999\n",
      "Epoch 189/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 52.2758 - accuracy: 0.5014 - val_loss: 51.9459 - val_accuracy: 0.4999\n",
      "Epoch 190/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 51.7038 - accuracy: 0.5004 - val_loss: 51.3768 - val_accuracy: 0.4999\n",
      "Epoch 191/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 51.1386 - accuracy: 0.4986 - val_loss: 50.8150 - val_accuracy: 0.4999\n",
      "Epoch 192/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 50.5768 - accuracy: 0.5031 - val_loss: 50.2602 - val_accuracy: 0.4999\n",
      "Epoch 193/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 50.0266 - accuracy: 0.4995 - val_loss: 49.7124 - val_accuracy: 0.4999\n",
      "Epoch 194/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 49.4813 - accuracy: 0.4996 - val_loss: 49.1713 - val_accuracy: 0.4999\n",
      "Epoch 195/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 48.9425 - accuracy: 0.5003 - val_loss: 48.6369 - val_accuracy: 0.4999\n",
      "Epoch 196/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 48.4127 - accuracy: 0.4981 - val_loss: 48.1087 - val_accuracy: 0.4999\n",
      "Epoch 197/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 47.8818 - accuracy: 0.5049 - val_loss: 47.5869 - val_accuracy: 0.4999\n",
      "Epoch 198/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 47.3659 - accuracy: 0.4989 - val_loss: 47.0710 - val_accuracy: 0.4999\n",
      "Epoch 199/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 46.8528 - accuracy: 0.4992 - val_loss: 46.5612 - val_accuracy: 0.4999\n",
      "Epoch 200/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 46.3448 - accuracy: 0.4995 - val_loss: 46.0570 - val_accuracy: 0.4999\n",
      "Epoch 201/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 45.8455 - accuracy: 0.4966 - val_loss: 45.5585 - val_accuracy: 0.4999\n",
      "Epoch 202/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 45.3495 - accuracy: 0.4948 - val_loss: 45.0655 - val_accuracy: 0.4999\n",
      "Epoch 203/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 44.8516 - accuracy: 0.5056 - val_loss: 44.5780 - val_accuracy: 0.4999\n",
      "Epoch 204/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 44.3706 - accuracy: 0.4986 - val_loss: 44.0958 - val_accuracy: 0.4999\n",
      "Epoch 205/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 43.8877 - accuracy: 0.5029 - val_loss: 43.6189 - val_accuracy: 0.4999\n",
      "Epoch 206/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 43.4137 - accuracy: 0.5015 - val_loss: 43.1470 - val_accuracy: 0.4999\n",
      "Epoch 207/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 42.9426 - accuracy: 0.5027 - val_loss: 42.6801 - val_accuracy: 0.4999\n",
      "Epoch 208/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 42.4793 - accuracy: 0.5003 - val_loss: 42.2181 - val_accuracy: 0.4999\n",
      "Epoch 209/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 42.0147 - accuracy: 0.5070 - val_loss: 41.7607 - val_accuracy: 0.4999\n",
      "Epoch 210/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 41.5638 - accuracy: 0.4989 - val_loss: 41.3079 - val_accuracy: 0.4999\n",
      "Epoch 211/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 41.1120 - accuracy: 0.5003 - val_loss: 40.8595 - val_accuracy: 0.4999\n",
      "Epoch 212/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 40.6665 - accuracy: 0.4978 - val_loss: 40.4152 - val_accuracy: 0.4999\n",
      "Epoch 213/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 40.2219 - accuracy: 0.5007 - val_loss: 39.9752 - val_accuracy: 0.4999\n",
      "Epoch 214/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 39.7849 - accuracy: 0.4986 - val_loss: 39.5392 - val_accuracy: 0.4999\n",
      "Epoch 215/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 39.3480 - accuracy: 0.5025 - val_loss: 39.1071 - val_accuracy: 0.4999\n",
      "Epoch 216/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 38.9181 - accuracy: 0.5000 - val_loss: 38.6790 - val_accuracy: 0.4999\n",
      "Epoch 217/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 38.4931 - accuracy: 0.4983 - val_loss: 38.2548 - val_accuracy: 0.4999\n",
      "Epoch 218/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 38.0698 - accuracy: 0.4990 - val_loss: 37.8345 - val_accuracy: 0.4999\n",
      "Epoch 219/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 37.6488 - accuracy: 0.5029 - val_loss: 37.4180 - val_accuracy: 0.4999\n",
      "Epoch 220/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 37.2343 - accuracy: 0.5021 - val_loss: 37.0052 - val_accuracy: 0.4999\n",
      "Epoch 221/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 36.8239 - accuracy: 0.4997 - val_loss: 36.5964 - val_accuracy: 0.4999\n",
      "Epoch 222/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 36.4169 - accuracy: 0.4989 - val_loss: 36.1911 - val_accuracy: 0.4999\n",
      "Epoch 223/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 36.0157 - accuracy: 0.4942 - val_loss: 35.7894 - val_accuracy: 0.4999\n",
      "Epoch 224/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 35.6123 - accuracy: 0.4997 - val_loss: 35.3915 - val_accuracy: 0.4999\n",
      "Epoch 225/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 35.2142 - accuracy: 0.5025 - val_loss: 34.9970 - val_accuracy: 0.4999\n",
      "Epoch 226/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 34.8256 - accuracy: 0.4934 - val_loss: 34.6059 - val_accuracy: 0.4999\n",
      "Epoch 227/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 34.4338 - accuracy: 0.4975 - val_loss: 34.2182 - val_accuracy: 0.4999\n",
      "Epoch 228/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 34.0457 - accuracy: 0.5004 - val_loss: 33.8338 - val_accuracy: 0.4999\n",
      "Epoch 229/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 33.6650 - accuracy: 0.4954 - val_loss: 33.4523 - val_accuracy: 0.4999\n",
      "Epoch 230/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 33.2826 - accuracy: 0.4994 - val_loss: 33.0741 - val_accuracy: 0.4999\n",
      "Epoch 231/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 32.9043 - accuracy: 0.5015 - val_loss: 32.6986 - val_accuracy: 0.4999\n",
      "Epoch 232/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 32.5315 - accuracy: 0.4984 - val_loss: 32.3259 - val_accuracy: 0.4999\n",
      "Epoch 233/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 32.1583 - accuracy: 0.5011 - val_loss: 31.9558 - val_accuracy: 0.4999\n",
      "Epoch 234/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 31.7905 - accuracy: 0.4986 - val_loss: 31.5880 - val_accuracy: 0.4999\n",
      "Epoch 235/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 31.4223 - accuracy: 0.5012 - val_loss: 31.2227 - val_accuracy: 0.4999\n",
      "Epoch 236/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 31.0603 - accuracy: 0.4962 - val_loss: 30.8597 - val_accuracy: 0.4999\n",
      "Epoch 237/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 30.6982 - accuracy: 0.4961 - val_loss: 30.4989 - val_accuracy: 0.4999\n",
      "Epoch 238/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 30.3354 - accuracy: 0.5021 - val_loss: 30.1402 - val_accuracy: 0.4999\n",
      "Epoch 239/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.9781 - accuracy: 0.5011 - val_loss: 29.7837 - val_accuracy: 0.4999\n",
      "Epoch 240/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.6251 - accuracy: 0.4952 - val_loss: 29.4294 - val_accuracy: 0.4999\n",
      "Epoch 241/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 29.2691 - accuracy: 0.5010 - val_loss: 29.0772 - val_accuracy: 0.4999\n",
      "Epoch 242/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 28.9194 - accuracy: 0.4968 - val_loss: 28.7272 - val_accuracy: 0.4999\n",
      "Epoch 243/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 28.5674 - accuracy: 0.5042 - val_loss: 28.3795 - val_accuracy: 0.4999\n",
      "Epoch 244/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 28.2214 - accuracy: 0.5014 - val_loss: 28.0338 - val_accuracy: 0.4999\n",
      "Epoch 245/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 27.8774 - accuracy: 0.4998 - val_loss: 27.6904 - val_accuracy: 0.4999\n",
      "Epoch 246/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 27.5358 - accuracy: 0.4971 - val_loss: 27.3491 - val_accuracy: 0.4999\n",
      "Epoch 247/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 27.1924 - accuracy: 0.5045 - val_loss: 27.0100 - val_accuracy: 0.4999\n",
      "Epoch 248/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 26.8552 - accuracy: 0.5014 - val_loss: 26.6730 - val_accuracy: 0.4999\n",
      "Epoch 249/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 26.5182 - accuracy: 0.5038 - val_loss: 26.3383 - val_accuracy: 0.4999\n",
      "Epoch 250/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 26.1850 - accuracy: 0.5025 - val_loss: 26.0057 - val_accuracy: 0.4999\n",
      "Epoch 251/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 25.8563 - accuracy: 0.4952 - val_loss: 25.6754 - val_accuracy: 0.4999\n",
      "Epoch 252/300\n",
      "335/335 [==============================] - 3s 8ms/step - loss: 25.5261 - accuracy: 0.4979 - val_loss: 25.3482 - val_accuracy: 0.4999\n",
      "Epoch 253/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 25.1980 - accuracy: 0.5019 - val_loss: 25.0230 - val_accuracy: 0.4999\n",
      "Epoch 254/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 24.8758 - accuracy: 0.4969 - val_loss: 24.7001 - val_accuracy: 0.4999\n",
      "Epoch 255/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 24.5526 - accuracy: 0.5001 - val_loss: 24.3793 - val_accuracy: 0.4999\n",
      "Epoch 256/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 24.2311 - accuracy: 0.5039 - val_loss: 24.0607 - val_accuracy: 0.4999\n",
      "Epoch 257/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 23.9168 - accuracy: 0.4950 - val_loss: 23.7442 - val_accuracy: 0.4999\n",
      "Epoch 258/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 23.6006 - accuracy: 0.4967 - val_loss: 23.4298 - val_accuracy: 0.4999\n",
      "Epoch 259/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 23.2843 - accuracy: 0.5039 - val_loss: 23.1177 - val_accuracy: 0.4999\n",
      "Epoch 260/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 22.9750 - accuracy: 0.4987 - val_loss: 22.8076 - val_accuracy: 0.4999\n",
      "Epoch 261/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 22.6664 - accuracy: 0.4975 - val_loss: 22.4998 - val_accuracy: 0.4999\n",
      "Epoch 262/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 22.3584 - accuracy: 0.5000 - val_loss: 22.1941 - val_accuracy: 0.4999\n",
      "Epoch 263/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 22.0538 - accuracy: 0.4996 - val_loss: 21.8906 - val_accuracy: 0.4999\n",
      "Epoch 264/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 21.7526 - accuracy: 0.4962 - val_loss: 21.5894 - val_accuracy: 0.4999\n",
      "Epoch 265/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 21.4509 - accuracy: 0.5008 - val_loss: 21.2909 - val_accuracy: 0.4999\n",
      "Epoch 266/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 21.1553 - accuracy: 0.4948 - val_loss: 20.9947 - val_accuracy: 0.4999\n",
      "Epoch 267/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 20.8575 - accuracy: 0.5019 - val_loss: 20.7007 - val_accuracy: 0.4999\n",
      "Epoch 268/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 20.5653 - accuracy: 0.4996 - val_loss: 20.4088 - val_accuracy: 0.4999\n",
      "Epoch 269/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 20.2741 - accuracy: 0.5001 - val_loss: 20.1191 - val_accuracy: 0.4999\n",
      "Epoch 270/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.9857 - accuracy: 0.4991 - val_loss: 19.8315 - val_accuracy: 0.4999\n",
      "Epoch 271/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.6997 - accuracy: 0.4971 - val_loss: 19.5460 - val_accuracy: 0.4999\n",
      "Epoch 272/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 19.4133 - accuracy: 0.5020 - val_loss: 19.2627 - val_accuracy: 0.4999\n",
      "Epoch 273/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 19.1310 - accuracy: 0.5021 - val_loss: 18.9816 - val_accuracy: 0.4999\n",
      "Epoch 274/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 18.8519 - accuracy: 0.4987 - val_loss: 18.7026 - val_accuracy: 0.4999\n",
      "Epoch 275/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.5722 - accuracy: 0.5034 - val_loss: 18.4257 - val_accuracy: 0.4999\n",
      "Epoch 276/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 18.2966 - accuracy: 0.5024 - val_loss: 18.1510 - val_accuracy: 0.4999\n",
      "Epoch 277/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 18.0241 - accuracy: 0.4984 - val_loss: 17.8784 - val_accuracy: 0.4999\n",
      "Epoch 278/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.7527 - accuracy: 0.4977 - val_loss: 17.6080 - val_accuracy: 0.4999\n",
      "Epoch 279/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 17.4821 - accuracy: 0.5011 - val_loss: 17.3397 - val_accuracy: 0.4999\n",
      "Epoch 280/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 17.2141 - accuracy: 0.5032 - val_loss: 17.0736 - val_accuracy: 0.4999\n",
      "Epoch 281/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.9504 - accuracy: 0.4982 - val_loss: 16.8096 - val_accuracy: 0.4999\n",
      "Epoch 282/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 16.6869 - accuracy: 0.5001 - val_loss: 16.5480 - val_accuracy: 0.4999\n",
      "Epoch 283/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.4268 - accuracy: 0.4987 - val_loss: 16.2889 - val_accuracy: 0.4999\n",
      "Epoch 284/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 16.1683 - accuracy: 0.5001 - val_loss: 16.0322 - val_accuracy: 0.4999\n",
      "Epoch 285/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.9136 - accuracy: 0.4963 - val_loss: 15.7775 - val_accuracy: 0.4999\n",
      "Epoch 286/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 15.6580 - accuracy: 0.5025 - val_loss: 15.5250 - val_accuracy: 0.4999\n",
      "Epoch 287/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 15.4077 - accuracy: 0.4982 - val_loss: 15.2746 - val_accuracy: 0.4999\n",
      "Epoch 288/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 15.1572 - accuracy: 0.5018 - val_loss: 15.0263 - val_accuracy: 0.4999\n",
      "Epoch 289/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.9105 - accuracy: 0.4998 - val_loss: 14.7802 - val_accuracy: 0.4999\n",
      "Epoch 290/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.6645 - accuracy: 0.5023 - val_loss: 14.5362 - val_accuracy: 0.4999\n",
      "Epoch 291/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 14.4207 - accuracy: 0.5047 - val_loss: 14.2943 - val_accuracy: 0.4999\n",
      "Epoch 292/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 14.1818 - accuracy: 0.4979 - val_loss: 14.0546 - val_accuracy: 0.4999\n",
      "Epoch 293/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 13.9443 - accuracy: 0.4930 - val_loss: 13.8170 - val_accuracy: 0.4999\n",
      "Epoch 294/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.7069 - accuracy: 0.4958 - val_loss: 13.5815 - val_accuracy: 0.4999\n",
      "Epoch 295/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.4715 - accuracy: 0.4986 - val_loss: 13.3482 - val_accuracy: 0.4999\n",
      "Epoch 296/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.2393 - accuracy: 0.4982 - val_loss: 13.1171 - val_accuracy: 0.4999\n",
      "Epoch 297/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 13.0099 - accuracy: 0.4964 - val_loss: 12.8887 - val_accuracy: 0.4999\n",
      "Epoch 298/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12.7818 - accuracy: 0.4986 - val_loss: 12.6624 - val_accuracy: 0.4999\n",
      "Epoch 299/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 12.5567 - accuracy: 0.4977 - val_loss: 12.4382 - val_accuracy: 0.4999\n",
      "Epoch 300/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 12.3328 - accuracy: 0.5004 - val_loss: 12.2162 - val_accuracy: 0.4999\n",
      "310/310 [==============================] - 1s 2ms/step - loss: 12.2162 - accuracy: 0.4999\n",
      "{'loss': 12.216221809387207, 'accuracy': 0.49987393617630005} \n",
      " 299 \n",
      "\n",
      "Model time: 9.170940812677145 minutes\n",
      "\n",
      "Total time: 251.97794787213206 minutes\n",
      "\n",
      "\n",
      "Model  115  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                   128\n",
      "Activation function         linear\n",
      "Dropout                        0.6\n",
      "L1                             0.0\n",
      "L2                            0.01\n",
      "Batch size                       8\n",
      "Optimizer                     Adam\n",
      "Learning rate                0.001\n",
      "Name: 6788691, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 22s 7ms/step - loss: 4.7372 - accuracy: 0.5221 - val_loss: 2.1351 - val_accuracy: 0.5781\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 19s 7ms/step - loss: 1.1510 - accuracy: 0.5766 - val_loss: 0.7348 - val_accuracy: 0.5639\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 19s 7ms/step - loss: 0.7125 - accuracy: 0.5448 - val_loss: 0.6952 - val_accuracy: 0.5001\n",
      "Epoch 4/300\n",
      "2677/2677 [==============================] - 18s 7ms/step - loss: 0.6940 - accuracy: 0.4971 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
      "Epoch 5/300\n",
      "2677/2677 [==============================] - 20s 8ms/step - loss: 0.6936 - accuracy: 0.5007 - val_loss: 0.6934 - val_accuracy: 0.5001\n",
      "Epoch 6/300\n",
      "2673/2677 [============================>.] - ETA: 0s - loss: 0.6938 - accuracy: 0.4990Restoring model weights from the end of the best epoch: 5.\n",
      "2677/2677 [==============================] - 20s 7ms/step - loss: 0.6938 - accuracy: 0.4990 - val_loss: 0.6945 - val_accuracy: 0.5001\n",
      "Epoch 6: early stopping\n",
      "2480/2480 [==============================] - 7s 3ms/step - loss: 0.6934 - accuracy: 0.5001\n",
      "{'loss': 0.6934072971343994, 'accuracy': 0.5001260638237} \n",
      " 5 \n",
      "\n",
      "Model time: 2.1063812375068665 minutes\n",
      "\n",
      "Total time: 254.0843957848847 minutes\n",
      "\n",
      "\n",
      "Model  116  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     2\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.9\n",
      "L1                             0.1\n",
      "L2                          0.0001\n",
      "Batch size                     256\n",
      "Optimizer                  RMSprop\n",
      "Learning rate               0.0001\n",
      "Name: 1708941, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 3s 16ms/step - loss: 4.0950 - accuracy: 0.5000 - val_loss: 3.9068 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.8042 - accuracy: 0.5018 - val_loss: 3.6316 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 3.5320 - accuracy: 0.5019 - val_loss: 3.3697 - val_accuracy: 0.4999\n",
      "Epoch 4/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 3.2785 - accuracy: 0.4970 - val_loss: 3.1219 - val_accuracy: 0.4999\n",
      "Epoch 5/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 3.0297 - accuracy: 0.5039 - val_loss: 2.8882 - val_accuracy: 0.4999\n",
      "Epoch 6/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.8051 - accuracy: 0.5006 - val_loss: 2.6713 - val_accuracy: 0.4999\n",
      "Epoch 7/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.5914 - accuracy: 0.5032 - val_loss: 2.4701 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.3952 - accuracy: 0.5016 - val_loss: 2.2840 - val_accuracy: 0.4999\n",
      "Epoch 9/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 2.2127 - accuracy: 0.5032 - val_loss: 2.1077 - val_accuracy: 0.4999\n",
      "Epoch 10/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 2.0432 - accuracy: 0.4986 - val_loss: 1.9421 - val_accuracy: 0.4999\n",
      "Epoch 11/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.8805 - accuracy: 0.4974 - val_loss: 1.7860 - val_accuracy: 0.4999\n",
      "Epoch 12/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.7300 - accuracy: 0.4968 - val_loss: 1.6451 - val_accuracy: 0.4988\n",
      "Epoch 13/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.5967 - accuracy: 0.4946 - val_loss: 1.5162 - val_accuracy: 0.4967\n",
      "Epoch 14/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.4700 - accuracy: 0.5002 - val_loss: 1.4019 - val_accuracy: 0.5068\n",
      "Epoch 15/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 1.3613 - accuracy: 0.4993 - val_loss: 1.3003 - val_accuracy: 0.5002\n",
      "Epoch 16/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.2679 - accuracy: 0.4997 - val_loss: 1.2154 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 1.1886 - accuracy: 0.4992 - val_loss: 1.1445 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.1252 - accuracy: 0.5003 - val_loss: 1.0895 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.0749 - accuracy: 0.5010 - val_loss: 1.0454 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 1.0363 - accuracy: 0.4993 - val_loss: 1.0138 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 1.0106 - accuracy: 0.5009 - val_loss: 0.9957 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.9965 - accuracy: 0.5018 - val_loss: 0.9859 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9902 - accuracy: 0.4971 - val_loss: 0.9799 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9831 - accuracy: 0.5004 - val_loss: 0.9737 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9769 - accuracy: 0.4986 - val_loss: 0.9675 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.9705 - accuracy: 0.5002 - val_loss: 0.9614 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.9636 - accuracy: 0.5017 - val_loss: 0.9552 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9572 - accuracy: 0.5019 - val_loss: 0.9490 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9504 - accuracy: 0.5015 - val_loss: 0.9428 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9443 - accuracy: 0.5014 - val_loss: 0.9365 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.9394 - accuracy: 0.4946 - val_loss: 0.9303 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9322 - accuracy: 0.4982 - val_loss: 0.9241 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9250 - accuracy: 0.5013 - val_loss: 0.9178 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.9172 - accuracy: 0.5060 - val_loss: 0.9115 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.9119 - accuracy: 0.5032 - val_loss: 0.9052 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "84/84 [==============================] - 0s 5ms/step - loss: 0.9060 - accuracy: 0.5010 - val_loss: 0.8995 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.9003 - accuracy: 0.5015 - val_loss: 0.8940 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8946 - accuracy: 0.5001 - val_loss: 0.8886 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8895 - accuracy: 0.4987 - val_loss: 0.8830 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8834 - accuracy: 0.5023 - val_loss: 0.8775 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8767 - accuracy: 0.5058 - val_loss: 0.8719 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8732 - accuracy: 0.4965 - val_loss: 0.8665 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8669 - accuracy: 0.4984 - val_loss: 0.8609 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.8601 - accuracy: 0.5048 - val_loss: 0.8554 - val_accuracy: 0.5001\n",
      "Epoch 45/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8557 - accuracy: 0.5004 - val_loss: 0.8498 - val_accuracy: 0.5001\n",
      "Epoch 46/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8509 - accuracy: 0.4953 - val_loss: 0.8444 - val_accuracy: 0.5001\n",
      "Epoch 47/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8445 - accuracy: 0.5004 - val_loss: 0.8388 - val_accuracy: 0.5001\n",
      "Epoch 48/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8381 - accuracy: 0.5040 - val_loss: 0.8335 - val_accuracy: 0.5001\n",
      "Epoch 49/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8338 - accuracy: 0.4970 - val_loss: 0.8287 - val_accuracy: 0.5001\n",
      "Epoch 50/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.8289 - accuracy: 0.4972 - val_loss: 0.8238 - val_accuracy: 0.5001\n",
      "Epoch 51/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.8234 - accuracy: 0.4995 - val_loss: 0.8190 - val_accuracy: 0.5001\n",
      "Epoch 52/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.8175 - accuracy: 0.5044 - val_loss: 0.8141 - val_accuracy: 0.5001\n",
      "Epoch 53/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8126 - accuracy: 0.5035 - val_loss: 0.8093 - val_accuracy: 0.5001\n",
      "Epoch 54/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8076 - accuracy: 0.5032 - val_loss: 0.8044 - val_accuracy: 0.5001\n",
      "Epoch 55/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8034 - accuracy: 0.4982 - val_loss: 0.7996 - val_accuracy: 0.5001\n",
      "Epoch 56/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7977 - accuracy: 0.5027 - val_loss: 0.7947 - val_accuracy: 0.5001\n",
      "Epoch 57/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7934 - accuracy: 0.4977 - val_loss: 0.7899 - val_accuracy: 0.5001\n",
      "Epoch 58/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7883 - accuracy: 0.4994 - val_loss: 0.7858 - val_accuracy: 0.5001\n",
      "Epoch 59/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7843 - accuracy: 0.4971 - val_loss: 0.7817 - val_accuracy: 0.5001\n",
      "Epoch 60/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7798 - accuracy: 0.5021 - val_loss: 0.7776 - val_accuracy: 0.5001\n",
      "Epoch 61/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7762 - accuracy: 0.4962 - val_loss: 0.7745 - val_accuracy: 0.5001\n",
      "Epoch 62/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7732 - accuracy: 0.5033 - val_loss: 0.7721 - val_accuracy: 0.5001\n",
      "Epoch 63/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7709 - accuracy: 0.4999 - val_loss: 0.7696 - val_accuracy: 0.5001\n",
      "Epoch 64/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7684 - accuracy: 0.5003 - val_loss: 0.7672 - val_accuracy: 0.5001\n",
      "Epoch 65/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.7664 - accuracy: 0.5003 - val_loss: 0.7655 - val_accuracy: 0.5001\n",
      "Epoch 66/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7647 - accuracy: 0.5003 - val_loss: 0.7638 - val_accuracy: 0.5001\n",
      "Epoch 67/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7630 - accuracy: 0.5003 - val_loss: 0.7621 - val_accuracy: 0.5001\n",
      "Epoch 68/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7613 - accuracy: 0.5003 - val_loss: 0.7605 - val_accuracy: 0.5001\n",
      "Epoch 69/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7596 - accuracy: 0.5003 - val_loss: 0.7588 - val_accuracy: 0.5001\n",
      "Epoch 70/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7579 - accuracy: 0.5003 - val_loss: 0.7571 - val_accuracy: 0.5001\n",
      "Epoch 71/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7562 - accuracy: 0.5003 - val_loss: 0.7554 - val_accuracy: 0.5001\n",
      "Epoch 72/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7545 - accuracy: 0.5003 - val_loss: 0.7537 - val_accuracy: 0.5001\n",
      "Epoch 73/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7529 - accuracy: 0.5003 - val_loss: 0.7520 - val_accuracy: 0.5001\n",
      "Epoch 74/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7512 - accuracy: 0.5003 - val_loss: 0.7503 - val_accuracy: 0.5001\n",
      "Epoch 75/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7495 - accuracy: 0.5003 - val_loss: 0.7487 - val_accuracy: 0.5001\n",
      "Epoch 76/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7478 - accuracy: 0.5003 - val_loss: 0.7470 - val_accuracy: 0.5001\n",
      "Epoch 77/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7461 - accuracy: 0.5003 - val_loss: 0.7453 - val_accuracy: 0.5001\n",
      "Epoch 78/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.7444 - accuracy: 0.5003 - val_loss: 0.7436 - val_accuracy: 0.5001\n",
      "Epoch 79/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7428 - accuracy: 0.5003 - val_loss: 0.7419 - val_accuracy: 0.5001\n",
      "Epoch 80/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7411 - accuracy: 0.5003 - val_loss: 0.7403 - val_accuracy: 0.5001\n",
      "Epoch 81/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7394 - accuracy: 0.5003 - val_loss: 0.7386 - val_accuracy: 0.5001\n",
      "Epoch 82/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.7377 - accuracy: 0.5003 - val_loss: 0.7369 - val_accuracy: 0.5001\n",
      "Epoch 83/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7360 - accuracy: 0.5003 - val_loss: 0.7352 - val_accuracy: 0.5001\n",
      "Epoch 84/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7344 - accuracy: 0.5003 - val_loss: 0.7335 - val_accuracy: 0.5001\n",
      "Epoch 85/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7327 - accuracy: 0.5003 - val_loss: 0.7318 - val_accuracy: 0.5001\n",
      "Epoch 86/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7310 - accuracy: 0.5003 - val_loss: 0.7302 - val_accuracy: 0.5001\n",
      "Epoch 87/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7293 - accuracy: 0.5003 - val_loss: 0.7285 - val_accuracy: 0.5001\n",
      "Epoch 88/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.7276 - accuracy: 0.5003 - val_loss: 0.7268 - val_accuracy: 0.5001\n",
      "Epoch 89/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7260 - accuracy: 0.5003 - val_loss: 0.7251 - val_accuracy: 0.5001\n",
      "Epoch 90/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7243 - accuracy: 0.5003 - val_loss: 0.7234 - val_accuracy: 0.5001\n",
      "Epoch 91/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7227 - accuracy: 0.5003 - val_loss: 0.7221 - val_accuracy: 0.5001\n",
      "Epoch 92/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7216 - accuracy: 0.5003 - val_loss: 0.7212 - val_accuracy: 0.5001\n",
      "Epoch 93/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.7208 - accuracy: 0.5003 - val_loss: 0.7204 - val_accuracy: 0.5001\n",
      "Epoch 94/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.7200 - accuracy: 0.5003 - val_loss: 0.7195 - val_accuracy: 0.5001\n",
      "Epoch 95/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7191 - accuracy: 0.5003 - val_loss: 0.7187 - val_accuracy: 0.5001\n",
      "Epoch 96/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7183 - accuracy: 0.5003 - val_loss: 0.7179 - val_accuracy: 0.5001\n",
      "Epoch 97/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.7174 - accuracy: 0.5003 - val_loss: 0.7170 - val_accuracy: 0.5001\n",
      "Epoch 98/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7166 - accuracy: 0.5005 - val_loss: 0.7162 - val_accuracy: 0.5001\n",
      "Epoch 99/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7158 - accuracy: 0.4961 - val_loss: 0.7154 - val_accuracy: 0.5001\n",
      "Epoch 100/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7149 - accuracy: 0.5003 - val_loss: 0.7145 - val_accuracy: 0.5001\n",
      "Epoch 101/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7141 - accuracy: 0.4960 - val_loss: 0.7137 - val_accuracy: 0.5001\n",
      "Epoch 102/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7132 - accuracy: 0.4956 - val_loss: 0.7128 - val_accuracy: 0.5001\n",
      "Epoch 103/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7124 - accuracy: 0.4959 - val_loss: 0.7120 - val_accuracy: 0.5001\n",
      "Epoch 104/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7116 - accuracy: 0.4994 - val_loss: 0.7112 - val_accuracy: 0.5001\n",
      "Epoch 105/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7107 - accuracy: 0.5002 - val_loss: 0.7103 - val_accuracy: 0.5001\n",
      "Epoch 106/300\n",
      "84/84 [==============================] - 1s 6ms/step - loss: 0.7099 - accuracy: 0.4977 - val_loss: 0.7095 - val_accuracy: 0.5001\n",
      "Epoch 107/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7090 - accuracy: 0.5015 - val_loss: 0.7086 - val_accuracy: 0.5001\n",
      "Epoch 108/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7082 - accuracy: 0.5003 - val_loss: 0.7078 - val_accuracy: 0.5001\n",
      "Epoch 109/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.7074 - accuracy: 0.5000 - val_loss: 0.7070 - val_accuracy: 0.5001\n",
      "Epoch 110/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7065 - accuracy: 0.5000 - val_loss: 0.7061 - val_accuracy: 0.5001\n",
      "Epoch 111/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7057 - accuracy: 0.4998 - val_loss: 0.7053 - val_accuracy: 0.5001\n",
      "Epoch 112/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7048 - accuracy: 0.4975 - val_loss: 0.7044 - val_accuracy: 0.5001\n",
      "Epoch 113/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7040 - accuracy: 0.4944 - val_loss: 0.7036 - val_accuracy: 0.5001\n",
      "Epoch 114/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7032 - accuracy: 0.4980 - val_loss: 0.7027 - val_accuracy: 0.5001\n",
      "Epoch 115/300\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.7023 - accuracy: 0.4992 - val_loss: 0.7019 - val_accuracy: 0.5001\n",
      "Epoch 116/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.7015 - accuracy: 0.5001 - val_loss: 0.7011 - val_accuracy: 0.5001\n",
      "Epoch 117/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.7006 - accuracy: 0.4987 - val_loss: 0.7002 - val_accuracy: 0.5001\n",
      "Epoch 118/300\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.6998 - accuracy: 0.5004 - val_loss: 0.6994 - val_accuracy: 0.5001\n",
      "Epoch 119/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6990 - accuracy: 0.4988 - val_loss: 0.6985 - val_accuracy: 0.5001\n",
      "Epoch 120/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6981 - accuracy: 0.4993 - val_loss: 0.6977 - val_accuracy: 0.5001\n",
      "Epoch 121/300\n",
      "84/84 [==============================] - 0s 6ms/step - loss: 0.6973 - accuracy: 0.5000 - val_loss: 0.6968 - val_accuracy: 0.5001\n",
      "Epoch 122/300\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.6964 - accuracy: 0.4992 - val_loss: 0.6960 - val_accuracy: 0.5001\n",
      "Epoch 123/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6956 - accuracy: 0.4997 - val_loss: 0.6952 - val_accuracy: 0.5001\n",
      "Epoch 124/300\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6950 - accuracy: 0.5005 - val_loss: 0.6949 - val_accuracy: 0.5001\n",
      "Epoch 125/300\n",
      "72/84 [========================>.....] - ETA: 0s - loss: 0.6949 - accuracy: 0.5003Restoring model weights from the end of the best epoch: 124.\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.6949 - accuracy: 0.5003 - val_loss: 0.6949 - val_accuracy: 0.5001\n",
      "Epoch 125: early stopping\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.5001\n",
      "{'loss': 0.6949275732040405, 'accuracy': 0.5001260638237} \n",
      " 124 \n",
      "\n",
      "Model time: 1.2821487188339233 minutes\n",
      "\n",
      "Total time: 255.36662781611085 minutes\n",
      "\n",
      "\n",
      "Model  117  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    2\n",
      "Hidden units                     8\n",
      "Activation function           tanh\n",
      "Dropout                        0.6\n",
      "L1                            0.01\n",
      "L2                             0.1\n",
      "Batch size                      64\n",
      "Optimizer                     Adam\n",
      "Learning rate               0.0001\n",
      "Name: 1891945, dtype: object\n",
      "NN2Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 4s 7ms/step - loss: 4.3914 - accuracy: 0.4980 - val_loss: 3.7281 - val_accuracy: 0.5082\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 3.3819 - accuracy: 0.5036 - val_loss: 2.9047 - val_accuracy: 0.5180\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 2.6581 - accuracy: 0.5026 - val_loss: 2.3065 - val_accuracy: 0.5345\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 2.1264 - accuracy: 0.5118 - val_loss: 1.8802 - val_accuracy: 0.5504\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.7499 - accuracy: 0.5096 - val_loss: 1.5786 - val_accuracy: 0.5631\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.4834 - accuracy: 0.5183 - val_loss: 1.3694 - val_accuracy: 0.5783\n",
      "Epoch 7/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.3040 - accuracy: 0.5203 - val_loss: 1.2275 - val_accuracy: 0.5884\n",
      "Epoch 8/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 1.1817 - accuracy: 0.5329 - val_loss: 1.1291 - val_accuracy: 0.5983\n",
      "Epoch 9/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0924 - accuracy: 0.5391 - val_loss: 1.0530 - val_accuracy: 0.6047\n",
      "Epoch 10/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 1.0230 - accuracy: 0.5389 - val_loss: 0.9913 - val_accuracy: 0.6060\n",
      "Epoch 11/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9659 - accuracy: 0.5404 - val_loss: 0.9398 - val_accuracy: 0.6111\n",
      "Epoch 12/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.9180 - accuracy: 0.5458 - val_loss: 0.8962 - val_accuracy: 0.6061\n",
      "Epoch 13/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.8776 - accuracy: 0.5455 - val_loss: 0.8593 - val_accuracy: 0.5939\n",
      "Epoch 14/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8433 - accuracy: 0.5404 - val_loss: 0.8280 - val_accuracy: 0.5744\n",
      "Epoch 15/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.8143 - accuracy: 0.5436 - val_loss: 0.8010 - val_accuracy: 0.5709\n",
      "Epoch 16/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7892 - accuracy: 0.5386 - val_loss: 0.7780 - val_accuracy: 0.5681\n",
      "Epoch 17/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7679 - accuracy: 0.5245 - val_loss: 0.7585 - val_accuracy: 0.5296\n",
      "Epoch 18/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7502 - accuracy: 0.5057 - val_loss: 0.7425 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7359 - accuracy: 0.4992 - val_loss: 0.7297 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.7243 - accuracy: 0.4944 - val_loss: 0.7192 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7150 - accuracy: 0.4972 - val_loss: 0.7110 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7077 - accuracy: 0.4980 - val_loss: 0.7047 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.7024 - accuracy: 0.5003 - val_loss: 0.7004 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6989 - accuracy: 0.4995 - val_loss: 0.6977 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.6968 - accuracy: 0.4977 - val_loss: 0.6960 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6954 - accuracy: 0.4979 - val_loss: 0.6949 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.6944 - accuracy: 0.5003 - val_loss: 0.6941 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6938 - accuracy: 0.4967 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.4962 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "321/335 [===========================>..] - ETA: 0s - loss: 0.6933 - accuracy: 0.4959Restoring model weights from the end of the best epoch: 30.\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.4969 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 31: early stopping\n",
      "310/310 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5001\n",
      "{'loss': 0.6932952404022217, 'accuracy': 0.5001260638237} \n",
      " 30 \n",
      "\n",
      "Model time: 0.9942823499441147 minutes\n",
      "\n",
      "Total time: 256.36096016690135 minutes\n",
      "\n",
      "\n",
      "Model  118  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     8\n",
      "Activation function        sigmoid\n",
      "Dropout                        0.2\n",
      "L1                             0.1\n",
      "L2                           100.0\n",
      "Batch size                     128\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 592790, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "168/168 [==============================] - 3s 9ms/step - loss: 66.1291 - accuracy: 0.5045 - val_loss: 4.8896 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "160/168 [===========================>..] - ETA: 0s - loss: 4.8935 - accuracy: 0.4982Restoring model weights from the end of the best epoch: 1.\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 4.8934 - accuracy: 0.4981 - val_loss: 4.8921 - val_accuracy: 0.4999\n",
      "Epoch 2: early stopping\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 4.8896 - accuracy: 0.4999\n",
      "{'loss': 4.889622688293457, 'accuracy': 0.49987393617630005} \n",
      " 1 \n",
      "\n",
      "Model time: 0.0868665799498558 minutes\n",
      "\n",
      "Total time: 256.4479100741446 minutes\n",
      "\n",
      "\n",
      "Model  119  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    1\n",
      "Hidden units                     4\n",
      "Activation function           tanh\n",
      "Dropout                        0.5\n",
      "L1                             1.0\n",
      "L2                             0.0\n",
      "Batch size                       8\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 331782, dtype: object\n",
      "NN1Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 4.1194 - accuracy: 0.5001 - val_loss: 4.1332 - val_accuracy: 0.5001\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 4.0193 - accuracy: 0.4957 - val_loss: 3.8499 - val_accuracy: 0.4999\n",
      "Epoch 3/300\n",
      "2653/2677 [============================>.] - ETA: 0s - loss: 4.0379 - accuracy: 0.5029Restoring model weights from the end of the best epoch: 2.\n",
      "2677/2677 [==============================] - 12s 4ms/step - loss: 4.0380 - accuracy: 0.5030 - val_loss: 4.2245 - val_accuracy: 0.5001\n",
      "Epoch 3: early stopping\n",
      "2480/2480 [==============================] - 6s 2ms/step - loss: 3.8499 - accuracy: 0.4999\n",
      "{'loss': 3.849914073944092, 'accuracy': 0.49987393617630005} \n",
      " 2 \n",
      "\n",
      "Model time: 0.7792992331087589 minutes\n",
      "\n",
      "Total time: 257.227542642504 minutes\n",
      "\n",
      "\n",
      "Model  120  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                     2\n",
      "Activation function           tanh\n",
      "Dropout                        0.9\n",
      "L1                             0.1\n",
      "L2                         0.00001\n",
      "Batch size                       8\n",
      "Optimizer                  RMSprop\n",
      "Learning rate              0.00001\n",
      "Name: 5791348, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "2677/2677 [==============================] - 18s 5ms/step - loss: 4.2550 - accuracy: 0.5001 - val_loss: 3.8052 - val_accuracy: 0.5093\n",
      "Epoch 2/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 3.4025 - accuracy: 0.4953 - val_loss: 3.0226 - val_accuracy: 0.5073\n",
      "Epoch 3/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 2.6892 - accuracy: 0.4941 - val_loss: 2.3798 - val_accuracy: 0.5080\n",
      "Epoch 4/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 2.1275 - accuracy: 0.5026 - val_loss: 1.8973 - val_accuracy: 0.5199\n",
      "Epoch 5/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 1.7143 - accuracy: 0.5009 - val_loss: 1.5543 - val_accuracy: 0.5234\n",
      "Epoch 6/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 1.4319 - accuracy: 0.4959 - val_loss: 1.3326 - val_accuracy: 0.5159\n",
      "Epoch 7/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.2779 - accuracy: 0.5051 - val_loss: 1.2454 - val_accuracy: 0.4999\n",
      "Epoch 8/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 1.2300 - accuracy: 0.4972 - val_loss: 1.2151 - val_accuracy: 0.5001\n",
      "Epoch 9/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.2004 - accuracy: 0.4968 - val_loss: 1.1857 - val_accuracy: 0.5001\n",
      "Epoch 10/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.1710 - accuracy: 0.4982 - val_loss: 1.1562 - val_accuracy: 0.5001\n",
      "Epoch 11/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 1.1415 - accuracy: 0.5003 - val_loss: 1.1267 - val_accuracy: 0.5001\n",
      "Epoch 12/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 1.1120 - accuracy: 0.4972 - val_loss: 1.0973 - val_accuracy: 0.5001\n",
      "Epoch 13/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 1.0826 - accuracy: 0.4950 - val_loss: 1.0678 - val_accuracy: 0.5001\n",
      "Epoch 14/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 1.0531 - accuracy: 0.5006 - val_loss: 1.0384 - val_accuracy: 0.5001\n",
      "Epoch 15/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 1.0236 - accuracy: 0.5021 - val_loss: 1.0089 - val_accuracy: 0.5001\n",
      "Epoch 16/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.9942 - accuracy: 0.4996 - val_loss: 0.9794 - val_accuracy: 0.5001\n",
      "Epoch 17/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.9649 - accuracy: 0.4974 - val_loss: 0.9508 - val_accuracy: 0.5001\n",
      "Epoch 18/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.9374 - accuracy: 0.4982 - val_loss: 0.9240 - val_accuracy: 0.5001\n",
      "Epoch 19/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.9113 - accuracy: 0.4993 - val_loss: 0.8998 - val_accuracy: 0.5001\n",
      "Epoch 20/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.8904 - accuracy: 0.5003 - val_loss: 0.8811 - val_accuracy: 0.5001\n",
      "Epoch 21/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.8717 - accuracy: 0.5021 - val_loss: 0.8623 - val_accuracy: 0.5001\n",
      "Epoch 22/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.8530 - accuracy: 0.5000 - val_loss: 0.8438 - val_accuracy: 0.5001\n",
      "Epoch 23/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.8359 - accuracy: 0.4956 - val_loss: 0.8285 - val_accuracy: 0.5001\n",
      "Epoch 24/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.8218 - accuracy: 0.5015 - val_loss: 0.8153 - val_accuracy: 0.5001\n",
      "Epoch 25/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.8099 - accuracy: 0.5006 - val_loss: 0.8046 - val_accuracy: 0.5001\n",
      "Epoch 26/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7992 - accuracy: 0.5010 - val_loss: 0.7939 - val_accuracy: 0.5001\n",
      "Epoch 27/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7885 - accuracy: 0.4997 - val_loss: 0.7831 - val_accuracy: 0.5001\n",
      "Epoch 28/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7787 - accuracy: 0.5001 - val_loss: 0.7746 - val_accuracy: 0.5001\n",
      "Epoch 29/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7706 - accuracy: 0.5000 - val_loss: 0.7666 - val_accuracy: 0.5001\n",
      "Epoch 30/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7626 - accuracy: 0.5013 - val_loss: 0.7585 - val_accuracy: 0.5001\n",
      "Epoch 31/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7545 - accuracy: 0.5006 - val_loss: 0.7505 - val_accuracy: 0.5001\n",
      "Epoch 32/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7465 - accuracy: 0.5035 - val_loss: 0.7425 - val_accuracy: 0.5001\n",
      "Epoch 33/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7385 - accuracy: 0.4991 - val_loss: 0.7345 - val_accuracy: 0.5001\n",
      "Epoch 34/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7304 - accuracy: 0.4974 - val_loss: 0.7264 - val_accuracy: 0.5001\n",
      "Epoch 35/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7237 - accuracy: 0.4967 - val_loss: 0.7210 - val_accuracy: 0.5001\n",
      "Epoch 36/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7183 - accuracy: 0.4983 - val_loss: 0.7157 - val_accuracy: 0.5001\n",
      "Epoch 37/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7130 - accuracy: 0.5015 - val_loss: 0.7103 - val_accuracy: 0.5001\n",
      "Epoch 38/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.7076 - accuracy: 0.5001 - val_loss: 0.7049 - val_accuracy: 0.5001\n",
      "Epoch 39/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.7023 - accuracy: 0.4975 - val_loss: 0.6996 - val_accuracy: 0.5001\n",
      "Epoch 40/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6978 - accuracy: 0.4995 - val_loss: 0.6964 - val_accuracy: 0.5001\n",
      "Epoch 41/300\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.6951 - accuracy: 0.5006 - val_loss: 0.6938 - val_accuracy: 0.5001\n",
      "Epoch 42/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 43/300\n",
      "2677/2677 [==============================] - 13s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 44/300\n",
      "2664/2677 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5007Restoring model weights from the end of the best epoch: 43.\n",
      "2677/2677 [==============================] - 14s 5ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.5001\n",
      "Epoch 44: early stopping\n",
      "2480/2480 [==============================] - 6s 2ms/step - loss: 0.6933 - accuracy: 0.5001\n",
      "{'loss': 0.6933229565620422, 'accuracy': 0.5001260638237} \n",
      " 43 \n",
      "\n",
      "Model time: 10.1010732203722 minutes\n",
      "\n",
      "Total time: 267.328699208796 minutes\n",
      "\n",
      "\n",
      "Model  121  out of  121\n",
      "Model type             FeedForward\n",
      "Hidden layers                    5\n",
      "Hidden units                   256\n",
      "Activation function           relu\n",
      "Dropout                        0.3\n",
      "L1                           0.001\n",
      "L2                             0.1\n",
      "Batch size                     256\n",
      "Optimizer                  RMSprop\n",
      "Learning rate                 0.01\n",
      "Name: 6896254, dtype: object\n",
      "NN5Layer\n",
      "Epoch 1/300\n",
      "84/84 [==============================] - 8s 56ms/step - loss: 5.6255 - accuracy: 0.5011 - val_loss: 2.9951 - val_accuracy: 0.4999\n",
      "Epoch 2/300\n",
      "83/84 [============================>.] - ETA: 0s - loss: 2.9953 - accuracy: 0.5022Restoring model weights from the end of the best epoch: 1.\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 2.9953 - accuracy: 0.5023 - val_loss: 2.9953 - val_accuracy: 0.4999\n",
      "Epoch 2: early stopping\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 2.9951 - accuracy: 0.4999\n",
      "{'loss': 2.995063066482544, 'accuracy': 0.49987393617630005} \n",
      " 1 \n",
      "\n",
      "Model time: 0.2600830867886543 minutes\n",
      "\n",
      "Total time: 267.58886559680104 minutes\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model type</th>\n",
       "      <th>Hidden layers</th>\n",
       "      <th>Hidden units</th>\n",
       "      <th>Activation function</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>ModelPointer</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Training Time (minutes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveZeroForecast</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>13.85457</td>\n",
       "      <td>451.71265</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveMeanForecast</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>14.69460</td>\n",
       "      <td>462.95569</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveFirmMeanForecast</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>16.44645</td>\n",
       "      <td>555.76861</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083549</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.65246</td>\n",
       "      <td>0.63117</td>\n",
       "      <td>3.2466397434473038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardLinear</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.65322</td>\n",
       "      <td>0.62346</td>\n",
       "      <td>0.3467678017914295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236039</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>327.50806</td>\n",
       "      <td>0.49987</td>\n",
       "      <td>0.8377627395093441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661530</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>256</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>348.03342</td>\n",
       "      <td>0.49987</td>\n",
       "      <td>0.09316733106970787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718339</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>1385.75037</td>\n",
       "      <td>0.49987</td>\n",
       "      <td>0.7915889881551266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753227</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>256</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>1393.81445</td>\n",
       "      <td>0.49987</td>\n",
       "      <td>0.24490175023674965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142870</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>1507.42932</td>\n",
       "      <td>0.50013</td>\n",
       "      <td>0.827267337590456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model type Hidden layers Hidden units Activation function  \\\n",
       "0            NaiveZeroForecast          None         None                None   \n",
       "0            NaiveMeanForecast          None         None                None   \n",
       "0        NaiveFirmMeanForecast          None         None                None   \n",
       "2083549            FeedForward             2           16                relu   \n",
       "0               StandardLinear          None         None                None   \n",
       "...                        ...           ...          ...                 ...   \n",
       "2236039            FeedForward             2           32                relu   \n",
       "661530             FeedForward             1           16                relu   \n",
       "2718339            FeedForward             2          256                relu   \n",
       "2753227            FeedForward             2          256              linear   \n",
       "2142870            FeedForward             2           16             sigmoid   \n",
       "\n",
       "        Dropout       L1     L2 Batch size Optimizer  Learning rate Epochs  \\\n",
       "0          None     None   None       None      None            NaN   None   \n",
       "0          None     None   None       None      None            NaN   None   \n",
       "0          None     None   None       None      None            NaN   None   \n",
       "2083549     0.5  0.00001    0.0         16   RMSprop         0.0001     28   \n",
       "0          None     None   None         32      Adam         0.0010      4   \n",
       "...         ...      ...    ...        ...       ...            ...    ...   \n",
       "2236039     0.5    100.0    0.0          8   RMSprop         0.0010      1   \n",
       "661530      0.0    100.0   10.0        256      Adam         0.0100      5   \n",
       "2718339     0.9    100.0    0.1          8      Adam         0.0010      1   \n",
       "2753227     0.8    100.0  100.0        256      Adam         0.0010      5   \n",
       "2142870     0.1    100.0    1.0          8   RMSprop         0.0100      2   \n",
       "\n",
       "              MAE        MSE  \\\n",
       "0        13.85457  451.71265   \n",
       "0        14.69460  462.95569   \n",
       "0        16.44645  555.76861   \n",
       "2083549       NaN        NaN   \n",
       "0             NaN        NaN   \n",
       "...           ...        ...   \n",
       "2236039       NaN        NaN   \n",
       "661530        NaN        NaN   \n",
       "2718339       NaN        NaN   \n",
       "2753227       NaN        NaN   \n",
       "2142870       NaN        NaN   \n",
       "\n",
       "                                              ModelPointer        loss  \\\n",
       "0                                                     None         NaN   \n",
       "0                                                     None         NaN   \n",
       "0                                                     None         NaN   \n",
       "2083549  <keras.engine.functional.Functional object at ...     0.65246   \n",
       "0        <keras.engine.functional.Functional object at ...     0.65322   \n",
       "...                                                    ...         ...   \n",
       "2236039  <keras.engine.functional.Functional object at ...   327.50806   \n",
       "661530   <keras.engine.functional.Functional object at ...   348.03342   \n",
       "2718339  <keras.engine.functional.Functional object at ...  1385.75037   \n",
       "2753227  <keras.engine.functional.Functional object at ...  1393.81445   \n",
       "2142870  <keras.engine.functional.Functional object at ...  1507.42932   \n",
       "\n",
       "         accuracy Training Time (minutes)  \n",
       "0             NaN                     NaN  \n",
       "0             NaN                     NaN  \n",
       "0             NaN                     NaN  \n",
       "2083549   0.63117      3.2466397434473038  \n",
       "0         0.62346      0.3467678017914295  \n",
       "...           ...                     ...  \n",
       "2236039   0.49987      0.8377627395093441  \n",
       "661530    0.49987     0.09316733106970787  \n",
       "2718339   0.49987      0.7915889881551266  \n",
       "2753227   0.49987     0.24490175023674965  \n",
       "2142870   0.50013       0.827267337590456  \n",
       "\n",
       "[124 rows x 17 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.precision\", 5)\n",
    "np.set_printoptions(precision=5, suppress=False)\n",
    "\n",
    "runningDate = datetime.now().strftime(\"%d-%m-%Y_%H%M\")\n",
    "\n",
    "\n",
    "#Comment these out to continue from last point\n",
    "MSEMatrix = pd.DataFrame()\n",
    "MSEMatrix = pd.concat((MSEMatrix, NaiveZeroGrid, NaiveMeanGrid, NaiveFirmMeanGrid), axis=0)\n",
    "\n",
    "\n",
    "#Random grid search\n",
    "seed = 183\n",
    "#import random\n",
    "#random.seed(seed)\n",
    "numberOfLassoRidgeModels = 20\n",
    "numberOfNNModels = 100  #176 models took 40 min   #120 Class4 models took 267min\n",
    "\n",
    "\n",
    "randomLinearGrid = linearGrid.drop(0).sample(n=numberOfLassoRidgeModels, random_state=seed)\n",
    "randomNNGrid = NNGrid.sample(n=numberOfNNModels, random_state=seed)\n",
    "HPGrid = pd.concat([StandardLinearGrid, randomLinearGrid, randomNNGrid])\n",
    "\n",
    "HPsize = np.shape(HPGrid)[0]\n",
    "HPRange = range(0, HPsize)\n",
    "\n",
    "startTime = time.time() / 60\n",
    "for n in HPRange:\n",
    "  \n",
    "  modelStartTime = time.time() / 60\n",
    "  print(\"Model \", str(n+1), \" out of \", str(HPsize))\n",
    "\n",
    "  HP = HPGrid.iloc[n]; print(HP)\n",
    "  CV = NNfunction(*HP, runningDate)\n",
    "\n",
    "  modelEndTime = time.time() / 60\n",
    "  modelTrainingDuration = modelEndTime - modelStartTime\n",
    "  totalTrainingDuration = modelEndTime - startTime\n",
    "\n",
    "  print(\"Model time: \" + str(modelTrainingDuration) + \" minutes\\n\")\n",
    "  print(\"Total time: \" + str(totalTrainingDuration) + \" minutes\\n\\n\")\n",
    "\n",
    "\n",
    "  newMSE = HPGrid.iloc[[n]]\n",
    "  trainResults = CV[0] | {\n",
    "      \"Epochs\": CV[1],\n",
    "      \"Training Time (minutes)\": modelTrainingDuration,\n",
    "      \"ModelPointer\": CV[2]\n",
    "      }\n",
    "\n",
    "  trainResults = pd.DataFrame(trainResults, index=newMSE.index)\n",
    "  newMSE = pd.concat([newMSE, trainResults], axis=1)\n",
    "  MSEMatrix = pd.concat((MSEMatrix, newMSE), axis=0)\n",
    "\n",
    "finalResults = MSEMatrix\n",
    "\n",
    "#finalResults[:,-1] = apply(finalResults[,-1], MARGIN=2, FUN=as.numeric)\n",
    "#finalResults = finalResults[order(finalResults[,\"MSE\"]),]\n",
    "#finalResults <- apply(finalResults, 2, as.character)\n",
    "\n",
    "#write.csv2(finalResults, \"results3.csv\", row.names = FALSE)\n",
    "\n",
    "\n",
    "#pd.DataFrame.to_csv(MSEMatrix, \"resultsPython.csv\")\n",
    "\n",
    "\n",
    "#finalResults = finalResults[order(finalResults[,\"MSE\"]),]\n",
    "\n",
    "formattedMSEMatrix = finalResults.sort_values(by=[\"MAE\", \"MSE\", \"loss\"], axis = 0)\n",
    "formattedMSEMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN1Layer\n",
      "Epoch 1/300\n",
      "335/335 [==============================] - 6s 13ms/step - loss: 13.8176 - mean_squared_error: 448.4057 - mean_absolute_error: 13.8103 - val_loss: 13.8741 - val_mean_squared_error: 451.5528 - val_mean_absolute_error: 13.8739\n",
      "Epoch 2/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 13.8154 - mean_squared_error: 448.3764 - mean_absolute_error: 13.8068 - val_loss: 13.8733 - val_mean_squared_error: 451.5221 - val_mean_absolute_error: 13.8733\n",
      "Epoch 3/300\n",
      "335/335 [==============================] - 3s 8ms/step - loss: 13.8132 - mean_squared_error: 448.4731 - mean_absolute_error: 13.8074 - val_loss: 13.8727 - val_mean_squared_error: 451.4934 - val_mean_absolute_error: 13.8729\n",
      "Epoch 4/300\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 13.8111 - mean_squared_error: 449.0232 - mean_absolute_error: 13.8124 - val_loss: 13.8722 - val_mean_squared_error: 451.4647 - val_mean_absolute_error: 13.8726\n",
      "Epoch 5/300\n",
      "335/335 [==============================] - 3s 9ms/step - loss: 13.8089 - mean_squared_error: 448.0246 - mean_absolute_error: 13.7995 - val_loss: 13.8719 - val_mean_squared_error: 451.4364 - val_mean_absolute_error: 13.8725\n",
      "Epoch 6/300\n",
      "335/335 [==============================] - 3s 9ms/step - loss: 13.8068 - mean_squared_error: 456.8812 - mean_absolute_error: 13.8261 - val_loss: 13.8717 - val_mean_squared_error: 451.4073 - val_mean_absolute_error: 13.8724\n",
      "Epoch 7/300\n",
      "330/335 [============================>.] - ETA: 0s - loss: 13.7900 - mean_squared_error: 447.4547 - mean_absolute_error: 13.7855Restoring model weights from the end of the best epoch: 6.\n",
      "335/335 [==============================] - 3s 8ms/step - loss: 13.8048 - mean_squared_error: 448.4214 - mean_absolute_error: 13.8044 - val_loss: 13.8716 - val_mean_squared_error: 451.3783 - val_mean_absolute_error: 13.8724\n",
      "Epoch 7: early stopping\n",
      "311/311 [==============================] - 1s 4ms/step - loss: 13.8717 - mean_squared_error: 451.4073 - mean_absolute_error: 13.8724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'loss': 13.871673583984375,\n",
       "  'mean_squared_error': 451.4072570800781,\n",
       "  'mean_absolute_error': 13.872403144836426},\n",
       " 6,\n",
       " <keras.engine.sequential.Sequential at 0x1680aaf7ca0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 13.7826/zeroForecastMAE\n",
    "\n",
    "NNfunction(modelType=\"FeedForward\", layers=1, units=1, activation=\"relu\",\n",
    "           dropout=0, L1=0.0001, L2=0,\n",
    "           batch_size=64, optimizer=\"Adam\", learning_rate=0.00001,\n",
    "           runningDate=datetime.now().strftime(\"%d-%m-%Y_%H%M\"))\n",
    "# Model  77  out of  105\n",
    "# Model type             FeedForward\n",
    "# Hidden layers                    1\n",
    "# Hidden units                     1\n",
    "# Activation function        sigmoid\n",
    "# Dropout                        0.1\n",
    "# L1                             0.1\n",
    "# L2                             1.0\n",
    "# Batch size                       8\n",
    "# Optimizer                     Adam\n",
    "# Learning rate              0.00001\n",
    "#mean_absolute_error: 13.7826\n",
    "\n",
    "\n",
    "\n",
    "# NNfunction(modelType=\"FeedForward\", layers=2, units=8, activation=\"sigmoid\",\n",
    "#            dropout=0.4, L1=10.0, L2=100.0,\n",
    "#            batch_size=16, optimizer=\"RMSprop\", learning_rate=0.00001,\n",
    "#            runningDate=datetime.now().strftime(\"%d-%m-%Y_%H%M\"))\n",
    "# Model  87  out of  105\n",
    "# Model type             FeedForward\n",
    "# Hidden layers                    2\n",
    "# Hidden units                     8\n",
    "# Activation function        sigmoid\n",
    "# Dropout                        0.4\n",
    "# L1                            10.0\n",
    "# L2                           100.0\n",
    "# Batch size                      16\n",
    "# Optimizer                  RMSprop\n",
    "# Learning rate              0.00001\n",
    "#mean_absolute_error: 13.7952\n",
    "\n",
    "\n",
    "\n",
    "# NNfunction(modelType=\"FeedForward\", layers=1, units=1, activation=\"sigmoid\",\n",
    "#            dropout=0.1, L1=0.1, L2=1.0,\n",
    "#            batch_size=8, optimizer=\"Adam\", learning_rate=0.00001,\n",
    "#            runningDate=datetime.now().strftime(\"%d-%m-%Y_%H%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model type</th>\n",
       "      <th>Hidden layers</th>\n",
       "      <th>Hidden units</th>\n",
       "      <th>Activation function</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>ModelPointer</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RegularizedLinear</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10386</td>\n",
       "      <td>0.04023</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.39589307457208633 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939800</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>14</td>\n",
       "      <td>0.10548</td>\n",
       "      <td>0.04111</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>1.7606019526720047 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41436</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>16</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>117</td>\n",
       "      <td>0.10569</td>\n",
       "      <td>0.03994</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>11.959730185568333 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardLinear</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10619</td>\n",
       "      <td>0.04076</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.3328503891825676 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>RegularizedLinear</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10632</td>\n",
       "      <td>0.04048</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.3433503657579422 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791090</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>128</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10803</td>\n",
       "      <td>0.04000</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.14216681942343712 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072978</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12179</td>\n",
       "      <td>0.04840</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.6307506896555424 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5688542</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>16</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.12444</td>\n",
       "      <td>0.04831</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.47779954224824905 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6316486</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.13266</td>\n",
       "      <td>0.05089</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.41091713309288025 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735662</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13270</td>\n",
       "      <td>0.05133</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.13773247227072716 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624282</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13271</td>\n",
       "      <td>0.05086</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.41430046036839485 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RegularizedLinear</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13328</td>\n",
       "      <td>0.05218</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.22950026020407677 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RegularizedLinear</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13360</td>\n",
       "      <td>0.05260</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.2220449410378933 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491101</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.13528</td>\n",
       "      <td>0.05404</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.5024172216653824 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848069</th>\n",
       "      <td>FeedForward</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.13820</td>\n",
       "      <td>0.05591</td>\n",
       "      <td>&lt;keras.engine.functional.Functional object at ...</td>\n",
       "      <td>0.4075200483202934 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveZeroForecast</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>13.85457</td>\n",
       "      <td>451.71265</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveMeanForecast</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>14.69460</td>\n",
       "      <td>462.95569</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveFirmMeanForecast</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>16.44645</td>\n",
       "      <td>555.76861</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model type Hidden layers Hidden units Activation function  \\\n",
       "75           RegularizedLinear          None         None                None   \n",
       "939800             FeedForward             1           64                tanh   \n",
       "41436              FeedForward             1            1                relu   \n",
       "0               StandardLinear          None         None                None   \n",
       "62           RegularizedLinear          None         None                None   \n",
       "2791090            FeedForward             2          256             sigmoid   \n",
       "5072978            FeedForward             4           32              linear   \n",
       "5688542            FeedForward             5            1              linear   \n",
       "6316486            FeedForward             5           16              linear   \n",
       "4735662            FeedForward             4            8                relu   \n",
       "1624282            FeedForward             2            2                relu   \n",
       "35           RegularizedLinear          None         None                None   \n",
       "21           RegularizedLinear          None         None                None   \n",
       "491101             FeedForward             1            8                tanh   \n",
       "5848069            FeedForward             5            2              linear   \n",
       "0            NaiveZeroForecast          None         None                None   \n",
       "0            NaiveMeanForecast          None         None                None   \n",
       "0        NaiveFirmMeanForecast          None         None                None   \n",
       "\n",
       "        Dropout       L1       L2 Batch size Optimizer  Learning rate Epochs  \\\n",
       "75         None  0.00001      1.0         32      Adam        0.00100      2   \n",
       "939800      0.1    0.001      0.1         16      Adam        0.00001     14   \n",
       "41436       0.0     0.01  0.00001         16   RMSprop        0.00001    117   \n",
       "0          None     None     None         32      Adam        0.00100      4   \n",
       "62         None    0.001  0.00001         32      Adam        0.00100      4   \n",
       "2791090     0.7   0.0001   0.0001        128      Adam        0.01000      1   \n",
       "5072978     0.4   0.0001      0.0          8      Adam        0.01000      1   \n",
       "5688542     0.3      0.0  0.00001         16   RMSprop        0.01000      2   \n",
       "6316486     0.4     0.01      0.1         32   RMSprop        0.01000      4   \n",
       "4735662     0.8      0.0    100.0         64   RMSprop        0.01000      1   \n",
       "1624282     0.7    0.001  0.00001         16      Adam        0.01000      2   \n",
       "35         None      1.0  0.00001         32      Adam        0.00100      2   \n",
       "21         None     10.0      1.0         32      Adam        0.00100      1   \n",
       "491101      0.6     10.0   0.0001         16   RMSprop        0.00010      3   \n",
       "5848069     0.4    100.0    100.0        128   RMSprop        0.00010     10   \n",
       "0          None     None     None       None      None            NaN   None   \n",
       "0          None     None     None       None      None            NaN   None   \n",
       "0          None     None     None       None      None            NaN   None   \n",
       "\n",
       "              MAE        MSE  \\\n",
       "75        0.10386    0.04023   \n",
       "939800    0.10548    0.04111   \n",
       "41436     0.10569    0.03994   \n",
       "0         0.10619    0.04076   \n",
       "62        0.10632    0.04048   \n",
       "2791090   0.10803    0.04000   \n",
       "5072978   0.12179    0.04840   \n",
       "5688542   0.12444    0.04831   \n",
       "6316486   0.13266    0.05089   \n",
       "4735662   0.13270    0.05133   \n",
       "1624282   0.13271    0.05086   \n",
       "35        0.13328    0.05218   \n",
       "21        0.13360    0.05260   \n",
       "491101    0.13528    0.05404   \n",
       "5848069   0.13820    0.05591   \n",
       "0        13.85457  451.71265   \n",
       "0        14.69460  462.95569   \n",
       "0        16.44645  555.76861   \n",
       "\n",
       "                                              ModelPointer  \\\n",
       "75       <keras.engine.functional.Functional object at ...   \n",
       "939800   <keras.engine.functional.Functional object at ...   \n",
       "41436    <keras.engine.functional.Functional object at ...   \n",
       "0        <keras.engine.functional.Functional object at ...   \n",
       "62       <keras.engine.functional.Functional object at ...   \n",
       "2791090  <keras.engine.functional.Functional object at ...   \n",
       "5072978  <keras.engine.functional.Functional object at ...   \n",
       "5688542  <keras.engine.functional.Functional object at ...   \n",
       "6316486  <keras.engine.functional.Functional object at ...   \n",
       "4735662  <keras.engine.functional.Functional object at ...   \n",
       "1624282  <keras.engine.functional.Functional object at ...   \n",
       "35       <keras.engine.functional.Functional object at ...   \n",
       "21       <keras.engine.functional.Functional object at ...   \n",
       "491101   <keras.engine.functional.Functional object at ...   \n",
       "5848069  <keras.engine.functional.Functional object at ...   \n",
       "0                                                     None   \n",
       "0                                                     None   \n",
       "0                                                     None   \n",
       "\n",
       "                       Training Time  \n",
       "75       0.39589307457208633 minutes  \n",
       "939800    1.7606019526720047 minutes  \n",
       "41436     11.959730185568333 minutes  \n",
       "0         0.3328503891825676 minutes  \n",
       "62        0.3433503657579422 minutes  \n",
       "2791090  0.14216681942343712 minutes  \n",
       "5072978   0.6307506896555424 minutes  \n",
       "5688542  0.47779954224824905 minutes  \n",
       "6316486  0.41091713309288025 minutes  \n",
       "4735662  0.13773247227072716 minutes  \n",
       "1624282  0.41430046036839485 minutes  \n",
       "35       0.22950026020407677 minutes  \n",
       "21        0.2220449410378933 minutes  \n",
       "491101    0.5024172216653824 minutes  \n",
       "5848069   0.4075200483202934 minutes  \n",
       "0                                NaN  \n",
       "0                                NaN  \n",
       "0                                NaN  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalResults = MSEMatrix\n",
    "formattedMSEMatrix = finalResults.sort_values(by=[\"MAE\", \"MSE\", \"loss\"], axis = 0)\n",
    "formattedMSEMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results//2Class//BestKerasModel1\\assets\n",
      "INFO:tensorflow:Assets written to: Results//2Class//BestKerasModel2\\assets\n",
      "INFO:tensorflow:Assets written to: Results//2Class//BestKerasModel3\\assets\n",
      "INFO:tensorflow:Assets written to: Results//2Class//BestKerasModel4\\assets\n",
      "INFO:tensorflow:Assets written to: Results//2Class//BestKerasModel5\\assets\n",
      "INFO:tensorflow:Assets written to: Results//2Class//KerasLinearModel\\assets\n"
     ]
    }
   ],
   "source": [
    "#MSEMatrix\n",
    "\n",
    "kerasModelResults = finalResults.dropna(subset = [\"ModelPointer\"])\n",
    "kerasModelResults = kerasModelResults.reset_index()\n",
    "index = kerasModelResults['loss'].idxmin()\n",
    "#bestParams = finalResults.iloc[index][:-3]\n",
    "#bestModel = finalResults(*bestParams)[1]\n",
    "#bestParams = finalResults[finalResults['MSE']==finalResults['MSE'].min()]\n",
    "\n",
    "for i in range(5):\n",
    "    bModel = kerasModelResults.iloc[i+1][\"ModelPointer\"]\n",
    "    modelPath = \"Results//2Class//BestKerasModel\" + str(i + 1)\n",
    "    bModel.save(modelPath)\n",
    "\n",
    "\n",
    "OLSModel = kerasModelResults[kerasModelResults[\"Model type\"] == \"StandardLinear\"][\"ModelPointer\"][0]\n",
    "modelPath = \"Results//2Class//KerasLinearModel\"\n",
    "OLSModel.save(modelPath)\n",
    "\n",
    "\n",
    "# # xTrainValiPooled = scaled_X[:validationSize,:]\n",
    "# # yTrainValiPooled = Y[:validationSize]\n",
    "\n",
    "# #xTrainValiPooled = scaled_X[:validationSize,:]\n",
    "# #xTrainValiPooled = X.loc[split!=\"Test\", :]\n",
    "# xTrainValiPooled = dummiesClean.loc[split!=\"Test\", :]\n",
    "# #yTrainValiPooled = Y[:validationSize]\n",
    "# yTrainValiPooled = Y[split!=\"Test\"]\n",
    "\n",
    "# #bestModel = bestParams[\"ModelPointer\"]\n",
    "# bestModel = kerasModelResults.iloc[index][\"ModelPointer\"]\n",
    "\n",
    "# callback = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# history = bestModel.fit(x=xTrainValiPooled, y=yTrainValiPooled,\n",
    "#                         batch_size=32, epochs=100,\n",
    "#                         callbacks=[callback], verbose=2, validation_split=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #bestModel.save('Results/BestKerasModel10')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 1s 2ms/step\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.251, 0.749], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [1.0, 0.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.234, 0.766], dtype=float32), [0.0, 1.0])\n",
      "(array([0.259, 0.741], dtype=float32), [1.0, 0.0])\n",
      "(array([0.339, 0.661], dtype=float32), [0.0, 1.0])\n",
      "(array([0.307, 0.693], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.307, 0.693], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.23, 0.77], dtype=float32), [1.0, 0.0])\n",
      "(array([0.114, 0.886], dtype=float32), [0.0, 1.0])\n",
      "(array([0.172, 0.828], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.185, 0.815], dtype=float32), [0.0, 1.0])\n",
      "(array([0.271, 0.729], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.76, 0.24], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.264, 0.736], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.227, 0.773], dtype=float32), [0.0, 1.0])\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.132, 0.868], dtype=float32), [1.0, 0.0])\n",
      "(array([0.172, 0.828], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [1.0, 0.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.215, 0.785], dtype=float32), [1.0, 0.0])\n",
      "(array([0.173, 0.827], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.298, 0.702], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.037, 0.963], dtype=float32), [0.0, 1.0])\n",
      "(array([0.048, 0.952], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [1.0, 0.0])\n",
      "(array([0.317, 0.683], dtype=float32), [1.0, 0.0])\n",
      "(array([0.337, 0.663], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.703, 0.297], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.756, 0.244], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.308, 0.692], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [1.0, 0.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.34, 0.66], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.82, 0.18], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.874, 0.126], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.787, 0.213], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [1.0, 0.0])\n",
      "(array([0.308, 0.692], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.232, 0.768], dtype=float32), [1.0, 0.0])\n",
      "(array([0.168, 0.832], dtype=float32), [0.0, 1.0])\n",
      "(array([0.199, 0.801], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.349, 0.651], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.212, 0.788], dtype=float32), [0.0, 1.0])\n",
      "(array([0.236, 0.764], dtype=float32), [0.0, 1.0])\n",
      "(array([0.313, 0.687], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.293, 0.707], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.334, 0.666], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.282, 0.718], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [1.0, 0.0])\n",
      "(array([0.17, 0.83], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.362, 0.638], dtype=float32), [0.0, 1.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.27, 0.73], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.341, 0.659], dtype=float32), [1.0, 0.0])\n",
      "(array([0.294, 0.706], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.731, 0.269], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.815, 0.185], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.193, 0.807], dtype=float32), [0.0, 1.0])\n",
      "(array([0.073, 0.927], dtype=float32), [0.0, 1.0])\n",
      "(array([0.203, 0.797], dtype=float32), [0.0, 1.0])\n",
      "(array([0.281, 0.719], dtype=float32), [0.0, 1.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.183, 0.817], dtype=float32), [1.0, 0.0])\n",
      "(array([0.196, 0.804], dtype=float32), [0.0, 1.0])\n",
      "(array([0.242, 0.758], dtype=float32), [0.0, 1.0])\n",
      "(array([0.251, 0.749], dtype=float32), [0.0, 1.0])\n",
      "(array([0.346, 0.654], dtype=float32), [1.0, 0.0])\n",
      "(array([0.298, 0.702], dtype=float32), [0.0, 1.0])\n",
      "(array([0.335, 0.665], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [0.0, 1.0])\n",
      "(array([0.787, 0.213], dtype=float32), [1.0, 0.0])\n",
      "(array([0.707, 0.293], dtype=float32), [0.0, 1.0])\n",
      "(array([0.796, 0.204], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.749, 0.251], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.253, 0.747], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.722, 0.278], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.253, 0.747], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.298, 0.702], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.211, 0.789], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.279, 0.721], dtype=float32), [0.0, 1.0])\n",
      "(array([0.242, 0.758], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.738, 0.262], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.33, 0.67], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.264, 0.736], dtype=float32), [1.0, 0.0])\n",
      "(array([0.221, 0.779], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.265, 0.735], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.34, 0.66], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.264, 0.736], dtype=float32), [1.0, 0.0])\n",
      "(array([0.215, 0.785], dtype=float32), [0.0, 1.0])\n",
      "(array([0.288, 0.712], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.313, 0.687], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.245, 0.755], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [1.0, 0.0])\n",
      "(array([0.209, 0.791], dtype=float32), [1.0, 0.0])\n",
      "(array([0.268, 0.732], dtype=float32), [1.0, 0.0])\n",
      "(array([0.235, 0.765], dtype=float32), [1.0, 0.0])\n",
      "(array([0.281, 0.719], dtype=float32), [1.0, 0.0])\n",
      "(array([0.133, 0.867], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.297, 0.703], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [0.0, 1.0])\n",
      "(array([0.84, 0.16], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.714, 0.286], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.796, 0.204], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.235, 0.765], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.255, 0.745], dtype=float32), [1.0, 0.0])\n",
      "(array([0.285, 0.715], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.28, 0.72], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.19, 0.81], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.231, 0.769], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.25, 0.75], dtype=float32), [0.0, 1.0])\n",
      "(array([0.173, 0.827], dtype=float32), [0.0, 1.0])\n",
      "(array([0.317, 0.683], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.905, 0.095], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [1.0, 0.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.313, 0.687], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.247, 0.753], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.282, 0.718], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.225, 0.775], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.237, 0.763], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.212, 0.788], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.263, 0.737], dtype=float32), [0.0, 1.0])\n",
      "(array([0.279, 0.721], dtype=float32), [0.0, 1.0])\n",
      "(array([0.145, 0.855], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.288, 0.712], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.253, 0.747], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.196, 0.804], dtype=float32), [0.0, 1.0])\n",
      "(array([0.136, 0.864], dtype=float32), [0.0, 1.0])\n",
      "(array([0.121, 0.879], dtype=float32), [0.0, 1.0])\n",
      "(array([0.236, 0.764], dtype=float32), [1.0, 0.0])\n",
      "(array([0.173, 0.827], dtype=float32), [1.0, 0.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.262, 0.738], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.313, 0.687], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.092, 0.908], dtype=float32), [0.0, 1.0])\n",
      "(array([0.24, 0.76], dtype=float32), [0.0, 1.0])\n",
      "(array([0.296, 0.704], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.185, 0.815], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.282, 0.718], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.248, 0.752], dtype=float32), [0.0, 1.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.276, 0.724], dtype=float32), [0.0, 1.0])\n",
      "(array([0.267, 0.733], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.254, 0.746], dtype=float32), [0.0, 1.0])\n",
      "(array([0.247, 0.753], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.233, 0.767], dtype=float32), [0.0, 1.0])\n",
      "(array([0.227, 0.773], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.278, 0.722], dtype=float32), [1.0, 0.0])\n",
      "(array([0.308, 0.692], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.168, 0.832], dtype=float32), [0.0, 1.0])\n",
      "(array([0.307, 0.693], dtype=float32), [1.0, 0.0])\n",
      "(array([0.341, 0.659], dtype=float32), [0.0, 1.0])\n",
      "(array([0.241, 0.759], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.293, 0.707], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.221, 0.779], dtype=float32), [0.0, 1.0])\n",
      "(array([0.232, 0.768], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [1.0, 0.0])\n",
      "(array([0.292, 0.708], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.249, 0.751], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.165, 0.835], dtype=float32), [1.0, 0.0])\n",
      "(array([0.249, 0.751], dtype=float32), [1.0, 0.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.285, 0.715], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.314, 0.686], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.283, 0.717], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.341, 0.659], dtype=float32), [0.0, 1.0])\n",
      "(array([0.399, 0.601], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.776, 0.224], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.332, 0.668], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.763, 0.237], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.805, 0.195], dtype=float32), [1.0, 0.0])\n",
      "(array([0.789, 0.211], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.304, 0.696], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.161, 0.839], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.308, 0.692], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.268, 0.732], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.3, 0.7], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.341, 0.659], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.362, 0.638], dtype=float32), [0.0, 1.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.361, 0.639], dtype=float32), [1.0, 0.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.259, 0.741], dtype=float32), [0.0, 1.0])\n",
      "(array([0.327, 0.673], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.792, 0.208], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.387, 0.613], dtype=float32), [1.0, 0.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.354, 0.646], dtype=float32), [1.0, 0.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [0.0, 1.0])\n",
      "(array([0.238, 0.762], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.201, 0.799], dtype=float32), [0.0, 1.0])\n",
      "(array([0.289, 0.711], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.306, 0.694], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.695, 0.305], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.779, 0.221], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.81, 0.19], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.659, 0.341], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [0.0, 1.0])\n",
      "(array([0.816, 0.184], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.73, 0.27], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.253, 0.747], dtype=float32), [0.0, 1.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.744, 0.256], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [1.0, 0.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.712, 0.288], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.7, 0.3], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.715, 0.285], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.851, 0.149], dtype=float32), [1.0, 0.0])\n",
      "(array([0.81, 0.19], dtype=float32), [1.0, 0.0])\n",
      "(array([0.791, 0.209], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.308, 0.692], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.742, 0.258], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.771, 0.229], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.703, 0.297], dtype=float32), [1.0, 0.0])\n",
      "(array([0.704, 0.296], dtype=float32), [0.0, 1.0])\n",
      "(array([0.835, 0.165], dtype=float32), [1.0, 0.0])\n",
      "(array([0.845, 0.155], dtype=float32), [0.0, 1.0])\n",
      "(array([0.887, 0.113], dtype=float32), [1.0, 0.0])\n",
      "(array([0.866, 0.134], dtype=float32), [1.0, 0.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.748, 0.252], dtype=float32), [0.0, 1.0])\n",
      "(array([0.287, 0.713], dtype=float32), [0.0, 1.0])\n",
      "(array([0.281, 0.719], dtype=float32), [0.0, 1.0])\n",
      "(array([0.274, 0.726], dtype=float32), [0.0, 1.0])\n",
      "(array([0.304, 0.696], dtype=float32), [0.0, 1.0])\n",
      "(array([0.27, 0.73], dtype=float32), [0.0, 1.0])\n",
      "(array([0.269, 0.731], dtype=float32), [0.0, 1.0])\n",
      "(array([0.281, 0.719], dtype=float32), [1.0, 0.0])\n",
      "(array([0.237, 0.763], dtype=float32), [1.0, 0.0])\n",
      "(array([0.189, 0.811], dtype=float32), [0.0, 1.0])\n",
      "(array([0.193, 0.807], dtype=float32), [0.0, 1.0])\n",
      "(array([0.369, 0.631], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.259, 0.741], dtype=float32), [0.0, 1.0])\n",
      "(array([0.228, 0.772], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.3, 0.7], dtype=float32), [0.0, 1.0])\n",
      "(array([0.106, 0.894], dtype=float32), [0.0, 1.0])\n",
      "(array([0.104, 0.896], dtype=float32), [0.0, 1.0])\n",
      "(array([0.07, 0.93], dtype=float32), [0.0, 1.0])\n",
      "(array([0.074, 0.926], dtype=float32), [0.0, 1.0])\n",
      "(array([0.058, 0.942], dtype=float32), [1.0, 0.0])\n",
      "(array([0.071, 0.929], dtype=float32), [0.0, 1.0])\n",
      "(array([0.163, 0.837], dtype=float32), [1.0, 0.0])\n",
      "(array([0.099, 0.901], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [1.0, 0.0])\n",
      "(array([0.239, 0.761], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.254, 0.746], dtype=float32), [0.0, 1.0])\n",
      "(array([0.251, 0.749], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.217, 0.783], dtype=float32), [0.0, 1.0])\n",
      "(array([0.247, 0.753], dtype=float32), [0.0, 1.0])\n",
      "(array([0.349, 0.651], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.207, 0.793], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.765, 0.235], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.088, 0.912], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.238, 0.762], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.78, 0.22], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.269, 0.731], dtype=float32), [0.0, 1.0])\n",
      "(array([0.357, 0.643], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.306, 0.694], dtype=float32), [0.0, 1.0])\n",
      "(array([0.28, 0.72], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [1.0, 0.0])\n",
      "(array([0.28, 0.72], dtype=float32), [0.0, 1.0])\n",
      "(array([0.274, 0.726], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.303, 0.697], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.739, 0.261], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.773, 0.227], dtype=float32), [1.0, 0.0])\n",
      "(array([0.705, 0.295], dtype=float32), [0.0, 1.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.725, 0.275], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.829, 0.171], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.768, 0.232], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.715, 0.285], dtype=float32), [1.0, 0.0])\n",
      "(array([0.739, 0.261], dtype=float32), [1.0, 0.0])\n",
      "(array([0.299, 0.701], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.244, 0.756], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [0.0, 1.0])\n",
      "(array([0.146, 0.854], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.289, 0.711], dtype=float32), [0.0, 1.0])\n",
      "(array([0.803, 0.197], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.718, 0.282], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.797, 0.203], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.288, 0.712], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [1.0, 0.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.184, 0.816], dtype=float32), [0.0, 1.0])\n",
      "(array([0.158, 0.842], dtype=float32), [0.0, 1.0])\n",
      "(array([0.28, 0.72], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.271, 0.729], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.762, 0.238], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.322, 0.678], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [0.0, 1.0])\n",
      "(array([0.231, 0.769], dtype=float32), [0.0, 1.0])\n",
      "(array([0.258, 0.742], dtype=float32), [0.0, 1.0])\n",
      "(array([0.19, 0.81], dtype=float32), [0.0, 1.0])\n",
      "(array([0.262, 0.738], dtype=float32), [0.0, 1.0])\n",
      "(array([0.302, 0.698], dtype=float32), [1.0, 0.0])\n",
      "(array([0.246, 0.754], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.3, 0.7], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.724, 0.276], dtype=float32), [0.0, 1.0])\n",
      "(array([0.811, 0.189], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.367, 0.633], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.234, 0.766], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.124, 0.876], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.296, 0.704], dtype=float32), [0.0, 1.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.225, 0.775], dtype=float32), [0.0, 1.0])\n",
      "(array([0.239, 0.761], dtype=float32), [0.0, 1.0])\n",
      "(array([0.18, 0.82], dtype=float32), [0.0, 1.0])\n",
      "(array([0.346, 0.654], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.341, 0.659], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.313, 0.687], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.733, 0.267], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.703, 0.297], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.28, 0.72], dtype=float32), [1.0, 0.0])\n",
      "(array([0.244, 0.756], dtype=float32), [0.0, 1.0])\n",
      "(array([0.272, 0.728], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.169, 0.831], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.267, 0.733], dtype=float32), [1.0, 0.0])\n",
      "(array([0.207, 0.793], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.307, 0.693], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.368, 0.632], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.186, 0.814], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.192, 0.808], dtype=float32), [0.0, 1.0])\n",
      "(array([0.174, 0.826], dtype=float32), [1.0, 0.0])\n",
      "(array([0.162, 0.838], dtype=float32), [0.0, 1.0])\n",
      "(array([0.19, 0.81], dtype=float32), [0.0, 1.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.28, 0.72], dtype=float32), [1.0, 0.0])\n",
      "(array([0.213, 0.787], dtype=float32), [0.0, 1.0])\n",
      "(array([0.24, 0.76], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.126, 0.874], dtype=float32), [1.0, 0.0])\n",
      "(array([0.141, 0.859], dtype=float32), [0.0, 1.0])\n",
      "(array([0.287, 0.713], dtype=float32), [1.0, 0.0])\n",
      "(array([0.202, 0.798], dtype=float32), [0.0, 1.0])\n",
      "(array([0.331, 0.669], dtype=float32), [1.0, 0.0])\n",
      "(array([0.302, 0.698], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.241, 0.759], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [1.0, 0.0])\n",
      "(array([0.105, 0.895], dtype=float32), [0.0, 1.0])\n",
      "(array([0.186, 0.814], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.325, 0.675], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.757, 0.243], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [1.0, 0.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.274, 0.726], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.215, 0.785], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.852, 0.148], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.213, 0.787], dtype=float32), [0.0, 1.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.179, 0.821], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.189, 0.811], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.171, 0.829], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.223, 0.777], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [0.0, 1.0])\n",
      "(array([0.304, 0.696], dtype=float32), [1.0, 0.0])\n",
      "(array([0.248, 0.752], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.302, 0.698], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.233, 0.767], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.822, 0.178], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.197, 0.803], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.775, 0.225], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.836, 0.164], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.746, 0.254], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.313, 0.687], dtype=float32), [0.0, 1.0])\n",
      "(array([0.301, 0.699], dtype=float32), [1.0, 0.0])\n",
      "(array([0.193, 0.807], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.189, 0.811], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.334, 0.666], dtype=float32), [1.0, 0.0])\n",
      "(array([0.835, 0.165], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.368, 0.632], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.804, 0.196], dtype=float32), [1.0, 0.0])\n",
      "(array([0.768, 0.232], dtype=float32), [1.0, 0.0])\n",
      "(array([0.802, 0.198], dtype=float32), [0.0, 1.0])\n",
      "(array([0.733, 0.267], dtype=float32), [1.0, 0.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.699, 0.301], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.286, 0.714], dtype=float32), [0.0, 1.0])\n",
      "(array([0.239, 0.761], dtype=float32), [0.0, 1.0])\n",
      "(array([0.267, 0.733], dtype=float32), [0.0, 1.0])\n",
      "(array([0.128, 0.872], dtype=float32), [0.0, 1.0])\n",
      "(array([0.178, 0.822], dtype=float32), [0.0, 1.0])\n",
      "(array([0.05, 0.95], dtype=float32), [1.0, 0.0])\n",
      "(array([0.122, 0.878], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.176, 0.824], dtype=float32), [1.0, 0.0])\n",
      "(array([0.209, 0.791], dtype=float32), [0.0, 1.0])\n",
      "(array([0.271, 0.729], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.836, 0.164], dtype=float32), [1.0, 0.0])\n",
      "(array([0.848, 0.152], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.25, 0.75], dtype=float32), [0.0, 1.0])\n",
      "(array([0.234, 0.766], dtype=float32), [0.0, 1.0])\n",
      "(array([0.203, 0.797], dtype=float32), [0.0, 1.0])\n",
      "(array([0.216, 0.784], dtype=float32), [0.0, 1.0])\n",
      "(array([0.161, 0.839], dtype=float32), [0.0, 1.0])\n",
      "(array([0.187, 0.813], dtype=float32), [1.0, 0.0])\n",
      "(array([0.228, 0.772], dtype=float32), [1.0, 0.0])\n",
      "(array([0.145, 0.855], dtype=float32), [0.0, 1.0])\n",
      "(array([0.175, 0.825], dtype=float32), [0.0, 1.0])\n",
      "(array([0.174, 0.826], dtype=float32), [0.0, 1.0])\n",
      "(array([0.336, 0.664], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.78, 0.22], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.762, 0.238], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.367, 0.633], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [0.0, 1.0])\n",
      "(array([0.287, 0.713], dtype=float32), [0.0, 1.0])\n",
      "(array([0.256, 0.744], dtype=float32), [1.0, 0.0])\n",
      "(array([0.226, 0.774], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.29, 0.71], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.725, 0.275], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.285, 0.715], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.732, 0.268], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.339, 0.661], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.135, 0.865], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.074, 0.926], dtype=float32), [0.0, 1.0])\n",
      "(array([0.115, 0.885], dtype=float32), [0.0, 1.0])\n",
      "(array([0.141, 0.859], dtype=float32), [0.0, 1.0])\n",
      "(array([0.136, 0.864], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.165, 0.835], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.185, 0.815], dtype=float32), [0.0, 1.0])\n",
      "(array([0.217, 0.783], dtype=float32), [0.0, 1.0])\n",
      "(array([0.117, 0.883], dtype=float32), [0.0, 1.0])\n",
      "(array([0.159, 0.841], dtype=float32), [0.0, 1.0])\n",
      "(array([0.15, 0.85], dtype=float32), [0.0, 1.0])\n",
      "(array([0.303, 0.697], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.31, 0.69], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.334, 0.666], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.733, 0.267], dtype=float32), [1.0, 0.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.308, 0.692], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [1.0, 0.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.271, 0.729], dtype=float32), [0.0, 1.0])\n",
      "(array([0.307, 0.693], dtype=float32), [0.0, 1.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.302, 0.698], dtype=float32), [1.0, 0.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.169, 0.831], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [1.0, 0.0])\n",
      "(array([0.375, 0.625], dtype=float32), [1.0, 0.0])\n",
      "(array([0.29, 0.71], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.314, 0.686], dtype=float32), [1.0, 0.0])\n",
      "(array([0.294, 0.706], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.707, 0.293], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.358, 0.642], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.308, 0.692], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.723, 0.277], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.274, 0.726], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.344, 0.656], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.294, 0.706], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [1.0, 0.0])\n",
      "(array([0.333, 0.667], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.294, 0.706], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.292, 0.708], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.163, 0.837], dtype=float32), [0.0, 1.0])\n",
      "(array([0.151, 0.849], dtype=float32), [0.0, 1.0])\n",
      "(array([0.155, 0.845], dtype=float32), [0.0, 1.0])\n",
      "(array([0.068, 0.932], dtype=float32), [0.0, 1.0])\n",
      "(array([0.095, 0.905], dtype=float32), [0.0, 1.0])\n",
      "(array([0.165, 0.835], dtype=float32), [1.0, 0.0])\n",
      "(array([0.299, 0.701], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.269, 0.731], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.339, 0.661], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.333, 0.667], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.289, 0.711], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.369, 0.631], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.215, 0.785], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.159, 0.841], dtype=float32), [0.0, 1.0])\n",
      "(array([0.256, 0.744], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.15, 0.85], dtype=float32), [0.0, 1.0])\n",
      "(array([0.118, 0.882], dtype=float32), [0.0, 1.0])\n",
      "(array([0.154, 0.846], dtype=float32), [1.0, 0.0])\n",
      "(array([0.204, 0.796], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.809, 0.191], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.768, 0.232], dtype=float32), [1.0, 0.0])\n",
      "(array([0.799, 0.201], dtype=float32), [1.0, 0.0])\n",
      "(array([0.142, 0.858], dtype=float32), [0.0, 1.0])\n",
      "(array([0.208, 0.792], dtype=float32), [1.0, 0.0])\n",
      "(array([0.123, 0.877], dtype=float32), [0.0, 1.0])\n",
      "(array([0.196, 0.804], dtype=float32), [0.0, 1.0])\n",
      "(array([0.106, 0.894], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.845, 0.155], dtype=float32), [1.0, 0.0])\n",
      "(array([0.803, 0.197], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.744, 0.256], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.218, 0.782], dtype=float32), [0.0, 1.0])\n",
      "(array([0.367, 0.633], dtype=float32), [1.0, 0.0])\n",
      "(array([0.374, 0.626], dtype=float32), [1.0, 0.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.197, 0.803], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.341, 0.659], dtype=float32), [1.0, 0.0])\n",
      "(array([0.28, 0.72], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.258, 0.742], dtype=float32), [1.0, 0.0])\n",
      "(array([0.358, 0.642], dtype=float32), [1.0, 0.0])\n",
      "(array([0.387, 0.613], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.831, 0.169], dtype=float32), [1.0, 0.0])\n",
      "(array([0.695, 0.305], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.279, 0.721], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.399, 0.601], dtype=float32), [1.0, 0.0])\n",
      "(array([0.685, 0.315], dtype=float32), [0.0, 1.0])\n",
      "(array([0.785, 0.215], dtype=float32), [1.0, 0.0])\n",
      "(array([0.742, 0.258], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.81, 0.19], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.708, 0.292], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.236, 0.764], dtype=float32), [0.0, 1.0])\n",
      "(array([0.231, 0.769], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.307, 0.693], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.168, 0.832], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.308, 0.692], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.306, 0.694], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.287, 0.713], dtype=float32), [1.0, 0.0])\n",
      "(array([0.286, 0.714], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.31, 0.69], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.305, 0.695], dtype=float32), [0.0, 1.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.273, 0.727], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.341, 0.659], dtype=float32), [1.0, 0.0])\n",
      "(array([0.257, 0.743], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.752, 0.248], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.218, 0.782], dtype=float32), [0.0, 1.0])\n",
      "(array([0.237, 0.763], dtype=float32), [0.0, 1.0])\n",
      "(array([0.317, 0.683], dtype=float32), [1.0, 0.0])\n",
      "(array([0.293, 0.707], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.336, 0.664], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.156, 0.844], dtype=float32), [0.0, 1.0])\n",
      "(array([0.282, 0.718], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.208, 0.792], dtype=float32), [1.0, 0.0])\n",
      "(array([0.282, 0.718], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.314, 0.686], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.283, 0.717], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.254, 0.746], dtype=float32), [0.0, 1.0])\n",
      "(array([0.18, 0.82], dtype=float32), [0.0, 1.0])\n",
      "(array([0.193, 0.807], dtype=float32), [0.0, 1.0])\n",
      "(array([0.265, 0.735], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.29, 0.71], dtype=float32), [0.0, 1.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.285, 0.715], dtype=float32), [0.0, 1.0])\n",
      "(array([0.281, 0.719], dtype=float32), [0.0, 1.0])\n",
      "(array([0.235, 0.765], dtype=float32), [0.0, 1.0])\n",
      "(array([0.235, 0.765], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.304, 0.696], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.306, 0.694], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.769, 0.231], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.284, 0.716], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.313, 0.687], dtype=float32), [0.0, 1.0])\n",
      "(array([0.108, 0.892], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.733, 0.267], dtype=float32), [1.0, 0.0])\n",
      "(array([0.783, 0.217], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.27, 0.73], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.784, 0.216], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.804, 0.196], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.776, 0.224], dtype=float32), [0.0, 1.0])\n",
      "(array([0.731, 0.269], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.212, 0.788], dtype=float32), [1.0, 0.0])\n",
      "(array([0.325, 0.675], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.756, 0.244], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.784, 0.216], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.296, 0.704], dtype=float32), [0.0, 1.0])\n",
      "(array([0.202, 0.798], dtype=float32), [0.0, 1.0])\n",
      "(array([0.255, 0.745], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.296, 0.704], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [1.0, 0.0])\n",
      "(array([0.333, 0.667], dtype=float32), [1.0, 0.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.738, 0.262], dtype=float32), [0.0, 1.0])\n",
      "(array([0.85, 0.15], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.76, 0.24], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.301, 0.699], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.304, 0.696], dtype=float32), [0.0, 1.0])\n",
      "(array([0.262, 0.738], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.264, 0.736], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.279, 0.721], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.321, 0.679], dtype=float32), [1.0, 0.0])\n",
      "(array([0.302, 0.698], dtype=float32), [1.0, 0.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.799, 0.201], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.251, 0.749], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.367, 0.633], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.228, 0.772], dtype=float32), [0.0, 1.0])\n",
      "(array([0.273, 0.727], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [1.0, 0.0])\n",
      "(array([0.26, 0.74], dtype=float32), [1.0, 0.0])\n",
      "(array([0.258, 0.742], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.778, 0.222], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.302, 0.698], dtype=float32), [0.0, 1.0])\n",
      "(array([0.246, 0.754], dtype=float32), [0.0, 1.0])\n",
      "(array([0.163, 0.837], dtype=float32), [0.0, 1.0])\n",
      "(array([0.339, 0.661], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.695, 0.305], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.746, 0.254], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.718, 0.282], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.242, 0.758], dtype=float32), [0.0, 1.0])\n",
      "(array([0.289, 0.711], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.747, 0.253], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.276, 0.724], dtype=float32), [0.0, 1.0])\n",
      "(array([0.325, 0.675], dtype=float32), [1.0, 0.0])\n",
      "(array([0.171, 0.829], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.302, 0.698], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.142, 0.858], dtype=float32), [0.0, 1.0])\n",
      "(array([0.306, 0.694], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.349, 0.651], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.876, 0.124], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.258, 0.742], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [1.0, 0.0])\n",
      "(array([0.228, 0.772], dtype=float32), [0.0, 1.0])\n",
      "(array([0.268, 0.732], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.786, 0.214], dtype=float32), [1.0, 0.0])\n",
      "(array([0.759, 0.241], dtype=float32), [0.0, 1.0])\n",
      "(array([0.84, 0.16], dtype=float32), [0.0, 1.0])\n",
      "(array([0.854, 0.146], dtype=float32), [1.0, 0.0])\n",
      "(array([0.835, 0.165], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [0.0, 1.0])\n",
      "(array([0.784, 0.216], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.691, 0.309], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.338, 0.662], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.797, 0.203], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.712, 0.288], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [1.0, 0.0])\n",
      "(array([0.284, 0.716], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.342, 0.658], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.731, 0.269], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.289, 0.711], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.163, 0.837], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.785, 0.215], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.3, 0.7], dtype=float32), [0.0, 1.0])\n",
      "(array([0.282, 0.718], dtype=float32), [1.0, 0.0])\n",
      "(array([0.369, 0.631], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.263, 0.737], dtype=float32), [0.0, 1.0])\n",
      "(array([0.256, 0.744], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.243, 0.757], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.333, 0.667], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.247, 0.753], dtype=float32), [0.0, 1.0])\n",
      "(array([0.185, 0.815], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.347, 0.653], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [0.0, 1.0])\n",
      "(array([0.754, 0.246], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.347, 0.653], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [1.0, 0.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.367, 0.633], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.287, 0.713], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.78, 0.22], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.817, 0.183], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [0.0, 1.0])\n",
      "(array([0.769, 0.231], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.296, 0.704], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.225, 0.775], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.858, 0.142], dtype=float32), [1.0, 0.0])\n",
      "(array([0.9, 0.1], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.215, 0.785], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.224, 0.776], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.141, 0.859], dtype=float32), [1.0, 0.0])\n",
      "(array([0.233, 0.767], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [1.0, 0.0])\n",
      "(array([0.33, 0.67], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.347, 0.653], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.354, 0.646], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.794, 0.206], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.262, 0.738], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.277, 0.723], dtype=float32), [0.0, 1.0])\n",
      "(array([0.147, 0.853], dtype=float32), [1.0, 0.0])\n",
      "(array([0.274, 0.726], dtype=float32), [1.0, 0.0])\n",
      "(array([0.367, 0.633], dtype=float32), [1.0, 0.0])\n",
      "(array([0.116, 0.884], dtype=float32), [1.0, 0.0])\n",
      "(array([0.218, 0.782], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.158, 0.842], dtype=float32), [0.0, 1.0])\n",
      "(array([0.264, 0.736], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.348, 0.652], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.733, 0.267], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.369, 0.631], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.367, 0.633], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.317, 0.683], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.217, 0.783], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.731, 0.269], dtype=float32), [0.0, 1.0])\n",
      "(array([0.76, 0.24], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.335, 0.665], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.796, 0.204], dtype=float32), [0.0, 1.0])\n",
      "(array([0.786, 0.214], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [1.0, 0.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.272, 0.728], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.236, 0.764], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.387, 0.613], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [0.0, 1.0])\n",
      "(array([0.816, 0.184], dtype=float32), [1.0, 0.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.769, 0.231], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.721, 0.279], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.361, 0.639], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.112, 0.888], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.329, 0.671], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.739, 0.261], dtype=float32), [1.0, 0.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.285, 0.715], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.273, 0.727], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.216, 0.784], dtype=float32), [0.0, 1.0])\n",
      "(array([0.194, 0.806], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [1.0, 0.0])\n",
      "(array([0.219, 0.781], dtype=float32), [0.0, 1.0])\n",
      "(array([0.177, 0.823], dtype=float32), [1.0, 0.0])\n",
      "(array([0.281, 0.719], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.284, 0.716], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.241, 0.759], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [0.0, 1.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [0.0, 1.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.765, 0.235], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.75, 0.25], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.23, 0.77], dtype=float32), [0.0, 1.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.259, 0.741], dtype=float32), [0.0, 1.0])\n",
      "(array([0.285, 0.715], dtype=float32), [0.0, 1.0])\n",
      "(array([0.749, 0.251], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.304, 0.696], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.199, 0.801], dtype=float32), [0.0, 1.0])\n",
      "(array([0.244, 0.756], dtype=float32), [0.0, 1.0])\n",
      "(array([0.275, 0.725], dtype=float32), [1.0, 0.0])\n",
      "(array([0.185, 0.815], dtype=float32), [1.0, 0.0])\n",
      "(array([0.194, 0.806], dtype=float32), [0.0, 1.0])\n",
      "(array([0.179, 0.821], dtype=float32), [1.0, 0.0])\n",
      "(array([0.221, 0.779], dtype=float32), [1.0, 0.0])\n",
      "(array([0.232, 0.768], dtype=float32), [1.0, 0.0])\n",
      "(array([0.193, 0.807], dtype=float32), [0.0, 1.0])\n",
      "(array([0.251, 0.749], dtype=float32), [0.0, 1.0])\n",
      "(array([0.232, 0.768], dtype=float32), [1.0, 0.0])\n",
      "(array([0.231, 0.769], dtype=float32), [1.0, 0.0])\n",
      "(array([0.245, 0.755], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.27, 0.73], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.29, 0.71], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.188, 0.812], dtype=float32), [1.0, 0.0])\n",
      "(array([0.256, 0.744], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.158, 0.842], dtype=float32), [0.0, 1.0])\n",
      "(array([0.311, 0.689], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.792, 0.208], dtype=float32), [1.0, 0.0])\n",
      "(array([0.787, 0.213], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.119, 0.881], dtype=float32), [0.0, 1.0])\n",
      "(array([0.138, 0.862], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.289, 0.711], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.28, 0.72], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.738, 0.262], dtype=float32), [0.0, 1.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.762, 0.238], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.235, 0.765], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.739, 0.261], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [0.0, 1.0])\n",
      "(array([0.768, 0.232], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.719, 0.281], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.872, 0.128], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.688, 0.312], dtype=float32), [0.0, 1.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [1.0, 0.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.283, 0.717], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.266, 0.734], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.293, 0.707], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.276, 0.724], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.367, 0.633], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.109, 0.891], dtype=float32), [1.0, 0.0])\n",
      "(array([0.731, 0.269], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.375, 0.625], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.277, 0.723], dtype=float32), [0.0, 1.0])\n",
      "(array([0.284, 0.716], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.223, 0.777], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [0.0, 1.0])\n",
      "(array([0.807, 0.193], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.339, 0.661], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.186, 0.814], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.314, 0.686], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.217, 0.783], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.186, 0.814], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.767, 0.233], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.234, 0.766], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.283, 0.717], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.821, 0.179], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.721, 0.279], dtype=float32), [1.0, 0.0])\n",
      "(array([0.767, 0.233], dtype=float32), [1.0, 0.0])\n",
      "(array([0.78, 0.22], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.218, 0.782], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [1.0, 0.0])\n",
      "(array([0.272, 0.728], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.273, 0.727], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [1.0, 0.0])\n",
      "(array([0.353, 0.647], dtype=float32), [1.0, 0.0])\n",
      "(array([0.321, 0.679], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.224, 0.776], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.261, 0.739], dtype=float32), [0.0, 1.0])\n",
      "(array([0.27, 0.73], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.243, 0.757], dtype=float32), [1.0, 0.0])\n",
      "(array([0.334, 0.666], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.823, 0.177], dtype=float32), [1.0, 0.0])\n",
      "(array([0.774, 0.226], dtype=float32), [1.0, 0.0])\n",
      "(array([0.831, 0.169], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.895, 0.105], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.367, 0.633], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.314, 0.686], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.226, 0.774], dtype=float32), [0.0, 1.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.282, 0.718], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.732, 0.268], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.355, 0.645], dtype=float32), [1.0, 0.0])\n",
      "(array([0.769, 0.231], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.804, 0.196], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.776, 0.224], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.858, 0.142], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.788, 0.212], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.237, 0.763], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.701, 0.299], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.278, 0.722], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.739, 0.261], dtype=float32), [1.0, 0.0])\n",
      "(array([0.723, 0.277], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.288, 0.712], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.253, 0.747], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.723, 0.277], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.272, 0.728], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.757, 0.243], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.331, 0.669], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.771, 0.229], dtype=float32), [0.0, 1.0])\n",
      "(array([0.858, 0.142], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.08, 0.92], dtype=float32), [0.0, 1.0])\n",
      "(array([0.296, 0.704], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.24, 0.76], dtype=float32), [0.0, 1.0])\n",
      "(array([0.134, 0.866], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.127, 0.873], dtype=float32), [0.0, 1.0])\n",
      "(array([0.298, 0.702], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.258, 0.742], dtype=float32), [0.0, 1.0])\n",
      "(array([0.229, 0.771], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.329, 0.671], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.346, 0.654], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.672, 0.328], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.369, 0.631], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.362, 0.638], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.238, 0.762], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.172, 0.828], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.783, 0.217], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.286, 0.714], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.079, 0.921], dtype=float32), [0.0, 1.0])\n",
      "(array([0.139, 0.861], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [1.0, 0.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.794, 0.206], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.299, 0.701], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.203, 0.797], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.342, 0.658], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.25, 0.75], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.266, 0.734], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [0.0, 1.0])\n",
      "(array([0.724, 0.276], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.323, 0.677], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.226, 0.774], dtype=float32), [0.0, 1.0])\n",
      "(array([0.287, 0.713], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.742, 0.258], dtype=float32), [1.0, 0.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.226, 0.774], dtype=float32), [0.0, 1.0])\n",
      "(array([0.31, 0.69], dtype=float32), [0.0, 1.0])\n",
      "(array([0.212, 0.788], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.681, 0.319], dtype=float32), [0.0, 1.0])\n",
      "(array([0.251, 0.749], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.257, 0.743], dtype=float32), [0.0, 1.0])\n",
      "(array([0.31, 0.69], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.156, 0.844], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.788, 0.212], dtype=float32), [1.0, 0.0])\n",
      "(array([0.774, 0.226], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.332, 0.668], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.335, 0.665], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.742, 0.258], dtype=float32), [0.0, 1.0])\n",
      "(array([0.762, 0.238], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [0.0, 1.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.748, 0.252], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.27, 0.73], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.395, 0.605], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.348, 0.652], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.271, 0.729], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.712, 0.288], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.717, 0.283], dtype=float32), [0.0, 1.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.348, 0.652], dtype=float32), [1.0, 0.0])\n",
      "(array([0.244, 0.756], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.721, 0.279], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.788, 0.212], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.313, 0.687], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.306, 0.694], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.291, 0.709], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.251, 0.749], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.693, 0.307], dtype=float32), [0.0, 1.0])\n",
      "(array([0.816, 0.184], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.163, 0.837], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.744, 0.256], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.194, 0.806], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.268, 0.732], dtype=float32), [1.0, 0.0])\n",
      "(array([0.339, 0.661], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.314, 0.686], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.3, 0.7], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.267, 0.733], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.248, 0.752], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.11, 0.89], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.367, 0.633], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.286, 0.714], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.302, 0.698], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.369, 0.631], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.709, 0.291], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.696, 0.304], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.712, 0.288], dtype=float32), [1.0, 0.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.296, 0.704], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.166, 0.834], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [0.0, 1.0])\n",
      "(array([0.84, 0.16], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.249, 0.751], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.761, 0.239], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.274, 0.726], dtype=float32), [1.0, 0.0])\n",
      "(array([0.395, 0.605], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.352, 0.648], dtype=float32), [1.0, 0.0])\n",
      "(array([0.327, 0.673], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.135, 0.865], dtype=float32), [0.0, 1.0])\n",
      "(array([0.055, 0.945], dtype=float32), [0.0, 1.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.26, 0.74], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.712, 0.288], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.733, 0.267], dtype=float32), [1.0, 0.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.361, 0.639], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.339, 0.661], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.235, 0.765], dtype=float32), [0.0, 1.0])\n",
      "(array([0.253, 0.747], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.203, 0.797], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.34, 0.66], dtype=float32), [1.0, 0.0])\n",
      "(array([0.364, 0.636], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.28, 0.72], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.325, 0.675], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.278, 0.722], dtype=float32), [0.0, 1.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.775, 0.225], dtype=float32), [1.0, 0.0])\n",
      "(array([0.767, 0.233], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [0.0, 1.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.302, 0.698], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.741, 0.259], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.341, 0.659], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.782, 0.218], dtype=float32), [1.0, 0.0])\n",
      "(array([0.763, 0.237], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.195, 0.805], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.739, 0.261], dtype=float32), [1.0, 0.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.767, 0.233], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.912, 0.088], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.73, 0.27], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.743, 0.257], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.22, 0.78], dtype=float32), [1.0, 0.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.221, 0.779], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.21, 0.79], dtype=float32), [0.0, 1.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.15, 0.85], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.307, 0.693], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.214, 0.786], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.269, 0.731], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.712, 0.288], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.767, 0.233], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.21, 0.79], dtype=float32), [0.0, 1.0])\n",
      "(array([0.284, 0.716], dtype=float32), [1.0, 0.0])\n",
      "(array([0.253, 0.747], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.726, 0.274], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.287, 0.713], dtype=float32), [1.0, 0.0])\n",
      "(array([0.249, 0.751], dtype=float32), [0.0, 1.0])\n",
      "(array([0.278, 0.722], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.358, 0.642], dtype=float32), [1.0, 0.0])\n",
      "(array([0.195, 0.805], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.73, 0.27], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.752, 0.248], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.824, 0.176], dtype=float32), [1.0, 0.0])\n",
      "(array([0.813, 0.187], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.823, 0.177], dtype=float32), [1.0, 0.0])\n",
      "(array([0.857, 0.143], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [0.0, 1.0])\n",
      "(array([0.747, 0.253], dtype=float32), [0.0, 1.0])\n",
      "(array([0.769, 0.231], dtype=float32), [1.0, 0.0])\n",
      "(array([0.754, 0.246], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.715, 0.285], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.726, 0.274], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.214, 0.786], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.332, 0.668], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.757, 0.243], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.759, 0.241], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.266, 0.734], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.704, 0.296], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.747, 0.253], dtype=float32), [1.0, 0.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.302, 0.698], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.749, 0.251], dtype=float32), [1.0, 0.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [0.0, 1.0])\n",
      "(array([0.801, 0.199], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [0.0, 1.0])\n",
      "(array([0.699, 0.301], dtype=float32), [0.0, 1.0])\n",
      "(array([0.831, 0.169], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.824, 0.176], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.786, 0.214], dtype=float32), [1.0, 0.0])\n",
      "(array([0.795, 0.205], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.124, 0.876], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.711, 0.289], dtype=float32), [0.0, 1.0])\n",
      "(array([0.715, 0.285], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.139, 0.861], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.697, 0.303], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.754, 0.246], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.7, 0.3], dtype=float32), [0.0, 1.0])\n",
      "(array([0.766, 0.234], dtype=float32), [1.0, 0.0])\n",
      "(array([0.748, 0.252], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.74, 0.26], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [0.0, 1.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.844, 0.156], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.797, 0.203], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.281, 0.719], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.747, 0.253], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.805, 0.195], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.208, 0.792], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.803, 0.197], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.153, 0.847], dtype=float32), [0.0, 1.0])\n",
      "(array([0.255, 0.745], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.739, 0.261], dtype=float32), [0.0, 1.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.703, 0.297], dtype=float32), [1.0, 0.0])\n",
      "(array([0.771, 0.229], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.771, 0.229], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.265, 0.735], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.267, 0.733], dtype=float32), [0.0, 1.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.242, 0.758], dtype=float32), [0.0, 1.0])\n",
      "(array([0.187, 0.813], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.785, 0.215], dtype=float32), [1.0, 0.0])\n",
      "(array([0.872, 0.128], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.367, 0.633], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.765, 0.235], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.761, 0.239], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.761, 0.239], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.277, 0.723], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.759, 0.241], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.774, 0.226], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.716, 0.284], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.785, 0.215], dtype=float32), [1.0, 0.0])\n",
      "(array([0.768, 0.232], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.271, 0.729], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.72, 0.28], dtype=float32), [0.0, 1.0])\n",
      "(array([0.721, 0.279], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.778, 0.222], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.338, 0.662], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.751, 0.249], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.759, 0.241], dtype=float32), [1.0, 0.0])\n",
      "(array([0.795, 0.205], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.085, 0.915], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.364, 0.636], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.27, 0.73], dtype=float32), [0.0, 1.0])\n",
      "(array([0.281, 0.719], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [1.0, 0.0])\n",
      "(array([0.375, 0.625], dtype=float32), [1.0, 0.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.745, 0.255], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.303, 0.697], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.721, 0.279], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.753, 0.247], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.725, 0.275], dtype=float32), [0.0, 1.0])\n",
      "(array([0.767, 0.233], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.736, 0.264], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.299, 0.701], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [0.0, 1.0])\n",
      "(array([0.248, 0.752], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.308, 0.692], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.307, 0.693], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.725, 0.275], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.791, 0.209], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.239, 0.761], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.715, 0.285], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.293, 0.707], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.277, 0.723], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.329, 0.671], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [1.0, 0.0])\n",
      "(array([0.256, 0.744], dtype=float32), [1.0, 0.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [1.0, 0.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.306, 0.694], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.265, 0.735], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.705, 0.295], dtype=float32), [0.0, 1.0])\n",
      "(array([0.75, 0.25], dtype=float32), [1.0, 0.0])\n",
      "(array([0.767, 0.233], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.115, 0.885], dtype=float32), [0.0, 1.0])\n",
      "(array([0.237, 0.763], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [0.0, 1.0])\n",
      "(array([0.753, 0.247], dtype=float32), [0.0, 1.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.31, 0.69], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [1.0, 0.0])\n",
      "(array([0.329, 0.671], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.881, 0.119], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.268, 0.732], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.283, 0.717], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.73, 0.27], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.746, 0.254], dtype=float32), [1.0, 0.0])\n",
      "(array([0.75, 0.25], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.338, 0.662], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.323, 0.677], dtype=float32), [1.0, 0.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.243, 0.757], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [0.0, 1.0])\n",
      "(array([0.769, 0.231], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.698, 0.302], dtype=float32), [0.0, 1.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.207, 0.793], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.789, 0.211], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.804, 0.196], dtype=float32), [1.0, 0.0])\n",
      "(array([0.795, 0.205], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [0.0, 1.0])\n",
      "(array([0.703, 0.297], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.762, 0.238], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.731, 0.269], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.29, 0.71], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.29, 0.71], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.797, 0.203], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.776, 0.224], dtype=float32), [1.0, 0.0])\n",
      "(array([0.758, 0.242], dtype=float32), [0.0, 1.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.319, 0.681], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.234, 0.766], dtype=float32), [0.0, 1.0])\n",
      "(array([0.237, 0.763], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.758, 0.242], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.798, 0.202], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.175, 0.825], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.369, 0.631], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.302, 0.698], dtype=float32), [1.0, 0.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.12, 0.88], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.819, 0.181], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.238, 0.762], dtype=float32), [0.0, 1.0])\n",
      "(array([0.209, 0.791], dtype=float32), [0.0, 1.0])\n",
      "(array([0.272, 0.728], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.246, 0.754], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.235, 0.765], dtype=float32), [0.0, 1.0])\n",
      "(array([0.266, 0.734], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.255, 0.745], dtype=float32), [0.0, 1.0])\n",
      "(array([0.267, 0.733], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.735, 0.265], dtype=float32), [0.0, 1.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [0.0, 1.0])\n",
      "(array([0.779, 0.221], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.825, 0.175], dtype=float32), [1.0, 0.0])\n",
      "(array([0.698, 0.302], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.16, 0.84], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.674, 0.326], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.164, 0.836], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.27, 0.73], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.172, 0.828], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.373, 0.627], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [1.0, 0.0])\n",
      "(array([0.343, 0.657], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [0.0, 1.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.746, 0.254], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.72, 0.28], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.179, 0.821], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.339, 0.661], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.782, 0.218], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.246, 0.754], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.819, 0.181], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.831, 0.169], dtype=float32), [1.0, 0.0])\n",
      "(array([0.745, 0.255], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.139, 0.861], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.262, 0.738], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.757, 0.243], dtype=float32), [1.0, 0.0])\n",
      "(array([0.766, 0.234], dtype=float32), [1.0, 0.0])\n",
      "(array([0.717, 0.283], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.374, 0.626], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.287, 0.713], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.886, 0.114], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.247, 0.753], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.268, 0.732], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.14, 0.86], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.744, 0.256], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.339, 0.661], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.361, 0.639], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.282, 0.718], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.329, 0.671], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [1.0, 0.0])\n",
      "(array([0.187, 0.813], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.337, 0.663], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.75, 0.25], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [0.0, 1.0])\n",
      "(array([0.804, 0.196], dtype=float32), [1.0, 0.0])\n",
      "(array([0.821, 0.179], dtype=float32), [1.0, 0.0])\n",
      "(array([0.799, 0.201], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.786, 0.214], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.801, 0.199], dtype=float32), [1.0, 0.0])\n",
      "(array([0.746, 0.254], dtype=float32), [1.0, 0.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.08, 0.92], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [1.0, 0.0])\n",
      "(array([0.139, 0.861], dtype=float32), [0.0, 1.0])\n",
      "(array([0.269, 0.731], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [1.0, 0.0])\n",
      "(array([0.239, 0.761], dtype=float32), [1.0, 0.0])\n",
      "(array([0.153, 0.847], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.703, 0.297], dtype=float32), [1.0, 0.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.265, 0.735], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.219, 0.781], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.278, 0.722], dtype=float32), [1.0, 0.0])\n",
      "(array([0.25, 0.75], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [1.0, 0.0])\n",
      "(array([0.163, 0.837], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [1.0, 0.0])\n",
      "(array([0.292, 0.708], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.387, 0.613], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.333, 0.667], dtype=float32), [0.0, 1.0])\n",
      "(array([0.304, 0.696], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.307, 0.693], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.223, 0.777], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.31, 0.69], dtype=float32), [1.0, 0.0])\n",
      "(array([0.254, 0.746], dtype=float32), [1.0, 0.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.398, 0.602], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.718, 0.282], dtype=float32), [1.0, 0.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.207, 0.793], dtype=float32), [0.0, 1.0])\n",
      "(array([0.29, 0.71], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.78, 0.22], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [1.0, 0.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.273, 0.727], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.747, 0.253], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.734, 0.266], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.314, 0.686], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.247, 0.753], dtype=float32), [0.0, 1.0])\n",
      "(array([0.319, 0.681], dtype=float32), [1.0, 0.0])\n",
      "(array([0.292, 0.708], dtype=float32), [0.0, 1.0])\n",
      "(array([0.271, 0.729], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.7, 0.3], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.799, 0.201], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.757, 0.243], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.782, 0.218], dtype=float32), [1.0, 0.0])\n",
      "(array([0.827, 0.173], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.782, 0.218], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.731, 0.269], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [0.0, 1.0])\n",
      "(array([0.726, 0.274], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.367, 0.633], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.736, 0.264], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [1.0, 0.0])\n",
      "(array([0.247, 0.753], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.718, 0.282], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [0.0, 1.0])\n",
      "(array([0.742, 0.258], dtype=float32), [1.0, 0.0])\n",
      "(array([0.692, 0.308], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.784, 0.216], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.759, 0.241], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.268, 0.732], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [1.0, 0.0])\n",
      "(array([0.269, 0.731], dtype=float32), [0.0, 1.0])\n",
      "(array([0.286, 0.714], dtype=float32), [0.0, 1.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [1.0, 0.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.228, 0.772], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.253, 0.747], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.296, 0.704], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.317, 0.683], dtype=float32), [0.0, 1.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.34, 0.66], dtype=float32), [1.0, 0.0])\n",
      "(array([0.307, 0.693], dtype=float32), [1.0, 0.0])\n",
      "(array([0.304, 0.696], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.121, 0.879], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [1.0, 0.0])\n",
      "(array([0.179, 0.821], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.796, 0.204], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.357, 0.643], dtype=float32), [0.0, 1.0])\n",
      "(array([0.298, 0.702], dtype=float32), [1.0, 0.0])\n",
      "(array([0.259, 0.741], dtype=float32), [1.0, 0.0])\n",
      "(array([0.196, 0.804], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.12, 0.88], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.34, 0.66], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.369, 0.631], dtype=float32), [0.0, 1.0])\n",
      "(array([0.268, 0.732], dtype=float32), [0.0, 1.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.198, 0.802], dtype=float32), [0.0, 1.0])\n",
      "(array([0.22, 0.78], dtype=float32), [0.0, 1.0])\n",
      "(array([0.174, 0.826], dtype=float32), [0.0, 1.0])\n",
      "(array([0.131, 0.869], dtype=float32), [0.0, 1.0])\n",
      "(array([0.046, 0.954], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.726, 0.274], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.745, 0.255], dtype=float32), [1.0, 0.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.326, 0.674], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.174, 0.826], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [0.0, 1.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.776, 0.224], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.748, 0.252], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [0.0, 1.0])\n",
      "(array([0.22, 0.78], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.353, 0.647], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.812, 0.188], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.313, 0.687], dtype=float32), [0.0, 1.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.278, 0.722], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.883, 0.117], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.313, 0.687], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.796, 0.204], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [1.0, 0.0])\n",
      "(array([0.316, 0.684], dtype=float32), [0.0, 1.0])\n",
      "(array([0.246, 0.754], dtype=float32), [0.0, 1.0])\n",
      "(array([0.327, 0.673], dtype=float32), [0.0, 1.0])\n",
      "(array([0.269, 0.731], dtype=float32), [0.0, 1.0])\n",
      "(array([0.276, 0.724], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.267, 0.733], dtype=float32), [0.0, 1.0])\n",
      "(array([0.097, 0.903], dtype=float32), [0.0, 1.0])\n",
      "(array([0.278, 0.722], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.714, 0.286], dtype=float32), [0.0, 1.0])\n",
      "(array([0.849, 0.151], dtype=float32), [1.0, 0.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.28, 0.72], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.314, 0.686], dtype=float32), [1.0, 0.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.172, 0.828], dtype=float32), [0.0, 1.0])\n",
      "(array([0.245, 0.755], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.231, 0.769], dtype=float32), [0.0, 1.0])\n",
      "(array([0.17, 0.83], dtype=float32), [0.0, 1.0])\n",
      "(array([0.112, 0.888], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.214, 0.786], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.73, 0.27], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.274, 0.726], dtype=float32), [0.0, 1.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.259, 0.741], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.279, 0.721], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.315, 0.685], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.253, 0.747], dtype=float32), [0.0, 1.0])\n",
      "(array([0.241, 0.759], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.787, 0.213], dtype=float32), [0.0, 1.0])\n",
      "(array([0.838, 0.162], dtype=float32), [1.0, 0.0])\n",
      "(array([0.737, 0.263], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.715, 0.285], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.882, 0.118], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.727, 0.273], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.151, 0.849], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.362, 0.638], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.723, 0.277], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.299, 0.701], dtype=float32), [0.0, 1.0])\n",
      "(array([0.201, 0.799], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.704, 0.296], dtype=float32), [0.0, 1.0])\n",
      "(array([0.748, 0.252], dtype=float32), [1.0, 0.0])\n",
      "(array([0.707, 0.293], dtype=float32), [0.0, 1.0])\n",
      "(array([0.807, 0.193], dtype=float32), [0.0, 1.0])\n",
      "(array([0.79, 0.21], dtype=float32), [0.0, 1.0])\n",
      "(array([0.865, 0.135], dtype=float32), [1.0, 0.0])\n",
      "(array([0.904, 0.096], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.771, 0.229], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.784, 0.216], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.276, 0.724], dtype=float32), [1.0, 0.0])\n",
      "(array([0.238, 0.762], dtype=float32), [0.0, 1.0])\n",
      "(array([0.158, 0.842], dtype=float32), [0.0, 1.0])\n",
      "(array([0.193, 0.807], dtype=float32), [0.0, 1.0])\n",
      "(array([0.306, 0.694], dtype=float32), [0.0, 1.0])\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.313, 0.687], dtype=float32), [1.0, 0.0])\n",
      "(array([0.202, 0.798], dtype=float32), [0.0, 1.0])\n",
      "(array([0.333, 0.667], dtype=float32), [1.0, 0.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.278, 0.722], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.75, 0.25], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.272, 0.728], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.766, 0.234], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.175, 0.825], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.218, 0.782], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.775, 0.225], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.762, 0.238], dtype=float32), [1.0, 0.0])\n",
      "(array([0.756, 0.244], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.225, 0.775], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.681, 0.319], dtype=float32), [0.0, 1.0])\n",
      "(array([0.745, 0.255], dtype=float32), [1.0, 0.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.721, 0.279], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.704, 0.296], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.783, 0.217], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [0.0, 1.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.327, 0.673], dtype=float32), [1.0, 0.0])\n",
      "(array([0.341, 0.659], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [1.0, 0.0])\n",
      "(array([0.276, 0.724], dtype=float32), [1.0, 0.0])\n",
      "(array([0.271, 0.729], dtype=float32), [0.0, 1.0])\n",
      "(array([0.268, 0.732], dtype=float32), [0.0, 1.0])\n",
      "(array([0.206, 0.794], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.79, 0.21], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.809, 0.191], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.288, 0.712], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.296, 0.704], dtype=float32), [0.0, 1.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.328, 0.672], dtype=float32), [1.0, 0.0])\n",
      "(array([0.234, 0.766], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.134, 0.866], dtype=float32), [0.0, 1.0])\n",
      "(array([0.233, 0.767], dtype=float32), [0.0, 1.0])\n",
      "(array([0.255, 0.745], dtype=float32), [0.0, 1.0])\n",
      "(array([0.289, 0.711], dtype=float32), [1.0, 0.0])\n",
      "(array([0.362, 0.638], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.284, 0.716], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.308, 0.692], dtype=float32), [0.0, 1.0])\n",
      "(array([0.718, 0.282], dtype=float32), [1.0, 0.0])\n",
      "(array([0.77, 0.23], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.263, 0.737], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.24, 0.76], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.27, 0.73], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.317, 0.683], dtype=float32), [1.0, 0.0])\n",
      "(array([0.346, 0.654], dtype=float32), [0.0, 1.0])\n",
      "(array([0.286, 0.714], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.336, 0.664], dtype=float32), [1.0, 0.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.353, 0.647], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.8, 0.2], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.112, 0.888], dtype=float32), [1.0, 0.0])\n",
      "(array([0.202, 0.798], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.058, 0.942], dtype=float32), [1.0, 0.0])\n",
      "(array([0.105, 0.895], dtype=float32), [1.0, 0.0])\n",
      "(array([0.17, 0.83], dtype=float32), [1.0, 0.0])\n",
      "(array([0.3, 0.7], dtype=float32), [1.0, 0.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.382, 0.618], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.271, 0.729], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.221, 0.779], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.218, 0.782], dtype=float32), [1.0, 0.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.801, 0.199], dtype=float32), [0.0, 1.0])\n",
      "(array([0.872, 0.128], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.141, 0.859], dtype=float32), [0.0, 1.0])\n",
      "(array([0.175, 0.825], dtype=float32), [1.0, 0.0])\n",
      "(array([0.095, 0.905], dtype=float32), [1.0, 0.0])\n",
      "(array([0.147, 0.853], dtype=float32), [1.0, 0.0])\n",
      "(array([0.155, 0.845], dtype=float32), [0.0, 1.0])\n",
      "(array([0.12, 0.88], dtype=float32), [0.0, 1.0])\n",
      "(array([0.197, 0.803], dtype=float32), [0.0, 1.0])\n",
      "(array([0.17, 0.83], dtype=float32), [0.0, 1.0])\n",
      "(array([0.233, 0.767], dtype=float32), [0.0, 1.0])\n",
      "(array([0.243, 0.757], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [1.0, 0.0])\n",
      "(array([0.175, 0.825], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [1.0, 0.0])\n",
      "(array([0.165, 0.835], dtype=float32), [0.0, 1.0])\n",
      "(array([0.253, 0.747], dtype=float32), [1.0, 0.0])\n",
      "(array([0.26, 0.74], dtype=float32), [0.0, 1.0])\n",
      "(array([0.241, 0.759], dtype=float32), [1.0, 0.0])\n",
      "(array([0.267, 0.733], dtype=float32), [0.0, 1.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.22, 0.78], dtype=float32), [0.0, 1.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.202, 0.798], dtype=float32), [1.0, 0.0])\n",
      "(array([0.258, 0.742], dtype=float32), [1.0, 0.0])\n",
      "(array([0.315, 0.685], dtype=float32), [1.0, 0.0])\n",
      "(array([0.207, 0.793], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.328, 0.672], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.263, 0.737], dtype=float32), [0.0, 1.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.379, 0.621], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.767, 0.233], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.206, 0.794], dtype=float32), [1.0, 0.0])\n",
      "(array([0.721, 0.279], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.347, 0.653], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [0.0, 1.0])\n",
      "(array([0.82, 0.18], dtype=float32), [1.0, 0.0])\n",
      "(array([0.75, 0.25], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.763, 0.237], dtype=float32), [1.0, 0.0])\n",
      "(array([0.29, 0.71], dtype=float32), [1.0, 0.0])\n",
      "(array([0.225, 0.775], dtype=float32), [0.0, 1.0])\n",
      "(array([0.284, 0.716], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [1.0, 0.0])\n",
      "(array([0.211, 0.789], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.135, 0.865], dtype=float32), [0.0, 1.0])\n",
      "(array([0.208, 0.792], dtype=float32), [1.0, 0.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.293, 0.707], dtype=float32), [0.0, 1.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [0.0, 1.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.725, 0.275], dtype=float32), [1.0, 0.0])\n",
      "(array([0.738, 0.262], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.854, 0.146], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.749, 0.251], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [1.0, 0.0])\n",
      "(array([0.232, 0.768], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.177, 0.823], dtype=float32), [0.0, 1.0])\n",
      "(array([0.41, 0.59], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.302, 0.698], dtype=float32), [0.0, 1.0])\n",
      "(array([0.344, 0.656], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [0.0, 1.0])\n",
      "(array([0.715, 0.285], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.718, 0.282], dtype=float32), [1.0, 0.0])\n",
      "(array([0.796, 0.204], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.254, 0.746], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [0.0, 1.0])\n",
      "(array([0.741, 0.259], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.798, 0.202], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.092, 0.908], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.175, 0.825], dtype=float32), [0.0, 1.0])\n",
      "(array([0.19, 0.81], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.709, 0.291], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.852, 0.148], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.357, 0.643], dtype=float32), [1.0, 0.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.26, 0.74], dtype=float32), [1.0, 0.0])\n",
      "(array([0.381, 0.619], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.331, 0.669], dtype=float32), [0.0, 1.0])\n",
      "(array([0.273, 0.727], dtype=float32), [0.0, 1.0])\n",
      "(array([0.187, 0.813], dtype=float32), [0.0, 1.0])\n",
      "(array([0.263, 0.737], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.271, 0.729], dtype=float32), [0.0, 1.0])\n",
      "(array([0.31, 0.69], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.313, 0.687], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.733, 0.267], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.305, 0.695], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.198, 0.802], dtype=float32), [0.0, 1.0])\n",
      "(array([0.267, 0.733], dtype=float32), [1.0, 0.0])\n",
      "(array([0.748, 0.252], dtype=float32), [1.0, 0.0])\n",
      "(array([0.816, 0.184], dtype=float32), [0.0, 1.0])\n",
      "(array([0.681, 0.319], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.727, 0.273], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.236, 0.764], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.857, 0.143], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.772, 0.228], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [0.0, 1.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.731, 0.269], dtype=float32), [1.0, 0.0])\n",
      "(array([0.742, 0.258], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.286, 0.714], dtype=float32), [0.0, 1.0])\n",
      "(array([0.34, 0.66], dtype=float32), [0.0, 1.0])\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.74, 0.26], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.693, 0.307], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.228, 0.772], dtype=float32), [1.0, 0.0])\n",
      "(array([0.807, 0.193], dtype=float32), [1.0, 0.0])\n",
      "(array([0.75, 0.25], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.672, 0.328], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [0.0, 1.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.276, 0.724], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.335, 0.665], dtype=float32), [0.0, 1.0])\n",
      "(array([0.197, 0.803], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.322, 0.678], dtype=float32), [0.0, 1.0])\n",
      "(array([0.155, 0.845], dtype=float32), [0.0, 1.0])\n",
      "(array([0.288, 0.712], dtype=float32), [1.0, 0.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.277, 0.723], dtype=float32), [0.0, 1.0])\n",
      "(array([0.34, 0.66], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.184, 0.816], dtype=float32), [0.0, 1.0])\n",
      "(array([0.24, 0.76], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.739, 0.261], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.72, 0.28], dtype=float32), [0.0, 1.0])\n",
      "(array([0.771, 0.229], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.244, 0.756], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.705, 0.295], dtype=float32), [0.0, 1.0])\n",
      "(array([0.751, 0.249], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.776, 0.224], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.279, 0.721], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.348, 0.652], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [1.0, 0.0])\n",
      "(array([0.269, 0.731], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.797, 0.203], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.392, 0.608], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [0.0, 1.0])\n",
      "(array([0.765, 0.235], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.758, 0.242], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.763, 0.237], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.274, 0.726], dtype=float32), [1.0, 0.0])\n",
      "(array([0.204, 0.796], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.38, 0.62], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [0.0, 1.0])\n",
      "(array([0.811, 0.189], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.79, 0.21], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.721, 0.279], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [0.0, 1.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.812, 0.188], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.719, 0.281], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.235, 0.765], dtype=float32), [0.0, 1.0])\n",
      "(array([0.316, 0.684], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.647, 0.353], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.763, 0.237], dtype=float32), [1.0, 0.0])\n",
      "(array([0.162, 0.838], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.79, 0.21], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.75, 0.25], dtype=float32), [1.0, 0.0])\n",
      "(array([0.712, 0.288], dtype=float32), [1.0, 0.0])\n",
      "(array([0.755, 0.245], dtype=float32), [0.0, 1.0])\n",
      "(array([0.885, 0.115], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.74, 0.26], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.3, 0.7], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [1.0, 0.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.86, 0.14], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [0.0, 1.0])\n",
      "(array([0.759, 0.241], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.354, 0.646], dtype=float32), [1.0, 0.0])\n",
      "(array([0.259, 0.741], dtype=float32), [0.0, 1.0])\n",
      "(array([0.278, 0.722], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.307, 0.693], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.299, 0.701], dtype=float32), [0.0, 1.0])\n",
      "(array([0.314, 0.686], dtype=float32), [1.0, 0.0])\n",
      "(array([0.192, 0.808], dtype=float32), [0.0, 1.0])\n",
      "(array([0.289, 0.711], dtype=float32), [1.0, 0.0])\n",
      "(array([0.298, 0.702], dtype=float32), [0.0, 1.0])\n",
      "(array([0.15, 0.85], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.829, 0.171], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [0.0, 1.0])\n",
      "(array([0.806, 0.194], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.798, 0.202], dtype=float32), [1.0, 0.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.319, 0.681], dtype=float32), [0.0, 1.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.311, 0.689], dtype=float32), [1.0, 0.0])\n",
      "(array([0.139, 0.861], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.736, 0.264], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.706, 0.294], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.298, 0.702], dtype=float32), [0.0, 1.0])\n",
      "(array([0.392, 0.608], dtype=float32), [1.0, 0.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.26, 0.74], dtype=float32), [0.0, 1.0])\n",
      "(array([0.105, 0.895], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.233, 0.767], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.773, 0.227], dtype=float32), [1.0, 0.0])\n",
      "(array([0.718, 0.282], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.757, 0.243], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.823, 0.177], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.075, 0.925], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.807, 0.193], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [0.0, 1.0])\n",
      "(array([0.816, 0.184], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.164, 0.836], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.245, 0.755], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.228, 0.772], dtype=float32), [0.0, 1.0])\n",
      "(array([0.131, 0.869], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.329, 0.671], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.785, 0.215], dtype=float32), [1.0, 0.0])\n",
      "(array([0.712, 0.288], dtype=float32), [0.0, 1.0])\n",
      "(array([0.815, 0.185], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.716, 0.284], dtype=float32), [0.0, 1.0])\n",
      "(array([0.781, 0.219], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.851, 0.149], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.747, 0.253], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.875, 0.125], dtype=float32), [1.0, 0.0])\n",
      "(array([0.721, 0.279], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.361, 0.639], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [1.0, 0.0])\n",
      "(array([0.301, 0.699], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [1.0, 0.0])\n",
      "(array([0.303, 0.697], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.757, 0.243], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.17, 0.83], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.798, 0.202], dtype=float32), [0.0, 1.0])\n",
      "(array([0.776, 0.224], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.294, 0.706], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.768, 0.232], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.235, 0.765], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.645, 0.355], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.717, 0.283], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.762, 0.238], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.74, 0.26], dtype=float32), [1.0, 0.0])\n",
      "(array([0.74, 0.26], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.771, 0.229], dtype=float32), [1.0, 0.0])\n",
      "(array([0.825, 0.175], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.332, 0.668], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.659, 0.341], dtype=float32), [0.0, 1.0])\n",
      "(array([0.783, 0.217], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.202, 0.798], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.348, 0.652], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.231, 0.769], dtype=float32), [1.0, 0.0])\n",
      "(array([0.152, 0.848], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.279, 0.721], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.274, 0.726], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.701, 0.299], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.749, 0.251], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.344, 0.656], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.754, 0.246], dtype=float32), [1.0, 0.0])\n",
      "(array([0.798, 0.202], dtype=float32), [0.0, 1.0])\n",
      "(array([0.74, 0.26], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.801, 0.199], dtype=float32), [1.0, 0.0])\n",
      "(array([0.766, 0.234], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [0.0, 1.0])\n",
      "(array([0.791, 0.209], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.639, 0.361], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [0.0, 1.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [0.0, 1.0])\n",
      "(array([0.785, 0.215], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.811, 0.189], dtype=float32), [1.0, 0.0])\n",
      "(array([0.789, 0.211], dtype=float32), [1.0, 0.0])\n",
      "(array([0.717, 0.283], dtype=float32), [0.0, 1.0])\n",
      "(array([0.819, 0.181], dtype=float32), [1.0, 0.0])\n",
      "(array([0.319, 0.681], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.231, 0.769], dtype=float32), [0.0, 1.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.39, 0.61], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.203, 0.797], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.236, 0.764], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.337, 0.663], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.39, 0.61], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.903, 0.097], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.784, 0.216], dtype=float32), [1.0, 0.0])\n",
      "(array([0.835, 0.165], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.765, 0.235], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.403, 0.597], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [1.0, 0.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.212, 0.788], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.41, 0.59], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.746, 0.254], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.805, 0.195], dtype=float32), [1.0, 0.0])\n",
      "(array([0.82, 0.18], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.829, 0.171], dtype=float32), [1.0, 0.0])\n",
      "(array([0.828, 0.172], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.358, 0.642], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [0.0, 1.0])\n",
      "(array([0.765, 0.235], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.453, 0.547], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.248, 0.752], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [0.0, 1.0])\n",
      "(array([0.715, 0.285], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [0.0, 1.0])\n",
      "(array([0.731, 0.269], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.752, 0.248], dtype=float32), [1.0, 0.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.267, 0.733], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.732, 0.268], dtype=float32), [1.0, 0.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.206, 0.794], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.726, 0.274], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.334, 0.666], dtype=float32), [0.0, 1.0])\n",
      "(array([0.339, 0.661], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.397, 0.603], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [0.0, 1.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [0.0, 1.0])\n",
      "(array([0.736, 0.264], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.214, 0.786], dtype=float32), [1.0, 0.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.829, 0.171], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [0.0, 1.0])\n",
      "(array([0.731, 0.269], dtype=float32), [0.0, 1.0])\n",
      "(array([0.074, 0.926], dtype=float32), [0.0, 1.0])\n",
      "(array([0.021, 0.979], dtype=float32), [0.0, 1.0])\n",
      "(array([0.095, 0.905], dtype=float32), [1.0, 0.0])\n",
      "(array([0.147, 0.853], dtype=float32), [0.0, 1.0])\n",
      "(array([0.208, 0.792], dtype=float32), [0.0, 1.0])\n",
      "(array([0.173, 0.827], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.823, 0.177], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.45, 0.55], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.713, 0.287], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [0.0, 1.0])\n",
      "(array([0.223, 0.777], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.647, 0.353], dtype=float32), [0.0, 1.0])\n",
      "(array([0.789, 0.211], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.693, 0.307], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [1.0, 0.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [0.0, 1.0])\n",
      "(array([0.167, 0.833], dtype=float32), [0.0, 1.0])\n",
      "(array([0.174, 0.826], dtype=float32), [0.0, 1.0])\n",
      "(array([0.079, 0.921], dtype=float32), [0.0, 1.0])\n",
      "(array([0.065, 0.935], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.196, 0.804], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.296, 0.704], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.749, 0.251], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.354, 0.646], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.292, 0.708], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.443, 0.557], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.038, 0.962], dtype=float32), [0.0, 1.0])\n",
      "(array([0.059, 0.941], dtype=float32), [0.0, 1.0])\n",
      "(array([0.12, 0.88], dtype=float32), [0.0, 1.0])\n",
      "(array([0.137, 0.863], dtype=float32), [0.0, 1.0])\n",
      "(array([0.111, 0.889], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.451, 0.549], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.411, 0.589], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.815, 0.185], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [0.0, 1.0])\n",
      "(array([0.762, 0.238], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.793, 0.207], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.324, 0.676], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.251, 0.749], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.218, 0.782], dtype=float32), [0.0, 1.0])\n",
      "(array([0.225, 0.775], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.342, 0.658], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.299, 0.701], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.368, 0.632], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.245, 0.755], dtype=float32), [0.0, 1.0])\n",
      "(array([0.357, 0.643], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.74, 0.26], dtype=float32), [1.0, 0.0])\n",
      "(array([0.75, 0.25], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.352, 0.648], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.282, 0.718], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.343, 0.657], dtype=float32), [1.0, 0.0])\n",
      "(array([0.384, 0.616], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.255, 0.745], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.819, 0.181], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.807, 0.193], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.779, 0.221], dtype=float32), [0.0, 1.0])\n",
      "(array([0.852, 0.148], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.773, 0.227], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.792, 0.208], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.853, 0.147], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.328, 0.672], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.444, 0.556], dtype=float32), [0.0, 1.0])\n",
      "(array([0.395, 0.605], dtype=float32), [0.0, 1.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.745, 0.255], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.455, 0.545], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.705, 0.295], dtype=float32), [0.0, 1.0])\n",
      "(array([0.794, 0.206], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.365, 0.635], dtype=float32), [0.0, 1.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.278, 0.722], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.793, 0.207], dtype=float32), [1.0, 0.0])\n",
      "(array([0.342, 0.658], dtype=float32), [1.0, 0.0])\n",
      "(array([0.433, 0.567], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.768, 0.232], dtype=float32), [1.0, 0.0])\n",
      "(array([0.809, 0.191], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.775, 0.225], dtype=float32), [1.0, 0.0])\n",
      "(array([0.833, 0.167], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.405, 0.595], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [1.0, 0.0])\n",
      "(array([0.764, 0.236], dtype=float32), [1.0, 0.0])\n",
      "(array([0.801, 0.199], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.732, 0.268], dtype=float32), [0.0, 1.0])\n",
      "(array([0.842, 0.158], dtype=float32), [1.0, 0.0])\n",
      "(array([0.836, 0.164], dtype=float32), [0.0, 1.0])\n",
      "(array([0.929, 0.071], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.735, 0.265], dtype=float32), [0.0, 1.0])\n",
      "(array([0.775, 0.225], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.697, 0.303], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.349, 0.651], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.448, 0.552], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.358, 0.642], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.63, 0.37], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.447, 0.553], dtype=float32), [0.0, 1.0])\n",
      "(array([0.32, 0.68], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.685, 0.315], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.757, 0.243], dtype=float32), [1.0, 0.0])\n",
      "(array([0.222, 0.778], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [0.0, 1.0])\n",
      "(array([0.755, 0.245], dtype=float32), [0.0, 1.0])\n",
      "(array([0.758, 0.242], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.486, 0.514], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.741, 0.259], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [1.0, 0.0])\n",
      "(array([0.639, 0.361], dtype=float32), [0.0, 1.0])\n",
      "(array([0.803, 0.197], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.796, 0.204], dtype=float32), [1.0, 0.0])\n",
      "(array([0.752, 0.248], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.404, 0.596], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [0.0, 1.0])\n",
      "(array([0.727, 0.273], dtype=float32), [0.0, 1.0])\n",
      "(array([0.717, 0.283], dtype=float32), [0.0, 1.0])\n",
      "(array([0.792, 0.208], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.753, 0.247], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.765, 0.235], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [0.0, 1.0])\n",
      "(array([0.755, 0.245], dtype=float32), [1.0, 0.0])\n",
      "(array([0.721, 0.279], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.4, 0.6], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.583, 0.417], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.689, 0.311], dtype=float32), [1.0, 0.0])\n",
      "(array([0.765, 0.235], dtype=float32), [1.0, 0.0])\n",
      "(array([0.708, 0.292], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.35, 0.65], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.249, 0.751], dtype=float32), [0.0, 1.0])\n",
      "(array([0.185, 0.815], dtype=float32), [0.0, 1.0])\n",
      "(array([0.832, 0.168], dtype=float32), [1.0, 0.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.736, 0.264], dtype=float32), [1.0, 0.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.561, 0.439], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.737, 0.263], dtype=float32), [0.0, 1.0])\n",
      "(array([0.256, 0.744], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.38, 0.62], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.217, 0.783], dtype=float32), [0.0, 1.0])\n",
      "(array([0.188, 0.812], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.244, 0.756], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.745, 0.255], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.643, 0.357], dtype=float32), [0.0, 1.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.749, 0.251], dtype=float32), [1.0, 0.0])\n",
      "(array([0.774, 0.226], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.779, 0.221], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.316, 0.684], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [1.0, 0.0])\n",
      "(array([0.419, 0.581], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.367, 0.633], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.415, 0.585], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.787, 0.213], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.755, 0.245], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [0.0, 1.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.766, 0.234], dtype=float32), [0.0, 1.0])\n",
      "(array([0.797, 0.203], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.699, 0.301], dtype=float32), [1.0, 0.0])\n",
      "(array([0.222, 0.778], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.676, 0.324], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.821, 0.179], dtype=float32), [1.0, 0.0])\n",
      "(array([0.746, 0.254], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.701, 0.299], dtype=float32), [0.0, 1.0])\n",
      "(array([0.803, 0.197], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.355, 0.645], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.583, 0.417], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.196, 0.804], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.401, 0.599], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [1.0, 0.0])\n",
      "(array([0.345, 0.655], dtype=float32), [0.0, 1.0])\n",
      "(array([0.131, 0.869], dtype=float32), [0.0, 1.0])\n",
      "(array([0.189, 0.811], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.085, 0.915], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.456, 0.544], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.175, 0.825], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [1.0, 0.0])\n",
      "(array([0.471, 0.529], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [1.0, 0.0])\n",
      "(array([0.476, 0.524], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.327, 0.673], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.675, 0.325], dtype=float32), [0.0, 1.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.595, 0.405], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.365, 0.635], dtype=float32), [1.0, 0.0])\n",
      "(array([0.211, 0.789], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [0.0, 1.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.712, 0.288], dtype=float32), [0.0, 1.0])\n",
      "(array([0.709, 0.291], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.7, 0.3], dtype=float32), [0.0, 1.0])\n",
      "(array([0.757, 0.243], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.126, 0.874], dtype=float32), [0.0, 1.0])\n",
      "(array([0.111, 0.889], dtype=float32), [0.0, 1.0])\n",
      "(array([0.168, 0.832], dtype=float32), [0.0, 1.0])\n",
      "(array([0.301, 0.699], dtype=float32), [1.0, 0.0])\n",
      "(array([0.191, 0.809], dtype=float32), [1.0, 0.0])\n",
      "(array([0.289, 0.711], dtype=float32), [1.0, 0.0])\n",
      "(array([0.283, 0.717], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.29, 0.71], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.23, 0.77], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.362, 0.638], dtype=float32), [1.0, 0.0])\n",
      "(array([0.447, 0.553], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.848, 0.152], dtype=float32), [1.0, 0.0])\n",
      "(array([0.37, 0.63], dtype=float32), [0.0, 1.0])\n",
      "(array([0.305, 0.695], dtype=float32), [0.0, 1.0])\n",
      "(array([0.439, 0.561], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.356, 0.644], dtype=float32), [0.0, 1.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.805, 0.195], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.777, 0.223], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.726, 0.274], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.529, 0.471], dtype=float32), [1.0, 0.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.24, 0.76], dtype=float32), [1.0, 0.0])\n",
      "(array([0.714, 0.286], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.806, 0.194], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.781, 0.219], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.786, 0.214], dtype=float32), [1.0, 0.0])\n",
      "(array([0.785, 0.215], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.403, 0.597], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.288, 0.712], dtype=float32), [1.0, 0.0])\n",
      "(array([0.275, 0.725], dtype=float32), [0.0, 1.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.376, 0.624], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.383, 0.617], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.443, 0.557], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.604, 0.396], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.832, 0.168], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.818, 0.182], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.764, 0.236], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.705, 0.295], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.864, 0.136], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.591, 0.409], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.609, 0.391], dtype=float32), [0.0, 1.0])\n",
      "(array([0.687, 0.313], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [0.0, 1.0])\n",
      "(array([0.7, 0.3], dtype=float32), [0.0, 1.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.804, 0.196], dtype=float32), [1.0, 0.0])\n",
      "(array([0.819, 0.181], dtype=float32), [1.0, 0.0])\n",
      "(array([0.791, 0.209], dtype=float32), [1.0, 0.0])\n",
      "(array([0.747, 0.253], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.805, 0.195], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.511, 0.489], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.458, 0.542], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.754, 0.246], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.745, 0.255], dtype=float32), [1.0, 0.0])\n",
      "(array([0.203, 0.797], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.775, 0.225], dtype=float32), [1.0, 0.0])\n",
      "(array([0.81, 0.19], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.559, 0.441], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.297, 0.703], dtype=float32), [0.0, 1.0])\n",
      "(array([0.236, 0.764], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.754, 0.246], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.435, 0.565], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [1.0, 0.0])\n",
      "(array([0.703, 0.297], dtype=float32), [1.0, 0.0])\n",
      "(array([0.596, 0.404], dtype=float32), [0.0, 1.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.597, 0.403], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.607, 0.393], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.656, 0.344], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.58, 0.42], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.588, 0.412], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.765, 0.235], dtype=float32), [1.0, 0.0])\n",
      "(array([0.765, 0.235], dtype=float32), [0.0, 1.0])\n",
      "(array([0.767, 0.233], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.771, 0.229], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [0.0, 1.0])\n",
      "(array([0.718, 0.282], dtype=float32), [1.0, 0.0])\n",
      "(array([0.78, 0.22], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.599, 0.401], dtype=float32), [0.0, 1.0])\n",
      "(array([0.757, 0.243], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.412, 0.588], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [1.0, 0.0])\n",
      "(array([0.421, 0.579], dtype=float32), [1.0, 0.0])\n",
      "(array([0.311, 0.689], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.618, 0.382], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.49, 0.51], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.735, 0.265], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.279, 0.721], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.318, 0.682], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.87, 0.13], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.814, 0.186], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [1.0, 0.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.558, 0.442], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.754, 0.246], dtype=float32), [1.0, 0.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.363, 0.637], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [1.0, 0.0])\n",
      "(array([0.415, 0.585], dtype=float32), [0.0, 1.0])\n",
      "(array([0.33, 0.67], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [1.0, 0.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.708, 0.292], dtype=float32), [0.0, 1.0])\n",
      "(array([0.766, 0.234], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [1.0, 0.0])\n",
      "(array([0.774, 0.226], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.277, 0.723], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.704, 0.296], dtype=float32), [1.0, 0.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [1.0, 0.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.66, 0.34], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.433, 0.567], dtype=float32), [0.0, 1.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.618, 0.382], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [1.0, 0.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.769, 0.231], dtype=float32), [1.0, 0.0])\n",
      "(array([0.645, 0.355], dtype=float32), [0.0, 1.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.477, 0.523], dtype=float32), [1.0, 0.0])\n",
      "(array([0.541, 0.459], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [1.0, 0.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.582, 0.418], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.63, 0.37], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.304, 0.696], dtype=float32), [0.0, 1.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.418, 0.582], dtype=float32), [1.0, 0.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.389, 0.611], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.351, 0.649], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.89, 0.11], dtype=float32), [1.0, 0.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.602, 0.398], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.112, 0.888], dtype=float32), [0.0, 1.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.613, 0.387], dtype=float32), [0.0, 1.0])\n",
      "(array([0.695, 0.305], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [1.0, 0.0])\n",
      "(array([0.312, 0.688], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.406, 0.594], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.436, 0.564], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [1.0, 0.0])\n",
      "(array([0.36, 0.64], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.712, 0.288], dtype=float32), [0.0, 1.0])\n",
      "(array([0.802, 0.198], dtype=float32), [1.0, 0.0])\n",
      "(array([0.402, 0.598], dtype=float32), [0.0, 1.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.588, 0.412], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.165, 0.835], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.152, 0.848], dtype=float32), [0.0, 1.0])\n",
      "(array([0.169, 0.831], dtype=float32), [0.0, 1.0])\n",
      "(array([0.572, 0.428], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.43, 0.57], dtype=float32), [0.0, 1.0])\n",
      "(array([0.662, 0.338], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.408, 0.592], dtype=float32), [1.0, 0.0])\n",
      "(array([0.371, 0.629], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.373, 0.627], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.778, 0.222], dtype=float32), [0.0, 1.0])\n",
      "(array([0.747, 0.253], dtype=float32), [0.0, 1.0])\n",
      "(array([0.55, 0.45], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.771, 0.229], dtype=float32), [0.0, 1.0])\n",
      "(array([0.266, 0.734], dtype=float32), [0.0, 1.0])\n",
      "(array([0.345, 0.655], dtype=float32), [1.0, 0.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [1.0, 0.0])\n",
      "(array([0.359, 0.641], dtype=float32), [0.0, 1.0])\n",
      "(array([0.419, 0.581], dtype=float32), [1.0, 0.0])\n",
      "(array([0.389, 0.611], dtype=float32), [1.0, 0.0])\n",
      "(array([0.468, 0.532], dtype=float32), [1.0, 0.0])\n",
      "(array([0.377, 0.623], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.864, 0.136], dtype=float32), [0.0, 1.0])\n",
      "(array([0.871, 0.129], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [1.0, 0.0])\n",
      "(array([0.434, 0.566], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [0.0, 1.0])\n",
      "(array([0.637, 0.363], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.538, 0.462], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.862, 0.138], dtype=float32), [0.0, 1.0])\n",
      "(array([0.176, 0.824], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.762, 0.238], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.627, 0.373], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.746, 0.254], dtype=float32), [0.0, 1.0])\n",
      "(array([0.836, 0.164], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.743, 0.257], dtype=float32), [0.0, 1.0])\n",
      "(array([0.721, 0.279], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.61, 0.39], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.772, 0.228], dtype=float32), [1.0, 0.0])\n",
      "(array([0.684, 0.316], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.822, 0.178], dtype=float32), [1.0, 0.0])\n",
      "(array([0.374, 0.626], dtype=float32), [1.0, 0.0])\n",
      "(array([0.409, 0.591], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.206, 0.794], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [0.0, 1.0])\n",
      "(array([0.738, 0.262], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.7, 0.3], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.786, 0.214], dtype=float32), [0.0, 1.0])\n",
      "(array([0.796, 0.204], dtype=float32), [0.0, 1.0])\n",
      "(array([0.819, 0.181], dtype=float32), [0.0, 1.0])\n",
      "(array([0.805, 0.195], dtype=float32), [1.0, 0.0])\n",
      "(array([0.793, 0.207], dtype=float32), [1.0, 0.0])\n",
      "(array([0.637, 0.363], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.545, 0.455], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.429, 0.571], dtype=float32), [0.0, 1.0])\n",
      "(array([0.473, 0.527], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.452, 0.548], dtype=float32), [1.0, 0.0])\n",
      "(array([0.473, 0.527], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.436, 0.564], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.396, 0.604], dtype=float32), [1.0, 0.0])\n",
      "(array([0.323, 0.677], dtype=float32), [0.0, 1.0])\n",
      "(array([0.314, 0.686], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [1.0, 0.0])\n",
      "(array([0.336, 0.664], dtype=float32), [0.0, 1.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.737, 0.263], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.566, 0.434], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.653, 0.347], dtype=float32), [1.0, 0.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.381, 0.619], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.442, 0.558], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.42, 0.58], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.542, 0.458], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.57, 0.43], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [0.0, 1.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.42, 0.58], dtype=float32), [0.0, 1.0])\n",
      "(array([0.375, 0.625], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.111, 0.889], dtype=float32), [0.0, 1.0])\n",
      "(array([0.611, 0.389], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.741, 0.259], dtype=float32), [1.0, 0.0])\n",
      "(array([0.722, 0.278], dtype=float32), [1.0, 0.0])\n",
      "(array([0.678, 0.322], dtype=float32), [1.0, 0.0])\n",
      "(array([0.47, 0.53], dtype=float32), [0.0, 1.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [0.0, 1.0])\n",
      "(array([0.577, 0.423], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.742, 0.258], dtype=float32), [1.0, 0.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.441, 0.559], dtype=float32), [1.0, 0.0])\n",
      "(array([0.624, 0.376], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.496, 0.504], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.506, 0.494], dtype=float32), [0.0, 1.0])\n",
      "(array([0.591, 0.409], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.644, 0.356], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.497, 0.503], dtype=float32), [1.0, 0.0])\n",
      "(array([0.341, 0.659], dtype=float32), [0.0, 1.0])\n",
      "(array([0.493, 0.507], dtype=float32), [1.0, 0.0])\n",
      "(array([0.333, 0.667], dtype=float32), [1.0, 0.0])\n",
      "(array([0.466, 0.534], dtype=float32), [1.0, 0.0])\n",
      "(array([0.212, 0.788], dtype=float32), [0.0, 1.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.532, 0.468], dtype=float32), [0.0, 1.0])\n",
      "(array([0.484, 0.516], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.259, 0.741], dtype=float32), [0.0, 1.0])\n",
      "(array([0.85, 0.15], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [0.0, 1.0])\n",
      "(array([0.796, 0.204], dtype=float32), [1.0, 0.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.668, 0.332], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.584, 0.416], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.532, 0.468], dtype=float32), [1.0, 0.0])\n",
      "(array([0.475, 0.525], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [1.0, 0.0])\n",
      "(array([0.58, 0.42], dtype=float32), [1.0, 0.0])\n",
      "(array([0.716, 0.284], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.416, 0.584], dtype=float32), [0.0, 1.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.774, 0.226], dtype=float32), [0.0, 1.0])\n",
      "(array([0.82, 0.18], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.573, 0.427], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.665, 0.335], dtype=float32), [0.0, 1.0])\n",
      "(array([0.507, 0.493], dtype=float32), [0.0, 1.0])\n",
      "(array([0.371, 0.629], dtype=float32), [0.0, 1.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.654, 0.346], dtype=float32), [1.0, 0.0])\n",
      "(array([0.638, 0.362], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [1.0, 0.0])\n",
      "(array([0.714, 0.286], dtype=float32), [0.0, 1.0])\n",
      "(array([0.786, 0.214], dtype=float32), [1.0, 0.0])\n",
      "(array([0.746, 0.254], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.446, 0.554], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [1.0, 0.0])\n",
      "(array([0.448, 0.552], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.407, 0.593], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.776, 0.224], dtype=float32), [1.0, 0.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.292, 0.708], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [1.0, 0.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.486, 0.514], dtype=float32), [0.0, 1.0])\n",
      "(array([0.62, 0.38], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [0.0, 1.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.709, 0.291], dtype=float32), [1.0, 0.0])\n",
      "(array([0.733, 0.267], dtype=float32), [0.0, 1.0])\n",
      "(array([0.567, 0.433], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.607, 0.393], dtype=float32), [0.0, 1.0])\n",
      "(array([0.664, 0.336], dtype=float32), [0.0, 1.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.405, 0.595], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.293, 0.707], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [1.0, 0.0])\n",
      "(array([0.439, 0.561], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.507, 0.493], dtype=float32), [1.0, 0.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [0.0, 1.0])\n",
      "(array([0.424, 0.576], dtype=float32), [0.0, 1.0])\n",
      "(array([0.48, 0.52], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.79, 0.21], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.482, 0.518], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.775, 0.225], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [0.0, 1.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.398, 0.602], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.469, 0.531], dtype=float32), [0.0, 1.0])\n",
      "(array([0.325, 0.675], dtype=float32), [0.0, 1.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.495, 0.505], dtype=float32), [1.0, 0.0])\n",
      "(array([0.643, 0.357], dtype=float32), [1.0, 0.0])\n",
      "(array([0.778, 0.222], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.386, 0.614], dtype=float32), [0.0, 1.0])\n",
      "(array([0.778, 0.222], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.432, 0.568], dtype=float32), [1.0, 0.0])\n",
      "(array([0.648, 0.352], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.57, 0.43], dtype=float32), [1.0, 0.0])\n",
      "(array([0.314, 0.686], dtype=float32), [0.0, 1.0])\n",
      "(array([0.703, 0.297], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [0.0, 1.0])\n",
      "(array([0.64, 0.36], dtype=float32), [1.0, 0.0])\n",
      "(array([0.437, 0.563], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [1.0, 0.0])\n",
      "(array([0.46, 0.54], dtype=float32), [0.0, 1.0])\n",
      "(array([0.466, 0.534], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.483, 0.517], dtype=float32), [0.0, 1.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.59, 0.41], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.432, 0.568], dtype=float32), [0.0, 1.0])\n",
      "(array([0.464, 0.536], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [0.0, 1.0])\n",
      "(array([0.731, 0.269], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.626, 0.374], dtype=float32), [1.0, 0.0])\n",
      "(array([0.543, 0.457], dtype=float32), [1.0, 0.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.385, 0.615], dtype=float32), [0.0, 1.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.509, 0.491], dtype=float32), [0.0, 1.0])\n",
      "(array([0.468, 0.532], dtype=float32), [0.0, 1.0])\n",
      "(array([0.5, 0.5], dtype=float32), [0.0, 1.0])\n",
      "(array([0.581, 0.419], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [0.0, 1.0])\n",
      "(array([0.455, 0.545], dtype=float32), [0.0, 1.0])\n",
      "(array([0.633, 0.367], dtype=float32), [1.0, 0.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.724, 0.276], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.542, 0.458], dtype=float32), [1.0, 0.0])\n",
      "(array([0.551, 0.449], dtype=float32), [1.0, 0.0])\n",
      "(array([0.498, 0.502], dtype=float32), [0.0, 1.0])\n",
      "(array([0.343, 0.657], dtype=float32), [0.0, 1.0])\n",
      "(array([0.674, 0.326], dtype=float32), [1.0, 0.0])\n",
      "(array([0.417, 0.583], dtype=float32), [0.0, 1.0])\n",
      "(array([0.593, 0.407], dtype=float32), [1.0, 0.0])\n",
      "(array([0.669, 0.331], dtype=float32), [0.0, 1.0])\n",
      "(array([0.67, 0.33], dtype=float32), [0.0, 1.0])\n",
      "(array([0.523, 0.477], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.497, 0.503], dtype=float32), [0.0, 1.0])\n",
      "(array([0.673, 0.327], dtype=float32), [1.0, 0.0])\n",
      "(array([0.611, 0.389], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [0.0, 1.0])\n",
      "(array([0.499, 0.501], dtype=float32), [0.0, 1.0])\n",
      "(array([0.474, 0.526], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.488, 0.512], dtype=float32), [1.0, 0.0])\n",
      "(array([0.589, 0.411], dtype=float32), [1.0, 0.0])\n",
      "(array([0.221, 0.779], dtype=float32), [0.0, 1.0])\n",
      "(array([0.167, 0.833], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.659, 0.341], dtype=float32), [1.0, 0.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.79, 0.21], dtype=float32), [1.0, 0.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.815, 0.185], dtype=float32), [1.0, 0.0])\n",
      "(array([0.751, 0.249], dtype=float32), [1.0, 0.0])\n",
      "(array([0.617, 0.383], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [0.0, 1.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.633, 0.367], dtype=float32), [0.0, 1.0])\n",
      "(array([0.477, 0.523], dtype=float32), [0.0, 1.0])\n",
      "(array([0.494, 0.506], dtype=float32), [0.0, 1.0])\n",
      "(array([0.775, 0.225], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.526, 0.474], dtype=float32), [1.0, 0.0])\n",
      "(array([0.531, 0.469], dtype=float32), [0.0, 1.0])\n",
      "(array([0.548, 0.452], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.461, 0.539], dtype=float32), [0.0, 1.0])\n",
      "(array([0.489, 0.511], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.459, 0.541], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.508, 0.492], dtype=float32), [1.0, 0.0])\n",
      "(array([0.494, 0.506], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.66, 0.34], dtype=float32), [0.0, 1.0])\n",
      "(array([0.769, 0.231], dtype=float32), [1.0, 0.0])\n",
      "(array([0.457, 0.543], dtype=float32), [0.0, 1.0])\n",
      "(array([0.774, 0.226], dtype=float32), [1.0, 0.0])\n",
      "(array([0.806, 0.194], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [1.0, 0.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.321, 0.679], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.493, 0.507], dtype=float32), [0.0, 1.0])\n",
      "(array([0.564, 0.436], dtype=float32), [1.0, 0.0])\n",
      "(array([0.54, 0.46], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [1.0, 0.0])\n",
      "(array([0.506, 0.494], dtype=float32), [1.0, 0.0])\n",
      "(array([0.509, 0.491], dtype=float32), [1.0, 0.0])\n",
      "(array([0.423, 0.577], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.582, 0.418], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [1.0, 0.0])\n",
      "(array([0.569, 0.431], dtype=float32), [1.0, 0.0])\n",
      "(array([0.676, 0.324], dtype=float32), [1.0, 0.0])\n",
      "(array([0.571, 0.429], dtype=float32), [1.0, 0.0])\n",
      "(array([0.503, 0.497], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.751, 0.249], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [1.0, 0.0])\n",
      "(array([0.686, 0.314], dtype=float32), [0.0, 1.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.487, 0.513], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.537, 0.463], dtype=float32), [1.0, 0.0])\n",
      "(array([0.414, 0.586], dtype=float32), [0.0, 1.0])\n",
      "(array([0.445, 0.555], dtype=float32), [0.0, 1.0])\n",
      "(array([0.408, 0.592], dtype=float32), [0.0, 1.0])\n",
      "(array([0.252, 0.748], dtype=float32), [0.0, 1.0])\n",
      "(array([0.391, 0.609], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.527, 0.473], dtype=float32), [0.0, 1.0])\n",
      "(array([0.535, 0.465], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.636, 0.364], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.491, 0.509], dtype=float32), [1.0, 0.0])\n",
      "(array([0.519, 0.481], dtype=float32), [1.0, 0.0])\n",
      "(array([0.369, 0.631], dtype=float32), [0.0, 1.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.505, 0.495], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.684, 0.316], dtype=float32), [1.0, 0.0])\n",
      "(array([0.682, 0.318], dtype=float32), [0.0, 1.0])\n",
      "(array([0.719, 0.281], dtype=float32), [1.0, 0.0])\n",
      "(array([0.6, 0.4], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.661, 0.339], dtype=float32), [0.0, 1.0])\n",
      "(array([0.677, 0.323], dtype=float32), [1.0, 0.0])\n",
      "(array([0.55, 0.45], dtype=float32), [0.0, 1.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.449, 0.551], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.709, 0.291], dtype=float32), [0.0, 1.0])\n",
      "(array([0.525, 0.475], dtype=float32), [0.0, 1.0])\n",
      "(array([0.692, 0.308], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.551, 0.449], dtype=float32), [0.0, 1.0])\n",
      "(array([0.106, 0.894], dtype=float32), [0.0, 1.0])\n",
      "(array([0.478, 0.522], dtype=float32), [1.0, 0.0])\n",
      "(array([0.467, 0.533], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.69, 0.31], dtype=float32), [0.0, 1.0])\n",
      "(array([0.431, 0.569], dtype=float32), [0.0, 1.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.707, 0.293], dtype=float32), [1.0, 0.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.564, 0.436], dtype=float32), [0.0, 1.0])\n",
      "(array([0.72, 0.28], dtype=float32), [1.0, 0.0])\n",
      "(array([0.572, 0.428], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.445, 0.555], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.491, 0.509], dtype=float32), [0.0, 1.0])\n",
      "(array([0.599, 0.401], dtype=float32), [1.0, 0.0])\n",
      "(array([0.629, 0.371], dtype=float32), [0.0, 1.0])\n",
      "(array([0.513, 0.487], dtype=float32), [0.0, 1.0])\n",
      "(array([0.606, 0.394], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.612, 0.388], dtype=float32), [0.0, 1.0])\n",
      "(array([0.56, 0.44], dtype=float32), [1.0, 0.0])\n",
      "(array([0.688, 0.312], dtype=float32), [1.0, 0.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.836, 0.164], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.485, 0.515], dtype=float32), [1.0, 0.0])\n",
      "(array([0.792, 0.208], dtype=float32), [1.0, 0.0])\n",
      "(array([0.625, 0.375], dtype=float32), [1.0, 0.0])\n",
      "(array([0.614, 0.386], dtype=float32), [0.0, 1.0])\n",
      "(array([0.6, 0.4], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.609, 0.391], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.541, 0.459], dtype=float32), [1.0, 0.0])\n",
      "(array([0.382, 0.618], dtype=float32), [0.0, 1.0])\n",
      "(array([0.544, 0.456], dtype=float32), [0.0, 1.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.665, 0.335], dtype=float32), [1.0, 0.0])\n",
      "(array([0.649, 0.351], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [0.0, 1.0])\n",
      "(array([0.595, 0.405], dtype=float32), [1.0, 0.0])\n",
      "(array([0.73, 0.27], dtype=float32), [1.0, 0.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.689, 0.311], dtype=float32), [0.0, 1.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.587, 0.413], dtype=float32), [0.0, 1.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.51, 0.49], dtype=float32), [0.0, 1.0])\n",
      "(array([0.837, 0.163], dtype=float32), [1.0, 0.0])\n",
      "(array([0.77, 0.23], dtype=float32), [1.0, 0.0])\n",
      "(array([0.728, 0.272], dtype=float32), [1.0, 0.0])\n",
      "(array([0.685, 0.315], dtype=float32), [1.0, 0.0])\n",
      "(array([0.61, 0.39], dtype=float32), [1.0, 0.0])\n",
      "(array([0.695, 0.305], dtype=float32), [0.0, 1.0])\n",
      "(array([0.462, 0.538], dtype=float32), [0.0, 1.0])\n",
      "(array([0.236, 0.764], dtype=float32), [0.0, 1.0])\n",
      "(array([0.597, 0.403], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.528, 0.472], dtype=float32), [1.0, 0.0])\n",
      "(array([0.657, 0.343], dtype=float32), [1.0, 0.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.747, 0.253], dtype=float32), [0.0, 1.0])\n",
      "(array([0.694, 0.306], dtype=float32), [1.0, 0.0])\n",
      "(array([0.759, 0.241], dtype=float32), [0.0, 1.0])\n",
      "(array([0.784, 0.216], dtype=float32), [1.0, 0.0])\n",
      "(array([0.516, 0.484], dtype=float32), [0.0, 1.0])\n",
      "(array([0.765, 0.235], dtype=float32), [1.0, 0.0])\n",
      "(array([0.428, 0.572], dtype=float32), [0.0, 1.0])\n",
      "(array([0.605, 0.395], dtype=float32), [1.0, 0.0])\n",
      "(array([0.62, 0.38], dtype=float32), [0.0, 1.0])\n",
      "(array([0.536, 0.464], dtype=float32), [1.0, 0.0])\n",
      "(array([0.488, 0.512], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.517, 0.483], dtype=float32), [0.0, 1.0])\n",
      "(array([0.476, 0.524], dtype=float32), [0.0, 1.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.679, 0.321], dtype=float32), [1.0, 0.0])\n",
      "(array([0.671, 0.329], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.562, 0.438], dtype=float32), [1.0, 0.0])\n",
      "(array([0.512, 0.488], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.388, 0.612], dtype=float32), [0.0, 1.0])\n",
      "(array([0.651, 0.349], dtype=float32), [1.0, 0.0])\n",
      "(array([0.696, 0.304], dtype=float32), [1.0, 0.0])\n",
      "(array([0.539, 0.461], dtype=float32), [0.0, 1.0])\n",
      "(array([0.71, 0.29], dtype=float32), [1.0, 0.0])\n",
      "(array([0.729, 0.271], dtype=float32), [0.0, 1.0])\n",
      "(array([0.622, 0.378], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.295, 0.705], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.686, 0.314], dtype=float32), [1.0, 0.0])\n",
      "(array([0.635, 0.365], dtype=float32), [1.0, 0.0])\n",
      "(array([0.44, 0.56], dtype=float32), [0.0, 1.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.594, 0.406], dtype=float32), [1.0, 0.0])\n",
      "(array([0.573, 0.427], dtype=float32), [0.0, 1.0])\n",
      "(array([0.397, 0.603], dtype=float32), [1.0, 0.0])\n",
      "(array([0.255, 0.745], dtype=float32), [0.0, 1.0])\n",
      "(array([0.262, 0.738], dtype=float32), [1.0, 0.0])\n",
      "(array([0.187, 0.813], dtype=float32), [0.0, 1.0])\n",
      "(array([0.675, 0.325], dtype=float32), [0.0, 1.0])\n",
      "(array([0.641, 0.359], dtype=float32), [1.0, 0.0])\n",
      "(array([0.748, 0.252], dtype=float32), [1.0, 0.0])\n",
      "(array([0.888, 0.112], dtype=float32), [0.0, 1.0])\n",
      "(array([0.782, 0.218], dtype=float32), [0.0, 1.0])\n",
      "(array([0.632, 0.368], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.724, 0.276], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [0.0, 1.0])\n",
      "(array([0.698, 0.302], dtype=float32), [1.0, 0.0])\n",
      "(array([0.76, 0.24], dtype=float32), [1.0, 0.0])\n",
      "(array([0.555, 0.445], dtype=float32), [1.0, 0.0])\n",
      "(array([0.576, 0.424], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.203, 0.797], dtype=float32), [0.0, 1.0])\n",
      "(array([0.658, 0.342], dtype=float32), [1.0, 0.0])\n",
      "(array([0.821, 0.179], dtype=float32), [0.0, 1.0])\n",
      "(array([0.617, 0.383], dtype=float32), [1.0, 0.0])\n",
      "(array([0.524, 0.476], dtype=float32), [0.0, 1.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.616, 0.384], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.621, 0.379], dtype=float32), [0.0, 1.0])\n",
      "(array([0.717, 0.283], dtype=float32), [1.0, 0.0])\n",
      "(array([0.667, 0.333], dtype=float32), [1.0, 0.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.631, 0.369], dtype=float32), [1.0, 0.0])\n",
      "(array([0.691, 0.309], dtype=float32), [1.0, 0.0])\n",
      "(array([0.549, 0.451], dtype=float32), [0.0, 1.0])\n",
      "(array([0.52, 0.48], dtype=float32), [0.0, 1.0])\n",
      "(array([0.579, 0.421], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.562, 0.438], dtype=float32), [0.0, 1.0])\n",
      "(array([0.634, 0.366], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.887, 0.113], dtype=float32), [1.0, 0.0])\n",
      "(array([0.818, 0.182], dtype=float32), [1.0, 0.0])\n",
      "(array([0.716, 0.284], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [0.0, 1.0])\n",
      "(array([0.504, 0.496], dtype=float32), [0.0, 1.0])\n",
      "(array([0.557, 0.443], dtype=float32), [1.0, 0.0])\n",
      "(array([0.658, 0.342], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.598, 0.402], dtype=float32), [1.0, 0.0])\n",
      "(array([0.734, 0.266], dtype=float32), [1.0, 0.0])\n",
      "(array([0.652, 0.348], dtype=float32), [1.0, 0.0])\n",
      "(array([0.67, 0.33], dtype=float32), [1.0, 0.0])\n",
      "(array([0.565, 0.435], dtype=float32), [1.0, 0.0])\n",
      "(array([0.568, 0.432], dtype=float32), [0.0, 1.0])\n",
      "(array([0.712, 0.288], dtype=float32), [1.0, 0.0])\n",
      "(array([0.69, 0.31], dtype=float32), [1.0, 0.0])\n",
      "(array([0.608, 0.392], dtype=float32), [1.0, 0.0])\n",
      "(array([0.642, 0.358], dtype=float32), [1.0, 0.0])\n",
      "(array([0.747, 0.253], dtype=float32), [1.0, 0.0])\n",
      "(array([0.522, 0.478], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [0.0, 1.0])\n",
      "(array([0.512, 0.488], dtype=float32), [1.0, 0.0])\n",
      "(array([0.65, 0.35], dtype=float32), [1.0, 0.0])\n",
      "(array([0.601, 0.399], dtype=float32), [1.0, 0.0])\n",
      "(array([0.663, 0.337], dtype=float32), [1.0, 0.0])\n",
      "(array([0.683, 0.317], dtype=float32), [0.0, 1.0])\n",
      "(array([0.534, 0.466], dtype=float32), [1.0, 0.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.711, 0.289], dtype=float32), [1.0, 0.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.501, 0.499], dtype=float32), [0.0, 1.0])\n",
      "(array([0.472, 0.528], dtype=float32), [0.0, 1.0])\n",
      "(array([0.666, 0.334], dtype=float32), [1.0, 0.0])\n",
      "(array([0.426, 0.574], dtype=float32), [1.0, 0.0])\n",
      "(array([0.628, 0.372], dtype=float32), [0.0, 1.0])\n",
      "(array([0.683, 0.317], dtype=float32), [1.0, 0.0])\n",
      "(array([0.703, 0.297], dtype=float32), [1.0, 0.0])\n",
      "(array([0.305, 0.695], dtype=float32), [0.0, 1.0])\n",
      "(array([0.584, 0.416], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [1.0, 0.0])\n",
      "(array([0.452, 0.548], dtype=float32), [0.0, 1.0])\n",
      "(array([0.87, 0.13], dtype=float32), [1.0, 0.0])\n",
      "(array([0.613, 0.387], dtype=float32), [1.0, 0.0])\n",
      "(array([0.465, 0.535], dtype=float32), [0.0, 1.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.729, 0.271], dtype=float32), [1.0, 0.0])\n",
      "(array([0.603, 0.397], dtype=float32), [0.0, 1.0])\n",
      "(array([0.393, 0.607], dtype=float32), [0.0, 1.0])\n",
      "(array([0.742, 0.258], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.585, 0.415], dtype=float32), [1.0, 0.0])\n",
      "(array([0.533, 0.467], dtype=float32), [0.0, 1.0])\n",
      "(array([0.681, 0.319], dtype=float32), [1.0, 0.0])\n",
      "(array([0.481, 0.519], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.374, 0.626], dtype=float32), [0.0, 1.0])\n",
      "(array([0.554, 0.446], dtype=float32), [1.0, 0.0])\n",
      "(array([0.399, 0.601], dtype=float32), [0.0, 1.0])\n",
      "(array([0.586, 0.414], dtype=float32), [0.0, 1.0])\n",
      "(array([0.624, 0.376], dtype=float32), [0.0, 1.0])\n",
      "(array([0.558, 0.442], dtype=float32), [1.0, 0.0])\n",
      "(array([0.536, 0.464], dtype=float32), [0.0, 1.0])\n",
      "(array([0.502, 0.498], dtype=float32), [0.0, 1.0])\n",
      "(array([0.646, 0.354], dtype=float32), [0.0, 1.0])\n",
      "(array([0.508, 0.492], dtype=float32), [0.0, 1.0])\n",
      "(array([0.78, 0.22], dtype=float32), [1.0, 0.0])\n",
      "(array([0.546, 0.454], dtype=float32), [1.0, 0.0])\n",
      "(array([0.518, 0.482], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.495, 0.505], dtype=float32), [0.0, 1.0])\n",
      "(array([0.82, 0.18], dtype=float32), [1.0, 0.0])\n",
      "(array([0.552, 0.448], dtype=float32), [0.0, 1.0])\n",
      "(array([0.615, 0.385], dtype=float32), [1.0, 0.0])\n",
      "(array([0.743, 0.257], dtype=float32), [1.0, 0.0])\n",
      "(array([0.499, 0.501], dtype=float32), [1.0, 0.0])\n",
      "(array([0.525, 0.475], dtype=float32), [1.0, 0.0])\n",
      "(array([0.309, 0.691], dtype=float32), [0.0, 1.0])\n",
      "(array([0.372, 0.628], dtype=float32), [0.0, 1.0])\n",
      "(array([0.438, 0.562], dtype=float32), [0.0, 1.0])\n",
      "(array([0.672, 0.328], dtype=float32), [1.0, 0.0])\n",
      "(array([0.556, 0.444], dtype=float32), [1.0, 0.0])\n",
      "(array([0.577, 0.423], dtype=float32), [1.0, 0.0])\n",
      "(array([0.594, 0.406], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [0.0, 1.0])\n",
      "(array([0.519, 0.481], dtype=float32), [0.0, 1.0])\n",
      "(array([0.378, 0.622], dtype=float32), [1.0, 0.0])\n",
      "(array([0.413, 0.587], dtype=float32), [0.0, 1.0])\n",
      "(array([0.68, 0.32], dtype=float32), [1.0, 0.0])\n",
      "(array([0.623, 0.377], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.529, 0.471], dtype=float32), [0.0, 1.0])\n",
      "(array([0.366, 0.634], dtype=float32), [0.0, 1.0])\n",
      "(array([0.619, 0.381], dtype=float32), [1.0, 0.0])\n",
      "(array([0.427, 0.573], dtype=float32), [0.0, 1.0])\n",
      "(array([0.492, 0.508], dtype=float32), [1.0, 0.0])\n",
      "(array([0.364, 0.636], dtype=float32), [0.0, 1.0])\n",
      "(array([0.574, 0.426], dtype=float32), [0.0, 1.0])\n",
      "(array([0.655, 0.345], dtype=float32), [1.0, 0.0])\n",
      "(array([0.454, 0.546], dtype=float32), [0.0, 1.0])\n",
      "(array([0.479, 0.521], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [0.0, 1.0])\n",
      "(array([0.515, 0.485], dtype=float32), [0.0, 1.0])\n",
      "(array([0.553, 0.447], dtype=float32), [0.0, 1.0])\n",
      "(array([0.556, 0.444], dtype=float32), [0.0, 1.0])\n",
      "(array([0.514, 0.486], dtype=float32), [1.0, 0.0])\n",
      "(array([0.422, 0.578], dtype=float32), [0.0, 1.0])\n",
      "(array([0.521, 0.479], dtype=float32), [1.0, 0.0])\n",
      "(array([0.504, 0.496], dtype=float32), [1.0, 0.0])\n",
      "(array([0.425, 0.575], dtype=float32), [0.0, 1.0])\n",
      "(array([0.575, 0.425], dtype=float32), [0.0, 1.0])\n",
      "(array([0.874, 0.126], dtype=float32), [1.0, 0.0])\n",
      "(array([0.478, 0.522], dtype=float32), [0.0, 1.0])\n",
      "(array([0.563, 0.437], dtype=float32), [1.0, 0.0])\n",
      "(array([0.53, 0.47], dtype=float32), [0.0, 1.0])\n",
      "(array([0.654, 0.346], dtype=float32), [0.0, 1.0])\n",
      "(array([0.449, 0.551], dtype=float32), [1.0, 0.0])\n",
      "(array([0.5, 0.5], dtype=float32), [1.0, 0.0])\n",
      "(array([0.579, 0.421], dtype=float32), [1.0, 0.0])\n",
      "(array([0.747, 0.253], dtype=float32), [1.0, 0.0])\n",
      "(array([0.511, 0.489], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.56, 0.44], dtype=float32), [0.0, 1.0])\n",
      "(array([0.569, 0.431], dtype=float32), [0.0, 1.0])\n",
      "(array([0.549, 0.451], dtype=float32), [1.0, 0.0])\n",
      "(array([0.661, 0.339], dtype=float32), [1.0, 0.0])\n",
      "(array([0.666, 0.334], dtype=float32), [0.0, 1.0])\n",
      "(array([0.636, 0.364], dtype=float32), [0.0, 1.0])\n",
      "(array([0.578, 0.422], dtype=float32), [1.0, 0.0])\n",
      "(array([0.547, 0.453], dtype=float32), [1.0, 0.0])\n",
      "(array([0.245, 0.755], dtype=float32), [0.0, 1.0])\n",
      "(array([0.846, 0.154], dtype=float32), [1.0, 0.0])\n",
      "(array([0.627, 0.373], dtype=float32), [0.0, 1.0])\n",
      "(array([0.426, 0.574], dtype=float32), [0.0, 1.0])\n",
      "(array([0.592, 0.408], dtype=float32), [1.0, 0.0])\n",
      "(array([0.394, 0.606], dtype=float32), [0.0, 1.0])\n",
      "(array([0.547, 0.453], dtype=float32), [0.0, 1.0])\n",
      "(array([0.463, 0.537], dtype=float32), [0.0, 1.0])\n",
      "(array([0.702, 0.298], dtype=float32), [1.0, 0.0])\n"
     ]
    }
   ],
   "source": [
    "kerasModelResults = finalResults.dropna(subset = [\"ModelPointer\"])\n",
    "kerasModelResults = kerasModelResults.reset_index()\n",
    "index = kerasModelResults['loss'].idxmin()\n",
    "bestModel = kerasModelResults.iloc[index][\"ModelPointer\"]\n",
    "#bestPredictions = bestModel.predict(x=xWinTest)\n",
    "bestPredictions = bestModel.predict(x=xWinVal)\n",
    "for n in zip(bestPredictions.round(3), yVal.tolist()):\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.scatter(bestPredictions, yTest)\n",
    "plt.scatter(bestPredictions[:,0], yVal[:,0])\n",
    "#plt.scatter(bestPredictions[:,1], yVal[:,1])\n",
    "#plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "#pearsonr(bestPredictions[:,0], yTest[:,0])\n",
    "pearsonr(bestPredictions[:,0], yVal[:,0])\n",
    "#pearsonr(bestPredictions[:, 1], yVal[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.49433315555697577, pvalue=0.0)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.scatter(bestPredictions[:,0], yTest[:,0])\n",
    "plt.scatter(bestPredictions[:,0], yVal[:,0])\n",
    "#plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "#pearsonr(bestPredictions[:,0], yTest[:,0])\n",
    "pearsonr(bestPredictions[:,0], yVal[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resPath = \"C:\\\\Users\\RobinForMLThesis\\\\OneDrive - Hanken Svenska handelshogskolan\\\\Master's_Thesis\\\\DataAnalysis\\\\resultsPython.csv\"\n",
    "\n",
    "# finalResults = pd.DataFrame(MSEMatrix)\n",
    "# pd.DataFrame.to_csv(finalResults, resPath)\n",
    "# #pd.DataFrame.to_csv(finalResults, \"resultsPython.csv\")\n",
    "\n",
    "# MSEMatrix.tofile(resPath, sep = ',')\n",
    "\n",
    "# finalResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124 entries, 0 to 6896254\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Model type               124 non-null    object \n",
      " 1   Hidden layers            100 non-null    object \n",
      " 2   Hidden units             100 non-null    object \n",
      " 3   Activation function      100 non-null    object \n",
      " 4   Dropout                  100 non-null    object \n",
      " 5   L1                       120 non-null    object \n",
      " 6   L2                       120 non-null    object \n",
      " 7   Batch size               121 non-null    object \n",
      " 8   Optimizer                121 non-null    object \n",
      " 9   Learning rate            121 non-null    float64\n",
      " 10  Epochs                   121 non-null    object \n",
      " 11  MAE                      3 non-null      float64\n",
      " 12  MSE                      3 non-null      float64\n",
      " 13  ModelPointer             121 non-null    object \n",
      " 14  loss                     121 non-null    float64\n",
      " 15  accuracy                 121 non-null    float64\n",
      " 16  Training Time (minutes)  121 non-null    object \n",
      "dtypes: float64(5), object(12)\n",
      "memory usage: 17.4+ KB\n"
     ]
    }
   ],
   "source": [
    "MSEMatrix.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "formattedMSEMatrix = MSEMatrix.drop([\"ModelPointer\"], axis=1)\n",
    "formattedMSEMatrix = formattedMSEMatrix.sort_values(by=[\"MAE\", \"MSE\", \"loss\"], axis = 0)\n",
    "#formattedMSEMatrix[[\"L1\", \"L2\"]] = round(formattedMSEMatrix[[\"L1\", \"L2\"]], 1)\n",
    "#formattedMSEMatrix = round(formattedMSEMatrix, 1)\n",
    "\n",
    "def RobRound(x): \n",
    "    if(x==None or math.isnan(x)): return None\n",
    "    else: return np.format_float_positional(x, precision=2, unique=False, fractional=False, trim='-', min_digits=None)\n",
    "\n",
    "def RobRoundFrac(x): \n",
    "    if(x==None or math.isnan(x)): return None\n",
    "    else: return np.format_float_positional(x, precision=3, unique=False, fractional=True, min_digits=None)\n",
    "\n",
    "def RobRoundTime(x): \n",
    "    if(x==None or math.isnan(x)): return None\n",
    "    else: return np.format_float_positional(x, precision=2, unique=False, fractional=True, min_digits=None)\n",
    "\n",
    "\n",
    "\n",
    "formattedMSEMatrix[\"L1\"] = formattedMSEMatrix[\"L1\"].apply(lambda x: RobRound(x))\n",
    "formattedMSEMatrix[\"L2\"] = formattedMSEMatrix[\"L2\"].apply(lambda x: RobRound(x))\n",
    "formattedMSEMatrix[\"MSE\"] = formattedMSEMatrix[\"MSE\"].apply(lambda x: RobRoundFrac(x))\n",
    "formattedMSEMatrix[\"MAE\"] = formattedMSEMatrix[\"MAE\"].apply(lambda x: RobRoundFrac(x))\n",
    "formattedMSEMatrix[\"loss\"] = formattedMSEMatrix[\"loss\"].apply(lambda x: RobRoundFrac(x))\n",
    "formattedMSEMatrix[\"accuracy\"] = formattedMSEMatrix[\"accuracy\"].apply(lambda x: RobRoundFrac(x))\n",
    "formattedMSEMatrix[\"Learning rate\"] = formattedMSEMatrix[\"Learning rate\"].apply(lambda x: RobRound(x))\n",
    "formattedMSEMatrix[\"Training Time (minutes)\"] = formattedMSEMatrix[\"Training Time (minutes)\"].apply(lambda x: RobRoundTime(float(x)))\n",
    "\n",
    "#formattedMSEMatrix = formattedMSEMatrix.fillna(value=np.nan)\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%d-%m-%Y_%H%M\")\n",
    "modelComparisonPathHTML = \"Results//2Class//ModelComparison_\" + str(now) + \".html\"\n",
    "modelComparisonPathCSV = \"Results//2Class//ModelComparison_\" + str(now) + \".csv\"\n",
    "\n",
    "#pd.DataFrame.to_csv(MSEMatrix, \"Results/ModelComparison.csv\", index=False)\n",
    "#pd.DataFrame.to_excel(MSEMatrix, \"Results/ModelComparison.xlsx\")\n",
    "pd.DataFrame.to_html(formattedMSEMatrix, modelComparisonPathHTML, index=False)\n",
    "pd.DataFrame.to_csv(formattedMSEMatrix, modelComparisonPathCSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nan'"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.format_float_positional(np.NaN, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124 entries, 0 to 2142870\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Model type               124 non-null    object \n",
      " 1   Hidden layers            100 non-null    float64\n",
      " 2   Hidden units             100 non-null    float64\n",
      " 3   Activation function      100 non-null    object \n",
      " 4   Dropout                  100 non-null    float64\n",
      " 5   L1                       120 non-null    object \n",
      " 6   L2                       120 non-null    object \n",
      " 7   Batch size               121 non-null    float64\n",
      " 8   Optimizer                121 non-null    object \n",
      " 9   Learning rate            124 non-null    object \n",
      " 10  Epochs                   121 non-null    float64\n",
      " 11  MAE                      124 non-null    object \n",
      " 12  MSE                      124 non-null    object \n",
      " 13  loss                     124 non-null    object \n",
      " 14  accuracy                 124 non-null    object \n",
      " 15  Training Time (minutes)  124 non-null    object \n",
      "dtypes: float64(5), object(11)\n",
      "memory usage: 16.5+ KB\n"
     ]
    }
   ],
   "source": [
    "formattedMSEMatrix.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEMatrixContinuation = pd.read_csv(modelComparisonPathCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable importance\n",
    "\n",
    "\n",
    "\n",
    "# VarImpData = np.asarray(xRatioData).astype('float32')\n",
    "# VarImpData = scipy.stats.mstats.winsorize(VarImpData, limits = (0.05, 0.95))\n",
    "# VarImpData = scaler.fit_transform(VarImpData)\n",
    "\n",
    "rows = len(finalResults[\"ModelPointer\"])\n",
    "cols = len(xWinVal.columns)\n",
    "zeroedXVal = np.array(xWinVal)\n",
    "\n",
    "rows = 5\n",
    "\n",
    "#VarImpResults = pd.DataFrame(columns = X.columns)\n",
    "VarImpArray = np.empty((rows, cols), dtype=float, order='C')\n",
    "normalMSEArray = np.empty((rows, 1), dtype=float, order='C')\n",
    "\n",
    "for row in range(0, rows):\n",
    "    \n",
    "    model = finalResults[\"ModelPointer\"][row]\n",
    "\n",
    "    loss = model.evaluate(zeroedXVal, yVal, batch_size=128, verbose = 0)\n",
    "    loss = [x for x in loss]\n",
    "    normalMSE = loss[0]\n",
    "    normalMSEArray[row, 0] = normalMSE\n",
    "\n",
    "    for col in range(0, cols):\n",
    "\n",
    "        # print(\"\\n\")\n",
    "        # print(\"Model \", str(row+1), \" out of \", str(rows))\n",
    "        # print(\"Variable \", str(col+1), \" out of \", str(cols))\n",
    "\n",
    "        zeroedXVal[:,col] = 0\n",
    "        #VarImpData[col].values[:] = 0\n",
    "        loss = model.evaluate(zeroedXVal, yVal, batch_size=128, verbose = 0)\n",
    "        zeroedXVal[:,col] = np.array(xWinVal[xWinVal.columns[col]])\n",
    "\n",
    "        try:\n",
    "            loss = [x for x in loss]\n",
    "            VarImpMSE = loss[0]\n",
    "            VarImpArray[row, col] = VarImpMSE\n",
    "            print(\"Loss is %s on model %s variable %s\" % (loss, row, col))\n",
    "        except:     \n",
    "            print(\"RobError!: Loss is %s on model %s variable %s\" % (loss, row, col))\n",
    "\n",
    "\n",
    "\n",
    "VarImpResults = pd.DataFrame(VarImpArray, columns = xWinVal.columns)\n",
    "normalMSEArray = pd.DataFrame(normalMSEArray, columns = [\"AllVariables\"])\n",
    "\n",
    "VarImpResults = pd.concat([VarImpResults, normalMSEArray], axis=1)\n",
    "\n",
    "VarImpMean = VarImpResults.mean(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "variableDescriptions = pd.read_excel(\n",
    "    \"Data/CompustatVariableDescriptions/VariableDescriptions.xlsx\",\n",
    "    header=2,\n",
    "    index_col=\"N\")\n",
    "\n",
    "variableDescriptions[\"Variable Name\"] = [n.strip() for n in variableDescriptions[\"Variable Name\"]]\n",
    "\n",
    "import re\n",
    "variableDescriptions[\"ShortDescr\"] = variableDescriptions[\"Description\"].apply(lambda x : re.sub(r\".*-- \", \"\", x))\n",
    "#variableDescriptions[\"ShortDescr\"] = variableDescriptions[\"ShortDescr\"].apply(lambda x : re.sub(r\" >.*\", \"\", x))\n",
    "#variableDescriptions[\"ShortDescr\"] = variableDescriptions[\"ShortDescr\"].apply(lambda x : re.sub(r\" -.*\", \"\", x))\n",
    "\n",
    "variableDescriptions[\"ShortDescr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VarImpMean = VarImpResults.mean(axis=0)\n",
    "VarImpMeanSorted = VarImpMean.sort_values(ascending=False)\n",
    "\n",
    "VarImpMeanSorted = VarImpMeanSorted - VarImpMean[\"AllVariables\"]\n",
    "\n",
    "VarImpMeanSorted = VarImpMeanSorted.rename(\"MSE Increase\")\n",
    "VarImpMeanSorted.index = VarImpMeanSorted.index.str.upper()\n",
    "\n",
    "VarImpMeanSorted = pd.merge(\n",
    "    VarImpMeanSorted, variableDescriptions, left_index=True, right_on=\"Variable Name\")\n",
    "\n",
    "pd.DataFrame.to_html(VarImpMeanSorted, \"Results/VariableImportance8.html\", index=False)\n",
    "\n",
    "VarImpMeanBest = VarImpMeanSorted[1:25]\n",
    "# VarImpMeanScaled = VarImpMeanBest - VarImpMeanBest.mean()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(\n",
    "    #VarImpMeanBest[\"Variable Name\"], VarImpMeanBest[\"MSE Increase\"], log=True, color=\"green\")  # , height = 0.4)#, width, bottom=VarImpMean.min(), align)\n",
    "    VarImpMeanBest[\"ShortDescr\"], VarImpMeanBest[\"MSE Increase\"], log=True, color=\"green\")  # , height = 0.4)#, width, bottom=VarImpMean.min(), align)\n",
    "\n",
    "plt.gca().invert_yaxis()  # labels read top-to-bottom\n",
    "\n",
    "\n",
    "plt.title(\"Variable Importance\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.xlabel(\"MSE Increase when variable is removed\")\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%d-%m-%Y_%H%M\")\n",
    "variableImportancePath = \"Results/VariableImportance_\" + str(now) + \".png\"\n",
    "\n",
    "plt.savefig(variableImportancePath)\n",
    "# from matplotlib.ticker import ScalarFormatter\n",
    "# plt.gca().xaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "676/676 - 4s - loss: 1987.6479 - mean_absolute_error: 20.3377 - val_loss: 2673.2761 - val_mean_absolute_error: 21.5853 - 4s/epoch - 5ms/step\n",
      "Epoch 2/300\n",
      "676/676 - 2s - loss: 1984.8063 - mean_absolute_error: 20.4015 - val_loss: 2667.5227 - val_mean_absolute_error: 21.5985 - 2s/epoch - 3ms/step\n",
      "Epoch 3/300\n",
      "676/676 - 3s - loss: 1982.5377 - mean_absolute_error: 20.4730 - val_loss: 2662.2070 - val_mean_absolute_error: 21.6164 - 3s/epoch - 4ms/step\n",
      "Epoch 4/300\n",
      "676/676 - 3s - loss: 1981.9677 - mean_absolute_error: 20.4623 - val_loss: 2662.0515 - val_mean_absolute_error: 21.6161 - 3s/epoch - 4ms/step\n",
      "Epoch 5/300\n",
      "676/676 - 2s - loss: 1979.8287 - mean_absolute_error: 20.4972 - val_loss: 2655.8665 - val_mean_absolute_error: 21.6415 - 2s/epoch - 4ms/step\n",
      "Epoch 6/300\n",
      "676/676 - 3s - loss: 1979.3455 - mean_absolute_error: 20.5257 - val_loss: 2657.9641 - val_mean_absolute_error: 21.6281 - 3s/epoch - 4ms/step\n",
      "Epoch 7/300\n",
      "676/676 - 2s - loss: 1978.1211 - mean_absolute_error: 20.5215 - val_loss: 2658.6785 - val_mean_absolute_error: 21.6273 - 2s/epoch - 4ms/step\n",
      "Epoch 8/300\n",
      "676/676 - 2s - loss: 1978.1366 - mean_absolute_error: 20.5117 - val_loss: 2651.6245 - val_mean_absolute_error: 21.6651 - 2s/epoch - 4ms/step\n",
      "Epoch 9/300\n",
      "676/676 - 2s - loss: 1977.0228 - mean_absolute_error: 20.5418 - val_loss: 2654.2568 - val_mean_absolute_error: 21.6431 - 2s/epoch - 4ms/step\n",
      "Epoch 10/300\n",
      "676/676 - 3s - loss: 1973.8014 - mean_absolute_error: 20.5580 - val_loss: 2653.6514 - val_mean_absolute_error: 21.6428 - 3s/epoch - 4ms/step\n",
      "Epoch 11/300\n",
      "676/676 - 2s - loss: 1975.0682 - mean_absolute_error: 20.5449 - val_loss: 2651.3606 - val_mean_absolute_error: 21.6532 - 2s/epoch - 4ms/step\n",
      "Epoch 12/300\n",
      "676/676 - 2s - loss: 1976.0897 - mean_absolute_error: 20.5575 - val_loss: 2652.7200 - val_mean_absolute_error: 21.6480 - 2s/epoch - 4ms/step\n",
      "Epoch 13/300\n",
      "676/676 - 2s - loss: 1977.8527 - mean_absolute_error: 20.5374 - val_loss: 2654.0151 - val_mean_absolute_error: 21.6473 - 2s/epoch - 4ms/step\n",
      "Epoch 14/300\n",
      "676/676 - 2s - loss: 1976.0255 - mean_absolute_error: 20.5701 - val_loss: 2648.2317 - val_mean_absolute_error: 21.6779 - 2s/epoch - 4ms/step\n",
      "Epoch 15/300\n",
      "676/676 - 2s - loss: 1977.6957 - mean_absolute_error: 20.5917 - val_loss: 2654.2246 - val_mean_absolute_error: 21.6459 - 2s/epoch - 4ms/step\n",
      "Epoch 16/300\n",
      "676/676 - 2s - loss: 1974.1180 - mean_absolute_error: 20.5783 - val_loss: 2650.9578 - val_mean_absolute_error: 21.6555 - 2s/epoch - 4ms/step\n",
      "Epoch 17/300\n",
      "676/676 - 2s - loss: 1972.9131 - mean_absolute_error: 20.5807 - val_loss: 2643.6887 - val_mean_absolute_error: 21.7116 - 2s/epoch - 4ms/step\n",
      "Epoch 18/300\n",
      "676/676 - 2s - loss: 1972.6036 - mean_absolute_error: 20.6041 - val_loss: 2649.3169 - val_mean_absolute_error: 21.6589 - 2s/epoch - 4ms/step\n",
      "Epoch 19/300\n",
      "676/676 - 2s - loss: 1973.5887 - mean_absolute_error: 20.6004 - val_loss: 2645.6135 - val_mean_absolute_error: 21.6796 - 2s/epoch - 4ms/step\n",
      "Epoch 20/300\n",
      "676/676 - 2s - loss: 1971.9674 - mean_absolute_error: 20.6042 - val_loss: 2650.6736 - val_mean_absolute_error: 21.6484 - 2s/epoch - 4ms/step\n",
      "Epoch 21/300\n",
      "676/676 - 2s - loss: 1974.2100 - mean_absolute_error: 20.5989 - val_loss: 2652.7808 - val_mean_absolute_error: 21.6370 - 2s/epoch - 4ms/step\n",
      "Epoch 22/300\n",
      "676/676 - 2s - loss: 1974.5027 - mean_absolute_error: 20.5696 - val_loss: 2647.2686 - val_mean_absolute_error: 21.6702 - 2s/epoch - 4ms/step\n",
      "Epoch 23/300\n",
      "676/676 - 2s - loss: 1969.7526 - mean_absolute_error: 20.6127 - val_loss: 2646.8120 - val_mean_absolute_error: 21.6656 - 2s/epoch - 4ms/step\n",
      "Epoch 24/300\n",
      "676/676 - 3s - loss: 1976.3724 - mean_absolute_error: 20.5807 - val_loss: 2650.5024 - val_mean_absolute_error: 21.6461 - 3s/epoch - 4ms/step\n",
      "Epoch 25/300\n",
      "676/676 - 2s - loss: 1971.7675 - mean_absolute_error: 20.6058 - val_loss: 2655.3330 - val_mean_absolute_error: 21.6292 - 2s/epoch - 4ms/step\n",
      "Epoch 26/300\n",
      "676/676 - 3s - loss: 1974.0725 - mean_absolute_error: 20.5812 - val_loss: 2648.4028 - val_mean_absolute_error: 21.6569 - 3s/epoch - 4ms/step\n",
      "Epoch 27/300\n",
      "676/676 - 3s - loss: 1972.4622 - mean_absolute_error: 20.5879 - val_loss: 2642.6697 - val_mean_absolute_error: 21.6911 - 3s/epoch - 4ms/step\n",
      "Epoch 28/300\n",
      "676/676 - 3s - loss: 1976.0781 - mean_absolute_error: 20.5901 - val_loss: 2647.0461 - val_mean_absolute_error: 21.6681 - 3s/epoch - 4ms/step\n",
      "Epoch 29/300\n",
      "676/676 - 2s - loss: 1972.2631 - mean_absolute_error: 20.5812 - val_loss: 2644.3945 - val_mean_absolute_error: 21.6979 - 2s/epoch - 4ms/step\n",
      "Epoch 30/300\n",
      "676/676 - 2s - loss: 1969.8347 - mean_absolute_error: 20.5946 - val_loss: 2640.4136 - val_mean_absolute_error: 21.7381 - 2s/epoch - 4ms/step\n",
      "Epoch 31/300\n",
      "676/676 - 2s - loss: 1974.3885 - mean_absolute_error: 20.5893 - val_loss: 2645.9524 - val_mean_absolute_error: 21.6734 - 2s/epoch - 4ms/step\n",
      "Epoch 32/300\n",
      "676/676 - 2s - loss: 1974.5073 - mean_absolute_error: 20.5999 - val_loss: 2649.5161 - val_mean_absolute_error: 21.6485 - 2s/epoch - 4ms/step\n",
      "Epoch 33/300\n",
      "676/676 - 2s - loss: 1969.8540 - mean_absolute_error: 20.6246 - val_loss: 2647.6079 - val_mean_absolute_error: 21.6563 - 2s/epoch - 4ms/step\n",
      "Epoch 34/300\n",
      "676/676 - 2s - loss: 1974.4076 - mean_absolute_error: 20.5989 - val_loss: 2647.2344 - val_mean_absolute_error: 21.6719 - 2s/epoch - 4ms/step\n",
      "Epoch 35/300\n",
      "676/676 - 2s - loss: 1972.2134 - mean_absolute_error: 20.6028 - val_loss: 2648.1902 - val_mean_absolute_error: 21.6527 - 2s/epoch - 4ms/step\n",
      "Epoch 36/300\n",
      "676/676 - 2s - loss: 1973.4902 - mean_absolute_error: 20.5943 - val_loss: 2652.4312 - val_mean_absolute_error: 21.6381 - 2s/epoch - 4ms/step\n",
      "Epoch 37/300\n",
      "676/676 - 2s - loss: 1972.5811 - mean_absolute_error: 20.5913 - val_loss: 2646.0923 - val_mean_absolute_error: 21.6706 - 2s/epoch - 4ms/step\n",
      "Epoch 38/300\n",
      "676/676 - 2s - loss: 1972.1854 - mean_absolute_error: 20.6024 - val_loss: 2647.1611 - val_mean_absolute_error: 21.6597 - 2s/epoch - 4ms/step\n",
      "Epoch 39/300\n",
      "676/676 - 2s - loss: 1973.4158 - mean_absolute_error: 20.6047 - val_loss: 2648.0759 - val_mean_absolute_error: 21.6550 - 2s/epoch - 4ms/step\n",
      "Epoch 40/300\n",
      "676/676 - 2s - loss: 1971.2179 - mean_absolute_error: 20.5973 - val_loss: 2644.3015 - val_mean_absolute_error: 21.6893 - 2s/epoch - 4ms/step\n",
      "Epoch 41/300\n",
      "676/676 - 2s - loss: 1975.6757 - mean_absolute_error: 20.5774 - val_loss: 2640.6638 - val_mean_absolute_error: 21.7303 - 2s/epoch - 4ms/step\n",
      "Epoch 42/300\n",
      "676/676 - 2s - loss: 1973.3784 - mean_absolute_error: 20.6091 - val_loss: 2642.2986 - val_mean_absolute_error: 21.7286 - 2s/epoch - 4ms/step\n",
      "Epoch 43/300\n",
      "676/676 - 2s - loss: 1973.8505 - mean_absolute_error: 20.5945 - val_loss: 2644.5376 - val_mean_absolute_error: 21.6943 - 2s/epoch - 4ms/step\n",
      "Epoch 44/300\n",
      "676/676 - 2s - loss: 1973.0338 - mean_absolute_error: 20.5881 - val_loss: 2648.1284 - val_mean_absolute_error: 21.6584 - 2s/epoch - 4ms/step\n",
      "Epoch 45/300\n",
      "676/676 - 2s - loss: 1973.1224 - mean_absolute_error: 20.5934 - val_loss: 2645.2800 - val_mean_absolute_error: 21.6747 - 2s/epoch - 4ms/step\n",
      "Epoch 46/300\n",
      "676/676 - 2s - loss: 1969.5941 - mean_absolute_error: 20.5892 - val_loss: 2643.5286 - val_mean_absolute_error: 21.6871 - 2s/epoch - 4ms/step\n",
      "Epoch 47/300\n",
      "676/676 - 2s - loss: 1974.2815 - mean_absolute_error: 20.6016 - val_loss: 2646.0120 - val_mean_absolute_error: 21.6860 - 2s/epoch - 4ms/step\n",
      "Epoch 48/300\n",
      "676/676 - 3s - loss: 1971.5770 - mean_absolute_error: 20.6250 - val_loss: 2647.8579 - val_mean_absolute_error: 21.6630 - 3s/epoch - 4ms/step\n",
      "Epoch 49/300\n",
      "676/676 - 2s - loss: 1971.5486 - mean_absolute_error: 20.5779 - val_loss: 2641.1033 - val_mean_absolute_error: 21.7238 - 2s/epoch - 4ms/step\n",
      "Epoch 50/300\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "676/676 - 2s - loss: 1972.0717 - mean_absolute_error: 20.6363 - val_loss: 2647.7349 - val_mean_absolute_error: 21.6547 - 2s/epoch - 3ms/step\n",
      "Epoch 50: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "bestModel = keras.models.load_model('Results/BestKerasModel8')\n",
    "#plot(model)\n",
    "\n",
    "\n",
    "bestModel = tf.keras.Sequential()\n",
    "bestModel.add(tf.keras.layers.Dense(units=5, activation=\"relu\"))\n",
    "bestModel.add(tf.keras.layers.Dropout(0.3))\n",
    "bestModel.add(tf.keras.layers.Dense(units=5, activation=\"relu\"))\n",
    "bestModel.add(tf.keras.layers.Dropout(0.3))\n",
    "bestModel.add(tf.keras.layers.Dense(units=5, activation=\"relu\"))\n",
    "bestModel.add(tf.keras.layers.Dropout(0.3))\n",
    "bestModel.add(tf.keras.layers.Dense(units=5, activation=\"relu\"))\n",
    "bestModel.add(tf.keras.layers.Dropout(0.3))\n",
    "bestModel.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "\n",
    "bestModel.reset_states()\n",
    "\n",
    "\n",
    "compiledBestModel = bestModel.compile(optimizer=\"RMSprop\",  # Adam(learning_rate=0.0001) #RMSprop #sgd\n",
    "                                      loss=\"MeanSquaredError\",  # 'tf.keras.losses.MeanSquaredError()',\n",
    "                                      metrics=['MeanAbsoluteError'])\n",
    "\n",
    "bestModel.reset_states()\n",
    "\n",
    "\n",
    "\n",
    "#xTrainValiPooled = scaled_X[:validationSize,:]\n",
    "xTrainValiPooled = X.loc[split==\"Validation\", :]\n",
    "#yTrainValiPooled = Y[:validationSize]\n",
    "yTrainValiPooled = Y[split==\"Validation\"]\n",
    "history = bestModel.fit(x=xTrainValiPooled, y=yTrainValiPooled, batch_size=32,\n",
    "                        epochs=300, verbose=2, validation_data=(xWinTest, yTest), callbacks = [callback])\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now().strftime(\"%d-%m-%Y_%H%M\")\n",
    "learningCurvePath = \"Results/LearningCurve_\" + str(now) + \".png\"\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig(learningCurvePath)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize network\n",
    "\n",
    "bestModel = keras.models.load_model('Results/BestKerasModel8')\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "\n",
    "\n",
    "# from datetime import datetime\n",
    "# now = datetime.now().strftime(\"%d-%m-%Y_%H%M\")\n",
    "# learningCurvePath = \"Results/LearningCurve_\" + str(now) + \".png\"\n",
    "\n",
    "ann_viz(bestModel, view=True, filename=\"Results/BestModel8\", title=\"Best Model Visualized\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 1)                 86        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86\n",
      "Trainable params: 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bestModel = keras.models.load_model('Results/BestKerasModel7')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Print summary\n",
    "modelSummary = bestModel.summary()\n",
    "print(modelSummary)\n",
    "\n",
    "\n",
    "# from datetime import datetime\n",
    "# now = datetime.now().strftime(\"%d-%m-%Y_%H%M\")\n",
    "# learningCurvePath = \"Results/LearningCurve_\" + str(now) + \".png\"\n",
    "\n",
    "with open('Results/BestModelSummary7.html', 'w') as f:\n",
    "\n",
    "    bestModel.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "# import pydot\n",
    "# import pydotplus\n",
    "# import graphviz\n",
    "\n",
    "# tf.keras.utils.plot_model(\n",
    "#     bestModel,\n",
    "#     to_file=\"Results/BestModel.png\",\n",
    "#     show_shapes=True,\n",
    "#     show_dtype=False,\n",
    "#     show_layer_names=True,\n",
    "#     rankdir=\"LR\",\n",
    "#     expand_nested=False,\n",
    "#     dpi=96,\n",
    "#     layer_range=None,\n",
    "#     show_layer_activations=True,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "#pred = model.predict(xWinVal, batch_size=128)\n",
    "\n",
    "#plt.scatter(pred, yVal)\n",
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ynew = model.predict_classes(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Geron 2019, 76, 320)\n",
    "\n",
    "#from sklearn import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "#(Geron 2019, 76)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "scoring='neg_mean_squared_error',\n",
    "return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "\n",
    "\n",
    "grid_search.best_params_\n",
    "\n",
    "grid_search.best_estimator_\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#(Geron 2019, 320)\n",
    "\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "\n",
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "\n",
    "rnd_search_cv.best_params_\n",
    "rnd_search_cv.best_score_\n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Chollet: DL for Python\n",
    "import kerastuner as kt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#If your search process crashes, you can always restart it—just specify overwrite=False in the tuner so that it can resume from the trial logs stored on disk.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6646144ec7618d86cefdfa307b5e5ba5f5893ee78adb19daf28ba13bcfecfb8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
