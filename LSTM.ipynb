{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Dense, Flatten\n",
    "import tensorflow.python.keras.optimizers\n",
    "import tensorflow.python.keras.metrics\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "#%%capture\n",
    "data_file_path = os.path.join(os.getcwd(), \"Data\\\\returnsData.csv\")\n",
    "returnsData = pd.read_csv(data_file_path)\n",
    "#returnsData.info(verbose=True)\n",
    "longReturns = returnsData[[\"YearQuarter\", \"gvkey\", \"quarterlyReturns\"]] #\"quarterlyVolatility\",\n",
    "#longReturns.info(verbose=True)\n",
    "wideReturns = pd.pivot(longReturns, index=\"YearQuarter\", columns=\"gvkey\", values=\"quarterlyReturns\")\n",
    "#wideReturns.info(verbose=True)\n",
    "#print(wideReturns.iloc[0:10,0:10])\n",
    "\n",
    "#wideReturns[\"YearQuarter\"] = wideReturns.index\n",
    "#wideReturns[\"YQ\"] = wideReturns.index\n",
    "\n",
    "trainSize = math.floor(len(wideReturns.index) * 0.5)\n",
    "validationSize = math.floor(len(wideReturns.index) * 0.75)\n",
    "testSize = len(wideReturns.index)\n",
    "# trainSize = len(wideReturns[\"YearQuarter\"]) * 0.5\n",
    "# validationSize = len(wideReturns[\"YearQuarter\"]) * 0.75\n",
    "#wideReturns[:,\"Split\"] = \n",
    "\n",
    "\n",
    "sample_length = 10\n",
    "\n",
    "#def preprocessData(startOfSplit, endOfSplit):\n",
    "dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data=wideReturns, targets=None,\n",
    "    sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "    batch_size=128,  shuffle=False, \n",
    "    start_index=startOfSplit, end_index=endOfSplit)\n",
    "\n",
    "for batch in dataset:\n",
    "  data = batch\n",
    "  #assert np.array_equal(inputs[0], wideReturns[:sample_length])\n",
    "  # second sample equals output timestamps 20-40\n",
    "  #assert np.array_equal(targets[1], wideReturns[sample_length:2*sample_length])\n",
    "  break\n",
    "\n",
    "print(data.shape)\n",
    "# print(dataset.cardinality())\n",
    "# print(dataset.cache())\n",
    "\n",
    "# xTrain = wideReturns.iloc[:(trainSize-sample_length),:]\n",
    "# yTrain = wideReturns.iloc[sample_length:trainSize,:]\n",
    "\n",
    "# xVal = wideReturns.iloc[(trainSize-sample_length):(validationSize-sample_length),:]\n",
    "# yVal = wideReturns.iloc[trainSize:validationSize,:]\n",
    "\n",
    "# xTest = wideReturns.iloc[validationSize-sample_length:-sample_length,:]\n",
    "# yTest = wideReturns.iloc[validationSize:,:]\n",
    "\n",
    "# xTrainReshaped = np.reshape(xTrain.to_numpy(), (-1, 1), order=\"F\")\n",
    "# yTrainReshaped = np.reshape(yTrain.to_numpy(), (-1, 1), order=\"F\")\n",
    "# xValReshaped = np.reshape(xVal.to_numpy(), (-1, 1), order=\"F\")\n",
    "# yValReshaped = np.reshape(yVal.to_numpy(), (-1, 1), order=\"F\")\n",
    "# xTestReshaped = np.reshape(xTest.to_numpy(), (-1, 1), order=\"F\")\n",
    "# yTestReshaped = np.reshape(yTest.to_numpy(), (-1, 1), order=\"F\")\n",
    "\n",
    "\n",
    "#[lags of YearQuarter, YearQuarter, gvkey] => [Batch, YearQuarter, None]\n",
    "reshapedData = np.transpose(a=data, axes=(2, 0, 1))\n",
    "reshapedData = np.reshape(reshapedData, (-1, sample_length))\n",
    "reshapedData = reshapedData[~np.isnan(reshapedData).any(axis=1),:]\n",
    "reshapedData = np.expand_dims(reshapedData, axis=2)\n",
    "#return reshapedData\n",
    "\n",
    "#scaledData = normlayer(reshapedData)\n",
    "\n",
    "# train = preprocessData(None, trainSize)\n",
    "# val = preprocessData(trainSize, validationSize)\n",
    "# test = preprocessData(validationSize, None)\n",
    "\n",
    "# xTrain, xVal, xTest = train[:,:-1,:], val[:,:-1,:], test[:,:-1,:]\n",
    "# yTrain, yVal, yTest = train[:,-1,:], val[:,-1,:], test[:,-1,:]\n",
    "\n",
    "normlayer = tf.keras.layers.Normalization(axis=None)\n",
    "#normlayer.adapt(xTrain[:,0,:])\n",
    "normlayer.adapt(wideReturns[trainSize,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.iloc[:(trainSize-sample_length),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length=10\n",
    "dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data=wideReturns.iloc[:-sample_length,:], targets=wideReturns.iloc[sample_length:, :],\n",
    "    sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "    batch_size=8,  shuffle=False, \n",
    "    start_index=None, end_index=None)\n",
    "\n",
    "for batch in dataset:\n",
    "    data, dataY = batch\n",
    "    #assert np.array_equal(inputs[0], wideReturns[:sample_length])\n",
    "    # second sample equals output timestamps 20-40\n",
    "    #assert np.array_equal(targets[1], wideReturns[sample_length:2*sample_length])\n",
    "    break\n",
    "\n",
    "trainSize = math.floor(data.shape[0] * 0.5)\n",
    "validationSize = math.floor(data.shape[0] * 0.75)\n",
    "\n",
    "xTrain, xVal, xTest = data[:trainSize,:-1,:], data[trainSize:validationSize,:-1,:], data[validationSize:,:-1,:]\n",
    "yTrain, yVal, yTest = data[:trainSize,-1,:], data[trainSize:validationSize,-1,:], data[validationSize:,-1,:]\n",
    "\n",
    "normlayer = tf.keras.layers.Normalization(axis=None)\n",
    "normlayer.adapt(xTrain[:,0,:])\n",
    "#normlayer.adapt(wideReturns.iloc[:trainSize,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=wideReturns.iloc[:-sample_length,:]\n",
    "b=wideReturns.iloc[sample_length:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainSize = math.floor(len(wideReturns.index) * 0.5)\n",
    "validationSize = math.floor(len(wideReturns.index) * 0.75)\n",
    "testSize = len(wideReturns.index)\n",
    "\n",
    "xTrain = wideReturns.iloc[:(trainSize-sample_length),:]\n",
    "yTrain = wideReturns.iloc[sample_length:trainSize,:]\n",
    "\n",
    "xVal = wideReturns.iloc[(trainSize-sample_length):(validationSize-sample_length),:]\n",
    "yVal = wideReturns.iloc[trainSize:validationSize,:]\n",
    "\n",
    "xTest = wideReturns.iloc[validationSize-sample_length:-sample_length,:]\n",
    "yTest = wideReturns.iloc[validationSize:,:]\n",
    "\n",
    "xTrainReshaped = np.reshape(xTrain.to_numpy(), (-1, 1), order=\"F\")\n",
    "yTrainReshaped = np.reshape(yTrain.to_numpy(), (-1, 1), order=\"F\")\n",
    "xValReshaped = np.reshape(xVal.to_numpy(), (-1, 1), order=\"F\")\n",
    "yValReshaped = np.reshape(yVal.to_numpy(), (-1, 1), order=\"F\")\n",
    "xTestReshaped = np.reshape(xTest.to_numpy(), (-1, 1), order=\"F\")\n",
    "yTestReshaped = np.reshape(yTest.to_numpy(), (-1, 1), order=\"F\")\n",
    "\n",
    "batch_size=1\n",
    "\n",
    "train = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data=xTrainReshaped, targets=yTrainReshaped,\n",
    "    sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "    batch_size=batch_size,  shuffle=False)\n",
    "validation = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data=xValReshaped, targets=yValReshaped,\n",
    "    sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "    batch_size=batch_size,  shuffle=False)\n",
    "test = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data=xTestReshaped, targets=yTestReshaped,\n",
    "    sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "    batch_size=batch_size,  shuffle=False)\n",
    "\n",
    "\n",
    "# train = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "#     data=xTrainReshaped, targets=yTrainReshaped,\n",
    "#     sequence_length=trainSize, sequence_stride=sample_length, sampling_rate=1,\n",
    "#     batch_size=batch_size,  shuffle=False)\n",
    "# validation = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "#     data=xValReshaped, targets=yValReshaped,\n",
    "#     sequence_length=validationSize-trainSize, sequence_stride=sample_length, sampling_rate=1,\n",
    "#     batch_size=batch_size,  shuffle=False)\n",
    "# test = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "#     data=xTestReshaped, targets=yTestReshaped,\n",
    "#     sequence_length=testSize-validationSize, sequence_stride=sample_length, sampling_rate=1,\n",
    "#     batch_size=batch_size,  shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = wideReturns.iloc[...,:15]\n",
    "b = list(train.take(10).as_numpy_iterator())\n",
    "#c = train.as_numpy_iterator()#[...,:10]\n",
    "list(train.take(1).as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wideReturns.head()\n",
    "#a = wideReturns.iloc[:10, :10]\n",
    "\n",
    "wideReturns.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(normlayer)\n",
    "model.add(tf.keras.layers.LSTM(units=5)) #, input_shape=(,sample_length-1)   #mask\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", #tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "              loss=\"MeanAbsoluteError\",\n",
    "              metrics=[tf.keras.losses.MeanSquaredError(), tf.keras.losses.MeanAbsoluteError()])\n",
    "\n",
    "#model.fit(x=xTrain, y=yTrain, batch_size=32, validation_data=(xVal, yVal))\n",
    "model.fit(x=dataset, batch_size=8)#, validation_data=(xVal, yVal))\n",
    "\n",
    "# class MyHyperModel(kt.HyperModel):\n",
    "#     def build(self, hp):\n",
    "#         model = Sequential()\n",
    "#         model.add(tf.keras.layers.LSTM(units=hp.Int(\"units\", min_value=32, max_value=512, step=32), input_shape=(sample_length-1,)))\n",
    "#         model.add(Dense(units=1))\n",
    "\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=hp.Int(\"learning_rate\", [16, 32])),\n",
    "#                   loss=\"MeanAbsoluteError\",\n",
    "#                   metrics=[tf.keras.losses.MeanSquaredError(), tf.keras.losses.MeanAbsoluteError()])\n",
    "#         return model\n",
    "\n",
    "#     def fit(self, hp, model, *args, **kwargs):\n",
    "#         return model.fit(\n",
    "#             *args,\n",
    "#             batch_size=hp.Choice(\"batch_size\", [16, 32]),\n",
    "#             **kwargs,\n",
    "#         )\n",
    "\n",
    "# tuner = kt.RandomSearch(\n",
    "#     MyHyperModel(),\n",
    "#     objective=\"val_accuracy\",\n",
    "#     max_trials=3,\n",
    "#     overwrite=True,\n",
    "#     directory=\"my_dir\",\n",
    "#     project_name=\"tune_hypermodel\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6646144ec7618d86cefdfa307b5e5ba5f5893ee78adb19daf28ba13bcfecfb8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
