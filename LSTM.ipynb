{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 10, 9668)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Dense, Flatten\n",
    "import tensorflow.python.keras.optimizers\n",
    "import tensorflow.python.keras.metrics\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "#%%capture\n",
    "data_file_path = os.path.join(os.getcwd(), \"Data\\\\returnsData.csv\")\n",
    "returnsData = pd.read_csv(data_file_path)\n",
    "#returnsData.info(verbose=True)\n",
    "longReturns = returnsData[[\"YearQuarter\", \"gvkey\", \"quarterlyReturns\"]] #\"quarterlyVolatility\",\n",
    "#longReturns.info(verbose=True)\n",
    "wideReturns = pd.pivot(longReturns, index=\"YearQuarter\", columns=\"gvkey\", values=\"quarterlyReturns\")\n",
    "#wideReturns.info(verbose=True)\n",
    "#print(wideReturns.iloc[0:10,0:10])\n",
    "\n",
    "#wideReturns[\"YearQuarter\"] = wideReturns.index\n",
    "#wideReturns[\"YQ\"] = wideReturns.index\n",
    "\n",
    "trainSize = math.floor(len(wideReturns.index) * 0.5)\n",
    "validationSize = math.floor(len(wideReturns.index) * 0.75)\n",
    "testSize = len(wideReturns.index)\n",
    "# trainSize = len(wideReturns[\"YearQuarter\"]) * 0.5\n",
    "# validationSize = len(wideReturns[\"YearQuarter\"]) * 0.75\n",
    "#wideReturns[:,\"Split\"] = \n",
    "\n",
    "# normlayer = tf.keras.layers.Normalization(axis=None)\n",
    "# #normlayer.adapt(xTrain[:,0,:])\n",
    "# normlayer.adapt(wideReturns[trainSize, :])\n",
    "\n",
    "\n",
    "sample_length = 10\n",
    "dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data=wideReturns, targets=None,\n",
    "    sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "    batch_size=128,  shuffle=False, \n",
    "    start_index=None, end_index=None)\n",
    "\n",
    "for batch in dataset:\n",
    "  data = batch\n",
    "  #assert np.array_equal(inputs[0], wideReturns[:sample_length])\n",
    "  # second sample equals output timestamps 20-40\n",
    "  #assert np.array_equal(targets[1], wideReturns[sample_length:2*sample_length])\n",
    "  break\n",
    "\n",
    "print(data.shape)\n",
    "# print(dataset.cardinality())\n",
    "# print(dataset.cache())\n",
    "\n",
    "#data = data[~np.isnan(data).any(axis=2),:]\n",
    "trainSize = math.floor(data.shape[0] * 0.5)\n",
    "validationSize = math.floor(data.shape[0] * 0.75)\n",
    "testSize = data.shape[0]\n",
    "\n",
    "# xTrain = data[:(trainSize-sample_length), :-1, :]\n",
    "# yTrain = data[sample_length:trainSize, -1, :]\n",
    "\n",
    "# xVal = data[(trainSize-sample_length):(validationSize-sample_length), :-1, :]\n",
    "# yVal = data[trainSize:validationSize, -1, :]\n",
    "\n",
    "# xTest = data[validationSize-sample_length:-sample_length, :-1, :]\n",
    "# yTest = data[validationSize:, -1, :]\n",
    "\n",
    "# xTrain = data[:trainSize, :-1, :]\n",
    "# yTrain = data[:trainSize, -1, :]\n",
    "\n",
    "# xVal = data[trainSize:validationSize, :-1, :]\n",
    "# yVal = data[trainSize:validationSize, -1, :]\n",
    "\n",
    "# xTest = data[validationSize:, :-1, :]\n",
    "# yTest = data[validationSize:, -1, :]\n",
    "\n",
    "# yTrain = np.expand_dims(yTrain, axis=1)\n",
    "# yVal = np.expand_dims(yVal, axis=1)\n",
    "# yTest = np.expand_dims(yTest, axis=1)\n",
    "\n",
    "train = data[:trainSize, :, :]\n",
    "validation = data[trainSize:validationSize, :, :]\n",
    "test = data[validationSize:, :, :]\n",
    "\n",
    "def preprocessData(rawData):\n",
    "  #[lags of YearQuarter, YearQuarter, gvkey] => [Batch, YearQuarter, None]\n",
    "  reshapedData = np.transpose(a=rawData, axes=(2, 0, 1))\n",
    "  reshapedData = np.reshape(reshapedData, (-1, rawData.shape[1]))\n",
    "  reshapedData = reshapedData[~np.isnan(reshapedData).any(axis=1),:]\n",
    "  reshapedData = np.expand_dims(reshapedData, axis=2)\n",
    "  return reshapedData\n",
    "\n",
    "# xTrainReshaped = preprocessData(xTrain)\n",
    "# yTrainReshaped = preprocessData(yTrain)\n",
    "# xValReshaped = preprocessData(xVal)\n",
    "# yValReshaped = preprocessData(yVal)\n",
    "# xTestReshaped = preprocessData(xTest)\n",
    "# yTestReshaped = preprocessData(yTest)\n",
    "\n",
    "train = preprocessData(train)\n",
    "validation = preprocessData(validation)\n",
    "test = preprocessData(test)\n",
    "\n",
    "xTrain, yTrain = train[:, :-1, :], train[:, -1, :]\n",
    "xVal, yVal = validation[:, :-1, :], validation[:, -1, :]\n",
    "xTest, yTest = test[:, :-1, :], test[:, -1, :]\n",
    "\n",
    "# train = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "#     data=xTrainReshaped, targets=yTrainReshaped,\n",
    "#     sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "#     batch_size=batch_size,  shuffle=False)\n",
    "# validation = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "#     data=xValReshaped, targets=yValReshaped,\n",
    "#     sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "#     batch_size=batch_size,  shuffle=False)\n",
    "# test = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "#     data=xTestReshaped, targets=yTestReshaped,\n",
    "#     sequence_length=sample_length, sequence_stride=1, sampling_rate=1,\n",
    "#     batch_size=batch_size,  shuffle=False)\n",
    "\n",
    "#scaledData = normlayer(reshapedData)\n",
    "\n",
    "# train = preprocessData(None, trainSize)\n",
    "# val = preprocessData(trainSize, validationSize)\n",
    "# test = preprocessData(validationSize, None)\n",
    "\n",
    "# xTrain, xVal, xTest = train[:,:-1,:], val[:,:-1,:], test[:,:-1,:]\n",
    "# yTrain, yVal, yTest = train[:,-1,:], val[:,-1,:], test[:,-1,:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 460/4465 [==>...........................] - ETA: 29s - loss: 15.4126 - mean_squared_error: 707.0060 - mean_absolute_error: 15.4126"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m#tf.keras.optimizers.Adam(learning_rate=0.001)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMeanAbsoluteError\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m               metrics\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError(), tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanAbsoluteError()])\n\u001b[0;32m     10\u001b[0m \u001b[39m#model.fit(x=xTrain, y=yTrain, batch_size=32, validation_data=(xVal, yVal))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m#model.fit(x=dataset, batch_size=8)#, validation_data=(xVal, yVal))\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mxTrain, y\u001b[39m=\u001b[39;49myTrain, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(xVal, yVal))\n\u001b[0;32m     14\u001b[0m \u001b[39m# class MyHyperModel(kt.HyperModel):\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m#     def build(self, hp):\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m#         model = Sequential()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m#     project_name=\"tune_hypermodel\",\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# )\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RobinForMLThesis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1181\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1182\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1183\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1184\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1185\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1186\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1187\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1188\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1189\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\RobinForMLThesis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\RobinForMLThesis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\RobinForMLThesis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\RobinForMLThesis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\RobinForMLThesis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\RobinForMLThesis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\RobinForMLThesis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(normlayer)\n",
    "model.add(tf.keras.layers.LSTM(units=5)) #, input_shape=(,sample_length-1)   #mask\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", #tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "              loss=\"MeanAbsoluteError\",\n",
    "              metrics=[tf.keras.losses.MeanSquaredError(), tf.keras.losses.MeanAbsoluteError()])\n",
    "\n",
    "#model.fit(x=xTrain, y=yTrain, batch_size=32, validation_data=(xVal, yVal))\n",
    "#model.fit(x=dataset, batch_size=8)#, validation_data=(xVal, yVal))\n",
    "model.fit(x=xTrain, y=yTrain, batch_size=32, validation_data=(xVal, yVal))\n",
    "\n",
    "# class MyHyperModel(kt.HyperModel):\n",
    "#     def build(self, hp):\n",
    "#         model = Sequential()\n",
    "#         model.add(tf.keras.layers.LSTM(units=hp.Int(\"units\", min_value=32, max_value=512, step=32), input_shape=(sample_length-1,)))\n",
    "#         model.add(Dense(units=1))\n",
    "\n",
    "#         model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=hp.Int(\"learning_rate\", [16, 32])),\n",
    "#                   loss=\"MeanAbsoluteError\",\n",
    "#                   metrics=[tf.keras.losses.MeanSquaredError(), tf.keras.losses.MeanAbsoluteError()])\n",
    "#         return model\n",
    "\n",
    "#     def fit(self, hp, model, *args, **kwargs):\n",
    "#         return model.fit(\n",
    "#             *args,\n",
    "#             batch_size=hp.Choice(\"batch_size\", [16, 32]),\n",
    "#             **kwargs,\n",
    "#         )\n",
    "\n",
    "# tuner = kt.RandomSearch(\n",
    "#     MyHyperModel(),\n",
    "#     objective=\"val_accuracy\",\n",
    "#     max_trials=3,\n",
    "#     overwrite=True,\n",
    "#     directory=\"my_dir\",\n",
    "#     project_name=\"tune_hypermodel\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6646144ec7618d86cefdfa307b5e5ba5f5893ee78adb19daf28ba13bcfecfb8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
